{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shiyi/miniconda3/envs/kaggle/lib/python3.11/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/home/shiyi/miniconda3/envs/kaggle/lib/python3.11/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "from engine_hms_model import CustomDataset, JobConfig, ModelConfig, CustomVITMAE\n",
    "from engine_hms_trainer import load_kaggle_data, TARGETS, TARGETS_PRED, BRAIN_ACTIVITY, DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_easy, train_hard, all_specs, all_eegs = load_kaggle_data(JobConfig.PATHS, JobConfig.ENTROPY_SPLIT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_mae_input(x): #<- (N, C, H, W)\n",
    "    x = torch.stack(x, dim=0)\n",
    "    concat_p1 = torch.cat(torch.chunk(x[:, :4, :, :], 4, dim=1), dim=2)\n",
    "    concat_p2 = torch.cat(torch.chunk(x[:, 4:, :, :], 4, dim=1), dim=2)\n",
    "    x_concat = torch.cat((concat_p1, concat_p2), dim=3)\n",
    "   \n",
    "    resized = F.interpolate(x_concat, size=(224, 224), mode='bilinear', align_corners=False)\n",
    "    stacked = resized.repeat(1, 3, 1, 1)\n",
    "    \n",
    "    return stacked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 6])\n"
     ]
    }
   ],
   "source": [
    "# Instantiate your model\n",
    "\n",
    "ModelConfig.MAE_HIDDEN_DROPOUT_PROB = 0.1\n",
    "ModelConfig.MAE_ATTENTION_DROPOUT_PROB = 0.1\n",
    "\n",
    "model = CustomVITMAE(ModelConfig)\n",
    "\n",
    "train_dataset = CustomDataset(train_easy, TARGETS, ModelConfig, all_specs, all_eegs)\n",
    "\n",
    "# Test the model with a single batch\n",
    "X, y = train_dataset[0]\n",
    "logits = model(X.unsqueeze(0))\n",
    "print(logits.shape)  # Expected to be [batch_size, num_classes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
