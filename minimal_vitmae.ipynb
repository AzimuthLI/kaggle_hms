{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from transformers import AutoImageProcessor, ViTMAEConfig, ViTMAEModel, ViTMAEForPreTraining\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "from engine_hms_model import CustomDataset, JobConfig, ModelConfig \n",
    "from engine_hms_trainer import load_kaggle_data, TARGETS, TARGETS_PRED, BRAIN_ACTIVITY, DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(TARGETS)\n",
    "print(TARGETS_PRED)\n",
    "print(BRAIN_ACTIVITY)\n",
    "print(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_easy, train_hard, all_specs, all_eegs = load_kaggle_data(JobConfig.PATHS, JobConfig.ENTROPY_SPLIT)\n",
    "\n",
    "my_dataset = CustomDataset(\n",
    "            train_easy, TARGETS, ModelConfig, all_specs, all_eegs, mode=\"train\")\n",
    "\n",
    "X, y = my_dataset[0]\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomMAE(nn.Module):\n",
    "    def __init__(self, backbone=\"\", num_classes=6, mlp_hidden_size=512, mae_dropout=0.05, mae_attention_dropout=0.05):\n",
    "        super(CustomMAE, self).__init__()\n",
    "\n",
    "        mae_config = ViTMAEConfig()\n",
    "        mae_config.hidden_dropout_prob = mae_dropout\n",
    "        mae_config.attention_probs_dropout_prob = mae_attention_dropout\n",
    "\n",
    "        self.pre_processor = AutoImageProcessor.from_pretrained(backbone)\n",
    "        self.vitmae = ViTMAEModel(mae_config).from_pretrained(backbone)\n",
    "        self.mlp_head = nn.Sequential(\n",
    "            nn.Linear(self.vitmae.config.hidden_size, mlp_hidden_size),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(mlp_hidden_size, num_classes)\n",
    "        )\n",
    "    \n",
    "    def __reshape_input(self, x):\n",
    "        # Split the input into two halves\n",
    "        # Concatenate each half along the height dimension\n",
    "        concat_1 = torch.cat(torch.chunk(x[:, :4, :, :], 4, dim=1), dim=2)\n",
    "        concat_2 = torch.cat(torch.chunk(x[:, 4:, :, :], 4, dim=1), dim=2)\n",
    "        # Concatenate the two parts along the width dimension\n",
    "        concatenated = torch.cat((concat_1, concat_2), dim=3)\n",
    "        # Stack to get 3 channels and resize\n",
    "        stacked = concatenated.repeat(1, 3, 1, 1)  # Replicate the single channel to get 3 channels\n",
    "        resized = F.interpolate(stacked, size=(224, 224), mode='bilinear', align_corners=False)\n",
    "        return resized\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.__reshape_input(x)\n",
    "        input_data = self.pre_processor(images=x, return_tensors=\"pt\", padding=True)\n",
    "        outputs = self.vitmae(**input_data)\n",
    "        last_hidden_state = outputs.last_hidden_state\n",
    "        logits = self.mlp_head(last_hidden_state[:, 0])\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CustomMAE(backbone='ModelConfig.BACKBONE', num_classes=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
