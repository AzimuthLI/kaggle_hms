{"cells":[{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Standard library imports\n","import os\n","import multiprocessing\n","import gc\n","import random\n","import time\n","import math\n","\n","# Third-party library imports\n","# import albumentations as A\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import pandas as pd\n","from glob import glob\n","from tqdm import tqdm\n","from typing import Dict, List\n","\n","# PyTorch imports\n","import torch\n","import torch.nn as nn\n","import timm\n","from torch.utils.data import DataLoader, Dataset\n","\n","\n","def select_device():\n","    if torch.cuda.is_available():\n","        os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1\"\n","        return torch.device(\"cuda:0\")\n","    else:\n","        return torch.device(\"cpu\")\n","\n","device = select_device()\n","print('Using', torch.cuda.device_count(), 'GPU(s)')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(DEVICE)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-03T10:47:39.991178Z","iopub.status.busy":"2024-03-03T10:47:39.990103Z","iopub.status.idle":"2024-03-03T10:47:39.997647Z","shell.execute_reply":"2024-03-03T10:47:39.996696Z","shell.execute_reply.started":"2024-03-03T10:47:39.991145Z"},"papermill":{"duration":0.016556,"end_time":"2024-01-14T22:51:51.671783","exception":false,"start_time":"2024-01-14T22:51:51.655227","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["class config:\n","    AMP = True\n","    BATCH_SIZE = 32\n","    EPOCHS = 6\n","    FOLDS = 5\n","    FREEZE = False\n","    GRADIENT_ACCUMULATION_STEPS = 1\n","    MAX_GRAD_NORM = 1e7\n","    MODEL = \"tf_efficientnet_b2\" #\"tf_efficientnet_b0\"\n","    NUM_FROZEN_LAYERS = 39\n","    NUM_WORKERS = 0 # multiprocessing.cpu_count()\n","    PRINT_FREQ = 50\n","    SEED = 20\n","    TRAIN_FULL_DATA = False\n","    VISUALIZE = True\n","    WEIGHT_DECAY = 0.01\n","    DATA_ARRANGE = 0\n","    \n","\n","from config_model import ModelConfig, KagglePaths, LocalPaths\n","paths = LocalPaths\n","\n","# class paths:\n","#     OUTPUT_DIR = \"/kaggle/working/\"\n","#     PRE_LOADED_EEGS = '/kaggle/input/brain-eeg-spectrograms/eeg_specs.npy'\n","#     PRE_LOADED_SPECTOGRAMS = '/kaggle/input/brain-spectrograms/specs.npy'\n","#     TRAIN_CSV = \"/kaggle/input/hms-harmful-brain-activity-classification/train.csv\"\n","#     TRAIN_EEGS = \"/kaggle/input/brain-eeg-spectrograms/EEG_Spectrograms/\"\n","#     TRAIN_SPECTOGRAMS = \"/kaggle/input/hms-harmful-brain-activity-classification/train_spectrograms/\"\n","#     TEST_CSV = \"/kaggle/input/hms-harmful-brain-activity-classification/test.csv\"\n","#     TEST_SPECTROGRAMS = \"/kaggle/input/hms-harmful-brain-activity-classification/test_spectrograms/\"\n","#     TEST_EEGS = \"/kaggle/input/hms-harmful-brain-activity-classification/test_eegs/\""]},{"cell_type":"markdown","metadata":{},"source":["# <b><span style='color:#F1A424'>|</span> Utils</b><a class='anchor' id='utils'></a> [↑](#top) "]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2024-03-03T10:47:41.352574Z","iopub.status.busy":"2024-03-03T10:47:41.351649Z","iopub.status.idle":"2024-03-03T10:47:41.376719Z","shell.execute_reply":"2024-03-03T10:47:41.375846Z","shell.execute_reply.started":"2024-03-03T10:47:41.352516Z"},"trusted":true},"outputs":[],"source":["class AverageMeter(object):\n","    \"\"\"Computes and stores the average and current value\"\"\"\n","    def __init__(self):\n","        self.reset()\n","\n","    def reset(self):\n","        self.val = 0\n","        self.avg = 0\n","        self.sum = 0\n","        self.count = 0\n","\n","    def update(self, val, n=1):\n","        self.val = val\n","        self.sum += val * n\n","        self.count += n\n","        self.avg = self.sum / self.count\n","\n","\n","def asMinutes(s: float):\n","    \"Convert to minutes.\"\n","    m = math.floor(s / 60)\n","    s -= m * 60\n","    return '%dm %ds' % (m, s)\n","\n","\n","def timeSince(since: float, percent: float):\n","    now = time.time()\n","    s = now - since\n","    es = s / (percent)\n","    rs = es - s\n","    return '%s (remain %s)' % (asMinutes(s), asMinutes(rs))\n","\n","\n","def get_logger(filename=paths.OUTPUT_DIR):\n","    from logging import getLogger, INFO, StreamHandler, FileHandler, Formatter\n","    logger = getLogger(__name__)\n","    logger.setLevel(INFO)\n","    handler1 = StreamHandler()\n","    handler1.setFormatter(Formatter(\"%(message)s\"))\n","    logger.addHandler(handler1)\n","\n","    # handler2 = FileHandler(filename=f\"{filename}.log\")\n","    # handler2.setFormatter(Formatter(\"%(message)s\"))\n","    # logger.addHandler(handler2)\n","    return logger\n","\n","\n","def plot_spectrogram(spectrogram_path: str):\n","    \"\"\"\n","    Source: https://www.kaggle.com/code/mvvppp/hms-eda-and-domain-journey\n","    Visualize spectogram recordings from a parquet file.\n","    :param spectrogram_path: path to the spectogram parquet.\n","    \"\"\"\n","    sample_spect = pd.read_parquet(spectrogram_path)\n","    \n","    split_spect = {\n","        \"LL\": sample_spect.filter(regex='^LL', axis=1),\n","        \"RL\": sample_spect.filter(regex='^RL', axis=1),\n","        \"RP\": sample_spect.filter(regex='^RP', axis=1),\n","        \"LP\": sample_spect.filter(regex='^LP', axis=1),\n","    }\n","    \n","    fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(12, 8))\n","    axes = axes.flatten()\n","    label_interval = 5\n","    for i, split_name in enumerate(split_spect.keys()):\n","        ax = axes[i]\n","        img = ax.imshow(np.log(split_spect[split_name]).T, cmap='viridis', aspect='auto', origin='lower')\n","        cbar = fig.colorbar(img, ax=ax)\n","        cbar.set_label('Log(Value)')\n","        ax.set_title(split_name)\n","        ax.set_ylabel(\"Frequency (Hz)\")\n","        ax.set_xlabel(\"Time\")\n","\n","        ax.set_yticks(np.arange(len(split_spect[split_name].columns)))\n","        ax.set_yticklabels([column_name[3:] for column_name in split_spect[split_name].columns])\n","        frequencies = [column_name[3:] for column_name in split_spect[split_name].columns]\n","        ax.set_yticks(np.arange(0, len(split_spect[split_name].columns), label_interval))\n","        ax.set_yticklabels(frequencies[::label_interval])\n","    plt.tight_layout()\n","    plt.show()\n","    \n","    \n","def seed_everything(seed: int):\n","    random.seed(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed) \n","\n","    \n","def sep():\n","    print(\"-\"*100)\n","    \n","\n","target_preds = [x + \"_pred\" for x in ['seizure_vote', 'lpd_vote', 'gpd_vote', 'lrda_vote', 'grda_vote', 'other_vote']]\n","label_to_num = {'Seizure': 0, 'LPD': 1, 'GPD': 2, 'LRDA': 3, 'GRDA': 4, 'Other':5}\n","num_to_label = {v: k for k, v in label_to_num.items()}\n","LOGGER = get_logger()\n","seed_everything(config.SEED)"]},{"cell_type":"markdown","metadata":{},"source":["# <b><span style='color:#F1A424'>|</span> Load Data \\& Preprocess</b><a class='anchor' id='load_data'></a> [↑](#top) \n","\n","The competition data description says that test data does not have multiple crops from the same `eeg_id`. Therefore we will train and validate using only 1 crop per `eeg_id`. There is a discussion about this [here][1].\n","\n","[1]: https://www.kaggle.com/competitions/hms-harmful-brain-activity-classification/discussion/467021"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-03T10:47:41.991031Z","iopub.status.busy":"2024-03-03T10:47:41.990339Z","iopub.status.idle":"2024-03-03T10:47:41.998069Z","shell.execute_reply":"2024-03-03T10:47:41.997101Z","shell.execute_reply.started":"2024-03-03T10:47:41.991001Z"},"trusted":true},"outputs":[],"source":["def get_non_overlap(df_csv, targets):\n","    # Reference Discussion:\n","    # https://www.kaggle.com/competitions/hms-harmful-brain-activity-classification/discussion/467021\n","\n","    # train and validate using only 1 crop per eeg_id\n","    # same results as Chris's notebook\n","\n","    tgt_list = targets.tolist()\n","\n","    agg_dict = {\n","        'spectrogram_id': 'first',\n","        'spectrogram_label_offset_seconds': ['min', 'max'],\n","        'patient_id': 'first',\n","    }\n","\n","    for t in tgt_list:\n","        agg_dict[t] = 'sum'\n","\n","    agg_dict['expert_consensus'] = 'first'\n","\n","    train = df_csv.groupby('eeg_id').agg(agg_dict)\n","    train.columns = ['_'.join(col).strip() for col in train.columns.values]\n","    train.columns = ['spectrogram_id', 'min', 'max', 'patient_id'] + tgt_list + ['target']\n","    train = train.reset_index(drop=False)\n","\n","    train[tgt_list] = train[tgt_list].div(train[tgt_list].sum(axis=1), axis='index')\n","\n","    return train"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["x = np.random.rand(4, 512, 512)\n","np.stack([x,x,x], axis=0).shape"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-03-03T10:47:42.354091Z","iopub.status.busy":"2024-03-03T10:47:42.353736Z","iopub.status.idle":"2024-03-03T10:47:42.647669Z","shell.execute_reply":"2024-03-03T10:47:42.646785Z","shell.execute_reply.started":"2024-03-03T10:47:42.354063Z"},"papermill":{"duration":0.288611,"end_time":"2024-01-14T22:51:51.984993","exception":false,"start_time":"2024-01-14T22:51:51.696382","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["os.chdir(\"../\")\n","\n","df = pd.read_csv(paths.TRAIN_CSV)\n","label_cols = df.columns[-6:]\n","print(f\"Train cataframe shape is: {df.shape}\")\n","print(f\"Labels: {list(label_cols)}\")\n","\n","df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-03T10:47:42.649628Z","iopub.status.busy":"2024-03-03T10:47:42.649325Z","iopub.status.idle":"2024-03-03T10:47:42.723413Z","shell.execute_reply":"2024-03-03T10:47:42.722439Z","shell.execute_reply.started":"2024-03-03T10:47:42.649604Z"},"trusted":true},"outputs":[],"source":["train_df = get_non_overlap(df, label_cols)\n","\n","train_df.head()"]},{"cell_type":"markdown","metadata":{},"source":["# <b><span style='color:#F1A424'>|</span> Dataset</b><a class='anchor' id='dataset'></a> [↑](#top) \n","\n","***\n","\n","Create a custom `Dataset` to load data.\n","\n","Our dataloader outputs both Kaggle spectrograms and EEG spectrogams as 8 channel image of size `(128, 256, 8)`\n","\n","[1]: https://www.kaggle.com/code/cdeotte/efficientnetb0-starter-lb-0-43/comments#2617811"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-03T10:47:43.458269Z","iopub.status.busy":"2024-03-03T10:47:43.457869Z","iopub.status.idle":"2024-03-03T10:47:43.473571Z","shell.execute_reply":"2024-03-03T10:47:43.472587Z","shell.execute_reply.started":"2024-03-03T10:47:43.458239Z"},"trusted":true},"outputs":[],"source":["class CustomDataset(Dataset):\n","    def __init__(\n","        self, \n","        df: pd.DataFrame, \n","        config,\n","        specs: Dict[int, np.ndarray],\n","        eeg_specs: Dict[int, np.ndarray],\n","        augment: bool = False,\n","        mode: str = 'train',\n","    ): \n","        self.df = df\n","        self.config = config\n","        self.batch_size = self.config.BATCH_SIZE\n","        self.augment = augment\n","        self.mode = mode\n","        self.spectograms = specs\n","        self.eeg_spectograms = eeg_specs\n","        \n","    def __len__(self):\n","        \"\"\"\n","        Denotes the number of batches per epoch.\n","        \"\"\"\n","        return len(self.df)\n","        \n","    def __getitem__(self, index):\n","        \"\"\"\n","        Generate one batch of data.\n","        \"\"\"\n","        X, y = self.__data_generation(index)\n","        if self.augment:\n","            X = self.__transform(X) \n","        return torch.tensor(X, dtype=torch.float32), torch.tensor(y, dtype=torch.float32)\n","                        \n","    def __data_generation(self, index):\n","        \"\"\"\n","        Generates data containing batch_size samples.\n","        \"\"\"\n","        X = np.zeros((128, 256, 8), dtype='float32')\n","        y = np.zeros(6, dtype='float32')\n","        img = np.ones((128,256), dtype='float32')\n","        row = self.df.iloc[index]\n","        \n","        if self.mode=='test': \n","            r = 0\n","        else: \n","            r = int((row['min'] + row['max']) // 4)\n","            \n","        for region in range(4): #spectrogram_id\n","            img = self.spectograms[row['spectrogram_id']][r:r+300, region*100:(region+1)*100].T\n","            \n","            # Log transform spectogram\n","            img = np.clip(img, np.exp(-4), np.exp(8))\n","            img = np.log(img)\n","\n","            # Standarize per image\n","            ep = 1e-6\n","            mu = np.nanmean(img.flatten())\n","            std = np.nanstd(img.flatten())\n","            img = (img-mu)/(std+ep)\n","            img = np.nan_to_num(img, nan=0.0)\n","            X[14:-14, :, region] = img[:, 22:-22] / 2.0\n","            img = self.eeg_spectograms[row.eeg_id]\n","            X[:, :, 4:] = img\n","                \n","            if self.mode != 'test':\n","                y = row[label_cols].values.astype(np.float32)\n","            \n","        return X, y\n","    \n","    def __transform(self, img):\n","        transforms = A.Compose([\n","            A.HorizontalFlip(p=0.5),\n","        ])\n","        return transforms(image=img)['image']"]},{"cell_type":"markdown","metadata":{},"source":["# <b><span style='color:#F1A424'>|</span> Model</b><a class='anchor' id='model'></a> [↑](#top) \n","\n","***\n","\n","We will be using the [timm](https://github.com/huggingface/pytorch-image-models) library for our models.\n","\n","Our models receives both Kaggle spectrograms and EEG spectrograms from our data loader. We then reshape these 8 spectrograms into 1 large flat image and feed it into EfficientNet."]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2024-03-03T10:47:43.813993Z","iopub.status.busy":"2024-03-03T10:47:43.813191Z","iopub.status.idle":"2024-03-03T10:47:43.824418Z","shell.execute_reply":"2024-03-03T10:47:43.823487Z","shell.execute_reply.started":"2024-03-03T10:47:43.813962Z"},"trusted":true},"outputs":[],"source":["class CustomModel(nn.Module):\n","    def __init__(self, config, num_classes: int = 6, pretrained: bool = True):\n","        super(CustomModel, self).__init__()\n","        self.USE_KAGGLE_SPECTROGRAMS = True\n","        self.USE_EEG_SPECTROGRAMS = True\n","        self.model = timm.create_model(\n","            config.MODEL,\n","            pretrained=pretrained,\n","            drop_rate = 0.1,\n","            drop_path_rate = 0.2,\n","        )\n","        \n","        self.preprocess = torch.nn.Conv2d(4, 3, 1, bias=True)\n","        \n","        if config.FREEZE:\n","            for i,(name, param) in enumerate(list(self.model.named_parameters())\\\n","                                             [0:config.NUM_FROZEN_LAYERS]):\n","                param.requires_grad = False\n","\n","        self.features = nn.Sequential(*list(self.model.children())[:-2])\n","        self.custom_layers = nn.Sequential(\n","            nn.AdaptiveAvgPool2d(1),\n","            nn.Flatten(),\n","            nn.Linear(self.model.num_features, num_classes)\n","        )\n","\n","    def __reshape_input(self, x):\n","        # input size: [batch * 128 * 256 * 8]\n","        \n","        # --> 256*256*4\n","        spectograms = x[:, :, :, 0:4]  \n","        eegs = x[:, :, :, 4:8] \n","        x = torch.cat([spectograms, eegs], dim=1)\n","        x = x.permute(0, 3, 1, 2)\n","        \n","        ## --> 512*512*3\n","        # spectograms = torch.cat([x[:, :, :, i:i+1] for i in range(4)], dim=1) \n","        # eegs = torch.cat([x[:, :, :, i:i+1] for i in range(4,8)], dim=1)\n","        # x = torch.cat([spectograms, eegs], dim=2)\n","        # x = torch.cat([x, x, x], dim=3)\n","        # x = x.permute(0, 3, 1, 2)\n","        \n","        return x\n","    \n","    def forward(self, x):\n","        x = self.__reshape_input(x)\n","        x = self.preprocess(x)\n","        x = self.features(x)\n","        x = self.custom_layers(x)\n","        return x"]},{"cell_type":"markdown","metadata":{},"source":["# <b><span style='color:#F1A424'>|</span> Train </b><a class='anchor' id='load_data'></a> [↑](#top) "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-03T10:47:44.535558Z","iopub.status.busy":"2024-03-03T10:47:44.535156Z","iopub.status.idle":"2024-03-03T10:47:44.539836Z","shell.execute_reply":"2024-03-03T10:47:44.538811Z","shell.execute_reply.started":"2024-03-03T10:47:44.535517Z"},"trusted":true},"outputs":[],"source":["train_mode = True"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.00881,"end_time":"2024-01-14T22:51:52.142747","exception":false,"start_time":"2024-01-14T22:51:52.133937","status":"completed"},"tags":[]},"source":["### <b><span style='color:#F1A424'>Read Train Spectrograms</span></b>\n","\n","\n","First we need to read in all 11k train spectrogram files. Reading thousands of files takes 11 minutes with Pandas. Instead, we can read 1 file from my [Kaggle dataset here][1] which contains all the 11k spectrograms in less than 1 minute! To use my Kaggle dataset, set variable `READ_SPEC_FILES = False`. Thank you for upvoting my helpful [dataset][1] :-)\n","\n","The resulting `all_spectograms` dictionary contains `spectogram_id` as keys (`int` keys) and the values are the spectogram sequences (as 2-dimensional `np.array`) of shape `(timesteps, 400)`.\n","\n","Each spectogram is a parquet file. This parquet, when converted to a pandas dataframe, results in a dataframe of shape `(time_steps, 401)`. First column is the `time` column and the remaining 400 columns are the recordings. There are 400 columns because there are, respectively, 100 rows associated to the 4 recording regions of the EEG electrodes: `LL`, `RL`, `LP`, `RP`. Column names also include the frequency in heartz.\n","\n","[1]: https://www.kaggle.com/datasets/cdeotte/brain-spectrograms\n","\n","The resulting `all_eegs` dictionary contains `eeg_id` as keys (`int` keys) and the values are the eeg sequences (as 3-dimensional `np.array`) of shape `(128, 256, 4)`."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-03T10:47:45.184709Z","iopub.status.busy":"2024-03-03T10:47:45.184324Z","iopub.status.idle":"2024-03-03T10:49:52.455622Z","shell.execute_reply":"2024-03-03T10:49:52.454424Z","shell.execute_reply.started":"2024-03-03T10:47:45.184681Z"},"papermill":{"duration":55.16894,"end_time":"2024-01-14T22:52:47.320438","exception":false,"start_time":"2024-01-14T22:51:52.151498","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["%%time\n","\n","if train_mode:\n","\n","    READ_SPEC_FILES = False\n","    READ_EEG_SPEC_FILES = False\n","\n","    paths_spectograms = glob(paths.TRAIN_SPECTOGRAMS + \"*.parquet\")\n","    print(f'There are {len(paths_spectograms)} spectrogram parquets')\n","\n","    if READ_SPEC_FILES:    \n","        all_spectrograms = {}\n","        for file_path in tqdm(paths_spectograms):\n","            aux = pd.read_parquet(file_path)\n","            name = int(file_path.split(\"/\")[-1].split('.')[0])\n","            all_spectrograms[name] = aux.iloc[:,1:].values\n","            del aux\n","    else:\n","        all_spectrograms = np.load(paths.PRE_LOADED_SPECTOGRAMS, allow_pickle=True).item()\n","\n","    if config.VISUALIZE:\n","        idx = np.random.randint(0,len(paths_spectograms))\n","        spectrogram_path = paths_spectograms[idx]\n","        plot_spectrogram(spectrogram_path)\n","\n","    paths_eegs = glob(paths.TRAIN_EEGS + \"*.npy\")\n","    print(f'There are {len(paths_eegs)} EEG spectograms')\n","\n","    if READ_EEG_SPEC_FILES:\n","        all_eegs = {}\n","        for file_path in tqdm(paths_eegs):\n","            eeg_id = file_path.split(\"/\")[-1].split(\".\")[0]\n","            eeg_spectogram = np.load(file_path)\n","            all_eegs[eeg_id] = eeg_spectogram\n","    else:\n","        all_eegs = np.load(paths.PRE_LOADED_EEGS, allow_pickle=True).item()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-03T10:49:52.457564Z","iopub.status.busy":"2024-03-03T10:49:52.457246Z","iopub.status.idle":"2024-03-03T10:49:54.097297Z","shell.execute_reply":"2024-03-03T10:49:54.095441Z","shell.execute_reply.started":"2024-03-03T10:49:52.457515Z"},"trusted":true},"outputs":[],"source":["if train_mode:\n","    \n","    train_dataset = CustomDataset(train_df, config, all_spectrograms, all_eegs, mode=\"train\")\n","    train_loader = DataLoader(\n","        train_dataset,\n","        batch_size=config.BATCH_SIZE,\n","        shuffle=False,\n","        num_workers=config.NUM_WORKERS, \n","        pin_memory=True, \n","        drop_last=True\n","    )\n","\n","    if config.VISUALIZE:\n","        X, y = train_dataset[0]\n","        print(f\"X shape: {X.shape}\")\n","        print(f\"y shape: {y.shape}\")\n","\n","        ROWS = 2\n","        COLS = 3\n","        for (X, y) in train_loader:\n","            plt.figure(figsize=(20,8))\n","            for row in range(ROWS):\n","                for col in range(COLS):\n","                    plt.subplot(ROWS, COLS, row*COLS + col+1)\n","                    t = y[row*COLS + col]\n","                    img = X[row*COLS + col, :, :, 0]\n","                    mn = img.flatten().min()\n","                    mx = img.flatten().max()\n","                    img = (img-mn)/(mx-mn)\n","                    plt.imshow(img)\n","                    tars = f'[{t[0]:0.2f}'\n","                    for s in t[1:]:\n","                        tars += f', {s:0.2f}'\n","                    eeg = train_df.eeg_id.values[row*config.BATCH_SIZE + row*COLS + col]\n","                    plt.title(f'EEG = {eeg}\\nTarget = {tars}',size=12)\n","                    plt.yticks([])\n","                    plt.ylabel('Frequencies (Hz)',size=14)\n","                    plt.xlabel('Time (sec)',size=16)\n","            plt.show()\n","            break"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-03T10:49:54.099089Z","iopub.status.busy":"2024-03-03T10:49:54.098796Z","iopub.status.idle":"2024-03-03T10:49:54.116155Z","shell.execute_reply":"2024-03-03T10:49:54.115260Z","shell.execute_reply.started":"2024-03-03T10:49:54.099064Z"},"trusted":true},"outputs":[],"source":["def train_epoch(train_loader, model, criterion, optimizer, epoch, scheduler, device):\n","    \"\"\"One epoch training pass.\"\"\"\n","    model.train() \n","    criterion = nn.KLDivLoss(reduction=\"batchmean\")\n","    scaler = torch.cuda.amp.GradScaler(enabled=config.AMP)\n","    losses = AverageMeter()\n","    start = end = time.time()\n","    global_step = 0\n","    \n","    # ========== ITERATE OVER TRAIN BATCHES ============\n","    with tqdm(train_loader, unit=\"train_batch\", desc='Train') as tqdm_train_loader:\n","        for step, (X, y) in enumerate(tqdm_train_loader):\n","            X = X.to(device)\n","            y = y.to(device)\n","            batch_size = y.size(0)\n","            with torch.cuda.amp.autocast(enabled=config.AMP):\n","                y_preds = model(X) \n","                loss = criterion(F.log_softmax(y_preds, dim=1), y)\n","            if config.GRADIENT_ACCUMULATION_STEPS > 1:\n","                loss = loss / config.GRADIENT_ACCUMULATION_STEPS\n","            losses.update(loss.item(), batch_size)\n","            scaler.scale(loss).backward()\n","            grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), config.MAX_GRAD_NORM)\n","\n","            if (step + 1) % config.GRADIENT_ACCUMULATION_STEPS == 0:\n","                scaler.step(optimizer)\n","                scaler.update()\n","                optimizer.zero_grad()\n","                global_step += 1\n","                scheduler.step()\n","            end = time.time()\n","\n","            # ========== LOG INFO ==========\n","            if step % config.PRINT_FREQ == 0 or step == (len(train_loader)-1):\n","                remain = timeSince(start, float(step+1)/len(train_loader))\n","                lr=scheduler.get_last_lr()[0]\n","                info = f\"Epoch: [{epoch+1}][{step}/{len(train_loader)}]\"\n","                info += f\"Elapsed {remain:s} Loss: {losses.avg:.4f} Grad: {grad_norm:.4f} LR: {lr:.8f}\"\n","                print(info)\n","\n","    return losses.avg\n","\n","\n","def valid_epoch(valid_loader, model, criterion, device):\n","    model.eval()\n","    softmax = nn.Softmax(dim=1)\n","    losses = AverageMeter()\n","    prediction_dict = {}\n","    preds = []\n","    start = end = time.time()\n","    with tqdm(valid_loader, unit=\"valid_batch\", desc='Validation') as tqdm_valid_loader:\n","        for step, (X, y) in enumerate(tqdm_valid_loader):\n","            X = X.to(device)\n","            y = y.to(device)\n","            batch_size = y.size(0)\n","            with torch.no_grad():\n","                y_preds = model(X)\n","                loss = criterion(F.log_softmax(y_preds, dim=1), y)\n","            if config.GRADIENT_ACCUMULATION_STEPS > 1:\n","                loss = loss / config.GRADIENT_ACCUMULATION_STEPS\n","            losses.update(loss.item(), batch_size)\n","            y_preds = y_preds\n","            preds.append(y_preds.to('cpu').numpy())\n","            end = time.time()\n","\n","            # ========== LOG INFO ==========\n","            if step % config.PRINT_FREQ == 0 or step == (len(valid_loader)-1):\n","                remain=timeSince(start, float(step+1)/len(valid_loader))\n","                info = f\"EVAL: [{step}/{len(valid_loader)}] Elapsed {remain:s} Loss: {losses.avg:.4f}\"\n","                print(info)\n","                \n","    prediction_dict[\"predictions\"] = np.concatenate(preds)\n","    return losses.avg, prediction_dict"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-03T10:49:54.118449Z","iopub.status.busy":"2024-03-03T10:49:54.118143Z","iopub.status.idle":"2024-03-03T10:49:54.134498Z","shell.execute_reply":"2024-03-03T10:49:54.133579Z","shell.execute_reply.started":"2024-03-03T10:49:54.118424Z"},"trusted":true},"outputs":[],"source":["from torch.optim.lr_scheduler import OneCycleLR\n","\n","def train_loop(df, fold, all_specs, all_eegs, model_postfix=None):\n","    \n","    LOGGER.info(f\"========== Fold: {fold} training ==========\")\n","\n","    # ======== SPLIT ==========\n","    train_folds = df[df['fold'] != fold].reset_index(drop=True)\n","    valid_folds = df[df['fold'] == fold].reset_index(drop=True)\n","    \n","    # ======== DATASETS ==========\n","    train_dataset = CustomDataset(train_folds, config, all_specs, all_eegs, mode=\"train\", augment=True)\n","    valid_dataset = CustomDataset(valid_folds, config, all_specs, all_eegs, mode=\"train\", augment=False)\n","    \n","    # ======== DATALOADERS ==========\n","    train_loader = DataLoader(train_dataset,\n","                              batch_size=config.BATCH_SIZE,\n","                              shuffle=False,\n","                              num_workers=config.NUM_WORKERS, pin_memory=True, drop_last=True)\n","    valid_loader = DataLoader(valid_dataset,\n","                              batch_size=config.BATCH_SIZE,\n","                              shuffle=False,\n","                              num_workers=config.NUM_WORKERS, pin_memory=True, drop_last=False)\n","    \n","    # ======== MODEL ==========\n","    model = CustomModel(config)\n","    model.to(device)\n","\n","    optimizer = torch.optim.AdamW(model.parameters(), lr=0.1, weight_decay=config.WEIGHT_DECAY)\n","    scheduler = OneCycleLR(\n","        optimizer,\n","        max_lr=1e-4,\n","        epochs=config.EPOCHS,\n","        steps_per_epoch=len(train_loader),\n","        pct_start=0.1,\n","        anneal_strategy=\"cos\",\n","        final_div_factor=100,\n","    )\n","\n","    # ======= LOSS ==========\n","    criterion = nn.KLDivLoss(reduction=\"batchmean\")\n","    \n","    best_loss = np.inf\n","    \n","    if not model_postfix:\n","        save_model = paths.OUTPUT_DIR + f\"/{config.MODEL.replace('/', '_')}_f{fold}_best.pth\"\n","    else:\n","        save_model = paths.OUTPUT_DIR + f\"/{config.MODEL.replace('/', '_')}_f{fold}_{model_postfix}.pth\"\n","        \n","    # ====== ITERATE EPOCHS ========\n","    for epoch in range(config.EPOCHS):\n","        start_time = time.time()\n","\n","        # ======= TRAIN ==========\n","        avg_train_loss = train_epoch(train_loader, model, criterion, optimizer, epoch, scheduler, device)\n","\n","        # ======= EVALUATION ==========\n","        avg_val_loss, prediction_dict = valid_epoch(valid_loader, model, criterion, device)\n","        predictions = prediction_dict[\"predictions\"]\n","        \n","        # ======= SCORING ==========\n","        elapsed = time.time() - start_time\n","\n","        LOGGER.info(f'Epoch {epoch+1} - avg_train_loss: {avg_train_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s')\n","        \n","        if avg_val_loss < best_loss:\n","            best_loss = avg_val_loss\n","            LOGGER.info(f'Epoch {epoch+1} - Save Best Loss: {best_loss:.4f} Model')\n","            torch.save(\n","                {'model': model.state_dict(), 'predictions': predictions},\n","                save_model\n","            )\n","\n","    predictions = torch.load(save_model, map_location=torch.device('cpu'))['predictions']\n","    valid_folds[target_preds] = predictions\n","\n","    torch.cuda.empty_cache()\n","    gc.collect()\n","    \n","    return valid_folds"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-03T10:49:54.136054Z","iopub.status.busy":"2024-03-03T10:49:54.135625Z","iopub.status.idle":"2024-03-03T10:49:54.148990Z","shell.execute_reply":"2024-03-03T10:49:54.148169Z","shell.execute_reply.started":"2024-03-03T10:49:54.136028Z"},"jupyter":{"source_hidden":true},"trusted":true},"outputs":[],"source":["def train_loop_full_data(df):\n","    train_dataset = CustomDataset(df, config, mode=\"train\", augment=True)\n","    train_loader = DataLoader(train_dataset,\n","                              batch_size=config.BATCH_SIZE_TRAIN,\n","                              shuffle=False,\n","                              num_workers=config.NUM_WORKERS, pin_memory=True, drop_last=True)\n","    model = CustomModel(config)\n","    model.to(device)\n","    optimizer = torch.optim.AdamW(model.parameters(), lr=0.1, weight_decay=config.WEIGHT_DECAY)\n","    scheduler = OneCycleLR(\n","        optimizer,\n","        max_lr=1e-3,\n","        epochs=config.EPOCHS,\n","        steps_per_epoch=len(train_loader),\n","        pct_start=0.1,\n","        anneal_strategy=\"cos\",\n","        final_div_factor=100,\n","    )\n","    criterion = nn.KLDivLoss(reduction=\"batchmean\")\n","    best_loss = np.inf\n","    for epoch in range(config.EPOCHS):\n","        start_time = time.time()\n","        avg_train_loss = train_epoch(train_loader, model, criterion, optimizer, epoch, scheduler, device)\n","        elapsed = time.time() - start_time\n","        LOGGER.info(f'Epoch {epoch+1} - avg_train_loss: {avg_train_loss:.4f}  time: {elapsed:.0f}s')\n","        torch.save(\n","            {'model': model.state_dict()},\n","            paths.OUTPUT_DIR + f\"/{config.MODEL.replace('/', '_')}_epoch_{epoch}.pth\")\n","    torch.cuda.empty_cache()\n","    gc.collect()\n","    return _"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-03T10:49:54.150513Z","iopub.status.busy":"2024-03-03T10:49:54.150113Z"},"trusted":true},"outputs":[],"source":["import torch.nn.functional as F\n","\n","def get_result(oof_df):\n","    kl_loss = nn.KLDivLoss(reduction=\"batchmean\")\n","    labels = torch.tensor(oof_df[label_cols].values)\n","    preds = torch.tensor(oof_df[target_preds].values)\n","    preds = F.log_softmax(preds, dim=1)\n","    result = kl_loss(preds, labels)\n","    return result\n","\n","if train_mode: \n","    from sklearn.model_selection import KFold, GroupKFold\n","    if not config.TRAIN_FULL_DATA:\n","\n","        gkf = GroupKFold(n_splits=config.FOLDS)\n","        for fold, (train_index, valid_index) in enumerate(gkf.split(train_df, train_df.target, train_df.patient_id)):\n","            train_df.loc[valid_index, \"fold\"] = int(fold)\n","\n","        display(train_df.groupby('fold').size()), sep()\n","        display(train_df.head())\n","\n","        oof_df = pd.DataFrame()\n","        for fold in range(config.FOLDS):\n","            if fold in [0, 1, 2, 3, 4]:\n","                _oof_df = train_loop(train_df, fold, all_spectrograms, all_eegs)\n","                oof_df = pd.concat([oof_df, _oof_df])\n","                LOGGER.info(f\"========== Fold {fold} result: {get_result(_oof_df)} ==========\")\n","                print(f\"========== Fold {fold} result: {get_result(_oof_df)} ==========\")\n","        oof_df = oof_df.reset_index(drop=True)\n","        LOGGER.info(f\"========== CV: {get_result(oof_df)} ==========\")\n","        oof_df.to_csv(paths.OUTPUT_DIR + '/oof_df.csv', index=False)\n","    else:\n","        train_loop_full_data(train_df)"]},{"cell_type":"markdown","metadata":{},"source":["# <b><span style='color:#F1A424'>|</span> Inference</b><a class='anchor' id='train'></a> [↑](#top) \n","\n","***"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-02T21:54:07.381313Z","iopub.status.busy":"2024-03-02T21:54:07.380988Z","iopub.status.idle":"2024-03-02T21:54:07.425578Z","shell.execute_reply":"2024-03-02T21:54:07.424610Z","shell.execute_reply.started":"2024-03-02T21:54:07.381287Z"},"trusted":true},"outputs":[],"source":["model_weights = [x for x in glob(\"/kaggle/input/hms-2562564-efficient-net/*.pth\")]\n","model_weights"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-02T21:54:07.427601Z","iopub.status.busy":"2024-03-02T21:54:07.427223Z","iopub.status.idle":"2024-03-02T21:54:07.465489Z","shell.execute_reply":"2024-03-02T21:54:07.464648Z","shell.execute_reply.started":"2024-03-02T21:54:07.427569Z"},"trusted":true},"outputs":[],"source":["import pywt, librosa\n","\n","USE_WAVELET = None \n","\n","NAMES = ['LL','LP','RP','RR']\n","\n","FEATS = [['Fp1','F7','T3','T5','O1'],\n","         ['Fp1','F3','C3','P3','O1'],\n","         ['Fp2','F8','T4','T6','O2'],\n","         ['Fp2','F4','C4','P4','O2']]\n","\n","# DENOISE FUNCTION\n","def maddest(d, axis=None):\n","    return np.mean(np.absolute(d - np.mean(d, axis)), axis)\n","\n","def denoise(x, wavelet='haar', level=1):    \n","    coeff = pywt.wavedec(x, wavelet, mode=\"per\")\n","    sigma = (1/0.6745) * maddest(coeff[-level])\n","\n","    uthresh = sigma * np.sqrt(2*np.log(len(x)))\n","    coeff[1:] = (pywt.threshold(i, value=uthresh, mode='hard') for i in coeff[1:])\n","\n","    ret=pywt.waverec(coeff, wavelet, mode='per')\n","    \n","    return ret\n","\n","def spectrogram_from_eeg(parquet_path, display=False, offset=None):\n","    \n","    # LOAD MIDDLE 50 SECONDS OF EEG SERIES\n","    eeg = pd.read_parquet(parquet_path)\n","#     print(eeg.shape)\n","    if offset is None:\n","        middle = (len(eeg)-10_000)//2\n","        eeg = eeg.iloc[middle:middle+10_000]\n","    else:\n","        eeg = eeg.iloc[offset:offset+10_000]\n","    \n","    # VARIABLE TO HOLD SPECTROGRAM\n","    img = np.zeros((128,256,4),dtype='float32')\n","    \n","    if display: plt.figure(figsize=(10,7))\n","    signals = []\n","    for k in range(4):\n","        COLS = FEATS[k]\n","        \n","        for kk in range(4):\n","        \n","            # COMPUTE PAIR DIFFERENCES\n","            x = eeg[COLS[kk]].values - eeg[COLS[kk+1]].values\n","\n","            # FILL NANS\n","            m = np.nanmean(x)\n","            if np.isnan(x).mean() < 1: \n","                x = np.nan_to_num(x,nan=m)\n","            else: x[:] = 0\n","\n","            # DENOISE\n","            if USE_WAVELET:\n","                x = denoise(x, wavelet=USE_WAVELET)\n","            signals.append(x)\n","\n","            # RAW SPECTROGRAM\n","            mel_spec = librosa.feature.melspectrogram(y=x, sr=200, hop_length=len(x)//256, \n","                  n_fft=1024, n_mels=128, fmin=0, fmax=20, win_length=128)\n","\n","            # LOG TRANSFORM\n","            width = (mel_spec.shape[1]//32)*32\n","            mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max).astype(np.float32)[:,:width]\n","\n","            # STANDARDIZE TO -1 TO 1\n","            mel_spec_db = (mel_spec_db+40)/40 \n","            img[:,:,k] += mel_spec_db\n","                \n","        # AVERAGE THE 4 MONTAGE DIFFERENCES\n","        img[:,:,k] /= 4.0\n","        \n","        if display:\n","            plt.subplot(2,2,k+1)\n","            plt.imshow(img[:,:,k],aspect='auto',origin='lower')\n","#             plt.title(f'EEG {eeg_id} - Spectrogram {NAMES[k]}')\n","            \n","    if display: \n","        plt.show()\n","        plt.figure(figsize=(10,5))\n","        offset = 0\n","        for k in range(4):\n","            if k>0: offset -= signals[3-k].min()\n","            plt.plot(range(10_000),signals[k]+offset,label=NAMES[3-k])\n","            offset += signals[3-k].max()\n","        plt.legend()\n","#         plt.title(f'EEG {eeg_id} Signals')\n","        plt.show()\n","        print(); print('#'*25); print()\n","        \n","    return img"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-02T21:54:07.467456Z","iopub.status.busy":"2024-03-02T21:54:07.467004Z","iopub.status.idle":"2024-03-02T21:54:07.485432Z","shell.execute_reply":"2024-03-02T21:54:07.484412Z","shell.execute_reply.started":"2024-03-02T21:54:07.467422Z"},"trusted":true},"outputs":[],"source":["test_df = pd.read_csv(paths.TEST_CSV)\n","print('Test shape',test_df.shape)\n","test_df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-02T21:54:07.487098Z","iopub.status.busy":"2024-03-02T21:54:07.486836Z","iopub.status.idle":"2024-03-02T21:54:10.420434Z","shell.execute_reply":"2024-03-02T21:54:10.419509Z","shell.execute_reply.started":"2024-03-02T21:54:07.487075Z"},"trusted":true},"outputs":[],"source":["# READ ALL SPECTROGRAMS\n","paths_spectrograms = glob(paths.TEST_SPECTROGRAMS + \"*.parquet\")\n","print(f'There are {len(paths_spectrograms)} spectrogram parquets')\n","all_spectrograms = {}\n","\n","for file_path in tqdm(paths_spectrograms):\n","    aux = pd.read_parquet(file_path)\n","    name = int(file_path.split(\"/\")[-1].split('.')[0])\n","    all_spectrograms[name] = aux.iloc[:,1:].values\n","    del aux\n","    \n","if config.VISUALIZE:\n","    idx = np.random.randint(0, len(paths_spectrograms))\n","    spectrogram_path = paths_spectrograms[idx]\n","    plot_spectrogram(spectrogram_path)\n","    "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-02T21:54:10.422342Z","iopub.status.busy":"2024-03-02T21:54:10.421727Z","iopub.status.idle":"2024-03-02T21:54:23.138760Z","shell.execute_reply":"2024-03-02T21:54:23.137849Z","shell.execute_reply.started":"2024-03-02T21:54:10.422308Z"},"trusted":true},"outputs":[],"source":["paths_eegs = glob(paths.TEST_EEGS + \"*.parquet\")\n","print(f'There are {len(paths_eegs)} EEG spectrograms')\n","all_eegs = {}\n","counter = 0\n","\n","for file_path in tqdm(paths_eegs):\n","    eeg_id = file_path.split(\"/\")[-1].split(\".\")[0]\n","    eeg_spectrogram = spectrogram_from_eeg(file_path, counter < 1)\n","    all_eegs[int(eeg_id)] = eeg_spectrogram\n","    counter += 1"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-02T21:54:23.140362Z","iopub.status.busy":"2024-03-02T21:54:23.139892Z","iopub.status.idle":"2024-03-02T21:54:23.153464Z","shell.execute_reply":"2024-03-02T21:54:23.152579Z","shell.execute_reply.started":"2024-03-02T21:54:23.140334Z"},"trusted":true},"outputs":[],"source":["test_dataset = CustomDataset(test_df, config, all_spectrograms, all_eegs, mode=\"test\")\n","test_loader = DataLoader(\n","    test_dataset,\n","    batch_size=config.BATCH_SIZE,\n","    shuffle=False,\n","    num_workers=config.NUM_WORKERS, pin_memory=True, drop_last=False\n",")\n","\n","X, y = test_dataset[0]\n","print(f\"X shape: {X.shape}\")\n","print(f\"y shape: {y.shape}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-02T21:54:23.156532Z","iopub.status.busy":"2024-03-02T21:54:23.156248Z","iopub.status.idle":"2024-03-02T21:54:23.164866Z","shell.execute_reply":"2024-03-02T21:54:23.163915Z","shell.execute_reply.started":"2024-03-02T21:54:23.156507Z"},"trusted":true},"outputs":[],"source":["def inference_function(test_loader, model, device):\n","    model.eval()\n","    softmax = nn.Softmax(dim=1)\n","    prediction_dict = {}\n","    preds = []\n","    with tqdm(test_loader, unit=\"test_batch\", desc='Inference') as tqdm_test_loader:\n","        for step, (X, y) in enumerate(tqdm_test_loader):\n","            X = X.to(device)\n","            y = y.to(device)\n","            batch_size = y.size(0)\n","            with torch.no_grad():\n","                y_preds = model(X)\n","            y_preds = softmax(y_preds)\n","            preds.append(y_preds.to('cpu').numpy()) \n","                \n","    prediction_dict[\"predictions\"] = np.concatenate(preds) \n","    return prediction_dict"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-02T21:54:23.166227Z","iopub.status.busy":"2024-03-02T21:54:23.165924Z","iopub.status.idle":"2024-03-02T21:54:24.059738Z","shell.execute_reply":"2024-03-02T21:54:24.058219Z","shell.execute_reply.started":"2024-03-02T21:54:23.166199Z"},"trusted":true},"outputs":[],"source":["predictions = []\n","\n","for model_weight in model_weights:\n","    test_dataset = CustomDataset(test_df, config, all_spectrograms, all_eegs, mode=\"test\", augment=False)\n","    train_loader = DataLoader(\n","        test_dataset,\n","        batch_size=config.BATCH_SIZE,\n","        shuffle=False,\n","        num_workers=config.NUM_WORKERS,\n","        pin_memory=True, drop_last=False\n","    )\n","    model = CustomModel(config, pretrained=False)\n","    checkpoint = torch.load(model_weight)\n","    model.load_state_dict(checkpoint[\"model\"])\n","    # model = torch.load(model_weight)\n","    model.to(device)\n","    prediction_dict = inference_function(test_loader, model, device)\n","    predictions.append(prediction_dict[\"predictions\"])\n","    torch.cuda.empty_cache()\n","    gc.collect()\n","    \n","predictions = np.array(predictions)\n","predictions = np.mean(predictions, axis=0)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-03-02T21:54:24.060955Z","iopub.status.idle":"2024-03-02T21:54:24.061488Z","shell.execute_reply":"2024-03-02T21:54:24.061252Z","shell.execute_reply.started":"2024-03-02T21:54:24.061225Z"},"trusted":true},"outputs":[],"source":["TARGETS = ['seizure_vote', 'lpd_vote', 'gpd_vote', 'lrda_vote', 'grda_vote', 'other_vote']\n","sub = pd.DataFrame({'eeg_id': test_df.eeg_id.values})\n","sub[TARGETS] = predictions\n","sub.to_csv('submission.csv',index=False)\n","print(f'Submissionn shape: {sub.shape}')\n","sub.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-03-02T21:54:24.063449Z","iopub.status.idle":"2024-03-02T21:54:24.064312Z","shell.execute_reply":"2024-03-02T21:54:24.064054Z","shell.execute_reply.started":"2024-03-02T21:54:24.064029Z"},"trusted":true},"outputs":[],"source":["sub[TARGETS].sum(axis=1)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"databundleVersionId":7469972,"sourceId":59093,"sourceType":"competition"},{"datasetId":4297749,"sourceId":7392733,"sourceType":"datasetVersion"},{"datasetId":4297782,"sourceId":7392775,"sourceType":"datasetVersion"},{"datasetId":4304475,"sourceId":7402356,"sourceType":"datasetVersion"},{"datasetId":4304949,"sourceId":7403069,"sourceType":"datasetVersion"},{"datasetId":4334995,"sourceId":7447509,"sourceType":"datasetVersion"},{"datasetId":4336944,"sourceId":7450712,"sourceType":"datasetVersion"},{"datasetId":1556982,"sourceId":7653720,"sourceType":"datasetVersion"},{"datasetId":4527359,"sourceId":7744973,"sourceType":"datasetVersion"},{"datasetId":4528430,"sourceId":7746490,"sourceType":"datasetVersion"},{"sourceId":158958765,"sourceType":"kernelVersion"}],"dockerImageVersionId":30636,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.2"},"papermill":{"default_parameters":{},"duration":270.012179,"end_time":"2024-01-14T22:56:02.916427","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2024-01-14T22:51:32.904248","version":"2.4.0"}},"nbformat":4,"nbformat_minor":4}
