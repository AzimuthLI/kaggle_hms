{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"trusted":true},"outputs":[],"source":["import os, gc, random\n","import numpy as np\n","import pandas as pd \n","from pathlib import Path\n","import matplotlib.pyplot as plt\n","from typing import List, Dict\n","from tqdm.notebook import tqdm\n","from time import time, ctime\n","import warnings\n","\n","from sklearn.model_selection import KFold, GroupKFold\n","\n","import torch\n","from torch import nn\n","from torch.nn import functional as F\n","from torch.utils.data import DataLoader, Dataset\n","from torchvision.transforms import v2\n","from torch.optim.lr_scheduler import OneCycleLR,  CosineAnnealingWarmRestarts\n","from torch.optim import Adam, AdamW\n","from torch.cuda.amp import autocast, GradScaler\n","\n","from scipy.signal import butter, lfilter, freqz\n","from scipy.stats import entropy\n","from scipy.special import rel_entr, softmax\n","\n","warnings.filterwarnings(\"ignore\")\n"]},{"cell_type":"code","execution_count":2,"metadata":{"trusted":true},"outputs":[],"source":["def get_logger(log_dir, logger_name=\"train_model.log\"):\n","    from logging import getLogger, INFO, StreamHandler, FileHandler, Formatter\n","    logger_file = os.path.join(log_dir, logger_name)\n","    logger = getLogger(__name__)\n","    logger.setLevel(INFO)\n","    handler1 = StreamHandler()\n","    handler1.setFormatter(Formatter(\"%(message)s\"))\n","    handler2 = FileHandler(filename=logger_file, mode=\"a+\")\n","    handler2.setFormatter(Formatter(\"%(message)s\"))\n","    logger.addHandler(handler1)\n","    logger.addHandler(handler2)\n","    return logger\n","\n","\n","def seed_everything(seed: int):\n","    random.seed(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)"]},{"cell_type":"code","execution_count":3,"metadata":{"trusted":true},"outputs":[],"source":["class ModelConfig:\n","    SEED = 20\n","    SPLIT_ENTROPY = 5.5\n","    MODEL_NAME = \"ResnetGRU_v1_LB048\"\n","    MODEL_BACKBONE = \"reset_gru\"\n","    BATCH_SIZE = 32\n","    EPOCHS = 20\n","    EARLY_STOP_ROUNDS = 5\n","    GRADIENT_ACCUMULATION_STEPS = 1\n","    DROP_RATE = 0.15 # default: 0.1\n","    DROP_PATH_RATE = 0.25 # default: 0.2\n","    WEIGHT_DECAY = 0.01\n","    AMP = True\n","    PRINT_FREQ = 100\n","    NUM_WORKERS = 0 \n","    MAX_GRAD_NORM = 1e7\n","    REGULARIZATION = 0.15\n","    RESNET_GRU_BANDPASS = None #(0.5, 20)\n","    RESNET_GRU_IN_CHANNELS = 8\n","    RESNET_GRU_KERNELS = [3, 5, 7, 9, 11]\n","    RESNET_GRU_FIXED_KERNEL_SIZE = 5\n","    RESNET_GRU_DOWNSAMPLE = 5 # None #5\n","    RESNET_GRU_HIDDEN_SIZE = 304 #448 #304\n","    RESNET_GRU_DILATED = False"]},{"cell_type":"code","execution_count":4,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Use Device:  cuda:0\n"]}],"source":["N_GPU = torch.cuda.device_count()\n","if N_GPU > 1:\n","    DEVICE = torch.device(\"cuda\")\n","    os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1\"\n","elif N_GPU == 1:\n","    DEVICE = torch.device(\"cuda:0\")\n","else:\n","    DEVICE = torch.device(\"cpu\")\n","\n","print(\"Use Device: \", DEVICE)"]},{"cell_type":"code","execution_count":5,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Output Dir:  ./outputs/\n","{'Fp1': 0, 'T3': 1, 'C3': 2, 'O1': 3, 'Fp2': 4, 'C4': 5, 'T4': 6, 'O2': 7}\n"]}],"source":["class KagglePaths:\n","    OUTPUT_DIR = \"/kaggle/working/\"\n","    PRE_LOADED_EEGS = '/kaggle/input/brain-eeg-spectrograms/eeg_specs.npy'\n","    PRE_LOADED_SPECTROGRAMS = '/kaggle/input/brain-spectrograms/specs.npy'\n","    TRAIN_CSV = \"/kaggle/input/hms-harmful-brain-activity-classification/train.csv\"\n","    TRAIN_EEGS = \"/kaggle/input/hms-harmful-brain-activity-classification/train_eegs/\"\n","    TRAIN_SPECTROGRAMS = \"/kaggle/input/hms-harmful-brain-activity-classification/train_spectrograms/\"\n","    TEST_CSV = \"/kaggle/input/hms-harmful-brain-activity-classification/test.csv\"\n","    TEST_SPECTROGRAMS = \"/kaggle/input/hms-harmful-brain-activity-classification/test_spectrograms/\"\n","    TEST_EEGS = \"/kaggle/input/hms-harmful-brain-activity-classification/test_eegs/\"\n","\n","\n","class LocalPaths:\n","    OUTPUT_DIR = \"./outputs/\"\n","    PRE_LOADED_EEGS = './inputs/brain-eeg-spectrograms/eeg_specs.npy'\n","    PRE_LOADED_SPECTROGRAMS = './inputs/brain-spectrograms/specs.npy'\n","    TRAIN_CSV = \"./inputs/hms-harmful-brain-activity-classification/train.csv\"\n","    TRAIN_EEGS = \"./inputs/hms-harmful-brain-activity-classification/train_eegs\"\n","    TRAIN_SPECTROGRAMS = \"./inputs/hms-harmful-brain-activity-classification/train_spectrograms\"\n","    TEST_CSV = \"./inputs/hms-harmful-brain-activity-classification/test.csv\"\n","    TEST_SPECTROGRAMS = \"./inputs/hms-harmful-brain-activity-classification/test_spectrograms\"\n","    TEST_EEGS = \"./inputs/hms-harmful-brain-activity-classification/test_eegs\"\n","\n","PATHS = KagglePaths if os.path.exists(\"/kaggle\") else LocalPaths\n","\n","print(\"Output Dir: \", PATHS.OUTPUT_DIR)\n","\n","EEG_FEAT_ALL = [\n","    'Fp1', 'F3', 'C3', 'P3', \n","    'F7', 'T3', 'T5', 'O1', \n","    'Fz', 'Cz', 'Pz', 'Fp2', \n","    'F4', 'C4', 'P4', 'F8', \n","    'T4', 'T6', 'O2', 'EKG'\n","    ]\n","\n","EEG_FEAT_USE =  ['Fp1','T3','C3','O1','Fp2','C4','T4','O2']\n","EEG_FEAT_INDEX = {x:y for x,y in zip(EEG_FEAT_USE, range(len(EEG_FEAT_USE)))}\n","\n","BRAIN_ACTIVITY = ['seizure', 'lpd', 'gpd', 'lrda', 'grda', 'other']\n","TARGETS = [f\"{lb}_vote\" for lb in BRAIN_ACTIVITY]\n","TARGETS_PRED = [f\"{lb}_pred\" for lb in BRAIN_ACTIVITY]\n","\n","seed_everything(ModelConfig.SEED)\n","\n","print(EEG_FEAT_INDEX)"]},{"cell_type":"code","execution_count":6,"metadata":{"trusted":true},"outputs":[],"source":["logger = get_logger(PATHS.OUTPUT_DIR, f\"{ModelConfig.MODEL_NAME}_train.log\")"]},{"cell_type":"markdown","metadata":{},"source":["# Load Data"]},{"cell_type":"code","execution_count":7,"metadata":{"trusted":true},"outputs":[],"source":["def eeg_from_parquet(parquet_path: str, use_feature=EEG_FEAT_USE, display: bool = False) -> np.ndarray:\n","    # === Extract full length EEG Sequence ===\n","    # fill missing values with mean\n","    # first fill missing values with mean of each column\n","    # then if all values are missing, fill with 0\n","    eeg = pd.read_parquet(parquet_path, columns=use_feature)\n","    eeg = eeg.fillna(eeg.mean(skipna=True)).fillna(0)\n","    data = eeg.values.astype(np.float32)\n","    \n","    rows = len(eeg)\n","    offset = (rows - 10_000) // 2 # 50 * 200 = 10_000\n","    data = data[offset:offset+10_000, :]\n","\n","    if display:\n","        fig, ax = plt.subplots(len(use_feature), 1, figsize=(10, 2*len(use_feature)), sharex=True)\n","        \n","        for i, feat in enumerate(use_feature):\n","            ax[i].plot(data[:, i], label=feat)\n","            ax[i].legend()\n","            ax[i].grid()\n","       \n","        name = parquet_path.split('/')[-1].split('.')[0]\n","        ax[0].set_title(f'EEG {name}',size=16)\n","        fig.tight_layout()\n","        plt.show()    \n","    return data"]},{"cell_type":"code","execution_count":8,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["CPU times: user 178 ms, sys: 1.27 s, total: 1.45 s\n","Wall time: 1.45 s\n"]}],"source":["%%time\n","CREATE_EEGS = False\n","ALL_EEG_SIGNALS = {}\n","eeg_paths = list(Path(PATHS.TRAIN_EEGS).glob('*.parquet'))\n","preload_eegs_path = Path('./inputs/eegs_full.npy')\n","\n","if CREATE_EEGS:\n","    count = 0\n","    for parquet_path in tqdm(eeg_paths, total=len(eeg_paths)):\n","        eeg_id = int(parquet_path.stem)\n","        eeg_path = str(parquet_path)\n","        data = eeg_from_parquet(eeg_path, display=False)\n","        ALL_EEG_SIGNALS[eeg_id] = data\n","        count += 1\n","    np.save(\"./inputs/eegs_full.npy\", ALL_EEG_SIGNALS)\n","else:\n","    ALL_EEG_SIGNALS = np.load(preload_eegs_path, allow_pickle=True).item()"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["def gen_non_overlap_samples(df_csv, targets):\n","    # Reference Discussion:\n","    # https://www.kaggle.com/competitions/hms-harmful-brain-activity-classification/discussion/467021\n","\n","    tgt_list = targets.tolist()\n","    brain_activity = ['seizure', 'lpd', 'gpd', 'lrda', 'grda', 'other']\n","\n","    agg_dict = {\n","        'spectrogram_id': 'first',\n","        'spectrogram_label_offset_seconds': ['min', 'max'],\n","        'patient_id': 'first',\n","        'expert_consensus': 'first'\n","    }\n","\n","    groupby = df_csv.groupby(['eeg_id'] + tgt_list)\n","    train = groupby.agg(agg_dict)\n","    train = train.reset_index()\n","    train.columns = ['_'.join(col).strip() for col in train.columns.values]\n","    train.columns = [\"eeg_id\"] + tgt_list + ['spectrogram_id', 'min', 'max', 'patient_id', 'target']\n","    \n","    train['total_votes'] = train[tgt_list].sum(axis=1)\n","    train[tgt_list] = train[tgt_list].div(train['total_votes'], axis=0)\n","    \n","    return train"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["# # Enhanced Samples Split \n","\n","# train_csv = pd.read_csv(PATHS.TRAIN_CSV)\n","# targets = train_csv.columns[-6:].tolist()\n","\n","# raw_csv_len = len(train_csv)\n","\n","# subset_counts = train_csv.groupby(['eeg_id']+targets).size().reset_index(name='subset_counts')\n","# train_csv = train_csv.merge(subset_counts, on=['eeg_id']+targets, how='left')\n","\n","# tmp_cols = ['expert_consensus', 'eeg_label_offset_seconds', 'subset_counts']\n","\n","# def sample_rule(x):\n","#     if (x['subset_counts'].min() > 3) & ((x['expert_consensus']!='Other').any()):\n","#         return x['eeg_label_offset_seconds'].sample(n=(x['subset_counts'].min()//3))\n","#     else:\n","#         return x['eeg_label_offset_seconds'].sample(n=1)\n","\n","# train_samples = train_csv.groupby(['eeg_id']+targets)[tmp_cols].apply(sample_rule).reset_index()\n","# train_samples = train_samples.rename(columns={'eeg_label_offset_seconds': 'eeg_off_seconds'})\n","# train_samples.drop(columns=['level_7'], inplace=True)\n","\n","# train_meta = train_csv.groupby(['eeg_id']+targets).agg({\n","#     'spectrogram_id': 'first',\n","#     'spectrogram_label_offset_seconds': ['min', 'max'],\n","#     'eeg_sub_id': 'count',\n","#     'eeg_label_offset_seconds': ['min', 'max'],\n","#     'patient_id': 'first',\n","# }).reset_index()\n","\n","# agged_cols = [\n","#     'spectrogram_id', 'min', 'max', 'subset_counts', 'eeg_off_min', 'eeg_off_max', 'patient_id'\n","# ]\n","# train_meta.columns = ['eeg_id'] + targets + agged_cols\n","# train_meta = train_meta[['eeg_id'] + agged_cols + targets]\n","\n","# train_meta['total_votes'] = train_meta[targets].sum(axis=1)\n","# train_meta['target'] = train_meta[targets].idxmax(axis=1).apply(lambda x: x.split('_')[0])\n","# train_meta['fold'] = -1\n","\n","# K_FOLDS = 5\n","# kf = KFold(n_splits=K_FOLDS, shuffle=False)\n","# unique_eegs = train_meta['eeg_id'].unique()\n","# for fold, (_, valid_idx) in enumerate(kf.split(unique_eegs)):\n","#     train_meta.loc[train_meta['eeg_id'].isin(unique_eegs[valid_idx]), 'fold'] = fold\n","\n","# train_all = train_samples.merge(train_meta, on=['eeg_id']+targets, how='left')\n","\n","# train_all[targets] = train_all[targets].div(train_all['total_votes'], axis=0)\n","\n","# train_all['stage'] = train_all['total_votes'].apply(lambda x: 1 if x < 10 else 2)\n","\n","# train_all"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["targets:  ['seizure_vote', 'lpd_vote', 'gpd_vote', 'lrda_vote', 'grda_vote', 'other_vote']\n","train_all.shape =  (20183, 13)\n","train_all nan_count:  0\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>eeg_id</th>\n","      <th>seizure_vote</th>\n","      <th>lpd_vote</th>\n","      <th>gpd_vote</th>\n","      <th>lrda_vote</th>\n","      <th>grda_vote</th>\n","      <th>other_vote</th>\n","      <th>spectrogram_id</th>\n","      <th>min</th>\n","      <th>max</th>\n","      <th>patient_id</th>\n","      <th>target</th>\n","      <th>total_votes</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>568657</td>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","      <td>0.25</td>\n","      <td>0.000000</td>\n","      <td>0.166667</td>\n","      <td>0.583333</td>\n","      <td>789577333</td>\n","      <td>0.0</td>\n","      <td>16.0</td>\n","      <td>20654</td>\n","      <td>Other</td>\n","      <td>12.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>582999</td>\n","      <td>0.0</td>\n","      <td>0.857143</td>\n","      <td>0.00</td>\n","      <td>0.071429</td>\n","      <td>0.000000</td>\n","      <td>0.071429</td>\n","      <td>1552638400</td>\n","      <td>0.0</td>\n","      <td>38.0</td>\n","      <td>20230</td>\n","      <td>LPD</td>\n","      <td>14.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>642382</td>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","      <td>0.00</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>1.000000</td>\n","      <td>14960202</td>\n","      <td>1008.0</td>\n","      <td>1032.0</td>\n","      <td>5955</td>\n","      <td>Other</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>751790</td>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","      <td>1.00</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>618728447</td>\n","      <td>908.0</td>\n","      <td>908.0</td>\n","      <td>38549</td>\n","      <td>GPD</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>778705</td>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","      <td>0.00</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>1.000000</td>\n","      <td>52296320</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>40955</td>\n","      <td>Other</td>\n","      <td>2.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   eeg_id  seizure_vote  lpd_vote  gpd_vote  lrda_vote  grda_vote  other_vote  \\\n","0  568657           0.0  0.000000      0.25   0.000000   0.166667    0.583333   \n","1  582999           0.0  0.857143      0.00   0.071429   0.000000    0.071429   \n","2  642382           0.0  0.000000      0.00   0.000000   0.000000    1.000000   \n","3  751790           0.0  0.000000      1.00   0.000000   0.000000    0.000000   \n","4  778705           0.0  0.000000      0.00   0.000000   0.000000    1.000000   \n","\n","   spectrogram_id     min     max  patient_id target  total_votes  \n","0       789577333     0.0    16.0       20654  Other         12.0  \n","1      1552638400     0.0    38.0       20230    LPD         14.0  \n","2        14960202  1008.0  1032.0        5955  Other          1.0  \n","3       618728447   908.0   908.0       38549    GPD          1.0  \n","4        52296320     0.0     0.0       40955  Other          2.0  "]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":[" \n","train_hard.shape =  (6492, 13)\n","train_hard nan_count:  0\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>eeg_id</th>\n","      <th>seizure_vote</th>\n","      <th>lpd_vote</th>\n","      <th>gpd_vote</th>\n","      <th>lrda_vote</th>\n","      <th>grda_vote</th>\n","      <th>other_vote</th>\n","      <th>spectrogram_id</th>\n","      <th>min</th>\n","      <th>max</th>\n","      <th>patient_id</th>\n","      <th>target</th>\n","      <th>total_votes</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>568657</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.250000</td>\n","      <td>0.000000</td>\n","      <td>0.166667</td>\n","      <td>0.583333</td>\n","      <td>789577333</td>\n","      <td>0.0</td>\n","      <td>16.0</td>\n","      <td>20654</td>\n","      <td>Other</td>\n","      <td>12.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>582999</td>\n","      <td>0.000000</td>\n","      <td>0.857143</td>\n","      <td>0.000000</td>\n","      <td>0.071429</td>\n","      <td>0.000000</td>\n","      <td>0.071429</td>\n","      <td>1552638400</td>\n","      <td>0.0</td>\n","      <td>38.0</td>\n","      <td>20230</td>\n","      <td>LPD</td>\n","      <td>14.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1895581</td>\n","      <td>0.076923</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.076923</td>\n","      <td>0.846154</td>\n","      <td>128369999</td>\n","      <td>1138.0</td>\n","      <td>1138.0</td>\n","      <td>47999</td>\n","      <td>Other</td>\n","      <td>13.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>2482631</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.133333</td>\n","      <td>0.066667</td>\n","      <td>0.133333</td>\n","      <td>0.666667</td>\n","      <td>978166025</td>\n","      <td>1902.0</td>\n","      <td>1944.0</td>\n","      <td>20606</td>\n","      <td>Other</td>\n","      <td>15.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>2521897</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.083333</td>\n","      <td>0.083333</td>\n","      <td>0.333333</td>\n","      <td>0.500000</td>\n","      <td>673742515</td>\n","      <td>0.0</td>\n","      <td>4.0</td>\n","      <td>62117</td>\n","      <td>Other</td>\n","      <td>12.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["    eeg_id  seizure_vote  lpd_vote  gpd_vote  lrda_vote  grda_vote  \\\n","0   568657      0.000000  0.000000  0.250000   0.000000   0.166667   \n","1   582999      0.000000  0.857143  0.000000   0.071429   0.000000   \n","2  1895581      0.076923  0.000000  0.000000   0.000000   0.076923   \n","3  2482631      0.000000  0.000000  0.133333   0.066667   0.133333   \n","4  2521897      0.000000  0.000000  0.083333   0.083333   0.333333   \n","\n","   other_vote  spectrogram_id     min     max  patient_id target  total_votes  \n","0    0.583333       789577333     0.0    16.0       20654  Other         12.0  \n","1    0.071429      1552638400     0.0    38.0       20230    LPD         14.0  \n","2    0.846154       128369999  1138.0  1138.0       47999  Other         13.0  \n","3    0.666667       978166025  1902.0  1944.0       20606  Other         15.0  \n","4    0.500000       673742515     0.0     4.0       62117  Other         12.0  "]},"metadata":{},"output_type":"display_data"}],"source":["# Original Split \n","\n","train_csv = pd.read_csv(PATHS.TRAIN_CSV)\n","targets = train_csv.columns[-6:]\n","\n","print(\"targets: \", targets.to_list())\n","\n","train_csv['total_votes'] = train_csv[targets].sum(axis=1)\n","train_csv[targets] = train_csv[targets].astype('float32')\n","\n","targets_prob = [f\"{t.split('_')[0]}_prob\" for t in targets]\n","train_csv[targets_prob] = train_csv[targets].div(train_csv['total_votes'], axis=0)\n","# train_csv['rel_entropy'] = train_csv[targets_prob].apply(lambda row: sum(rel_entr([1/6]*6, row.values+1e-5)), axis=1)\n","# train_csv['entropy'] = train_csv[targets_prob].apply(lambda row: entropy(row.values), axis=1)\n","\n","# hard_csv = train_csv[train_csv['entropy'] < ModelConfig.SPLIT_ENTROPY].copy().reset_index(drop=True)\n","# hard_csv = train_csv[train_csv['entropy'] >= 0.75].copy().reset_index(drop=True)\n","hard_csv = train_csv[train_csv['total_votes'] >= 6].copy().reset_index(drop=True)\n","\n","\n","train_all = gen_non_overlap_samples(train_csv, targets)\n","train_hard = gen_non_overlap_samples(hard_csv, targets)\n","\n","print(\"train_all.shape = \", train_all.shape)\n","print(\"train_all nan_count: \", train_all.isnull().sum().sum())\n","display(train_all.head())\n","\n","print(\" \")\n","\n","print(\"train_hard.shape = \", train_hard.shape)\n","print(\"train_hard nan_count: \", train_hard.isnull().sum().sum())\n","display(train_hard.head())"]},{"cell_type":"markdown","metadata":{},"source":["# Dataset"]},{"cell_type":"code","execution_count":12,"metadata":{"trusted":true},"outputs":[],"source":["# Functional Utils\n","def butter_bandpass_filter(data, lowcut, highcut, fs, order=5):\n","    b, a = butter(order, [lowcut, highcut], fs=fs, btype='band')\n","    y = lfilter(b, a, data)\n","    return y\n","\n","def denoise_filter(x):\n","    # Sample rate and desired cutoff frequencies (in Hz).\n","    fs = 200.0\n","    lowcut = 1.0\n","    highcut = 25.0\n","    \n","    # Filter a noisy signal.\n","    T = 50\n","    nsamples = T * fs\n","    t = np.arange(0, nsamples) / fs\n","    y = butter_bandpass_filter(x, lowcut, highcut, fs, order=6)\n","    y = (y + np.roll(y,-1)+ np.roll(y,-2)+ np.roll(y,-3))/4\n","    y = y[0:-1:4]\n","    \n","    return y\n","\n","def mu_law_encoding(data, mu):\n","    mu_x = np.sign(data) * np.log(1 + mu * np.abs(data)) / np.log(mu + 1)\n","    return mu_x\n","\n","def mu_law_expansion(data, mu):\n","    s = np.sign(data) * (np.exp(np.abs(data) * np.log(mu + 1)) - 1) / mu\n","    return s\n","\n","def quantize_data(data, classes):\n","    mu_x = mu_law_encoding(data, classes)\n","    return mu_x #quantized\n","\n","def butter_lowpass_filter(data, cutoff_freq=20, sampling_rate=200, order=4):\n","    nyquist = 0.5 * sampling_rate\n","    normal_cutoff = cutoff_freq / nyquist\n","    b, a = butter(order, normal_cutoff, btype='low', analog=False)\n","    filtered_data = lfilter(b, a, data, axis=0)\n","    return filtered_data\n"]},{"cell_type":"code","execution_count":13,"metadata":{"trusted":true},"outputs":[],"source":["class EEGSeqDataset(Dataset):\n","    def __init__(self, df, config, eegs, mode='train', verbose=False):\n","        self.df = df\n","        self.mode = mode\n","        self.eegs = eegs\n","        self.verbose = verbose\n","        self.downsample = config.RESNET_GRU_DOWNSAMPLE\n","        self.use_bandpass = config.RESNET_GRU_BANDPASS\n","    \n","    def __len__(self):\n","        return len(self.df)\n","\n","    def __getitem__(self, idx):\n","        \n","        X, y_prob = self.__data_generation(idx)\n","        \n","        if self.downsample is not None:\n","            X = X[::self.downsample,:]\n","        \n","        return torch.tensor(X, dtype=torch.float32), torch.tensor(y_prob, dtype=torch.float32)\n","    \n","    def __data_generation(self, index):\n","        row = self.df.iloc[index]\n","        \n","        if self.verbose:\n","            print(f\"Row {index}\", row[['eeg_id', 'eeg_off_min', 'target']].tolist())\n","\n","        X = np.zeros((10_000, 8), dtype='float32')\n","        \n","        # # start_sec = int((row['eeg_off_min'] + row['eeg_off_max']) // 2)\n","        # eeg_seq = self.eegs[row.eeg_id]\n","        # len_seq = eeg_seq.shape[0]\n","        # start_at = int(row['eeg_off_min']) + (len_seq - 10_000) // 2 \n","        # # !!! use randomly sampled offset !!!\n","        # # start_sec = int(row['eeg_off_sample']) \n","        # data = eeg_seq[start_at:start_at+10_000, :]\n","        \n","        data = self.eegs[row.eeg_id]\n","\n","        # === Feature engineering ===\n","        X[:,0] = data[:,EEG_FEAT_INDEX['Fp1']] - data[:,EEG_FEAT_INDEX['T3']]\n","        X[:,1] = data[:,EEG_FEAT_INDEX['T3']] - data[:,EEG_FEAT_INDEX['O1']]\n","\n","        X[:,2] = data[:,EEG_FEAT_INDEX['Fp1']] - data[:,EEG_FEAT_INDEX['C3']]\n","        X[:,3] = data[:,EEG_FEAT_INDEX['C3']] - data[:,EEG_FEAT_INDEX['O1']]\n","\n","        X[:,4] = data[:,EEG_FEAT_INDEX['Fp2']] - data[:,EEG_FEAT_INDEX['C4']]\n","        X[:,5] = data[:,EEG_FEAT_INDEX['C4']] - data[:,EEG_FEAT_INDEX['O2']]\n","\n","        X[:,6] = data[:,EEG_FEAT_INDEX['Fp2']] - data[:,EEG_FEAT_INDEX['T4']]\n","        X[:,7] = data[:,EEG_FEAT_INDEX['T4']] - data[:,EEG_FEAT_INDEX['O2']]\n","\n","        # === Standarize ===\n","        X = np.clip(X,-1024, 1024)\n","        X = np.nan_to_num(X, nan=0) / 32.0\n","\n","        # === Butter Low-pass Filter ===\n","        # ??? change to bandpass filter (low=0.5, hight=20, order=2) ???\n","        if self.use_bandpass is not None:\n","            X = butter_lowpass_filter(X, self.use_bandpass[0], self.use_bandpass[1], order=2)\n","            \n","        X = butter_lowpass_filter(X) \n","        \n","        if self.mode != 'test':\n","            y_prob = row[TARGETS].values.astype(np.float32)\n","        else:\n","            y_prob = np.zeros(6, dtype='float32')\n","\n","        return X, y_prob "]},{"cell_type":"code","execution_count":14,"metadata":{"trusted":true},"outputs":[],"source":["# # visualize the dataset\n","# train_dataset = EEGSeqDataset(train_all, ModelConfig, ALL_EEG_SIGNALS, mode=\"train\")\n","# train_loader = DataLoader(train_dataset, drop_last=True, batch_size=16, num_workers=4, pin_memory=True, shuffle=False)\n","\n","# for batch in train_loader:\n","#     X, y = batch\n","#     print(f\"X shape: {X.shape}\")\n","#     print(f\"y shape: {y.shape}\")\n","    \n","#     fig, axes = plt.subplots(4, 1, figsize=(20, 20))\n","#     ax_idx = 0\n","#     for item in np.random.choice(range(X.shape[0]), 4):\n","#         offset = 0\n","#         for col in range(X.shape[-1]):\n","#             if col != 0:\n","#                 offset -= X[item,:,col].min()\n","#             axes[ax_idx].plot(np.arange(X.shape[1]), X[item,:,col]+offset, label=f'feature {col+1}')\n","#             offset += X[item,:,col].max()\n","#         print(y[item])\n","#         # axes[ax_idx].set_title(f'Weight = {weights[item]}',size=14)\n","#         axes[ax_idx].legend()\n","#         ax_idx += 1\n","#     fig.tight_layout()\n","#     plt.show()\n","#     break\n","\n","# del train_dataset, train_loader\n","# torch.cuda.empty_cache()\n","# gc.collect()"]},{"cell_type":"markdown","metadata":{},"source":["# Model"]},{"cell_type":"markdown","metadata":{},"source":["### Resnet 1D Encoder"]},{"cell_type":"code","execution_count":15,"metadata":{"jupyter":{"source_hidden":true},"trusted":true},"outputs":[],"source":["class ResNet_1D_Block(nn.Module):\n","    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, downsampling, dropout=0.0, dilation=1):\n","        super(ResNet_1D_Block, self).__init__()\n","        self.block = nn.Sequential(\n","            nn.BatchNorm1d(num_features=in_channels),\n","            nn.Hardswish(), #nn.ReLU(),\n","            nn.Dropout(p=dropout),\n","            nn.Conv1d(in_channels, out_channels, kernel_size, stride, padding, dilation=dilation, bias=False),\n","            nn.BatchNorm1d(num_features=out_channels),\n","            nn.Hardswish(), #nn.ReLU(),\n","            nn.Dropout(p=dropout),\n","            nn.Conv1d(out_channels, out_channels, kernel_size, stride, padding, dilation=dilation, bias=False),\n","            nn.MaxPool1d(kernel_size=2, stride=2, padding=0)\n","        )\n","        self.downsampling = downsampling\n","\n","    def forward(self, x):\n","        identity = self.downsampling(x)\n","        out = self.block(x)\n","        out += identity\n","        return out\n","\n","class SelfAttentionPooling(nn.Module):\n","    \"\"\"\n","    Implementation of SelfAttentionPooling \n","    Original Paper: Self-Attention Encoding and Pooling for Speaker Recognition\n","    https://arxiv.org/pdf/2008.01077v1.pdf\n","    \"\"\"\n","    def __init__(self, input_dim):\n","        super(SelfAttentionPooling, self).__init__()\n","        self.W = nn.Linear(input_dim, 1)\n","        self.softmax = nn.Softmax(dim=1)\n","        \n","    def forward(self, batch_rep):\n","        \"\"\"\n","        input:\n","            batch_rep : size (N, T, H), N: batch size, T: sequence length, H: Hidden dimension\n","        attention_weight:\n","            att_w : size (N, T, 1)\n","        return:\n","            utter_rep: size (N, H)\n","        \"\"\"\n","        att_w = self.softmax(self.W(batch_rep).squeeze(-1)).unsqueeze(-1)\n","        utter_rep = torch.sum(batch_rep * att_w, dim=1)\n","\n","        return utter_rep\n","\n","class ResNetGRU(nn.Module):\n","    def __init__(self, config=ModelConfig, num_classes=6):\n","        super(ResNetGRU, self).__init__()\n","\n","        self.planes = 24\n","        self.kernels = config.RESNET_GRU_KERNELS\n","        self.in_channels = config.RESNET_GRU_IN_CHANNELS\n","        self.use_dilation = config.RESNET_GRU_DILATED\n","\n","        fixed_kernel_size = config.RESNET_GRU_FIXED_KERNEL_SIZE\n","        hidden_size = config.RESNET_GRU_HIDDEN_SIZE\n","\n","        # Define the separate convolutional layers\n","        self.parallel_conv = self._make_parallel_conv_layers()\n","        # Define the ResNet part of the model\n","        self.resnet_part = self._make_resnet_part(fixed_kernel_size, n_blocks=9)\n","        # Define the GRU part of the model\n","        self.rnn = nn.GRU(input_size=self.in_channels, hidden_size=128, num_layers=1, bidirectional=True)\n","        self.pooling = SelfAttentionPooling(256)\n","        # Define the final fully connected layer\n","        self.fc = nn.Linear(in_features=hidden_size, out_features=num_classes)\n","\n","    def _make_parallel_conv_layers(self):\n","        return nn.ModuleList([\n","            nn.Conv1d(\n","                in_channels=self.in_channels, \n","                out_channels=self.planes, \n","                kernel_size=kernel_size,\n","                stride=1, \n","                padding=0, \n","                bias=False\n","            ) for kernel_size in self.kernels\n","        ])\n","\n","    def _make_resnet_part(self, fixed_kernel_size, n_blocks=9):\n","        # prepare resnet layers\n","        downsampling = nn.MaxPool1d(kernel_size=2, stride=2, padding=0)\n","\n","        if self.use_dilation:\n","            dilation_rates = [1, 2, 2, 2, 2, 4, 4, 4, 4] #[1] * n_blocks\n","        else:\n","            dilation_rates = [1] * n_blocks\n","\n","        paddings = [fixed_kernel_size//2 * rate for rate in dilation_rates]\n","        resnet_layers = [\n","            ResNet_1D_Block(\n","                in_channels=self.planes, \n","                out_channels=self.planes, \n","                kernel_size=fixed_kernel_size, \n","                stride=1, \n","                padding=paddings[i], \n","                downsampling=downsampling,\n","                dropout=0.0,\n","                dilation=dilation_rates[i])\n","            for i in range(n_blocks)\n","        ]\n","        # return the resnet encoder\n","        return nn.Sequential(\n","            nn.BatchNorm1d(num_features=self.planes),\n","            nn.SiLU(), #nn.ReLU(inplace=False),\n","            nn.Conv1d(\n","                in_channels=self.planes, \n","                out_channels=self.planes, \n","                kernel_size=fixed_kernel_size, \n","                stride=2, \n","                padding=2, \n","                bias=False\n","            ),\n","            *resnet_layers,\n","            nn.BatchNorm1d(num_features=self.planes),\n","            nn.SiLU(), #nn.ReLU(inplace=False),\n","            nn.AvgPool1d(kernel_size=6, stride=6, padding=2)\n","        )\n","    \n","    def forward(self, x):\n","        # extract features using resnet \n","        x = x.permute(0, 2, 1)\n","        out_sep = [conv(x) for conv in self.parallel_conv]\n","        out = torch.cat(out_sep, dim=2)\n","        out = self.resnet_part(out)\n","        out = out.reshape(out.shape[0], -1)\n","        # extract features using rnn\n","        rnn_out, _ = self.rnn(x.permute(0, 2, 1))\n","        new_rnn_h = self.pooling(rnn_out)\n","        # concatenate the features\n","        new_out = torch.cat([out, new_rnn_h], dim=1) \n","        # total features = 424 = 24*6 + 128*2 \n","        # pass through the final fully connected layer\n","        result = self.fc(new_out)  \n","        \n","        return result\n"]},{"cell_type":"markdown","metadata":{},"source":["### Dilated Inception Wavenet Encoder"]},{"cell_type":"code","execution_count":16,"metadata":{"trusted":true},"outputs":[],"source":["# from typing import List\n","\n","# class DilatedInception(nn.Module):\n","#     def __init__(self, in_channels: int, out_channels: int, kernel_sizes: List[int], dilation: int) -> None:\n","#         super().__init__()\n","#         assert out_channels % len(kernel_sizes) == 0, \"`out_channels` must be divisible by the number of kernel sizes.\"\n","#         hidden_dim = out_channels // len(kernel_sizes)\n","#         self.convs = nn.ModuleList([\n","#             nn.Conv1d(in_channels, hidden_dim, k, padding='same', dilation=dilation)\n","#             for k in kernel_sizes\n","#         ])\n","\n","#     def forward(self, x):\n","#         outputs = [conv(x) for conv in self.convs]\n","#         out = torch.cat(outputs, dim=1)\n","#         return out\n","\n","# class GatedTCN(nn.Module):\n","#     def __init__(self, in_dim: int, h_dim: int, kernel_sizes: List[int], dilation_factor: int, dropout: float = 0.0) -> None:\n","#         super().__init__()\n","#         self.filt = DilatedInception(in_dim, h_dim, kernel_sizes, dilation=dilation_factor)\n","#         self.gate = DilatedInception(in_dim, h_dim, kernel_sizes, dilation=dilation_factor)\n","#         self.dropout = nn.Dropout(dropout)\n","\n","#     def forward(self, x):\n","#         x_filt = torch.tanh(self.filt(x))\n","#         x_gate = torch.sigmoid(self.gate(x))\n","#         h = x_filt * x_gate\n","#         h = self.dropout(h)\n","#         return h\n","\n","# class WaveBlock(nn.Module):\n","#     def __init__(self, n_layers: int, in_dim: int, h_dim: int, kernel_sizes: List[int]) -> None:\n","#         super().__init__()\n","#         self.dilation_rates = [2**i for i in range(n_layers)]\n","#         self.in_conv = nn.Conv1d(in_dim, h_dim, kernel_size=1)\n","#         self.gated_tcns = nn.ModuleList([\n","#             GatedTCN(h_dim, h_dim, kernel_sizes, dilation)\n","#             for dilation in self.dilation_rates\n","#         ])\n","#         self.skip_convs = nn.ModuleList([\n","#             nn.Conv1d(h_dim, h_dim, kernel_size=1)\n","#             for _ in range(n_layers)\n","#             ])\n","#         self._initialize_weights()\n","\n","#     def _initialize_weights(self):\n","#         nn.init.xavier_uniform_(self.in_conv.weight, gain=nn.init.calculate_gain('relu'))\n","#         nn.init.zeros_(self.in_conv.bias)\n","#         for conv in self.skip_convs:\n","#             nn.init.xavier_uniform_(conv.weight, gain=nn.init.calculate_gain('relu'))\n","#             nn.init.zeros_(conv.bias)\n","\n","#     def forward(self, x):\n","#         # x: (B, C, L)\n","#         x = self.in_conv(x)\n","#         x_skip = x\n","#         for gated_tcn, skip_conv in zip(self.gated_tcns, self.skip_convs):\n","#             x = gated_tcn(x)\n","#             x = skip_conv(x)\n","#             x_skip = x_skip + x\n","#         return x_skip\n","\n","# class DilatedWaveNet(nn.Module):\n","#     \"\"\"WaveNet architecture with dilated inception conv, enhanced with list comprehension for input processing.\"\"\"\n","\n","#     def __init__(self, kernel_sizes: List[int]) -> None:\n","#         super().__init__()\n","#         self.kernel_sizes = kernel_sizes\n","        \n","#         # Initialize wave blocks with specified kernel sizes\n","#         self.wave_module = nn.Sequential(\n","#             WaveBlock(9, 8, 128, self.kernel_sizes), #12\n","#             WaveBlock(6, 128, 256, self.kernel_sizes), #8\n","#             WaveBlock(3, 256, 512, self.kernel_sizes), #4\n","#             WaveBlock(1, 512, 512, self.kernel_sizes), #1\n","#         )\n","#         self.pool_layer = nn.AdaptiveAvgPool1d(1)\n","\n","#     def forward(self, x) -> torch.Tensor:\n","#         # x: (B, L, C)\n","#         bs, seq_len, n_channels = x.shape\n","#         x = x.permute(0, 2, 1) # -> (B, C, L)\n","#         # Process different parts of the input with list comprehension\n","#         x = self.wave_module(x)\n","#         x = self.pool_layer(x) # ->(B, 512, 1)\n","#         x = x.reshape(bs, n_channels, -1).reshape(bs, n_channels//2, 2, 64)\n","#         features = x.mean(dim=2).reshape(bs, -1) # -> (16, 256)\n","# #         pooled_outputs = [(x[:, i:i+64] + x[:, i+64:i+128]) / 2 for i in range(0, n_channels, 2)]\n","# #         # Combine the pooled features and reshape for classification\n","# #         features = torch.cat(pooled_outputs, dim=1).reshape(bs, -1)\n","       \n","#         return features"]},{"cell_type":"markdown","metadata":{},"source":["### Dilated ResNet 1D Encoder"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[],"source":["# class ResnetBlock(nn.Module):\n","#     def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, dilation=1, dropout=0.0):\n","#         super(ResnetBlock, self).__init__()\n","\n","#         self.bn1 = nn.BatchNorm1d(in_channels)\n","#         self.relu1 = nn.ReLU()\n","#         self.conv1 = nn.Conv1d(\n","#             in_channels, out_channels, kernel_size, \n","#             stride=stride, \n","#             padding=dilation*(kernel_size//2), \n","#             dilation=dilation, \n","#             bias=False)\n","#         self.drop1 = nn.Dropout(p=dropout)\n","#         self.bn2 = nn.BatchNorm1d(out_channels)\n","#         self.relu2 = nn.ReLU()\n","#         self.drop2 = nn.Dropout(p=dropout)\n","#         self.conv2 = nn.Conv1d(\n","#             out_channels, out_channels, kernel_size, \n","#             stride=stride, \n","#             padding=dilation*(kernel_size//2), \n","#             dilation=dilation, \n","#             bias=False)\n","        \n","#         self.bn3 = nn.BatchNorm1d(out_channels)\n","#         self.relu3 = nn.ReLU()\n","#         self.downsample = nn.MaxPool1d(kernel_size=2, stride=2, padding=0)\n","\n","#     def forward(self, x):\n","#         identity = x\n","#         identity = self.downsample(identity)\n","\n","#         out = self.bn1(x)\n","#         out = self.relu1(out)\n","#         out = self.drop1(out)\n","#         out = self.conv1(out)\n","\n","#         out = self.bn2(out)\n","#         out = self.relu2(out)\n","#         out = self.drop2(out)\n","#         out = self.conv2(out)\n","\n","#         out = self.downsample(out)\n","\n","#         out += identity\n","#         out = self.bn3(out)\n","#         out = self.relu3(out)\n","\n","#         return out\n","\n","# class DilatedResnet(nn.Module):\n","#     def __init__(self, in_channels, out_channels, kernel_size, n_layers, expansion_factor=4):\n","#         super(DilatedResnet, self).__init__()\n","\n","#         self.in_channels = in_channels\n","#         self.kernel_size = kernel_size\n","#         self.h_dim = out_channels // n_layers\n","        \n","#         fix_kernel_size = 5\n","#         self.conv1 = nn.Conv1d(\n","#             self.in_channels, self.h_dim, kernel_size=fix_kernel_size, stride=1, padding=fix_kernel_size//2\n","#             )\n","\n","#         dilation_rates = [expansion_factor**i for i in range(n_layers)]\n","\n","#         self.blocks = nn.ModuleList([\n","#             ResnetBlock(self.h_dim, self.h_dim, self.kernel_size, dilation=dilation)\n","#             for dilation in dilation_rates\n","#         ])\n","\n","#     def forward(self, x):\n","#         x = self.conv1(x)\n","#         outputs = [ block(x) for block in self.blocks ]\n","#         output = torch.cat(outputs, dim=1)\n","        \n","#         return output\n","\n","# class DilatedResnetEncoder(nn.Module):\n","#     def __init__(self, kernel_sizes=[3, 5, 7, 9], in_channels=8, planes=24, dilate_layers=[6,3,1], expansion_factor=4):\n","#         super(DilatedResnetEncoder, self).__init__()\n","\n","#         self.in_channels = in_channels\n","#         self.planes = planes\n","#         self.kernel_sizes = kernel_sizes\n","#         self.dilate_layers = dilate_layers # must be 3 layers\n","#         self.expansion_factor = expansion_factor\n","        \n","#         # out_channels = self.planes * self.in_channels\n","#         # fix_kernel_size = 5\n","#         # self.conv1 = nn.Conv1d(\n","#         #     self.in_channels, out_channels, kernel_size=fix_kernel_size, stride=1, padding=fix_kernel_size//2\n","#         #     )\n","        \n","#         self.blocks = nn.ModuleList([\n","#             self._make_dilated_block(kernel_size)\n","#             for kernel_size in self.kernel_sizes\n","#         ])\n","\n","#         bottleneck_in_channels = self.in_channels * self.planes * self.dilate_layers[1] * self.dilate_layers[2]\n","#         bottoleneck_out_channels = self.in_channels * self.planes\n","\n","#         self.bottleneck = nn.Sequential(\n","#             nn.BatchNorm1d(num_features=bottleneck_in_channels),\n","#             nn.ReLU(),\n","#             nn.Conv1d(\n","#                 in_channels=bottleneck_in_channels,\n","#                 out_channels=bottoleneck_out_channels,\n","#                 kernel_size=1,\n","#                 stride=1,\n","#                 padding=0,\n","#                 bias=False\n","#             )\n","#         )\n","        \n","#         self.pooling = nn.AdaptiveAvgPool1d(1)\n","#         # self.blocks = nn.ModuleList([\n","#         #     nn.Sequential(*[\n","#         #         ResidualBlock(\n","#         #             out_channels, out_channels, kernel_size, dilation=dilation\n","#         #         ) for dilation in self.dilate_layers\n","#         #     ])\n","#         #     for kernel_size in self.kernel_sizes\n","#         # ])\n","\n","#     def _make_dilated_block(self, kernel_size):\n","#         out_channel_1 = self.in_channels * self.planes\n","#         block_1 = DilatedResnet(self.in_channels, out_channel_1, kernel_size, self.dilate_layers[0], self.expansion_factor)\n","\n","#         out_channel_2 = out_channel_1 * self.dilate_layers[1]\n","#         block_2 = DilatedResnet(out_channel_1, out_channel_2, kernel_size, self.dilate_layers[1], self.expansion_factor)\n","\n","#         out_channel_3 = out_channel_2 * self.dilate_layers[2]\n","#         block_3 = DilatedResnet(out_channel_2, out_channel_3, kernel_size, self.dilate_layers[2], self.expansion_factor)\n","\n","#         return nn.Sequential(block_1, block_2, block_3)\n","        \n","    \n","#     def forward(self, x):\n","#         # <- # [batch_size, seq_len=2000, in_channels=8]\n","#         x = x.permute(0, 2, 1)\n","#         # x = self.conv1(x)\n","#         outputs = [ block(x) for block in self.blocks ]\n","#         outputs = [ self.bottleneck(out) for out in outputs ]\n","#         output = torch.cat(outputs, dim=1)\n","#         output = self.pooling(output).squeeze(-1)\n","        \n","#         return output"]},{"cell_type":"code","execution_count":18,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["X shape: torch.Size([16, 2000, 8])\n","y shape: torch.Size([16, 6])\n","torch.Size([16, 6])\n"]},{"data":{"text/plain":["0"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["train_dataset = EEGSeqDataset(train_all, ModelConfig, ALL_EEG_SIGNALS, mode=\"train\")\n","train_loader = DataLoader(train_dataset, drop_last=True, batch_size=16, num_workers=4, pin_memory=True, shuffle=False)\n","\n","model = ResNetGRU(config=ModelConfig, num_classes=6)\n","\n","model.to(DEVICE)\n","for i, batch in enumerate(train_loader):\n","    X, y = batch\n","    X = X.to(DEVICE)\n","    y = y.to(DEVICE)\n","    print(f\"X shape: {X.shape}\")\n","    print(f\"y shape: {y.shape}\")\n","    \n","    y_pred = model(X)\n","    print(y_pred.shape)\n","    break \n","\n","del model, train_dataset, train_loader, X, y\n","torch.cuda.empty_cache()\n","gc.collect()"]},{"cell_type":"code","execution_count":19,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Fri Apr  5 14:16:19 2024       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 470.239.06   Driver Version: 470.239.06   CUDA Version: 11.4     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  NVIDIA GeForce ...  Off  | 00000000:0B:00.0 Off |                  N/A |\n","| 26%   36C    P2    55W / 260W |   1605MiB / 11019MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|    0   N/A  N/A      1423      G   /usr/lib/xorg/Xorg                  9MiB |\n","|    0   N/A  N/A      1822      G   /usr/bin/gnome-shell                4MiB |\n","|    0   N/A  N/A    477648      C   ...a3/envs/kaggle/bin/python     1587MiB |\n","+-----------------------------------------------------------------------------+\n"]}],"source":["!nvidia-smi"]},{"cell_type":"markdown","metadata":{},"source":["# Train"]},{"cell_type":"code","execution_count":20,"metadata":{"trusted":true},"outputs":[],"source":["\n","class AverageMeter(object):\n","    \"\"\"Computes and stores the average and current value\"\"\"\n","\n","    def __init__(self):\n","        self.reset()\n","\n","    def reset(self):\n","        self.val = 0\n","        self.avg = 0\n","        self.sum = 0\n","        self.count = 0\n","\n","    def update(self, val, n=1):\n","        self.val = val\n","        self.sum += val * n\n","        self.count += n\n","        self.avg = self.sum / self.count\n","        \n","class Trainer:\n","\n","    def __init__(self, model, config, logger):\n","\n","        self.model = model\n","        self.logger = logger\n","        self.config = config\n","        \n","        self.early_stop_rounds = config.EARLY_STOP_ROUNDS\n","        self.early_stop_counter = 0\n","        \n","        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","        self.kl_div_loss = nn.KLDivLoss(reduction='batchmean')\n","        self.ce_loss = nn.CrossEntropyLoss()\n","        self.gamma = config.REGULARIZATION\n","        \n","        # self.criterion = nn.KLDivLoss(reduction=\"batchmean\")\n","    \n","    def criterion(self, y_pred, y_true, weights=None, mode='train'):\n","        kl_loss = self.kl_div_loss(F.log_softmax(y_pred, dim=1), y_true)\n","        if (self.gamma is not None) & (mode == 'train'):\n","            softmax_probs = F.softmax(y_pred, dim=1)  # Compute softmax probabilities\n","            entropy_loss = -(softmax_probs * torch.log(softmax_probs + 1e-9)).sum(dim=1).mean(dim=0) # Compute entropy, add epsilon to avoid log(0)\n","            return kl_loss - self.gamma * entropy_loss\n","        else:\n","            return kl_loss\n","        \n","    def train(self, train_loader, valid_loader, from_checkpoint=None):\n","\n","        self.optimizer = AdamW(self.model.parameters(), lr=8e-3, weight_decay=self.config.WEIGHT_DECAY)\n","\n","        # CosineAnnealingWarmRestarts( \n","        #     self.optimizer,\n","        #     T_0=20,\n","        #     eta_min=1e-6,\n","        #     T_mult=1,\n","        #     last_epoch=-1\n","        # )\n","        self.scheduler =  OneCycleLR(\n","            self.optimizer,\n","            max_lr=1e-4,\n","            epochs=self.config.EPOCHS,\n","            steps_per_epoch=len(train_loader),\n","            pct_start=0.1,\n","            anneal_strategy=\"cos\",\n","            final_div_factor=100,\n","        )\n","\n","        if from_checkpoint is not None:\n","            self.model.load_state_dict(torch.load(from_checkpoint, map_location=self.device))\n","\n","        self.model.to(self.device)\n","        best_weights, best_preds, best_loss = None, None, float(\"inf\")\n","        loss_records = {\"train\": [], \"valid\": []}\n","\n","        for epoch in range(self.config.EPOCHS):\n","            start_epoch = time()\n","\n","            train_loss, _ = self._train_or_valid_epoch(epoch, train_loader, is_train=True)\n","            valid_loss, valid_preds = self._train_or_valid_epoch(epoch, valid_loader, is_train=False)\n","\n","            loss_records[\"train\"].append(train_loss)\n","            loss_records[\"valid\"].append(valid_loss)\n","\n","            elapsed = time() - start_epoch\n","\n","            info = f\"{'-' * 100}\\nEpoch {epoch + 1} - \"\n","            info += f\"Average Loss: (train) {train_loss:.4f}; (valid) {valid_loss:.4f} | Time: {elapsed:.2f}s\"\n","            self.logger.info(info)\n","\n","            if valid_loss < best_loss:\n","                best_loss = valid_loss\n","                best_weights = self.model.state_dict()\n","                best_preds = valid_preds\n","                self.logger.info(f\"Best model found in epoch {epoch + 1} | valid loss: {best_loss:.4f}\")\n","                self.early_stop_counter = 0\n","            \n","            else:\n","                self.early_stop_counter += 1\n","                if self.early_stop_counter >= self.early_stop_rounds:\n","                    self.logger.info(f\"Early stopping at epoch {epoch + 1}\")\n","                    break\n","\n","        return best_weights, best_preds, loss_records\n","\n","    def _train_or_valid_epoch(self, epoch_id, dataloader, is_train=True):\n","\n","        self.model.train() if is_train else self.model.eval()\n","        mode = \"Train\" if is_train else \"Valid\"\n","\n","        len_loader = len(dataloader)\n","        scaler = GradScaler(enabled=self.config.AMP)\n","        loss_meter, predicts_record = AverageMeter(), []\n","\n","        start = time()\n","        pbar = tqdm(dataloader, total=len(dataloader), unit=\"batch\", desc=f\"{mode} [{epoch_id}]\")\n","        for step, (X, y) in enumerate(pbar):\n","            X, y = X.to(self.device), y.to(self.device)\n","\n","            if is_train:\n","                with autocast(enabled=self.config.AMP):\n","                    y_pred = self.model(X)\n","                    loss = self.criterion(y_pred, y)\n","                if self.config.GRADIENT_ACCUMULATION_STEPS > 1:\n","                    loss = loss / self.config.GRADIENT_ACCUMULATION_STEPS\n","                scaler.scale(loss).backward()\n","                grad_norm = torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.config.MAX_GRAD_NORM)\n","                if (step + 1) % self.config.GRADIENT_ACCUMULATION_STEPS == 0:\n","                    scaler.step(self.optimizer)\n","                    scaler.update()\n","                    self.optimizer.zero_grad()\n","                    self.scheduler.step()\n","            else:\n","                with torch.no_grad():\n","                    y_pred = self.model(X)\n","                    loss = self.criterion(y_pred, y, mode='valid')\n","                if self.config.GRADIENT_ACCUMULATION_STEPS > 1:\n","                    loss = loss / self.config.GRADIENT_ACCUMULATION_STEPS\n","                \n","                predicts_record.append(y_pred.to('cpu').numpy())\n","            \n","            loss_meter.update(loss.item(), y.size(0))\n","            end = time()\n","\n","            if (step % self.config.PRINT_FREQ == 0) or (step == (len_loader - 1)):\n","                lr = self.scheduler.get_last_lr()[0]\n","                info = f\"Epoch {epoch_id + 1} [{step}/{len_loader}] | {mode} Loss: {loss_meter.avg:.4f}\"\n","                if is_train:\n","                    info += f\" Grad: {grad_norm:.4f} LR: {lr:.4e}\"\n","                info += f\" | Elapse: {end - start:.2f}s\"\n","                print(info)\n","\n","        if not is_train:\n","            predicts_record = np.concatenate(predicts_record)\n","            \n","        return loss_meter.avg, predicts_record\n"]},{"cell_type":"code","execution_count":21,"metadata":{"trusted":true},"outputs":[],"source":["def train_fold(model, fold_id, train_folds, valid_folds, logger, stage=1, checkpoint=None):\n","\n","    train_dataset = EEGSeqDataset(train_folds, ModelConfig, ALL_EEG_SIGNALS, mode=\"train\")\n","    valid_dataset = EEGSeqDataset(valid_folds, ModelConfig, ALL_EEG_SIGNALS, mode=\"valid\")\n","\n","    # ======== DATALOADERS ==========\n","    loader_kwargs = {\n","        \"batch_size\": ModelConfig.BATCH_SIZE,\n","        \"num_workers\": ModelConfig.NUM_WORKERS,\n","        \"pin_memory\": True,\n","        \"shuffle\": False,\n","    }\n","\n","    train_loader = DataLoader(train_dataset, drop_last=True, collate_fn=None, **loader_kwargs)\n","    valid_loader = DataLoader(valid_dataset, drop_last=False, collate_fn=None, **loader_kwargs)\n","\n","    if checkpoint is not None:\n","        print(f\"Loading model from checkpoint: {checkpoint}\")\n","\n","    trainer = Trainer(model, ModelConfig, logger)\n","    best_weights, best_preds, loss_records = trainer.train(\n","        train_loader, valid_loader, from_checkpoint=checkpoint)\n","\n","    save_model_name = f\"{ModelConfig.MODEL_NAME}_fold_{fold_id}_stage_{stage}.pth\"\n","    torch.save(best_weights, os.path.join(PATHS.OUTPUT_DIR, save_model_name))\n","\n","    del train_dataset, valid_dataset, train_loader, valid_loader\n","    torch.cuda.empty_cache()\n","    gc.collect()\n","\n","    return best_preds, loss_records"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[],"source":["def evaluate_oof(oof_df):\n","    '''\n","    Evaluate the out-of-fold dataframe using KL Divergence (torch and kaggle)\n","    '''\n","    kl_loss = nn.KLDivLoss(reduction=\"batchmean\")\n","    labels = torch.tensor(oof_df[TARGETS].values.astype('float32'))\n","    preds = F.log_softmax(\n","        torch.tensor(oof_df[TARGETS_PRED].values.astype('float32'), requires_grad=False),\n","        dim=1\n","    )\n","    kl_torch = kl_loss(preds, labels).item()\n","\n","    return kl_torch"]},{"cell_type":"code","execution_count":23,"metadata":{"trusted":true},"outputs":[],"source":["from kl_divergence import score as kaggle_score \n","from sklearn.metrics import confusion_matrix\n","import seaborn as sns\n","\n","TARGET2ID = {'Seizure': 0, 'LPD': 1, 'GPD': 2, 'LRDA': 3, 'GRDA': 4, 'Other': 5}\n","\n","def calc_kaggle_score(oof_df):\n","    submission_df = oof_df[['eeg_id']+TARGETS_PRED].copy()\n","    submission_df.columns = ['eeg_id'] + TARGETS\n","    solution_df = oof_df[['eeg_id']+TARGETS].copy()\n","    return kaggle_score(solution_df, submission_df, 'eeg_id')\n","\n","def analyze_oof(oof_csv):\n","\n","    kl_criteria = nn.KLDivLoss(reduction='batchmean')\n","    softmax = nn.Softmax(dim=1)\n","\n","    oof_df = pd.read_csv(oof_csv)\n","    oof_df['target_pred'] = oof_df[TARGETS_PRED].apply(lambda x: np.argmax(x), axis=1)\n","    oof_df['target_id'] = oof_df[TARGETS].apply(lambda x: np.argmax(x), axis=1)\n","    \n","    oof_df[\"kl_loss\"] = oof_df.apply(\n","    lambda row: \n","        kl_criteria(\n","            F.log_softmax(\n","                    torch.tensor(row[TARGETS_PRED].values.astype(np.float32)).unsqueeze(0)\n","                , dim=1\n","                ), \n","            torch.tensor(row[TARGETS].values.astype(np.float32))\n","            ).numpy(),\n","    axis=1)\n","\n","    oof_df[\"kl_loss\"] = oof_df['kl_loss'].astype(np.float32)\n","\n","    oof_df[TARGETS_PRED] = softmax( torch.tensor(oof_df[TARGETS_PRED].values.astype(np.float32)) )\n","\n","    oof_df.head()\n","\n","    return oof_df"]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[],"source":["def prepare_k_fold(df, k_folds=5):\n","\n","    kf = KFold(n_splits=k_folds, shuffle=True, random_state=ModelConfig.SEED)\n","    unique_spec_id = df['spectrogram_id'].unique()\n","    df['fold'] = k_folds\n","\n","    for fold, (train_index, valid_index) in enumerate(kf.split(unique_spec_id)):\n","        df.loc[df['spectrogram_id'].isin(unique_spec_id[valid_index]), 'fold'] = fold\n","\n","    return df"]},{"cell_type":"code","execution_count":25,"metadata":{"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["****************************************************************************************************\n","Script Start: Fri Apr  5 14:16:28 2024\n","Model Configurations:\n","SEED: 20\n","SPLIT_ENTROPY: 5.5\n","MODEL_NAME: ResnetGRU_v1_LB048\n","MODEL_BACKBONE: reset_gru\n","BATCH_SIZE: 32\n","EPOCHS: 20\n","EARLY_STOP_ROUNDS: 5\n","GRADIENT_ACCUMULATION_STEPS: 1\n","DROP_RATE: 0.15\n","DROP_PATH_RATE: 0.25\n","WEIGHT_DECAY: 0.01\n","AMP: True\n","PRINT_FREQ: 100\n","NUM_WORKERS: 0\n","MAX_GRAD_NORM: 10000000.0\n","REGULARIZATION: 0.15\n","RESNET_GRU_BANDPASS: None\n","RESNET_GRU_IN_CHANNELS: 8\n","RESNET_GRU_KERNELS: [3, 5, 7, 9, 11]\n","RESNET_GRU_FIXED_KERNEL_SIZE: 5\n","RESNET_GRU_DOWNSAMPLE: 5\n","RESNET_GRU_HIDDEN_SIZE: 304\n","RESNET_GRU_DILATED: False\n","****************************************************************************************************\n","====================================================================================================\n","Fold: 0\n","====================================================================================================\n","- Stage 1 | Train: 16195; Valid: 3988 -\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"96e310eb6de74c41a0bde26874b2c2a0","version_major":2,"version_minor":0},"text/plain":["Train [0]:   0%|          | 0/506 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 1 [0/506] | Train Loss: 1.2684 Grad: 80195.3828 LR: 4.0002e-06 | Elapse: 0.23s\n","Epoch 1 [100/506] | Train Loss: 1.1780 Grad: 91877.4531 LR: 6.3447e-06 | Elapse: 6.03s\n","Epoch 1 [200/506] | Train Loss: 1.1851 Grad: 78362.3906 LR: 1.3062e-05 | Elapse: 11.85s\n","Epoch 1 [300/506] | Train Loss: 1.1739 Grad: 52261.8555 LR: 2.3509e-05 | Elapse: 17.65s\n","Epoch 1 [400/506] | Train Loss: 1.1569 Grad: 65165.1328 LR: 3.6686e-05 | Elapse: 23.46s\n","Epoch 1 [500/506] | Train Loss: 1.1345 Grad: 50491.7734 LR: 5.1329e-05 | Elapse: 29.27s\n","Epoch 1 [505/506] | Train Loss: 1.1335 Grad: 49006.5547 LR: 5.2075e-05 | Elapse: 29.56s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"726a1e7b123349a89d4290fd3856e023","version_major":2,"version_minor":0},"text/plain":["Valid [0]:   0%|          | 0/125 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 1 [0/125] | Valid Loss: 1.2688 | Elapse: 0.07s\n","Epoch 1 [100/125] | Valid Loss: 1.3073 | Elapse: 5.09s\n"]},{"name":"stderr","output_type":"stream","text":["----------------------------------------------------------------------------------------------------\n","Epoch 1 - Average Loss: (train) 1.1335; (valid) 1.3002 | Time: 35.85s\n","Best model found in epoch 1 | valid loss: 1.3002\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1 [124/125] | Valid Loss: 1.3002 | Elapse: 6.28s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5e63e29ea634426eafc959af573cc774","version_major":2,"version_minor":0},"text/plain":["Train [1]:   0%|          | 0/506 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 2 [0/506] | Train Loss: 1.0906 Grad: 53102.0742 LR: 5.2224e-05 | Elapse: 0.06s\n","Epoch 2 [100/506] | Train Loss: 1.0051 Grad: 114642.4766 LR: 6.6890e-05 | Elapse: 5.93s\n","Epoch 2 [200/506] | Train Loss: 1.0109 Grad: 54453.7422 LR: 8.0129e-05 | Elapse: 11.80s\n","Epoch 2 [300/506] | Train Loss: 1.0020 Grad: 49530.3711 LR: 9.0674e-05 | Elapse: 17.65s\n","Epoch 2 [400/506] | Train Loss: 0.9903 Grad: 42100.6680 LR: 9.7515e-05 | Elapse: 23.48s\n","Epoch 2 [500/506] | Train Loss: 0.9761 Grad: 49098.9688 LR: 9.9996e-05 | Elapse: 29.30s\n","Epoch 2 [505/506] | Train Loss: 0.9753 Grad: 72887.2188 LR: 1.0000e-04 | Elapse: 29.59s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"da3109a0e6e842bb84688d003c544fa0","version_major":2,"version_minor":0},"text/plain":["Valid [1]:   0%|          | 0/125 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 2 [0/125] | Valid Loss: 0.9886 | Elapse: 0.05s\n","Epoch 2 [100/125] | Valid Loss: 1.1559 | Elapse: 5.03s\n"]},{"name":"stderr","output_type":"stream","text":["----------------------------------------------------------------------------------------------------\n","Epoch 2 - Average Loss: (train) 0.9753; (valid) 1.1520 | Time: 35.80s\n","Best model found in epoch 2 | valid loss: 1.1520\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 2 [124/125] | Valid Loss: 1.1520 | Elapse: 6.21s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"58b8cb3374884250a3c50f6fb006bfc1","version_major":2,"version_minor":0},"text/plain":["Train [2]:   0%|          | 0/506 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 3 [0/506] | Train Loss: 1.0148 Grad: 54527.7500 LR: 1.0000e-04 | Elapse: 0.06s\n","Epoch 3 [100/506] | Train Loss: 0.8859 Grad: 143155.5938 LR: 9.9969e-05 | Elapse: 5.90s\n","Epoch 3 [200/506] | Train Loss: 0.8889 Grad: 76853.5703 LR: 9.9879e-05 | Elapse: 11.75s\n","Epoch 3 [300/506] | Train Loss: 0.8759 Grad: 64058.4180 LR: 9.9729e-05 | Elapse: 17.59s\n","Epoch 3 [400/506] | Train Loss: 0.8652 Grad: 101814.7109 LR: 9.9520e-05 | Elapse: 23.43s\n","Epoch 3 [500/506] | Train Loss: 0.8544 Grad: 112661.5781 LR: 9.9253e-05 | Elapse: 29.33s\n","Epoch 3 [505/506] | Train Loss: 0.8536 Grad: 172687.9688 LR: 9.9238e-05 | Elapse: 29.62s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"cc415f5c6ce946f79ecc379db455477e","version_major":2,"version_minor":0},"text/plain":["Valid [2]:   0%|          | 0/125 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 3 [0/125] | Valid Loss: 0.8720 | Elapse: 0.05s\n","Epoch 3 [100/125] | Valid Loss: 1.0324 | Elapse: 5.06s\n"]},{"name":"stderr","output_type":"stream","text":["----------------------------------------------------------------------------------------------------\n","Epoch 3 - Average Loss: (train) 0.8536; (valid) 1.0284 | Time: 35.88s\n","Best model found in epoch 3 | valid loss: 1.0284\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 3 [124/125] | Valid Loss: 1.0284 | Elapse: 6.25s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"cdc2954f87f54c7190f683bb82a567ee","version_major":2,"version_minor":0},"text/plain":["Train [3]:   0%|          | 0/506 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 4 [0/506] | Train Loss: 0.9465 Grad: 107741.2969 LR: 9.9235e-05 | Elapse: 0.06s\n","Epoch 4 [100/506] | Train Loss: 0.7908 Grad: 168054.0625 LR: 9.8905e-05 | Elapse: 5.92s\n","Epoch 4 [200/506] | Train Loss: 0.7956 Grad: 95452.7344 LR: 9.8517e-05 | Elapse: 11.76s\n","Epoch 4 [300/506] | Train Loss: 0.7864 Grad: 108433.1328 LR: 9.8071e-05 | Elapse: 17.64s\n","Epoch 4 [400/506] | Train Loss: 0.7799 Grad: 142799.2656 LR: 9.7569e-05 | Elapse: 23.51s\n","Epoch 4 [500/506] | Train Loss: 0.7705 Grad: 185971.6250 LR: 9.7009e-05 | Elapse: 29.36s\n","Epoch 4 [505/506] | Train Loss: 0.7697 Grad: 243632.0938 LR: 9.6980e-05 | Elapse: 29.66s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"abb32e6d42ce485f9cc06d2ef98a54cb","version_major":2,"version_minor":0},"text/plain":["Valid [3]:   0%|          | 0/125 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 4 [0/125] | Valid Loss: 0.7766 | Elapse: 0.06s\n","Epoch 4 [100/125] | Valid Loss: 0.9451 | Elapse: 5.05s\n"]},{"name":"stderr","output_type":"stream","text":["----------------------------------------------------------------------------------------------------\n","Epoch 4 - Average Loss: (train) 0.7697; (valid) 0.9418 | Time: 35.89s\n","Best model found in epoch 4 | valid loss: 0.9418\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 4 [124/125] | Valid Loss: 0.9418 | Elapse: 6.23s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"43a2170454b840499a9aa8bd2a2e1f66","version_major":2,"version_minor":0},"text/plain":["Train [4]:   0%|          | 0/506 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 5 [0/506] | Train Loss: 0.8508 Grad: 142093.4844 LR: 9.6974e-05 | Elapse: 0.06s\n","Epoch 5 [100/506] | Train Loss: 0.7134 Grad: 200724.8281 LR: 9.6355e-05 | Elapse: 5.92s\n","Epoch 5 [200/506] | Train Loss: 0.7141 Grad: 124650.0859 LR: 9.5682e-05 | Elapse: 11.78s\n","Epoch 5 [300/506] | Train Loss: 0.7060 Grad: 171952.1875 LR: 9.4954e-05 | Elapse: 17.64s\n","Epoch 5 [400/506] | Train Loss: 0.7010 Grad: 192114.5469 LR: 9.4172e-05 | Elapse: 23.44s\n","Epoch 5 [500/506] | Train Loss: 0.6930 Grad: 230700.6406 LR: 9.3338e-05 | Elapse: 29.22s\n","Epoch 5 [505/506] | Train Loss: 0.6923 Grad: 306685.9062 LR: 9.3295e-05 | Elapse: 29.51s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a975437aa54d44e2b829fabfe1a46408","version_major":2,"version_minor":0},"text/plain":["Valid [4]:   0%|          | 0/125 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 5 [0/125] | Valid Loss: 0.6830 | Elapse: 0.05s\n","Epoch 5 [100/125] | Valid Loss: 0.8775 | Elapse: 4.99s\n"]},{"name":"stderr","output_type":"stream","text":["----------------------------------------------------------------------------------------------------\n","Epoch 5 - Average Loss: (train) 0.6923; (valid) 0.8740 | Time: 35.68s\n","Best model found in epoch 5 | valid loss: 0.8740\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 5 [124/125] | Valid Loss: 0.8740 | Elapse: 6.17s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"09b53a6bef2e49d68c5305fbeb60ebb7","version_major":2,"version_minor":0},"text/plain":["Train [5]:   0%|          | 0/506 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 6 [0/506] | Train Loss: 0.7521 Grad: 217481.0156 LR: 9.3287e-05 | Elapse: 0.06s\n","Epoch 6 [100/506] | Train Loss: 0.6364 Grad: 214858.6406 LR: 9.2398e-05 | Elapse: 5.90s\n","Epoch 6 [200/506] | Train Loss: 0.6395 Grad: 179513.4375 LR: 9.1459e-05 | Elapse: 11.74s\n","Epoch 6 [300/506] | Train Loss: 0.6331 Grad: 243579.5781 LR: 9.0471e-05 | Elapse: 17.55s\n","Epoch 6 [400/506] | Train Loss: 0.6307 Grad: 178296.9688 LR: 8.9434e-05 | Elapse: 23.34s\n","Epoch 6 [500/506] | Train Loss: 0.6247 Grad: 282665.1562 LR: 8.8351e-05 | Elapse: 29.17s\n","Epoch 6 [505/506] | Train Loss: 0.6240 Grad: 348618.1562 LR: 8.8296e-05 | Elapse: 29.45s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6928e02b1a9c4a7caadfebe4fb23fe29","version_major":2,"version_minor":0},"text/plain":["Valid [5]:   0%|          | 0/125 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 6 [0/125] | Valid Loss: 0.6522 | Elapse: 0.06s\n","Epoch 6 [100/125] | Valid Loss: 0.8300 | Elapse: 4.94s\n"]},{"name":"stderr","output_type":"stream","text":["----------------------------------------------------------------------------------------------------\n","Epoch 6 - Average Loss: (train) 0.6240; (valid) 0.8277 | Time: 35.55s\n","Best model found in epoch 6 | valid loss: 0.8277\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 6 [124/125] | Valid Loss: 0.8277 | Elapse: 6.10s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4c3245f93b4646479267cffbb8fce83b","version_major":2,"version_minor":0},"text/plain":["Train [6]:   0%|          | 0/506 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 7 [0/506] | Train Loss: 0.6522 Grad: 261430.0000 LR: 8.8285e-05 | Elapse: 0.06s\n","Epoch 7 [100/506] | Train Loss: 0.5753 Grad: 273790.9375 LR: 8.7153e-05 | Elapse: 5.83s\n","Epoch 7 [200/506] | Train Loss: 0.5823 Grad: 232632.1719 LR: 8.5977e-05 | Elapse: 11.55s\n","Epoch 7 [300/506] | Train Loss: 0.5779 Grad: 312131.6875 LR: 8.4759e-05 | Elapse: 17.34s\n","Epoch 7 [400/506] | Train Loss: 0.5773 Grad: 207232.3750 LR: 8.3499e-05 | Elapse: 23.13s\n","Epoch 7 [500/506] | Train Loss: 0.5733 Grad: 336507.2500 LR: 8.2199e-05 | Elapse: 28.98s\n","Epoch 7 [505/506] | Train Loss: 0.5726 Grad: 408953.1562 LR: 8.2133e-05 | Elapse: 29.27s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4b5a177c31364c5095164a00692a8771","version_major":2,"version_minor":0},"text/plain":["Valid [6]:   0%|          | 0/125 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 7 [0/125] | Valid Loss: 0.6340 | Elapse: 0.05s\n","Epoch 7 [100/125] | Valid Loss: 0.8045 | Elapse: 5.04s\n"]},{"name":"stderr","output_type":"stream","text":["----------------------------------------------------------------------------------------------------\n","Epoch 7 - Average Loss: (train) 0.5726; (valid) 0.8025 | Time: 35.48s\n","Best model found in epoch 7 | valid loss: 0.8025\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 7 [124/125] | Valid Loss: 0.8025 | Elapse: 6.21s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6fda5a39de72464ca5fc9eb050b99a69","version_major":2,"version_minor":0},"text/plain":["Train [7]:   0%|          | 0/506 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 8 [0/506] | Train Loss: 0.5914 Grad: 293529.8438 LR: 8.2120e-05 | Elapse: 0.06s\n","Epoch 8 [100/506] | Train Loss: 0.5344 Grad: 408541.4062 LR: 8.0780e-05 | Elapse: 5.87s\n","Epoch 8 [200/506] | Train Loss: 0.5428 Grad: 296973.5000 LR: 7.9403e-05 | Elapse: 11.70s\n","Epoch 8 [300/506] | Train Loss: 0.5387 Grad: 318389.6250 LR: 7.7991e-05 | Elapse: 17.51s\n","Epoch 8 [400/506] | Train Loss: 0.5389 Grad: 249331.1094 LR: 7.6546e-05 | Elapse: 23.32s\n","Epoch 8 [500/506] | Train Loss: 0.5360 Grad: 399929.4688 LR: 7.5070e-05 | Elapse: 29.14s\n","Epoch 8 [505/506] | Train Loss: 0.5354 Grad: 449000.7812 LR: 7.4995e-05 | Elapse: 29.43s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"fce59f88f40f423f8cb00c05c9ac8e8d","version_major":2,"version_minor":0},"text/plain":["Valid [7]:   0%|          | 0/125 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 8 [0/125] | Valid Loss: 0.6372 | Elapse: 0.05s\n","Epoch 8 [100/125] | Valid Loss: 0.7918 | Elapse: 4.98s\n"]},{"name":"stderr","output_type":"stream","text":["----------------------------------------------------------------------------------------------------\n","Epoch 8 - Average Loss: (train) 0.5354; (valid) 0.7886 | Time: 35.57s\n","Best model found in epoch 8 | valid loss: 0.7886\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 8 [124/125] | Valid Loss: 0.7886 | Elapse: 6.13s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0b819fe554df40dca17fd2a39608cbf8","version_major":2,"version_minor":0},"text/plain":["Train [8]:   0%|          | 0/506 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 9 [0/506] | Train Loss: 0.5614 Grad: 322659.9375 LR: 7.4980e-05 | Elapse: 0.06s\n","Epoch 9 [100/506] | Train Loss: 0.5018 Grad: 373975.7188 LR: 7.3472e-05 | Elapse: 5.89s\n","Epoch 9 [200/506] | Train Loss: 0.5112 Grad: 321378.5625 LR: 7.1936e-05 | Elapse: 11.69s\n","Epoch 9 [300/506] | Train Loss: 0.5073 Grad: 355235.1875 LR: 7.0374e-05 | Elapse: 17.51s\n","Epoch 9 [400/506] | Train Loss: 0.5073 Grad: 301291.4062 LR: 6.8788e-05 | Elapse: 23.32s\n","Epoch 9 [500/506] | Train Loss: 0.5052 Grad: 454428.0000 LR: 6.7179e-05 | Elapse: 29.16s\n","Epoch 9 [505/506] | Train Loss: 0.5045 Grad: 425457.8750 LR: 6.7098e-05 | Elapse: 29.45s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3a4b6609c8d74644836efe731b257ac3","version_major":2,"version_minor":0},"text/plain":["Valid [8]:   0%|          | 0/125 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 9 [0/125] | Valid Loss: 0.6402 | Elapse: 0.06s\n","Epoch 9 [100/125] | Valid Loss: 0.7847 | Elapse: 5.01s\n"]},{"name":"stderr","output_type":"stream","text":["----------------------------------------------------------------------------------------------------\n","Epoch 9 - Average Loss: (train) 0.5045; (valid) 0.7813 | Time: 35.64s\n","Best model found in epoch 9 | valid loss: 0.7813\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 9 [124/125] | Valid Loss: 0.7813 | Elapse: 6.18s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"803b868522044ff39e6aca5492c8728f","version_major":2,"version_minor":0},"text/plain":["Train [9]:   0%|          | 0/506 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 10 [0/506] | Train Loss: 0.5404 Grad: 351547.0312 LR: 6.7082e-05 | Elapse: 0.06s\n","Epoch 10 [100/506] | Train Loss: 0.4766 Grad: 345213.4375 LR: 6.5452e-05 | Elapse: 5.87s\n","Epoch 10 [200/506] | Train Loss: 0.4845 Grad: 323537.2500 LR: 6.3803e-05 | Elapse: 11.68s\n","Epoch 10 [300/506] | Train Loss: 0.4804 Grad: 345002.1875 LR: 6.2138e-05 | Elapse: 17.48s\n","Epoch 10 [400/506] | Train Loss: 0.4806 Grad: 323527.0625 LR: 6.0459e-05 | Elapse: 23.29s\n","Epoch 10 [500/506] | Train Loss: 0.4794 Grad: 480301.7188 LR: 5.8767e-05 | Elapse: 29.10s\n","Epoch 10 [505/506] | Train Loss: 0.4788 Grad: 420606.3750 LR: 5.8682e-05 | Elapse: 29.39s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4b12274dab6c4b99b166626b8e1e99a7","version_major":2,"version_minor":0},"text/plain":["Valid [9]:   0%|          | 0/125 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 10 [0/125] | Valid Loss: 0.6448 | Elapse: 0.05s\n","Epoch 10 [100/125] | Valid Loss: 0.7819 | Elapse: 4.94s\n"]},{"name":"stderr","output_type":"stream","text":["----------------------------------------------------------------------------------------------------\n","Epoch 10 - Average Loss: (train) 0.4788; (valid) 0.7780 | Time: 35.50s\n","Best model found in epoch 10 | valid loss: 0.7780\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 10 [124/125] | Valid Loss: 0.7780 | Elapse: 6.11s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ede953e2953d46348a58acae3ff8796e","version_major":2,"version_minor":0},"text/plain":["Train [10]:   0%|          | 0/506 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 11 [0/506] | Train Loss: 0.5322 Grad: 384572.7500 LR: 5.8665e-05 | Elapse: 0.06s\n","Epoch 11 [100/506] | Train Loss: 0.4544 Grad: 477156.4062 LR: 5.6962e-05 | Elapse: 5.90s\n","Epoch 11 [200/506] | Train Loss: 0.4614 Grad: 327621.5000 LR: 5.5251e-05 | Elapse: 11.68s\n","Epoch 11 [300/506] | Train Loss: 0.4578 Grad: 344887.4688 LR: 5.3534e-05 | Elapse: 17.47s\n","Epoch 11 [400/506] | Train Loss: 0.4579 Grad: 358464.0000 LR: 5.1813e-05 | Elapse: 23.24s\n","Epoch 11 [500/506] | Train Loss: 0.4573 Grad: 448427.0312 LR: 5.0089e-05 | Elapse: 29.05s\n","Epoch 11 [505/506] | Train Loss: 0.4567 Grad: 392904.2812 LR: 5.0003e-05 | Elapse: 29.34s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"86ef9413730f4549b653c741f1798cae","version_major":2,"version_minor":0},"text/plain":["Valid [10]:   0%|          | 0/125 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 11 [0/125] | Valid Loss: 0.6481 | Elapse: 0.05s\n","Epoch 11 [100/125] | Valid Loss: 0.7784 | Elapse: 4.96s\n"]},{"name":"stderr","output_type":"stream","text":["----------------------------------------------------------------------------------------------------\n","Epoch 11 - Average Loss: (train) 0.4567; (valid) 0.7743 | Time: 35.50s\n","Best model found in epoch 11 | valid loss: 0.7743\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 11 [124/125] | Valid Loss: 0.7743 | Elapse: 6.15s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"87f62efaa8a24848963f18ce22707f71","version_major":2,"version_minor":0},"text/plain":["Train [11]:   0%|          | 0/506 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 12 [0/506] | Train Loss: 0.5248 Grad: 403977.9375 LR: 4.9986e-05 | Elapse: 0.06s\n","Epoch 12 [100/506] | Train Loss: 0.4366 Grad: 469689.9062 LR: 4.8262e-05 | Elapse: 5.94s\n","Epoch 12 [200/506] | Train Loss: 0.4429 Grad: 161050.9531 LR: 4.6540e-05 | Elapse: 11.84s\n","Epoch 12 [300/506] | Train Loss: 0.4395 Grad: 189595.3125 LR: 4.4823e-05 | Elapse: 17.72s\n","Epoch 12 [400/506] | Train Loss: 0.4396 Grad: 187260.0781 LR: 4.3112e-05 | Elapse: 23.57s\n","Epoch 12 [500/506] | Train Loss: 0.4389 Grad: 229485.7188 LR: 4.1409e-05 | Elapse: 29.46s\n","Epoch 12 [505/506] | Train Loss: 0.4384 Grad: 218033.7500 LR: 4.1324e-05 | Elapse: 29.76s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8fe0b5c0634b4f2894ef15ab54fc7bee","version_major":2,"version_minor":0},"text/plain":["Valid [11]:   0%|          | 0/125 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 12 [0/125] | Valid Loss: 0.6560 | Elapse: 0.06s\n","Epoch 12 [100/125] | Valid Loss: 0.7758 | Elapse: 5.09s\n"]},{"name":"stderr","output_type":"stream","text":["----------------------------------------------------------------------------------------------------\n","Epoch 12 - Average Loss: (train) 0.4384; (valid) 0.7719 | Time: 36.03s\n","Best model found in epoch 12 | valid loss: 0.7719\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 12 [124/125] | Valid Loss: 0.7719 | Elapse: 6.28s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1a7cb3e595704a69925edfa37338024d","version_major":2,"version_minor":0},"text/plain":["Train [12]:   0%|          | 0/506 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 13 [0/506] | Train Loss: 0.5095 Grad: 417216.2188 LR: 4.1307e-05 | Elapse: 0.06s\n","Epoch 13 [100/506] | Train Loss: 0.4227 Grad: 483879.3125 LR: 3.9615e-05 | Elapse: 5.95s\n","Epoch 13 [200/506] | Train Loss: 0.4280 Grad: 162385.4844 LR: 3.7935e-05 | Elapse: 11.83s\n","Epoch 13 [300/506] | Train Loss: 0.4248 Grad: 190978.4375 LR: 3.6270e-05 | Elapse: 17.68s\n","Epoch 13 [400/506] | Train Loss: 0.4246 Grad: 192297.6719 LR: 3.4621e-05 | Elapse: 23.56s\n","Epoch 13 [500/506] | Train Loss: 0.4239 Grad: 245336.6250 LR: 3.2991e-05 | Elapse: 29.44s\n","Epoch 13 [505/506] | Train Loss: 0.4235 Grad: 219295.6875 LR: 3.2910e-05 | Elapse: 29.74s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"127efa8c94df4556b1c579a8391b5f86","version_major":2,"version_minor":0},"text/plain":["Valid [12]:   0%|          | 0/125 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 13 [0/125] | Valid Loss: 0.6573 | Elapse: 0.06s\n","Epoch 13 [100/125] | Valid Loss: 0.7787 | Elapse: 5.09s\n"]},{"name":"stderr","output_type":"stream","text":["----------------------------------------------------------------------------------------------------\n","Epoch 13 - Average Loss: (train) 0.4235; (valid) 0.7743 | Time: 36.03s\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 13 [124/125] | Valid Loss: 0.7743 | Elapse: 6.29s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"02b9fa7d799948248a0982ab6f14d8a8","version_major":2,"version_minor":0},"text/plain":["Train [13]:   0%|          | 0/506 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 14 [0/506] | Train Loss: 0.4937 Grad: 413178.5625 LR: 3.2893e-05 | Elapse: 0.06s\n","Epoch 14 [100/506] | Train Loss: 0.4089 Grad: 442404.2500 LR: 3.1284e-05 | Elapse: 5.93s\n","Epoch 14 [200/506] | Train Loss: 0.4152 Grad: 161424.9219 LR: 2.9698e-05 | Elapse: 11.81s\n","Epoch 14 [300/506] | Train Loss: 0.4117 Grad: 195883.5469 LR: 2.8135e-05 | Elapse: 17.69s\n","Epoch 14 [400/506] | Train Loss: 0.4118 Grad: 203452.6719 LR: 2.6598e-05 | Elapse: 23.56s\n","Epoch 14 [500/506] | Train Loss: 0.4114 Grad: 261012.3281 LR: 2.5090e-05 | Elapse: 29.41s\n","Epoch 14 [505/506] | Train Loss: 0.4110 Grad: 250546.7031 LR: 2.5015e-05 | Elapse: 29.70s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"eb6c78b3c56542d59b90047babbaaf34","version_major":2,"version_minor":0},"text/plain":["Valid [13]:   0%|          | 0/125 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 14 [0/125] | Valid Loss: 0.6742 | Elapse: 0.05s\n","Epoch 14 [100/125] | Valid Loss: 0.7860 | Elapse: 4.97s\n"]},{"name":"stderr","output_type":"stream","text":["----------------------------------------------------------------------------------------------------\n","Epoch 14 - Average Loss: (train) 0.4110; (valid) 0.7817 | Time: 35.85s\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 14 [124/125] | Valid Loss: 0.7817 | Elapse: 6.14s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ec277014eae24b7a98c5478a262221f1","version_major":2,"version_minor":0},"text/plain":["Train [14]:   0%|          | 0/506 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 15 [0/506] | Train Loss: 0.4836 Grad: 437445.1875 LR: 2.5000e-05 | Elapse: 0.06s\n","Epoch 15 [100/506] | Train Loss: 0.3984 Grad: 448795.0312 LR: 2.3523e-05 | Elapse: 5.87s\n","Epoch 15 [200/506] | Train Loss: 0.4055 Grad: 164959.5156 LR: 2.2077e-05 | Elapse: 11.66s\n","Epoch 15 [300/506] | Train Loss: 0.4018 Grad: 201572.6719 LR: 2.0665e-05 | Elapse: 17.44s\n","Epoch 15 [400/506] | Train Loss: 0.4020 Grad: 199329.3125 LR: 1.9287e-05 | Elapse: 23.20s\n","Epoch 15 [500/506] | Train Loss: 0.4016 Grad: 265736.7500 LR: 1.7946e-05 | Elapse: 28.95s\n","Epoch 15 [505/506] | Train Loss: 0.4013 Grad: 250533.9531 LR: 1.7880e-05 | Elapse: 29.25s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"747919441afc4202a746de4c5b852ac6","version_major":2,"version_minor":0},"text/plain":["Valid [14]:   0%|          | 0/125 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 15 [0/125] | Valid Loss: 0.6668 | Elapse: 0.05s\n","Epoch 15 [100/125] | Valid Loss: 0.7859 | Elapse: 4.98s\n"]},{"name":"stderr","output_type":"stream","text":["----------------------------------------------------------------------------------------------------\n","Epoch 15 - Average Loss: (train) 0.4013; (valid) 0.7819 | Time: 35.43s\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 15 [124/125] | Valid Loss: 0.7819 | Elapse: 6.18s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"fe92db6704e64ef5ba8b903e5779f632","version_major":2,"version_minor":0},"text/plain":["Train [15]:   0%|          | 0/506 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 16 [0/506] | Train Loss: 0.4693 Grad: 435731.2500 LR: 1.7867e-05 | Elapse: 0.06s\n","Epoch 16 [100/506] | Train Loss: 0.3906 Grad: 418348.7188 LR: 1.6567e-05 | Elapse: 5.95s\n","Epoch 16 [200/506] | Train Loss: 0.3980 Grad: 187387.9062 LR: 1.5306e-05 | Elapse: 11.83s\n","Epoch 16 [300/506] | Train Loss: 0.3941 Grad: 209733.6094 LR: 1.4087e-05 | Elapse: 17.70s\n","Epoch 16 [400/506] | Train Loss: 0.3944 Grad: 206978.6719 LR: 1.2910e-05 | Elapse: 23.59s\n","Epoch 16 [500/506] | Train Loss: 0.3942 Grad: 268343.4062 LR: 1.1777e-05 | Elapse: 29.45s\n","Epoch 16 [505/506] | Train Loss: 0.3939 Grad: 232819.5312 LR: 1.1722e-05 | Elapse: 29.74s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1a584aee287d493cb0007c98df3e590f","version_major":2,"version_minor":0},"text/plain":["Valid [15]:   0%|          | 0/125 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 16 [0/125] | Valid Loss: 0.6539 | Elapse: 0.06s\n","Epoch 16 [100/125] | Valid Loss: 0.7808 | Elapse: 5.08s\n"]},{"name":"stderr","output_type":"stream","text":["----------------------------------------------------------------------------------------------------\n","Epoch 16 - Average Loss: (train) 0.3939; (valid) 0.7772 | Time: 36.00s\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 16 [124/125] | Valid Loss: 0.7772 | Elapse: 6.26s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9f21b8d64546450ebcd2de3cf4ce4a5f","version_major":2,"version_minor":0},"text/plain":["Train [16]:   0%|          | 0/506 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 17 [0/506] | Train Loss: 0.4542 Grad: 437523.4688 LR: 1.1711e-05 | Elapse: 0.06s\n","Epoch 17 [100/506] | Train Loss: 0.3843 Grad: 429806.3750 LR: 1.0627e-05 | Elapse: 5.86s\n","Epoch 17 [200/506] | Train Loss: 0.3917 Grad: 366589.3750 LR: 9.5894e-06 | Elapse: 11.71s\n","Epoch 17 [300/506] | Train Loss: 0.3880 Grad: 434062.6875 LR: 8.6001e-06 | Elapse: 17.55s\n","Epoch 17 [400/506] | Train Loss: 0.3885 Grad: 399524.8438 LR: 7.6602e-06 | Elapse: 23.39s\n","Epoch 17 [500/506] | Train Loss: 0.3887 Grad: 521177.2812 LR: 6.7706e-06 | Elapse: 29.20s\n","Epoch 17 [505/506] | Train Loss: 0.3883 Grad: 404653.5625 LR: 6.7274e-06 | Elapse: 29.50s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a1e833a832b342d2a0215ecbc1bcdaac","version_major":2,"version_minor":0},"text/plain":["Valid [16]:   0%|          | 0/125 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 17 [0/125] | Valid Loss: 0.6332 | Elapse: 0.06s\n","Epoch 17 [100/125] | Valid Loss: 0.7701 | Elapse: 5.05s\n"]},{"name":"stderr","output_type":"stream","text":["----------------------------------------------------------------------------------------------------\n","Epoch 17 - Average Loss: (train) 0.3883; (valid) 0.7670 | Time: 35.73s\n","Best model found in epoch 17 | valid loss: 0.7670\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 17 [124/125] | Valid Loss: 0.7670 | Elapse: 6.23s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"799613c5686046d39836c98a5ddce185","version_major":2,"version_minor":0},"text/plain":["Train [17]:   0%|          | 0/506 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 18 [0/506] | Train Loss: 0.4415 Grad: 453314.6562 LR: 6.7188e-06 | Elapse: 0.06s\n","Epoch 18 [100/506] | Train Loss: 0.3795 Grad: 460740.4375 LR: 5.8838e-06 | Elapse: 5.93s\n","Epoch 18 [200/506] | Train Loss: 0.3865 Grad: 346845.5312 LR: 5.1013e-06 | Elapse: 11.81s\n","Epoch 18 [300/506] | Train Loss: 0.3831 Grad: 429666.3438 LR: 4.3722e-06 | Elapse: 17.65s\n","Epoch 18 [400/506] | Train Loss: 0.3838 Grad: 395700.4688 LR: 3.6975e-06 | Elapse: 23.53s\n","Epoch 18 [500/506] | Train Loss: 0.3842 Grad: 495364.7812 LR: 3.0778e-06 | Elapse: 29.45s\n","Epoch 18 [505/506] | Train Loss: 0.3838 Grad: 374180.7500 LR: 3.0483e-06 | Elapse: 29.75s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c0acca200239463d9ee29d6f482078d5","version_major":2,"version_minor":0},"text/plain":["Valid [17]:   0%|          | 0/125 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 18 [0/125] | Valid Loss: 0.6213 | Elapse: 0.06s\n","Epoch 18 [100/125] | Valid Loss: 0.7641 | Elapse: 5.13s\n"]},{"name":"stderr","output_type":"stream","text":["----------------------------------------------------------------------------------------------------\n","Epoch 18 - Average Loss: (train) 0.3838; (valid) 0.7610 | Time: 36.07s\n","Best model found in epoch 18 | valid loss: 0.7610\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 18 [124/125] | Valid Loss: 0.7610 | Elapse: 6.32s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0091d168f43b4244821e58aa0a2a6095","version_major":2,"version_minor":0},"text/plain":["Train [18]:   0%|          | 0/506 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 19 [0/506] | Train Loss: 0.4324 Grad: 466297.4375 LR: 3.0424e-06 | Elapse: 0.06s\n","Epoch 19 [100/506] | Train Loss: 0.3765 Grad: 486212.8438 LR: 2.4819e-06 | Elapse: 5.96s\n","Epoch 19 [200/506] | Train Loss: 0.3827 Grad: 342458.9688 LR: 1.9780e-06 | Elapse: 11.86s\n","Epoch 19 [300/506] | Train Loss: 0.3794 Grad: 421612.6875 LR: 1.5313e-06 | Elapse: 17.71s\n","Epoch 19 [400/506] | Train Loss: 0.3804 Grad: 402213.8750 LR: 1.1422e-06 | Elapse: 23.46s\n","Epoch 19 [500/506] | Train Loss: 0.3809 Grad: 475659.3125 LR: 8.1133e-07 | Elapse: 29.26s\n","Epoch 19 [505/506] | Train Loss: 0.3806 Grad: 366938.5312 LR: 7.9632e-07 | Elapse: 29.55s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4d6511f065ca480db2b8e07bff97f749","version_major":2,"version_minor":0},"text/plain":["Valid [18]:   0%|          | 0/125 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 19 [0/125] | Valid Loss: 0.6210 | Elapse: 0.05s\n","Epoch 19 [100/125] | Valid Loss: 0.7642 | Elapse: 4.96s\n"]},{"name":"stderr","output_type":"stream","text":["----------------------------------------------------------------------------------------------------\n","Epoch 19 - Average Loss: (train) 0.3806; (valid) 0.7608 | Time: 35.67s\n","Best model found in epoch 19 | valid loss: 0.7608\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 19 [124/125] | Valid Loss: 0.7608 | Elapse: 6.12s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"89bc549fa2014111b9c180b08879ce5f","version_major":2,"version_minor":0},"text/plain":["Train [19]:   0%|          | 0/506 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 20 [0/506] | Train Loss: 0.4238 Grad: 457406.4375 LR: 7.9333e-07 | Elapse: 0.06s\n","Epoch 20 [100/506] | Train Loss: 0.3742 Grad: 483715.2500 LR: 5.2448e-07 | Elapse: 5.84s\n","Epoch 20 [200/506] | Train Loss: 0.3802 Grad: 169096.0312 LR: 3.1452e-07 | Elapse: 11.61s\n","Epoch 20 [300/506] | Train Loss: 0.3771 Grad: 210287.4844 LR: 1.6368e-07 | Elapse: 17.38s\n","Epoch 20 [400/506] | Train Loss: 0.3784 Grad: 199132.4531 LR: 7.2154e-08 | Elapse: 23.21s\n","Epoch 20 [500/506] | Train Loss: 0.3790 Grad: 234816.3750 LR: 4.0048e-08 | Elapse: 29.08s\n","Epoch 20 [505/506] | Train Loss: 0.3787 Grad: 185101.1875 LR: 4.0003e-08 | Elapse: 29.37s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"cc694803bbc04e1ebec64dadfdabadd1","version_major":2,"version_minor":0},"text/plain":["Valid [19]:   0%|          | 0/125 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 20 [0/125] | Valid Loss: 0.6222 | Elapse: 0.05s\n","Epoch 20 [100/125] | Valid Loss: 0.7651 | Elapse: 5.05s\n"]},{"name":"stderr","output_type":"stream","text":["----------------------------------------------------------------------------------------------------\n","Epoch 20 - Average Loss: (train) 0.3787; (valid) 0.7616 | Time: 35.62s\n","====================================================================================================\n","Fold 0 Valid Loss: 0.7607576847076416\n","Elapse: 11.92 min \n","====================================================================================================\n","- Stage 2 | Train: 5215; Valid: 1277 -\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 20 [124/125] | Valid Loss: 0.7616 | Elapse: 6.24s\n","Loading model from checkpoint: outputs/ResnetGRU_v1_LB048_fold_0_stage_1.pth\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"365fe136f8394bed8fe780e61b7ab363","version_major":2,"version_minor":0},"text/plain":["Train [0]:   0%|          | 0/162 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 1 [0/162] | Train Loss: 0.3661 Grad: 593422.6250 LR: 4.0023e-06 | Elapse: 0.07s\n","Epoch 1 [100/162] | Train Loss: 0.3350 Grad: 254626.6562 LR: 2.5357e-05 | Elapse: 5.95s\n","Epoch 1 [161/162] | Train Loss: 0.3279 Grad: 330593.0000 LR: 5.2233e-05 | Elapse: 9.54s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d1a7c91ee4a24ba68f563b1a650d4754","version_major":2,"version_minor":0},"text/plain":["Valid [0]:   0%|          | 0/40 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 1 [0/40] | Valid Loss: 0.4260 | Elapse: 0.06s\n"]},{"name":"stderr","output_type":"stream","text":["----------------------------------------------------------------------------------------------------\n","Epoch 1 - Average Loss: (train) 0.3279; (valid) 0.5163 | Time: 11.56s\n","Best model found in epoch 1 | valid loss: 0.5163\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1 [39/40] | Valid Loss: 0.5163 | Elapse: 2.01s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"bdee913f5a6842c287c1fa9aedeffa42","version_major":2,"version_minor":0},"text/plain":["Train [1]:   0%|          | 0/162 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 2 [0/162] | Train Loss: 0.2025 Grad: 477145.7188 LR: 5.2700e-05 | Elapse: 0.06s\n","Epoch 2 [100/162] | Train Loss: 0.2761 Grad: 396974.6875 LR: 9.2056e-05 | Elapse: 5.93s\n","Epoch 2 [161/162] | Train Loss: 0.2713 Grad: 303789.8750 LR: 1.0000e-04 | Elapse: 9.47s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8da0bc01b70d4170a783308e07554230","version_major":2,"version_minor":0},"text/plain":["Valid [1]:   0%|          | 0/40 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 2 [0/40] | Valid Loss: 0.4043 | Elapse: 0.06s\n"]},{"name":"stderr","output_type":"stream","text":["----------------------------------------------------------------------------------------------------\n","Epoch 2 - Average Loss: (train) 0.2713; (valid) 0.4910 | Time: 11.50s\n","Best model found in epoch 2 | valid loss: 0.4910\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 2 [39/40] | Valid Loss: 0.4910 | Elapse: 2.03s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d04443ca5d89409e8536014a4b6f110a","version_major":2,"version_minor":0},"text/plain":["Train [2]:   0%|          | 0/162 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 3 [0/162] | Train Loss: 0.1622 Grad: 363285.7812 LR: 1.0000e-04 | Elapse: 0.06s\n","Epoch 3 [100/162] | Train Loss: 0.2351 Grad: 333028.8750 LR: 9.9699e-05 | Elapse: 5.85s\n","Epoch 3 [161/162] | Train Loss: 0.2309 Grad: 434766.6250 LR: 9.9231e-05 | Elapse: 9.37s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"28063c5e76f74f619fd70dde1aa58bfa","version_major":2,"version_minor":0},"text/plain":["Valid [2]:   0%|          | 0/40 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 3 [0/40] | Valid Loss: 0.3919 | Elapse: 0.05s\n"]},{"name":"stderr","output_type":"stream","text":["----------------------------------------------------------------------------------------------------\n","Epoch 3 - Average Loss: (train) 0.2309; (valid) 0.4788 | Time: 11.33s\n","Best model found in epoch 3 | valid loss: 0.4788\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 3 [39/40] | Valid Loss: 0.4788 | Elapse: 1.96s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1c31f661063f4dd6a9a57d9da1413a0e","version_major":2,"version_minor":0},"text/plain":["Train [3]:   0%|          | 0/162 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 4 [0/162] | Train Loss: 0.1403 Grad: 319835.6562 LR: 9.9222e-05 | Elapse: 0.06s\n","Epoch 4 [100/162] | Train Loss: 0.2065 Grad: 320664.2188 LR: 9.7992e-05 | Elapse: 5.85s\n","Epoch 4 [161/162] | Train Loss: 0.2033 Grad: 415324.2188 LR: 9.6967e-05 | Elapse: 9.37s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"49720cc33e95476c886e0bed99cbe40d","version_major":2,"version_minor":0},"text/plain":["Valid [3]:   0%|          | 0/40 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 4 [0/40] | Valid Loss: 0.3897 | Elapse: 0.06s\n"]},{"name":"stderr","output_type":"stream","text":["----------------------------------------------------------------------------------------------------\n","Epoch 4 - Average Loss: (train) 0.2033; (valid) 0.4760 | Time: 11.34s\n","Best model found in epoch 4 | valid loss: 0.4760\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 4 [39/40] | Valid Loss: 0.4760 | Elapse: 1.97s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"636a00ee58244681998e3fa359088e6d","version_major":2,"version_minor":0},"text/plain":["Train [4]:   0%|          | 0/162 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 5 [0/162] | Train Loss: 0.1277 Grad: 322941.9062 LR: 9.6949e-05 | Elapse: 0.06s\n","Epoch 5 [100/162] | Train Loss: 0.1873 Grad: 307812.0312 LR: 9.4828e-05 | Elapse: 5.80s\n","Epoch 5 [161/162] | Train Loss: 0.1846 Grad: 446240.5938 LR: 9.3277e-05 | Elapse: 9.30s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9d9855c68f9e4013be6bcfcc30f9b464","version_major":2,"version_minor":0},"text/plain":["Valid [4]:   0%|          | 0/40 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 5 [0/40] | Valid Loss: 0.3986 | Elapse: 0.05s\n"]},{"name":"stderr","output_type":"stream","text":["----------------------------------------------------------------------------------------------------\n","Epoch 5 - Average Loss: (train) 0.1846; (valid) 0.4762 | Time: 11.26s\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 5 [39/40] | Valid Loss: 0.4762 | Elapse: 1.96s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"98361acc38e5485186acb78fcd773b80","version_major":2,"version_minor":0},"text/plain":["Train [5]:   0%|          | 0/162 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 6 [0/162] | Train Loss: 0.1088 Grad: 294581.9688 LR: 9.3250e-05 | Elapse: 0.06s\n","Epoch 6 [100/162] | Train Loss: 0.1724 Grad: 299174.4375 LR: 9.0302e-05 | Elapse: 5.87s\n","Epoch 6 [161/162] | Train Loss: 0.1698 Grad: 399720.8750 LR: 8.8272e-05 | Elapse: 9.41s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b68624063e6549ecad65efb7efd81627","version_major":2,"version_minor":0},"text/plain":["Valid [5]:   0%|          | 0/40 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 6 [0/40] | Valid Loss: 0.3920 | Elapse: 0.05s\n"]},{"name":"stderr","output_type":"stream","text":["----------------------------------------------------------------------------------------------------\n","Epoch 6 - Average Loss: (train) 0.1698; (valid) 0.4816 | Time: 11.40s\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 6 [39/40] | Valid Loss: 0.4816 | Elapse: 1.98s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b1b787ea2082456391db4ca0494ef549","version_major":2,"version_minor":0},"text/plain":["Train [6]:   0%|          | 0/162 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 7 [0/162] | Train Loss: 0.1028 Grad: 323307.8438 LR: 8.8238e-05 | Elapse: 0.06s\n","Epoch 7 [100/162] | Train Loss: 0.1581 Grad: 291224.8750 LR: 8.4553e-05 | Elapse: 5.88s\n","Epoch 7 [161/162] | Train Loss: 0.1550 Grad: 366607.1875 LR: 8.2105e-05 | Elapse: 9.43s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"28162b2af5ae48639b9e4f64ad2afa45","version_major":2,"version_minor":0},"text/plain":["Valid [6]:   0%|          | 0/40 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 7 [0/40] | Valid Loss: 0.3935 | Elapse: 0.06s\n"]},{"name":"stderr","output_type":"stream","text":["----------------------------------------------------------------------------------------------------\n","Epoch 7 - Average Loss: (train) 0.1550; (valid) 0.4796 | Time: 11.42s\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 7 [39/40] | Valid Loss: 0.4796 | Elapse: 1.99s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4d8095de35c04bda87e2a32adedac2a2","version_major":2,"version_minor":0},"text/plain":["Train [7]:   0%|          | 0/162 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 8 [0/162] | Train Loss: 0.0917 Grad: 307416.5000 LR: 8.2064e-05 | Elapse: 0.06s\n","Epoch 8 [100/162] | Train Loss: 0.1446 Grad: 356699.0000 LR: 7.7754e-05 | Elapse: 5.90s\n","Epoch 8 [161/162] | Train Loss: 0.1421 Grad: 310882.4375 LR: 7.4963e-05 | Elapse: 9.44s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6da2757ddeac4525907741dc03395cac","version_major":2,"version_minor":0},"text/plain":["Valid [7]:   0%|          | 0/40 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 8 [0/40] | Valid Loss: 0.3930 | Elapse: 0.05s\n"]},{"name":"stderr","output_type":"stream","text":["----------------------------------------------------------------------------------------------------\n","Epoch 8 - Average Loss: (train) 0.1421; (valid) 0.4856 | Time: 11.41s\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 8 [39/40] | Valid Loss: 0.4856 | Elapse: 1.96s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ce0b46acd0c542af999416f89086d0a6","version_major":2,"version_minor":0},"text/plain":["Train [8]:   0%|          | 0/162 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 9 [0/162] | Train Loss: 0.0859 Grad: 341965.7812 LR: 7.4917e-05 | Elapse: 0.06s\n","Epoch 9 [100/162] | Train Loss: 0.1376 Grad: 416422.4688 LR: 7.0112e-05 | Elapse: 5.86s\n","Epoch 9 [161/162] | Train Loss: 0.1342 Grad: 335053.6250 LR: 6.7064e-05 | Elapse: 9.41s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"17b7c407f2aa4823a4d20146fa266093","version_major":2,"version_minor":0},"text/plain":["Valid [8]:   0%|          | 0/40 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 9 [0/40] | Valid Loss: 0.3881 | Elapse: 0.06s\n"]},{"name":"stderr","output_type":"stream","text":["----------------------------------------------------------------------------------------------------\n","Epoch 9 - Average Loss: (train) 0.1342; (valid) 0.4828 | Time: 11.39s\n","Early stopping at epoch 9\n","====================================================================================================\n","Fold 0 Valid Loss: 0.4760229289531708\n","Elapse: 1.71 min \n","====================================================================================================\n","Fold 0 Elapse: 13.63 min\n","====================================================================================================\n","Fold: 1\n","====================================================================================================\n","- Stage 1 | Train: 16297; Valid: 3886 -\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 9 [39/40] | Valid Loss: 0.4828 | Elapse: 1.97s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"fc7ef913ae3e4ce0b7684603a255d910","version_major":2,"version_minor":0},"text/plain":["Train [0]:   0%|          | 0/509 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 1 [0/509] | Train Loss: 1.1793 Grad: 69410.4766 LR: 4.0002e-06 | Elapse: 0.07s\n","Epoch 1 [100/509] | Train Loss: 1.1798 Grad: 92523.1406 LR: 6.3173e-06 | Elapse: 5.92s\n","Epoch 1 [200/509] | Train Loss: 1.1841 Grad: 90920.8359 LR: 1.2959e-05 | Elapse: 11.73s\n","Epoch 1 [300/509] | Train Loss: 1.1747 Grad: 52713.0156 LR: 2.3297e-05 | Elapse: 17.49s\n","Epoch 1 [400/509] | Train Loss: 1.1617 Grad: 67290.0703 LR: 3.6352e-05 | Elapse: 23.24s\n","Epoch 1 [500/509] | Train Loss: 1.1426 Grad: 53618.8516 LR: 5.0888e-05 | Elapse: 28.99s\n","Epoch 1 [508/509] | Train Loss: 1.1405 Grad: 55252.0859 LR: 5.2074e-05 | Elapse: 29.45s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"72464d501a7c460e862c45c1dad4107a","version_major":2,"version_minor":0},"text/plain":["Valid [0]:   0%|          | 0/122 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 1 [0/122] | Valid Loss: 1.2659 | Elapse: 0.05s\n","Epoch 1 [100/122] | Valid Loss: 1.3081 | Elapse: 4.95s\n"]},{"name":"stderr","output_type":"stream","text":["----------------------------------------------------------------------------------------------------\n","Epoch 1 - Average Loss: (train) 1.1405; (valid) 1.3078 | Time: 35.42s\n","Best model found in epoch 1 | valid loss: 1.3078\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1 [121/122] | Valid Loss: 1.3078 | Elapse: 5.96s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f6446b07c7ab4172b28ccf4978942604","version_major":2,"version_minor":0},"text/plain":["Train [1]:   0%|          | 0/509 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 2 [0/509] | Train Loss: 1.0079 Grad: 53654.5859 LR: 5.2222e-05 | Elapse: 0.06s\n","Epoch 2 [100/509] | Train Loss: 1.0134 Grad: 106202.3906 LR: 6.6805e-05 | Elapse: 5.81s\n","Epoch 2 [200/509] | Train Loss: 1.0155 Grad: 63047.9414 LR: 7.9985e-05 | Elapse: 11.63s\n","Epoch 2 [300/509] | Train Loss: 1.0051 Grad: 51056.9414 LR: 9.0517e-05 | Elapse: 17.51s\n","Epoch 2 [400/509] | Train Loss: 0.9947 Grad: 75958.4375 LR: 9.7402e-05 | Elapse: 23.37s\n","Epoch 2 [500/509] | Train Loss: 0.9805 Grad: 57373.7930 LR: 9.9989e-05 | Elapse: 29.25s\n","Epoch 2 [508/509] | Train Loss: 0.9792 Grad: 74742.3750 LR: 1.0000e-04 | Elapse: 29.72s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9ba88ca7fa9e48f39936e61336d8b505","version_major":2,"version_minor":0},"text/plain":["Valid [1]:   0%|          | 0/122 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 2 [0/122] | Valid Loss: 1.0424 | Elapse: 0.06s\n","Epoch 2 [100/122] | Valid Loss: 1.1434 | Elapse: 5.03s\n"]},{"name":"stderr","output_type":"stream","text":["----------------------------------------------------------------------------------------------------\n","Epoch 2 - Average Loss: (train) 0.9792; (valid) 1.1426 | Time: 35.77s\n","Best model found in epoch 2 | valid loss: 1.1426\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 2 [121/122] | Valid Loss: 1.1426 | Elapse: 6.06s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a0f390ee23364d9baff5afa3bbcb4baa","version_major":2,"version_minor":0},"text/plain":["Train [2]:   0%|          | 0/509 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 3 [0/509] | Train Loss: 0.9545 Grad: 67669.6484 LR: 1.0000e-04 | Elapse: 0.06s\n","Epoch 3 [100/509] | Train Loss: 0.8937 Grad: 133077.8594 LR: 9.9969e-05 | Elapse: 5.88s\n","Epoch 3 [200/509] | Train Loss: 0.8948 Grad: 90648.4688 LR: 9.9880e-05 | Elapse: 11.77s\n","Epoch 3 [300/509] | Train Loss: 0.8824 Grad: 85809.8906 LR: 9.9732e-05 | Elapse: 17.59s\n","Epoch 3 [400/509] | Train Loss: 0.8693 Grad: 131071.8359 LR: 9.9526e-05 | Elapse: 23.43s\n","Epoch 3 [500/509] | Train Loss: 0.8539 Grad: 98700.2344 LR: 9.9261e-05 | Elapse: 29.25s\n","Epoch 3 [508/509] | Train Loss: 0.8525 Grad: 160402.2500 LR: 9.9238e-05 | Elapse: 29.72s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a3d5c90afb264226861c8a0d587a84ef","version_major":2,"version_minor":0},"text/plain":["Valid [2]:   0%|          | 0/122 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 3 [0/122] | Valid Loss: 0.9456 | Elapse: 0.06s\n","Epoch 3 [100/122] | Valid Loss: 0.9765 | Elapse: 5.02s\n"]},{"name":"stderr","output_type":"stream","text":["----------------------------------------------------------------------------------------------------\n","Epoch 3 - Average Loss: (train) 0.8525; (valid) 0.9781 | Time: 35.76s\n","Best model found in epoch 3 | valid loss: 0.9781\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 3 [121/122] | Valid Loss: 0.9781 | Elapse: 6.03s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e21d01eefad644818c47b560fe8a47db","version_major":2,"version_minor":0},"text/plain":["Train [3]:   0%|          | 0/509 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 4 [0/509] | Train Loss: 0.8009 Grad: 106448.2656 LR: 9.9235e-05 | Elapse: 0.06s\n","Epoch 4 [100/509] | Train Loss: 0.7724 Grad: 232273.6406 LR: 9.8907e-05 | Elapse: 5.93s\n","Epoch 4 [200/509] | Train Loss: 0.7743 Grad: 102067.2969 LR: 9.8522e-05 | Elapse: 11.78s\n","Epoch 4 [300/509] | Train Loss: 0.7690 Grad: 148286.0781 LR: 9.8080e-05 | Elapse: 17.63s\n","Epoch 4 [400/509] | Train Loss: 0.7630 Grad: 144000.2969 LR: 9.7581e-05 | Elapse: 23.51s\n","Epoch 4 [500/509] | Train Loss: 0.7542 Grad: 132777.4688 LR: 9.7027e-05 | Elapse: 29.43s\n","Epoch 4 [508/509] | Train Loss: 0.7533 Grad: 200525.3125 LR: 9.6980e-05 | Elapse: 29.90s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"bc7b9f75de564bb385daa9cad980e5c0","version_major":2,"version_minor":0},"text/plain":["Valid [3]:   0%|          | 0/122 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 4 [0/122] | Valid Loss: 0.9021 | Elapse: 0.06s\n","Epoch 4 [100/122] | Valid Loss: 0.8885 | Elapse: 5.02s\n"]},{"name":"stderr","output_type":"stream","text":["----------------------------------------------------------------------------------------------------\n","Epoch 4 - Average Loss: (train) 0.7533; (valid) 0.8902 | Time: 35.94s\n","Best model found in epoch 4 | valid loss: 0.8902\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 4 [121/122] | Valid Loss: 0.8902 | Elapse: 6.04s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c93c95c0fcf24d16ac2ae088647aa131","version_major":2,"version_minor":0},"text/plain":["Train [4]:   0%|          | 0/509 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 5 [0/509] | Train Loss: 0.7206 Grad: 150494.5938 LR: 9.6974e-05 | Elapse: 0.07s\n","Epoch 5 [100/509] | Train Loss: 0.6963 Grad: 249340.6719 LR: 9.6359e-05 | Elapse: 5.95s\n","Epoch 5 [200/509] | Train Loss: 0.6987 Grad: 147700.2812 LR: 9.5690e-05 | Elapse: 11.80s\n","Epoch 5 [300/509] | Train Loss: 0.6979 Grad: 167487.0781 LR: 9.4967e-05 | Elapse: 17.64s\n","Epoch 5 [400/509] | Train Loss: 0.6940 Grad: 161822.1875 LR: 9.4191e-05 | Elapse: 23.46s\n","Epoch 5 [500/509] | Train Loss: 0.6877 Grad: 158788.5625 LR: 9.3364e-05 | Elapse: 29.30s\n","Epoch 5 [508/509] | Train Loss: 0.6868 Grad: 236574.7344 LR: 9.3295e-05 | Elapse: 29.77s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7751e69bb84d4484ad197e00669426c6","version_major":2,"version_minor":0},"text/plain":["Valid [4]:   0%|          | 0/122 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 5 [0/122] | Valid Loss: 0.8514 | Elapse: 0.06s\n","Epoch 5 [100/122] | Valid Loss: 0.8236 | Elapse: 5.01s\n"]},{"name":"stderr","output_type":"stream","text":["----------------------------------------------------------------------------------------------------\n","Epoch 5 - Average Loss: (train) 0.6868; (valid) 0.8250 | Time: 35.81s\n","Best model found in epoch 5 | valid loss: 0.8250\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 5 [121/122] | Valid Loss: 0.8250 | Elapse: 6.04s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9dac1dd64de54bb8aa4d5734b18552c6","version_major":2,"version_minor":0},"text/plain":["Train [5]:   0%|          | 0/509 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 6 [0/509] | Train Loss: 0.6302 Grad: 208906.9531 LR: 9.3287e-05 | Elapse: 0.06s\n","Epoch 6 [100/509] | Train Loss: 0.6305 Grad: 313859.2188 LR: 9.2404e-05 | Elapse: 5.89s\n","Epoch 6 [200/509] | Train Loss: 0.6325 Grad: 153518.8594 LR: 9.1471e-05 | Elapse: 11.70s\n","Epoch 6 [300/509] | Train Loss: 0.6359 Grad: 185078.3750 LR: 9.0489e-05 | Elapse: 17.52s\n","Epoch 6 [400/509] | Train Loss: 0.6332 Grad: 185347.0312 LR: 8.9460e-05 | Elapse: 23.31s\n","Epoch 6 [500/509] | Train Loss: 0.6292 Grad: 190019.6406 LR: 8.8384e-05 | Elapse: 29.06s\n","Epoch 6 [508/509] | Train Loss: 0.6284 Grad: 251891.5469 LR: 8.8296e-05 | Elapse: 29.53s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"235e2300461b4b59bc0697e05623f7c4","version_major":2,"version_minor":0},"text/plain":["Valid [5]:   0%|          | 0/122 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 6 [0/122] | Valid Loss: 0.7678 | Elapse: 0.05s\n","Epoch 6 [100/122] | Valid Loss: 0.7711 | Elapse: 4.97s\n"]},{"name":"stderr","output_type":"stream","text":["----------------------------------------------------------------------------------------------------\n","Epoch 6 - Average Loss: (train) 0.6284; (valid) 0.7723 | Time: 35.50s\n","Best model found in epoch 6 | valid loss: 0.7723\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 6 [121/122] | Valid Loss: 0.7723 | Elapse: 5.97s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"39f5278e1703443dade4a0758a58b68e","version_major":2,"version_minor":0},"text/plain":["Train [6]:   0%|          | 0/509 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 7 [0/509] | Train Loss: 0.5701 Grad: 247719.0000 LR: 8.8285e-05 | Elapse: 0.06s\n","Epoch 7 [100/509] | Train Loss: 0.5780 Grad: 392204.2500 LR: 8.7160e-05 | Elapse: 5.90s\n","Epoch 7 [200/509] | Train Loss: 0.5798 Grad: 200495.4062 LR: 8.5992e-05 | Elapse: 11.71s\n","Epoch 7 [300/509] | Train Loss: 0.5858 Grad: 227940.8438 LR: 8.4781e-05 | Elapse: 17.49s\n","Epoch 7 [400/509] | Train Loss: 0.5839 Grad: 207104.8281 LR: 8.3529e-05 | Elapse: 23.25s\n","Epoch 7 [500/509] | Train Loss: 0.5816 Grad: 237092.8750 LR: 8.2238e-05 | Elapse: 29.02s\n","Epoch 7 [508/509] | Train Loss: 0.5809 Grad: 281906.6250 LR: 8.2133e-05 | Elapse: 29.48s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"463f0b5c0dca4b448089acb4b470e37d","version_major":2,"version_minor":0},"text/plain":["Valid [6]:   0%|          | 0/122 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 7 [0/122] | Valid Loss: 0.7391 | Elapse: 0.05s\n","Epoch 7 [100/122] | Valid Loss: 0.7397 | Elapse: 4.95s\n"]},{"name":"stderr","output_type":"stream","text":["----------------------------------------------------------------------------------------------------\n","Epoch 7 - Average Loss: (train) 0.5809; (valid) 0.7403 | Time: 35.43s\n","Best model found in epoch 7 | valid loss: 0.7403\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 7 [121/122] | Valid Loss: 0.7403 | Elapse: 5.95s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d3f0ab87fad34012a16476cbbdf1dc6d","version_major":2,"version_minor":0},"text/plain":["Train [7]:   0%|          | 0/509 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 8 [0/509] | Train Loss: 0.5185 Grad: 303157.2500 LR: 8.2120e-05 | Elapse: 0.06s\n","Epoch 8 [100/509] | Train Loss: 0.5361 Grad: 359751.6562 LR: 8.0788e-05 | Elapse: 5.83s\n","Epoch 8 [200/509] | Train Loss: 0.5379 Grad: 230786.9688 LR: 7.9420e-05 | Elapse: 11.65s\n","Epoch 8 [300/509] | Train Loss: 0.5455 Grad: 296062.2500 LR: 7.8017e-05 | Elapse: 17.41s\n","Epoch 8 [400/509] | Train Loss: 0.5441 Grad: 199862.6406 LR: 7.6581e-05 | Elapse: 23.17s\n","Epoch 8 [500/509] | Train Loss: 0.5430 Grad: 260365.6875 LR: 7.5114e-05 | Elapse: 28.95s\n","Epoch 8 [508/509] | Train Loss: 0.5423 Grad: 340483.7188 LR: 7.4995e-05 | Elapse: 29.41s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4dbf1ed88e624a38a06129f1e6463d35","version_major":2,"version_minor":0},"text/plain":["Valid [7]:   0%|          | 0/122 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 8 [0/122] | Valid Loss: 0.7298 | Elapse: 0.06s\n","Epoch 8 [100/122] | Valid Loss: 0.7254 | Elapse: 4.99s\n"]},{"name":"stderr","output_type":"stream","text":["----------------------------------------------------------------------------------------------------\n","Epoch 8 - Average Loss: (train) 0.5423; (valid) 0.7259 | Time: 35.41s\n","Best model found in epoch 8 | valid loss: 0.7259\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 8 [121/122] | Valid Loss: 0.7259 | Elapse: 6.00s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"80e9e2249f404dd88d1c1f84a45d0560","version_major":2,"version_minor":0},"text/plain":["Train [8]:   0%|          | 0/509 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 9 [0/509] | Train Loss: 0.4890 Grad: 365742.0938 LR: 7.4980e-05 | Elapse: 0.06s\n","Epoch 9 [100/509] | Train Loss: 0.5040 Grad: 330425.4375 LR: 7.3481e-05 | Elapse: 5.90s\n","Epoch 9 [200/509] | Train Loss: 0.5051 Grad: 258849.5312 LR: 7.1954e-05 | Elapse: 11.72s\n","Epoch 9 [300/509] | Train Loss: 0.5124 Grad: 338355.4375 LR: 7.0402e-05 | Elapse: 17.56s\n","Epoch 9 [400/509] | Train Loss: 0.5107 Grad: 214271.2656 LR: 6.8825e-05 | Elapse: 23.38s\n","Epoch 9 [500/509] | Train Loss: 0.5102 Grad: 302050.3125 LR: 6.7227e-05 | Elapse: 29.19s\n","Epoch 9 [508/509] | Train Loss: 0.5096 Grad: 385796.7500 LR: 6.7098e-05 | Elapse: 29.66s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a6a2b805c9954cf6a7846c6e6f06dafe","version_major":2,"version_minor":0},"text/plain":["Valid [8]:   0%|          | 0/122 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 9 [0/122] | Valid Loss: 0.7275 | Elapse: 0.06s\n","Epoch 9 [100/122] | Valid Loss: 0.7167 | Elapse: 4.99s\n"]},{"name":"stderr","output_type":"stream","text":["----------------------------------------------------------------------------------------------------\n","Epoch 9 - Average Loss: (train) 0.5096; (valid) 0.7167 | Time: 35.66s\n","Best model found in epoch 9 | valid loss: 0.7167\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 9 [121/122] | Valid Loss: 0.7167 | Elapse: 5.99s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9570e30e8d724a348c0549d3b0852938","version_major":2,"version_minor":0},"text/plain":["Train [9]:   0%|          | 0/509 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 10 [0/509] | Train Loss: 0.4648 Grad: 418563.3125 LR: 6.7082e-05 | Elapse: 0.06s\n","Epoch 10 [100/509] | Train Loss: 0.4768 Grad: 271099.7812 LR: 6.5461e-05 | Elapse: 5.84s\n","Epoch 10 [200/509] | Train Loss: 0.4773 Grad: 296733.3125 LR: 6.3823e-05 | Elapse: 11.61s\n","Epoch 10 [300/509] | Train Loss: 0.4845 Grad: 179545.7656 LR: 6.2168e-05 | Elapse: 17.38s\n","Epoch 10 [400/509] | Train Loss: 0.4825 Grad: 119956.2188 LR: 6.0499e-05 | Elapse: 23.13s\n","Epoch 10 [500/509] | Train Loss: 0.4823 Grad: 170726.9531 LR: 5.8817e-05 | Elapse: 28.88s\n","Epoch 10 [508/509] | Train Loss: 0.4818 Grad: 191448.4219 LR: 5.8682e-05 | Elapse: 29.34s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9de5d99fe61b4369a0c66a0bfc8a079e","version_major":2,"version_minor":0},"text/plain":["Valid [9]:   0%|          | 0/122 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 10 [0/122] | Valid Loss: 0.7185 | Elapse: 0.05s\n","Epoch 10 [100/122] | Valid Loss: 0.7126 | Elapse: 4.95s\n"]},{"name":"stderr","output_type":"stream","text":["----------------------------------------------------------------------------------------------------\n","Epoch 10 - Average Loss: (train) 0.4818; (valid) 0.7117 | Time: 35.30s\n","Best model found in epoch 10 | valid loss: 0.7117\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 10 [121/122] | Valid Loss: 0.7117 | Elapse: 5.96s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5194062c1567446d815b7d5638d35416","version_major":2,"version_minor":0},"text/plain":["Train [10]:   0%|          | 0/509 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 11 [0/509] | Train Loss: 0.4354 Grad: 418568.5625 LR: 5.8665e-05 | Elapse: 0.06s\n","Epoch 11 [100/509] | Train Loss: 0.4537 Grad: 249907.0000 LR: 5.6972e-05 | Elapse: 5.83s\n","Epoch 11 [200/509] | Train Loss: 0.4539 Grad: 151304.6094 LR: 5.5272e-05 | Elapse: 11.61s\n","Epoch 11 [300/509] | Train Loss: 0.4612 Grad: 228233.0469 LR: 5.3565e-05 | Elapse: 17.40s\n","Epoch 11 [400/509] | Train Loss: 0.4593 Grad: 124595.0391 LR: 5.1853e-05 | Elapse: 23.17s\n","Epoch 11 [500/509] | Train Loss: 0.4593 Grad: 188009.1875 LR: 5.0140e-05 | Elapse: 28.93s\n","Epoch 11 [508/509] | Train Loss: 0.4589 Grad: 216001.2188 LR: 5.0003e-05 | Elapse: 29.38s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ed70d62936b441dd9249a26ab0f84de0","version_major":2,"version_minor":0},"text/plain":["Valid [10]:   0%|          | 0/122 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 11 [0/122] | Valid Loss: 0.7278 | Elapse: 0.05s\n","Epoch 11 [100/122] | Valid Loss: 0.7151 | Elapse: 4.97s\n"]},{"name":"stderr","output_type":"stream","text":["----------------------------------------------------------------------------------------------------\n","Epoch 11 - Average Loss: (train) 0.4589; (valid) 0.7143 | Time: 35.36s\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 11 [121/122] | Valid Loss: 0.7143 | Elapse: 5.98s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5a9bb88613a3431ca396d6086c085533","version_major":2,"version_minor":0},"text/plain":["Train [11]:   0%|          | 0/509 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 12 [0/509] | Train Loss: 0.4150 Grad: 414473.9375 LR: 4.9986e-05 | Elapse: 0.06s\n","Epoch 12 [100/509] | Train Loss: 0.4324 Grad: 113931.4766 LR: 4.8272e-05 | Elapse: 5.82s\n","Epoch 12 [200/509] | Train Loss: 0.4342 Grad: 189202.9844 LR: 4.6561e-05 | Elapse: 11.59s\n","Epoch 12 [300/509] | Train Loss: 0.4412 Grad: 267092.4688 LR: 4.4854e-05 | Elapse: 17.38s\n","Epoch 12 [400/509] | Train Loss: 0.4394 Grad: 130323.6562 LR: 4.3152e-05 | Elapse: 23.17s\n","Epoch 12 [500/509] | Train Loss: 0.4394 Grad: 208410.8906 LR: 4.1459e-05 | Elapse: 28.95s\n","Epoch 12 [508/509] | Train Loss: 0.4391 Grad: 247866.1250 LR: 4.1324e-05 | Elapse: 29.42s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e5a51f4f1cea4190afd537015cda3137","version_major":2,"version_minor":0},"text/plain":["Valid [11]:   0%|          | 0/122 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 12 [0/122] | Valid Loss: 0.7513 | Elapse: 0.06s\n","Epoch 12 [100/122] | Valid Loss: 0.7211 | Elapse: 5.10s\n"]},{"name":"stderr","output_type":"stream","text":["----------------------------------------------------------------------------------------------------\n","Epoch 12 - Average Loss: (train) 0.4391; (valid) 0.7207 | Time: 35.57s\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 12 [121/122] | Valid Loss: 0.7207 | Elapse: 6.14s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"512b410d1be1483488ccdb5917484497","version_major":2,"version_minor":0},"text/plain":["Train [12]:   0%|          | 0/509 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 13 [0/509] | Train Loss: 0.3915 Grad: 384790.0000 LR: 4.1307e-05 | Elapse: 0.06s\n","Epoch 13 [100/509] | Train Loss: 0.4161 Grad: 211454.7656 LR: 3.9625e-05 | Elapse: 5.96s\n","Epoch 13 [200/509] | Train Loss: 0.4179 Grad: 965024.5625 LR: 3.7955e-05 | Elapse: 11.83s\n","Epoch 13 [300/509] | Train Loss: 0.4245 Grad: 478166.1250 LR: 3.6300e-05 | Elapse: 17.71s\n","Epoch 13 [400/509] | Train Loss: 0.4224 Grad: 264149.9688 LR: 3.4660e-05 | Elapse: 23.59s\n","Epoch 13 [500/509] | Train Loss: 0.4228 Grad: 424831.3125 LR: 3.3039e-05 | Elapse: 29.46s\n","Epoch 13 [508/509] | Train Loss: 0.4225 Grad: 615422.5000 LR: 3.2910e-05 | Elapse: 29.92s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"aa6ad7c395ac43e4a4bd03da99227310","version_major":2,"version_minor":0},"text/plain":["Valid [12]:   0%|          | 0/122 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 13 [0/122] | Valid Loss: 0.7739 | Elapse: 0.05s\n","Epoch 13 [100/122] | Valid Loss: 0.7336 | Elapse: 5.05s\n"]},{"name":"stderr","output_type":"stream","text":["----------------------------------------------------------------------------------------------------\n","Epoch 13 - Average Loss: (train) 0.4225; (valid) 0.7342 | Time: 36.01s\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 13 [121/122] | Valid Loss: 0.7342 | Elapse: 6.09s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"73a127898a574713979c5a801403151d","version_major":2,"version_minor":0},"text/plain":["Train [13]:   0%|          | 0/509 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 14 [0/509] | Train Loss: 0.3692 Grad: 356557.8125 LR: 3.2894e-05 | Elapse: 0.06s\n","Epoch 14 [100/509] | Train Loss: 0.4003 Grad: 119309.8203 LR: 3.1294e-05 | Elapse: 5.93s\n","Epoch 14 [200/509] | Train Loss: 0.4027 Grad: 297859.4688 LR: 2.9716e-05 | Elapse: 11.79s\n","Epoch 14 [300/509] | Train Loss: 0.4089 Grad: 237865.0469 LR: 2.8163e-05 | Elapse: 17.68s\n","Epoch 14 [400/509] | Train Loss: 0.4073 Grad: 140659.1562 LR: 2.6635e-05 | Elapse: 23.55s\n","Epoch 14 [500/509] | Train Loss: 0.4081 Grad: 215797.0000 LR: 2.5134e-05 | Elapse: 29.45s\n","Epoch 14 [508/509] | Train Loss: 0.4079 Grad: 349521.1875 LR: 2.5015e-05 | Elapse: 29.92s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e4204b04645c4467a389aa3f6a6e1ac8","version_major":2,"version_minor":0},"text/plain":["Valid [13]:   0%|          | 0/122 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 14 [0/122] | Valid Loss: 0.7819 | Elapse: 0.06s\n","Epoch 14 [100/122] | Valid Loss: 0.7425 | Elapse: 5.05s\n"]},{"name":"stderr","output_type":"stream","text":["----------------------------------------------------------------------------------------------------\n","Epoch 14 - Average Loss: (train) 0.4079; (valid) 0.7445 | Time: 35.99s\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 14 [121/122] | Valid Loss: 0.7445 | Elapse: 6.07s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8e0668bac4a04e0ea41b258e2f6758d6","version_major":2,"version_minor":0},"text/plain":["Train [14]:   0%|          | 0/509 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 15 [0/509] | Train Loss: 0.3534 Grad: 365969.9688 LR: 2.5000e-05 | Elapse: 0.06s\n","Epoch 15 [100/509] | Train Loss: 0.3880 Grad: 119525.3281 LR: 2.3532e-05 | Elapse: 5.94s\n","Epoch 15 [200/509] | Train Loss: 0.3905 Grad: 222382.5312 LR: 2.2094e-05 | Elapse: 11.80s\n","Epoch 15 [300/509] | Train Loss: 0.3963 Grad: 260401.3594 LR: 2.0690e-05 | Elapse: 17.67s\n","Epoch 15 [400/509] | Train Loss: 0.3949 Grad: 151630.3281 LR: 1.9320e-05 | Elapse: 23.53s\n","Epoch 15 [500/509] | Train Loss: 0.3964 Grad: 260798.7656 LR: 1.7985e-05 | Elapse: 29.42s\n","Epoch 15 [508/509] | Train Loss: 0.3961 Grad: 331158.6250 LR: 1.7880e-05 | Elapse: 29.88s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c6c90e58b9b243cb8558d559b16d8299","version_major":2,"version_minor":0},"text/plain":["Valid [14]:   0%|          | 0/122 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 15 [0/122] | Valid Loss: 0.7609 | Elapse: 0.05s\n","Epoch 15 [100/122] | Valid Loss: 0.7331 | Elapse: 5.07s\n"]},{"name":"stderr","output_type":"stream","text":["----------------------------------------------------------------------------------------------------\n","Epoch 15 - Average Loss: (train) 0.3961; (valid) 0.7354 | Time: 35.99s\n","Early stopping at epoch 15\n","====================================================================================================\n","Fold 1 Valid Loss: 0.7116912603378296\n","Elapse: 8.92 min \n","====================================================================================================\n","- Stage 2 | Train: 5248; Valid: 1244 -\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 15 [121/122] | Valid Loss: 0.7354 | Elapse: 6.11s\n","Loading model from checkpoint: outputs/ResnetGRU_v1_LB048_fold_1_stage_1.pth\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"511fd4fe23bc432d8d51ada4ad106104","version_major":2,"version_minor":0},"text/plain":["Train [0]:   0%|          | 0/164 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 1 [0/164] | Train Loss: 0.4731 Grad: 844993.0625 LR: 4.0022e-06 | Elapse: 0.07s\n","Epoch 1 [100/164] | Train Loss: 0.3414 Grad: 303061.4375 LR: 2.4879e-05 | Elapse: 5.99s\n","Epoch 1 [163/164] | Train Loss: 0.3304 Grad: 371534.6875 LR: 5.2231e-05 | Elapse: 9.74s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"81fd4eb2ab02499ba411760c2f7698dd","version_major":2,"version_minor":0},"text/plain":["Valid [0]:   0%|          | 0/39 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 1 [0/39] | Valid Loss: 0.4658 | Elapse: 0.06s\n"]},{"name":"stderr","output_type":"stream","text":["----------------------------------------------------------------------------------------------------\n","Epoch 1 - Average Loss: (train) 0.3304; (valid) 0.5135 | Time: 11.73s\n","Best model found in epoch 1 | valid loss: 0.5135\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1 [38/39] | Valid Loss: 0.5135 | Elapse: 1.99s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"268ba4817bc14940987798702c8e667d","version_major":2,"version_minor":0},"text/plain":["Train [1]:   0%|          | 0/164 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 2 [0/164] | Train Loss: 0.3493 Grad: 659771.3750 LR: 5.2692e-05 | Elapse: 0.06s\n","Epoch 2 [100/164] | Train Loss: 0.2825 Grad: 563418.3125 LR: 9.1734e-05 | Elapse: 6.00s\n","Epoch 2 [163/164] | Train Loss: 0.2747 Grad: 546782.7500 LR: 1.0000e-04 | Elapse: 9.74s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5537763861994e22920131adf3ae9cf5","version_major":2,"version_minor":0},"text/plain":["Valid [1]:   0%|          | 0/39 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 2 [0/39] | Valid Loss: 0.4805 | Elapse: 0.06s\n"]},{"name":"stderr","output_type":"stream","text":["----------------------------------------------------------------------------------------------------\n","Epoch 2 - Average Loss: (train) 0.2747; (valid) 0.4909 | Time: 11.71s\n","Best model found in epoch 2 | valid loss: 0.4909\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 2 [38/39] | Valid Loss: 0.4909 | Elapse: 1.97s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8c176395bb734425baac0bb29cdb5fd0","version_major":2,"version_minor":0},"text/plain":["Train [2]:   0%|          | 0/164 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 3 [0/164] | Train Loss: 0.2736 Grad: 503929.5312 LR: 1.0000e-04 | Elapse: 0.06s\n","Epoch 3 [100/164] | Train Loss: 0.2372 Grad: 534429.1250 LR: 9.9706e-05 | Elapse: 5.99s\n","Epoch 3 [163/164] | Train Loss: 0.2301 Grad: 488043.6875 LR: 9.9231e-05 | Elapse: 9.67s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1ff8471abfe34399bc7b6b25754a9a00","version_major":2,"version_minor":0},"text/plain":["Valid [2]:   0%|          | 0/39 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 3 [0/39] | Valid Loss: 0.4786 | Elapse: 0.06s\n"]},{"name":"stderr","output_type":"stream","text":["----------------------------------------------------------------------------------------------------\n","Epoch 3 - Average Loss: (train) 0.2301; (valid) 0.4860 | Time: 11.61s\n","Best model found in epoch 3 | valid loss: 0.4860\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 3 [38/39] | Valid Loss: 0.4860 | Elapse: 1.94s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7c3e6adb3f38490fb5ee1ef82dd912ea","version_major":2,"version_minor":0},"text/plain":["Train [3]:   0%|          | 0/164 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 4 [0/164] | Train Loss: 0.2250 Grad: 388162.5312 LR: 9.9222e-05 | Elapse: 0.06s\n","Epoch 4 [100/164] | Train Loss: 0.2055 Grad: 474863.4062 LR: 9.8011e-05 | Elapse: 5.91s\n","Epoch 4 [163/164] | Train Loss: 0.2008 Grad: 434401.6875 LR: 9.6968e-05 | Elapse: 9.58s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"84431370234f4e6faabd4a94146ac457","version_major":2,"version_minor":0},"text/plain":["Valid [3]:   0%|          | 0/39 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 4 [0/39] | Valid Loss: 0.4715 | Elapse: 0.05s\n"]},{"name":"stderr","output_type":"stream","text":["----------------------------------------------------------------------------------------------------\n","Epoch 4 - Average Loss: (train) 0.2008; (valid) 0.4829 | Time: 11.52s\n","Best model found in epoch 4 | valid loss: 0.4829\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 4 [38/39] | Valid Loss: 0.4829 | Elapse: 1.94s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f7acc1825b21462a88d540d1e335f24e","version_major":2,"version_minor":0},"text/plain":["Train [4]:   0%|          | 0/164 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 5 [0/164] | Train Loss: 0.1904 Grad: 358780.3438 LR: 9.6949e-05 | Elapse: 0.06s\n","Epoch 5 [100/164] | Train Loss: 0.1847 Grad: 417525.6250 LR: 9.4857e-05 | Elapse: 5.91s\n","Epoch 5 [163/164] | Train Loss: 0.1807 Grad: 372016.7188 LR: 9.3277e-05 | Elapse: 9.59s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e30227689012412e95ac94d3ef0a84bf","version_major":2,"version_minor":0},"text/plain":["Valid [4]:   0%|          | 0/39 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 5 [0/39] | Valid Loss: 0.4546 | Elapse: 0.05s\n"]},{"name":"stderr","output_type":"stream","text":["----------------------------------------------------------------------------------------------------\n","Epoch 5 - Average Loss: (train) 0.1807; (valid) 0.4837 | Time: 11.53s\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 5 [38/39] | Valid Loss: 0.4837 | Elapse: 1.94s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b2279bd8f8444cdb9ed8b9d1409dd70c","version_major":2,"version_minor":0},"text/plain":["Train [5]:   0%|          | 0/164 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 6 [0/164] | Train Loss: 0.1624 Grad: 335529.5312 LR: 9.3251e-05 | Elapse: 0.06s\n","Epoch 6 [100/164] | Train Loss: 0.1676 Grad: 377167.5312 LR: 9.0342e-05 | Elapse: 5.90s\n","Epoch 6 [163/164] | Train Loss: 0.1643 Grad: 384231.4062 LR: 8.8273e-05 | Elapse: 9.58s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9fab463b7cad4d678c40cd6de56063d6","version_major":2,"version_minor":0},"text/plain":["Valid [5]:   0%|          | 0/39 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 6 [0/39] | Valid Loss: 0.4471 | Elapse: 0.05s\n"]},{"name":"stderr","output_type":"stream","text":["----------------------------------------------------------------------------------------------------\n","Epoch 6 - Average Loss: (train) 0.1643; (valid) 0.4837 | Time: 11.53s\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 6 [38/39] | Valid Loss: 0.4837 | Elapse: 1.94s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"bacfaca8c6f948838c0ed53f4bb65f55","version_major":2,"version_minor":0},"text/plain":["Train [6]:   0%|          | 0/164 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 7 [0/164] | Train Loss: 0.1506 Grad: 354350.1562 LR: 8.8238e-05 | Elapse: 0.06s\n","Epoch 7 [100/164] | Train Loss: 0.1540 Grad: 364490.1875 LR: 8.4601e-05 | Elapse: 5.92s\n","Epoch 7 [163/164] | Train Loss: 0.1509 Grad: 349594.5625 LR: 8.2106e-05 | Elapse: 9.60s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3b709941429846f18129b0eb6bc7ab08","version_major":2,"version_minor":0},"text/plain":["Valid [6]:   0%|          | 0/39 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 7 [0/39] | Valid Loss: 0.4417 | Elapse: 0.05s\n"]},{"name":"stderr","output_type":"stream","text":["----------------------------------------------------------------------------------------------------\n","Epoch 7 - Average Loss: (train) 0.1509; (valid) 0.4845 | Time: 11.55s\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 7 [38/39] | Valid Loss: 0.4845 | Elapse: 1.95s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7b1ac2ecba424cb8ab12faa2beaf7fd9","version_major":2,"version_minor":0},"text/plain":["Train [7]:   0%|          | 0/164 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 8 [0/164] | Train Loss: 0.1324 Grad: 333563.8125 LR: 8.2065e-05 | Elapse: 0.06s\n","Epoch 8 [100/164] | Train Loss: 0.1414 Grad: 326394.4375 LR: 7.7810e-05 | Elapse: 5.92s\n","Epoch 8 [163/164] | Train Loss: 0.1378 Grad: 294935.5625 LR: 7.4964e-05 | Elapse: 9.63s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6e52772cc4a14c77906cc8c71841133d","version_major":2,"version_minor":0},"text/plain":["Valid [7]:   0%|          | 0/39 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 8 [0/39] | Valid Loss: 0.4422 | Elapse: 0.05s\n"]},{"name":"stderr","output_type":"stream","text":["----------------------------------------------------------------------------------------------------\n","Epoch 8 - Average Loss: (train) 0.1378; (valid) 0.4865 | Time: 11.59s\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 8 [38/39] | Valid Loss: 0.4865 | Elapse: 1.96s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9f4d1fc36ee446809088300d7b2a2823","version_major":2,"version_minor":0},"text/plain":["Train [8]:   0%|          | 0/164 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 9 [0/164] | Train Loss: 0.1220 Grad: 343690.4062 LR: 7.4918e-05 | Elapse: 0.07s\n","Epoch 9 [100/164] | Train Loss: 0.1304 Grad: 344828.9062 LR: 7.0174e-05 | Elapse: 5.90s\n","Epoch 9 [163/164] | Train Loss: 0.1273 Grad: 431970.7500 LR: 6.7064e-05 | Elapse: 9.58s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ea711dd78ab341dc9254aee04941a3f3","version_major":2,"version_minor":0},"text/plain":["Valid [8]:   0%|          | 0/39 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 9 [0/39] | Valid Loss: 0.4307 | Elapse: 0.05s\n"]},{"name":"stderr","output_type":"stream","text":["----------------------------------------------------------------------------------------------------\n","Epoch 9 - Average Loss: (train) 0.1273; (valid) 0.4884 | Time: 11.54s\n","Early stopping at epoch 9\n","====================================================================================================\n","Fold 1 Valid Loss: 0.4829496145248413\n","Elapse: 1.74 min \n","====================================================================================================\n","Fold 1 Elapse: 10.66 min\n","====================================================================================================\n","Fold: 2\n","====================================================================================================\n","- Stage 1 | Train: 16059; Valid: 4124 -\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 9 [38/39] | Valid Loss: 0.4884 | Elapse: 1.96s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f086569587be4d81a2caaa2c34aac59a","version_major":2,"version_minor":0},"text/plain":["Train [0]:   0%|          | 0/501 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 1 [0/501] | Train Loss: 1.1643 Grad: 69165.1562 LR: 4.0002e-06 | Elapse: 0.07s\n","Epoch 1 [100/501] | Train Loss: 1.1853 Grad: 92249.0312 LR: 6.3914e-06 | Elapse: 5.92s\n","Epoch 1 [200/501] | Train Loss: 1.1902 Grad: 74951.2734 LR: 1.3238e-05 | Elapse: 11.77s\n","Epoch 1 [300/501] | Train Loss: 1.1796 Grad: 81393.1719 LR: 2.3872e-05 | Elapse: 17.61s\n","Epoch 1 [400/501] | Train Loss: 1.1650 Grad: 54243.9375 LR: 3.7253e-05 | Elapse: 23.51s\n","Epoch 1 [500/501] | Train Loss: 1.1443 Grad: 61172.1406 LR: 5.2075e-05 | Elapse: 29.37s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b5903c056c4f4d08999be2cbac3c4d9d","version_major":2,"version_minor":0},"text/plain":["Valid [0]:   0%|          | 0/129 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 1 [0/129] | Valid Loss: 1.2066 | Elapse: 0.06s\n","Epoch 1 [100/129] | Valid Loss: 1.2773 | Elapse: 5.05s\n"]},{"name":"stderr","output_type":"stream","text":["----------------------------------------------------------------------------------------------------\n","Epoch 1 - Average Loss: (train) 1.1443; (valid) 1.2764 | Time: 35.82s\n","Best model found in epoch 1 | valid loss: 1.2764\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1 [128/129] | Valid Loss: 1.2764 | Elapse: 6.44s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c4579155f8a64daeb56bbb9e0bfade90","version_major":2,"version_minor":0},"text/plain":["Train [1]:   0%|          | 0/501 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 2 [0/501] | Train Loss: 1.0055 Grad: 51859.8789 LR: 5.2226e-05 | Elapse: 0.06s\n","Epoch 2 [100/501] | Train Loss: 1.0266 Grad: 57134.0547 LR: 6.7033e-05 | Elapse: 5.94s\n","Epoch 2 [200/501] | Train Loss: 1.0293 Grad: 72883.2422 LR: 8.0372e-05 | Elapse: 11.83s\n","Epoch 2 [300/501] | Train Loss: 1.0162 Grad: 61675.7383 LR: 9.0939e-05 | Elapse: 17.73s\n","Epoch 2 [400/501] | Train Loss: 1.0071 Grad: 46217.4023 LR: 9.7702e-05 | Elapse: 23.54s\n","Epoch 2 [500/501] | Train Loss: 0.9930 Grad: 78389.1406 LR: 1.0000e-04 | Elapse: 29.29s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e5c76ffffbfa41a1b77d3be21ff2ef38","version_major":2,"version_minor":0},"text/plain":["Valid [1]:   0%|          | 0/129 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 2 [0/129] | Valid Loss: 1.0113 | Elapse: 0.05s\n","Epoch 2 [100/129] | Valid Loss: 1.1727 | Elapse: 4.96s\n"]},{"name":"stderr","output_type":"stream","text":["----------------------------------------------------------------------------------------------------\n","Epoch 2 - Average Loss: (train) 0.9930; (valid) 1.1724 | Time: 35.64s\n","Best model found in epoch 2 | valid loss: 1.1724\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 2 [128/129] | Valid Loss: 1.1724 | Elapse: 6.35s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"835e1b99772948299437608ab01e93a8","version_major":2,"version_minor":0},"text/plain":["Train [2]:   0%|          | 0/501 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 3 [0/501] | Train Loss: 0.8875 Grad: 50919.2930 LR: 1.0000e-04 | Elapse: 0.06s\n","Epoch 3 [100/501] | Train Loss: 0.9188 Grad: 112362.1562 LR: 9.9968e-05 | Elapse: 5.90s\n","Epoch 3 [200/501] | Train Loss: 0.9204 Grad: 77045.0859 LR: 9.9876e-05 | Elapse: 11.72s\n","Epoch 3 [300/501] | Train Loss: 0.9014 Grad: 101666.7422 LR: 9.9724e-05 | Elapse: 17.52s\n","Epoch 3 [400/501] | Train Loss: 0.8890 Grad: 96002.7812 LR: 9.9511e-05 | Elapse: 23.26s\n","Epoch 3 [500/501] | Train Loss: 0.8728 Grad: 124664.9062 LR: 9.9238e-05 | Elapse: 29.02s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"67d0a52de8784b37869cfa0cbb5029d1","version_major":2,"version_minor":0},"text/plain":["Valid [2]:   0%|          | 0/129 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 3 [0/129] | Valid Loss: 0.9058 | Elapse: 0.06s\n","Epoch 3 [100/129] | Valid Loss: 1.0518 | Elapse: 5.02s\n"]},{"name":"stderr","output_type":"stream","text":["----------------------------------------------------------------------------------------------------\n","Epoch 3 - Average Loss: (train) 0.8728; (valid) 1.0538 | Time: 35.43s\n","Best model found in epoch 3 | valid loss: 1.0538\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 3 [128/129] | Valid Loss: 1.0538 | Elapse: 6.40s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"fe6dc2bb1dc5428c9842080df219369d","version_major":2,"version_minor":0},"text/plain":["Train [3]:   0%|          | 0/501 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 4 [0/501] | Train Loss: 0.7823 Grad: 96998.8281 LR: 9.9235e-05 | Elapse: 0.06s\n","Epoch 4 [100/501] | Train Loss: 0.8000 Grad: 185075.1719 LR: 9.8901e-05 | Elapse: 5.89s\n","Epoch 4 [200/501] | Train Loss: 0.8018 Grad: 111904.7109 LR: 9.8509e-05 | Elapse: 11.72s\n","Epoch 4 [300/501] | Train Loss: 0.7869 Grad: 112767.6484 LR: 9.8057e-05 | Elapse: 17.54s\n","Epoch 4 [400/501] | Train Loss: 0.7790 Grad: 127650.0781 LR: 9.7547e-05 | Elapse: 23.36s\n","Epoch 4 [500/501] | Train Loss: 0.7670 Grad: 184311.3281 LR: 9.6980e-05 | Elapse: 29.25s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"98d2f6ac19c04eccb942ba023d950450","version_major":2,"version_minor":0},"text/plain":["Valid [3]:   0%|          | 0/129 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 4 [0/129] | Valid Loss: 0.8350 | Elapse: 0.06s\n","Epoch 4 [100/129] | Valid Loss: 0.9519 | Elapse: 4.98s\n"]},{"name":"stderr","output_type":"stream","text":["----------------------------------------------------------------------------------------------------\n","Epoch 4 - Average Loss: (train) 0.7670; (valid) 0.9552 | Time: 35.59s\n","Best model found in epoch 4 | valid loss: 0.9552\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 4 [128/129] | Valid Loss: 0.9552 | Elapse: 6.34s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"76e1c45cc8ac4198b3a2395cdcb51df5","version_major":2,"version_minor":0},"text/plain":["Train [4]:   0%|          | 0/501 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 5 [0/501] | Train Loss: 0.6882 Grad: 145122.7188 LR: 9.6974e-05 | Elapse: 0.06s\n","Epoch 5 [100/501] | Train Loss: 0.7159 Grad: 172939.0938 LR: 9.6349e-05 | Elapse: 5.84s\n","Epoch 5 [200/501] | Train Loss: 0.7183 Grad: 142902.0625 LR: 9.5668e-05 | Elapse: 11.66s\n","Epoch 5 [300/501] | Train Loss: 0.7081 Grad: 146032.7969 LR: 9.4931e-05 | Elapse: 17.48s\n","Epoch 5 [400/501] | Train Loss: 0.7028 Grad: 182895.2031 LR: 9.4140e-05 | Elapse: 23.26s\n","Epoch 5 [500/501] | Train Loss: 0.6935 Grad: 284014.5625 LR: 9.3295e-05 | Elapse: 29.03s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a07fd244dcfa4432928866fe36b5c1e1","version_major":2,"version_minor":0},"text/plain":["Valid [4]:   0%|          | 0/129 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 5 [0/129] | Valid Loss: 0.7869 | Elapse: 0.05s\n","Epoch 5 [100/129] | Valid Loss: 0.8857 | Elapse: 4.94s\n"]},{"name":"stderr","output_type":"stream","text":["----------------------------------------------------------------------------------------------------\n","Epoch 5 - Average Loss: (train) 0.6935; (valid) 0.8900 | Time: 35.33s\n","Best model found in epoch 5 | valid loss: 0.8900\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 5 [128/129] | Valid Loss: 0.8900 | Elapse: 6.30s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9dccbff2a27146d780196bbdc69d7e3d","version_major":2,"version_minor":0},"text/plain":["Train [5]:   0%|          | 0/501 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 6 [0/501] | Train Loss: 0.6284 Grad: 178026.7344 LR: 9.3287e-05 | Elapse: 0.06s\n","Epoch 6 [100/501] | Train Loss: 0.6485 Grad: 197400.6875 LR: 9.2389e-05 | Elapse: 5.85s\n","Epoch 6 [200/501] | Train Loss: 0.6510 Grad: 181837.7500 LR: 9.1440e-05 | Elapse: 11.63s\n","Epoch 6 [300/501] | Train Loss: 0.6432 Grad: 215369.5312 LR: 9.0440e-05 | Elapse: 17.47s\n","Epoch 6 [400/501] | Train Loss: 0.6390 Grad: 206390.5938 LR: 8.9392e-05 | Elapse: 23.24s\n","Epoch 6 [500/501] | Train Loss: 0.6315 Grad: 343411.3438 LR: 8.8296e-05 | Elapse: 29.03s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"598cf3754cf247cfaf32649bbf912542","version_major":2,"version_minor":0},"text/plain":["Valid [5]:   0%|          | 0/129 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 6 [0/129] | Valid Loss: 0.7255 | Elapse: 0.05s\n","Epoch 6 [100/129] | Valid Loss: 0.8315 | Elapse: 4.95s\n"]},{"name":"stderr","output_type":"stream","text":["----------------------------------------------------------------------------------------------------\n","Epoch 6 - Average Loss: (train) 0.6315; (valid) 0.8375 | Time: 35.35s\n","Best model found in epoch 6 | valid loss: 0.8375\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 6 [128/129] | Valid Loss: 0.8375 | Elapse: 6.32s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3391a940b4074c0d867d1a3781603512","version_major":2,"version_minor":0},"text/plain":["Train [6]:   0%|          | 0/501 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 7 [0/501] | Train Loss: 0.5894 Grad: 218227.4375 LR: 8.8285e-05 | Elapse: 0.06s\n","Epoch 7 [100/501] | Train Loss: 0.5949 Grad: 279976.3750 LR: 8.7141e-05 | Elapse: 5.88s\n","Epoch 7 [200/501] | Train Loss: 0.5981 Grad: 221898.9375 LR: 8.5953e-05 | Elapse: 11.69s\n","Epoch 7 [300/501] | Train Loss: 0.5922 Grad: 240851.1562 LR: 8.4721e-05 | Elapse: 17.51s\n","Epoch 7 [400/501] | Train Loss: 0.5894 Grad: 226390.4688 LR: 8.3448e-05 | Elapse: 23.28s\n","Epoch 7 [500/501] | Train Loss: 0.5837 Grad: 344993.8750 LR: 8.2133e-05 | Elapse: 29.04s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"06b1062cf35145afa1268a02a4bc1f41","version_major":2,"version_minor":0},"text/plain":["Valid [6]:   0%|          | 0/129 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 7 [0/129] | Valid Loss: 0.6785 | Elapse: 0.05s\n","Epoch 7 [100/129] | Valid Loss: 0.8030 | Elapse: 5.03s\n"]},{"name":"stderr","output_type":"stream","text":["----------------------------------------------------------------------------------------------------\n","Epoch 7 - Average Loss: (train) 0.5837; (valid) 0.8098 | Time: 35.46s\n","Best model found in epoch 7 | valid loss: 0.8098\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 7 [128/129] | Valid Loss: 0.8098 | Elapse: 6.41s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e733a57e27234dd9a73a43af42de693e","version_major":2,"version_minor":0},"text/plain":["Train [7]:   0%|          | 0/501 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 8 [0/501] | Train Loss: 0.5730 Grad: 261837.0156 LR: 8.2120e-05 | Elapse: 0.06s\n","Epoch 8 [100/501] | Train Loss: 0.5551 Grad: 329673.9375 LR: 8.0766e-05 | Elapse: 5.81s\n","Epoch 8 [200/501] | Train Loss: 0.5585 Grad: 273346.0625 LR: 7.9375e-05 | Elapse: 11.66s\n","Epoch 8 [300/501] | Train Loss: 0.5537 Grad: 256957.7656 LR: 7.7948e-05 | Elapse: 17.49s\n","Epoch 8 [400/501] | Train Loss: 0.5516 Grad: 238785.9062 LR: 7.6488e-05 | Elapse: 23.29s\n","Epoch 8 [500/501] | Train Loss: 0.5469 Grad: 380429.6875 LR: 7.4995e-05 | Elapse: 29.09s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2f7e520f08f64d9a8c8b4781d161884e","version_major":2,"version_minor":0},"text/plain":["Valid [7]:   0%|          | 0/129 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 8 [0/129] | Valid Loss: 0.6534 | Elapse: 0.05s\n","Epoch 8 [100/129] | Valid Loss: 0.7865 | Elapse: 5.00s\n"]},{"name":"stderr","output_type":"stream","text":["----------------------------------------------------------------------------------------------------\n","Epoch 8 - Average Loss: (train) 0.5469; (valid) 0.7939 | Time: 35.46s\n","Best model found in epoch 8 | valid loss: 0.7939\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 8 [128/129] | Valid Loss: 0.7939 | Elapse: 6.36s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1d8ec12b7287405b870a2be3037340b1","version_major":2,"version_minor":0},"text/plain":["Train [8]:   0%|          | 0/501 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 9 [0/501] | Train Loss: 0.5425 Grad: 297699.9062 LR: 7.4980e-05 | Elapse: 0.06s\n","Epoch 9 [100/501] | Train Loss: 0.5218 Grad: 333373.8438 LR: 7.3457e-05 | Elapse: 5.82s\n","Epoch 9 [200/501] | Train Loss: 0.5262 Grad: 296808.0312 LR: 7.1905e-05 | Elapse: 11.61s\n","Epoch 9 [300/501] | Train Loss: 0.5225 Grad: 264322.2188 LR: 7.0326e-05 | Elapse: 17.38s\n","Epoch 9 [400/501] | Train Loss: 0.5205 Grad: 249217.1719 LR: 6.8723e-05 | Elapse: 23.18s\n","Epoch 9 [500/501] | Train Loss: 0.5163 Grad: 386530.0000 LR: 6.7098e-05 | Elapse: 28.98s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"53743a55a7cc4236bb4fa00eba21da24","version_major":2,"version_minor":0},"text/plain":["Valid [8]:   0%|          | 0/129 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 9 [0/129] | Valid Loss: 0.6340 | Elapse: 0.05s\n","Epoch 9 [100/129] | Valid Loss: 0.7783 | Elapse: 5.00s\n"]},{"name":"stderr","output_type":"stream","text":["----------------------------------------------------------------------------------------------------\n","Epoch 9 - Average Loss: (train) 0.5163; (valid) 0.7859 | Time: 35.36s\n","Best model found in epoch 9 | valid loss: 0.7859\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 9 [128/129] | Valid Loss: 0.7859 | Elapse: 6.38s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b349eb583be94e078807131fae0a8aef","version_major":2,"version_minor":0},"text/plain":["Train [9]:   0%|          | 0/501 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 10 [0/501] | Train Loss: 0.5171 Grad: 377319.9688 LR: 6.7081e-05 | Elapse: 0.06s\n","Epoch 10 [100/501] | Train Loss: 0.4917 Grad: 383122.3125 LR: 6.5435e-05 | Elapse: 5.90s\n","Epoch 10 [200/501] | Train Loss: 0.4974 Grad: 320017.2812 LR: 6.3770e-05 | Elapse: 11.72s\n","Epoch 10 [300/501] | Train Loss: 0.4946 Grad: 286101.3438 LR: 6.2088e-05 | Elapse: 17.53s\n","Epoch 10 [400/501] | Train Loss: 0.4930 Grad: 266061.3750 LR: 6.0391e-05 | Elapse: 23.32s\n","Epoch 10 [500/501] | Train Loss: 0.4893 Grad: 426692.2188 LR: 5.8682e-05 | Elapse: 29.13s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"340a6f8b51fe45c184e08fff7ae48239","version_major":2,"version_minor":0},"text/plain":["Valid [9]:   0%|          | 0/129 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 10 [0/129] | Valid Loss: 0.6280 | Elapse: 0.06s\n","Epoch 10 [100/129] | Valid Loss: 0.7760 | Elapse: 4.99s\n"]},{"name":"stderr","output_type":"stream","text":["----------------------------------------------------------------------------------------------------\n","Epoch 10 - Average Loss: (train) 0.4893; (valid) 0.7836 | Time: 35.52s\n","Best model found in epoch 10 | valid loss: 0.7836\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 10 [128/129] | Valid Loss: 0.7836 | Elapse: 6.38s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3b427dcf0cbb42148e2095835dd6e674","version_major":2,"version_minor":0},"text/plain":["Train [10]:   0%|          | 0/501 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 11 [0/501] | Train Loss: 0.4941 Grad: 458205.9375 LR: 5.8665e-05 | Elapse: 0.06s\n","Epoch 11 [100/501] | Train Loss: 0.4660 Grad: 346321.3438 LR: 5.6945e-05 | Elapse: 5.98s\n","Epoch 11 [200/501] | Train Loss: 0.4723 Grad: 335475.7188 LR: 5.5217e-05 | Elapse: 11.87s\n","Epoch 11 [300/501] | Train Loss: 0.4706 Grad: 304074.0312 LR: 5.3482e-05 | Elapse: 17.75s\n","Epoch 11 [400/501] | Train Loss: 0.4699 Grad: 279756.5938 LR: 5.1743e-05 | Elapse: 23.60s\n","Epoch 11 [500/501] | Train Loss: 0.4663 Grad: 456661.4062 LR: 5.0003e-05 | Elapse: 29.45s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f0d6f8cb0be34c0abee3d72985a14f2e","version_major":2,"version_minor":0},"text/plain":["Valid [10]:   0%|          | 0/129 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 11 [0/129] | Valid Loss: 0.6255 | Elapse: 0.05s\n","Epoch 11 [100/129] | Valid Loss: 0.7759 | Elapse: 5.03s\n"]},{"name":"stderr","output_type":"stream","text":["----------------------------------------------------------------------------------------------------\n","Epoch 11 - Average Loss: (train) 0.4663; (valid) 0.7832 | Time: 35.87s\n","Best model found in epoch 11 | valid loss: 0.7832\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 11 [128/129] | Valid Loss: 0.7832 | Elapse: 6.41s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3af7340dc3a24de9a1cce656290a57a3","version_major":2,"version_minor":0},"text/plain":["Train [11]:   0%|          | 0/501 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 12 [0/501] | Train Loss: 0.4748 Grad: 479602.2188 LR: 4.9985e-05 | Elapse: 0.06s\n","Epoch 12 [100/501] | Train Loss: 0.4449 Grad: 457880.2812 LR: 4.8244e-05 | Elapse: 5.95s\n","Epoch 12 [200/501] | Train Loss: 0.4513 Grad: 361366.8438 LR: 4.6506e-05 | Elapse: 11.81s\n","Epoch 12 [300/501] | Train Loss: 0.4507 Grad: 277206.9688 LR: 4.4771e-05 | Elapse: 17.65s\n","Epoch 12 [400/501] | Train Loss: 0.4503 Grad: 297676.3438 LR: 4.3043e-05 | Elapse: 23.46s\n","Epoch 12 [500/501] | Train Loss: 0.4468 Grad: 448860.6562 LR: 4.1324e-05 | Elapse: 29.32s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a75a1923a3ba4faaa7979f55280a71b9","version_major":2,"version_minor":0},"text/plain":["Valid [11]:   0%|          | 0/129 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 12 [0/129] | Valid Loss: 0.6157 | Elapse: 0.05s\n","Epoch 12 [100/129] | Valid Loss: 0.7756 | Elapse: 5.02s\n"]},{"name":"stderr","output_type":"stream","text":["----------------------------------------------------------------------------------------------------\n","Epoch 12 - Average Loss: (train) 0.4468; (valid) 0.7830 | Time: 35.73s\n","Best model found in epoch 12 | valid loss: 0.7830\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 12 [128/129] | Valid Loss: 0.7830 | Elapse: 6.40s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8c7ad69306144120b1957225c1b1a24c","version_major":2,"version_minor":0},"text/plain":["Train [12]:   0%|          | 0/501 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 13 [0/501] | Train Loss: 0.4679 Grad: 463101.3125 LR: 4.1307e-05 | Elapse: 0.06s\n","Epoch 13 [100/501] | Train Loss: 0.4272 Grad: 776869.2500 LR: 3.9598e-05 | Elapse: 5.90s\n","Epoch 13 [200/501] | Train Loss: 0.4337 Grad: 389003.0938 LR: 3.7902e-05 | Elapse: 11.75s\n","Epoch 13 [300/501] | Train Loss: 0.4335 Grad: 248919.4062 LR: 3.6220e-05 | Elapse: 17.60s\n","Epoch 13 [400/501] | Train Loss: 0.4332 Grad: 322751.4688 LR: 3.4555e-05 | Elapse: 23.42s\n","Epoch 13 [500/501] | Train Loss: 0.4300 Grad: 451475.0625 LR: 3.2909e-05 | Elapse: 29.26s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ae3c97579e974040a008fd0b70fe59f7","version_major":2,"version_minor":0},"text/plain":["Valid [12]:   0%|          | 0/129 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 13 [0/129] | Valid Loss: 0.6083 | Elapse: 0.05s\n","Epoch 13 [100/129] | Valid Loss: 0.7773 | Elapse: 5.02s\n"]},{"name":"stderr","output_type":"stream","text":["----------------------------------------------------------------------------------------------------\n","Epoch 13 - Average Loss: (train) 0.4300; (valid) 0.7842 | Time: 35.67s\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 13 [128/129] | Valid Loss: 0.7842 | Elapse: 6.41s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5d2580016e344bdb8da84dc1841b8632","version_major":2,"version_minor":0},"text/plain":["Train [13]:   0%|          | 0/501 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 14 [0/501] | Train Loss: 0.4615 Grad: 465948.0625 LR: 3.2893e-05 | Elapse: 0.06s\n","Epoch 14 [100/501] | Train Loss: 0.4130 Grad: 396299.1250 LR: 3.1268e-05 | Elapse: 5.88s\n","Epoch 14 [200/501] | Train Loss: 0.4194 Grad: 404624.3125 LR: 2.9666e-05 | Elapse: 11.72s\n","Epoch 14 [300/501] | Train Loss: 0.4197 Grad: 242286.8438 LR: 2.8088e-05 | Elapse: 17.59s\n","Epoch 14 [400/501] | Train Loss: 0.4195 Grad: 353097.5625 LR: 2.6537e-05 | Elapse: 23.46s\n","Epoch 14 [500/501] | Train Loss: 0.4164 Grad: 424852.9688 LR: 2.5015e-05 | Elapse: 29.37s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f5d7db3d66814941b6bcf9528d60e09c","version_major":2,"version_minor":0},"text/plain":["Valid [13]:   0%|          | 0/129 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 14 [0/129] | Valid Loss: 0.6132 | Elapse: 0.06s\n","Epoch 14 [100/129] | Valid Loss: 0.7819 | Elapse: 5.04s\n"]},{"name":"stderr","output_type":"stream","text":["----------------------------------------------------------------------------------------------------\n","Epoch 14 - Average Loss: (train) 0.4164; (valid) 0.7888 | Time: 35.80s\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 14 [128/129] | Valid Loss: 0.7888 | Elapse: 6.42s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f0c537791aaf4a399e352aa1fc89bb61","version_major":2,"version_minor":0},"text/plain":["Train [14]:   0%|          | 0/501 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 15 [0/501] | Train Loss: 0.4509 Grad: 449130.0938 LR: 2.5000e-05 | Elapse: 0.06s\n","Epoch 15 [100/501] | Train Loss: 0.4031 Grad: 563441.0625 LR: 2.3508e-05 | Elapse: 5.90s\n","Epoch 15 [200/501] | Train Loss: 0.4095 Grad: 422241.9688 LR: 2.2048e-05 | Elapse: 11.76s\n","Epoch 15 [300/501] | Train Loss: 0.4092 Grad: 220113.0938 LR: 2.0623e-05 | Elapse: 17.65s\n","Epoch 15 [400/501] | Train Loss: 0.4089 Grad: 365379.3750 LR: 1.9233e-05 | Elapse: 23.46s\n","Epoch 15 [500/501] | Train Loss: 0.4062 Grad: 426586.3438 LR: 1.7880e-05 | Elapse: 29.26s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8b9714f2bab64de8b6ed34c8944fcb64","version_major":2,"version_minor":0},"text/plain":["Valid [14]:   0%|          | 0/129 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 15 [0/129] | Valid Loss: 0.6156 | Elapse: 0.06s\n","Epoch 15 [100/129] | Valid Loss: 0.7840 | Elapse: 4.94s\n"]},{"name":"stderr","output_type":"stream","text":["----------------------------------------------------------------------------------------------------\n","Epoch 15 - Average Loss: (train) 0.4062; (valid) 0.7909 | Time: 35.56s\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 15 [128/129] | Valid Loss: 0.7909 | Elapse: 6.30s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1851a5c233564a06b4c44490966d3ffc","version_major":2,"version_minor":0},"text/plain":["Train [15]:   0%|          | 0/501 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 16 [0/501] | Train Loss: 0.4444 Grad: 445666.0312 LR: 1.7867e-05 | Elapse: 0.06s\n","Epoch 16 [100/501] | Train Loss: 0.3955 Grad: 364561.4062 LR: 1.6554e-05 | Elapse: 5.80s\n","Epoch 16 [200/501] | Train Loss: 0.4016 Grad: 461645.0000 LR: 1.5281e-05 | Elapse: 11.54s\n","Epoch 16 [300/501] | Train Loss: 0.4009 Grad: 240433.7812 LR: 1.4050e-05 | Elapse: 17.24s\n","Epoch 16 [400/501] | Train Loss: 0.4008 Grad: 390066.1250 LR: 1.2864e-05 | Elapse: 22.95s\n","Epoch 16 [500/501] | Train Loss: 0.3983 Grad: 429118.9375 LR: 1.1722e-05 | Elapse: 28.68s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6284f444898f4b4f850086761ef36ece","version_major":2,"version_minor":0},"text/plain":["Valid [15]:   0%|          | 0/129 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 16 [0/129] | Valid Loss: 0.6069 | Elapse: 0.05s\n","Epoch 16 [100/129] | Valid Loss: 0.7817 | Elapse: 4.92s\n"]},{"name":"stderr","output_type":"stream","text":["----------------------------------------------------------------------------------------------------\n","Epoch 16 - Average Loss: (train) 0.3983; (valid) 0.7892 | Time: 34.96s\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 16 [128/129] | Valid Loss: 0.7892 | Elapse: 6.28s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"bc395709d93f414aa2f755c08818d102","version_major":2,"version_minor":0},"text/plain":["Train [16]:   0%|          | 0/501 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 17 [0/501] | Train Loss: 0.4387 Grad: 454773.9375 LR: 1.1711e-05 | Elapse: 0.06s\n","Epoch 17 [100/501] | Train Loss: 0.3904 Grad: 357592.5938 LR: 1.0616e-05 | Elapse: 5.80s\n","Epoch 17 [200/501] | Train Loss: 0.3963 Grad: 700681.3750 LR: 9.5690e-06 | Elapse: 11.56s\n","Epoch 17 [300/501] | Train Loss: 0.3954 Grad: 255800.9375 LR: 8.5711e-06 | Elapse: 17.31s\n","Epoch 17 [400/501] | Train Loss: 0.3955 Grad: 407495.4375 LR: 7.6235e-06 | Elapse: 22.97s\n","Epoch 17 [500/501] | Train Loss: 0.3934 Grad: 399049.5312 LR: 6.7273e-06 | Elapse: 28.68s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6383ea658afc4f268d1972baf5b05a07","version_major":2,"version_minor":0},"text/plain":["Valid [16]:   0%|          | 0/129 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 17 [0/129] | Valid Loss: 0.5997 | Elapse: 0.05s\n","Epoch 17 [100/129] | Valid Loss: 0.7785 | Elapse: 4.94s\n"]},{"name":"stderr","output_type":"stream","text":["----------------------------------------------------------------------------------------------------\n","Epoch 17 - Average Loss: (train) 0.3934; (valid) 0.7868 | Time: 34.98s\n","Early stopping at epoch 17\n","====================================================================================================\n","Fold 2 Valid Loss: 0.7829928398132324\n","Elapse: 10.06 min \n","====================================================================================================\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 17 [128/129] | Valid Loss: 0.7868 | Elapse: 6.30s\n"]},{"name":"stderr","output_type":"stream","text":["- Stage 2 | Train: 5070; Valid: 1422 -\n"]},{"name":"stdout","output_type":"stream","text":["Loading model from checkpoint: outputs/ResnetGRU_v1_LB048_fold_2_stage_1.pth\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c48e5430419443f1913c832b3187e4e0","version_major":2,"version_minor":0},"text/plain":["Train [0]:   0%|          | 0/158 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 1 [0/158] | Train Loss: 0.5660 Grad: 854411.8125 LR: 4.0024e-06 | Elapse: 0.06s\n","Epoch 1 [100/158] | Train Loss: 0.3738 Grad: 469991.0000 LR: 2.6361e-05 | Elapse: 5.82s\n","Epoch 1 [157/158] | Train Loss: 0.3567 Grad: 406150.2812 LR: 5.2239e-05 | Elapse: 9.11s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"353547d393b54ed6963833a5e65a852a","version_major":2,"version_minor":0},"text/plain":["Valid [0]:   0%|          | 0/45 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 1 [0/45] | Valid Loss: 0.4418 | Elapse: 0.06s\n"]},{"name":"stderr","output_type":"stream","text":["----------------------------------------------------------------------------------------------------\n","Epoch 1 - Average Loss: (train) 0.3567; (valid) 0.5688 | Time: 11.30s\n","Best model found in epoch 1 | valid loss: 0.5688\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1 [44/45] | Valid Loss: 0.5688 | Elapse: 2.19s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"49ba6c94fe3840598bc1ed23c59eea6b","version_major":2,"version_minor":0},"text/plain":["Train [1]:   0%|          | 0/158 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 2 [0/158] | Train Loss: 0.4592 Grad: 658347.8750 LR: 5.2718e-05 | Elapse: 0.06s\n","Epoch 2 [100/158] | Train Loss: 0.3056 Grad: 338311.8750 LR: 9.2706e-05 | Elapse: 5.84s\n","Epoch 2 [157/158] | Train Loss: 0.2921 Grad: 257837.0938 LR: 1.0000e-04 | Elapse: 9.13s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3e7911c6a94d4ad4b1f061bbd80b8362","version_major":2,"version_minor":0},"text/plain":["Valid [1]:   0%|          | 0/45 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 2 [0/45] | Valid Loss: 0.3484 | Elapse: 0.05s\n"]},{"name":"stderr","output_type":"stream","text":["----------------------------------------------------------------------------------------------------\n","Epoch 2 - Average Loss: (train) 0.2921; (valid) 0.5093 | Time: 11.32s\n","Best model found in epoch 2 | valid loss: 0.5093\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 2 [44/45] | Valid Loss: 0.5093 | Elapse: 2.18s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4183cf4ba653423f80fcca3091679b36","version_major":2,"version_minor":0},"text/plain":["Train [2]:   0%|          | 0/158 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 3 [0/158] | Train Loss: 0.3860 Grad: 567232.5625 LR: 1.0000e-04 | Elapse: 0.06s\n","Epoch 3 [100/158] | Train Loss: 0.2534 Grad: 500141.4688 LR: 9.9683e-05 | Elapse: 5.73s\n","Epoch 3 [157/158] | Train Loss: 0.2444 Grad: 343914.7500 LR: 9.9231e-05 | Elapse: 9.01s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a5bbdaf861ff4e2697f50e54e9170810","version_major":2,"version_minor":0},"text/plain":["Valid [2]:   0%|          | 0/45 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 3 [0/45] | Valid Loss: 0.3424 | Elapse: 0.05s\n"]},{"name":"stderr","output_type":"stream","text":["----------------------------------------------------------------------------------------------------\n","Epoch 3 - Average Loss: (train) 0.2444; (valid) 0.5016 | Time: 11.20s\n","Best model found in epoch 3 | valid loss: 0.5016\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 3 [44/45] | Valid Loss: 0.5016 | Elapse: 2.18s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7680be77158349b580dd4f833b106b7c","version_major":2,"version_minor":0},"text/plain":["Train [3]:   0%|          | 0/158 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 4 [0/158] | Train Loss: 0.3197 Grad: 455687.1250 LR: 9.9221e-05 | Elapse: 0.06s\n","Epoch 4 [100/158] | Train Loss: 0.2219 Grad: 478701.4688 LR: 9.7953e-05 | Elapse: 5.81s\n","Epoch 4 [157/158] | Train Loss: 0.2149 Grad: 306076.0312 LR: 9.6967e-05 | Elapse: 9.09s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"41c886081fc745c48f2199b1ced0e8c8","version_major":2,"version_minor":0},"text/plain":["Valid [3]:   0%|          | 0/45 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 4 [0/45] | Valid Loss: 0.3377 | Elapse: 0.05s\n"]},{"name":"stderr","output_type":"stream","text":["----------------------------------------------------------------------------------------------------\n","Epoch 4 - Average Loss: (train) 0.2149; (valid) 0.5001 | Time: 11.27s\n","Best model found in epoch 4 | valid loss: 0.5001\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 4 [44/45] | Valid Loss: 0.5001 | Elapse: 2.18s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9ef130aa4c9048ca957ed5bb354e6bd9","version_major":2,"version_minor":0},"text/plain":["Train [4]:   0%|          | 0/158 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 5 [0/158] | Train Loss: 0.2846 Grad: 431568.4688 LR: 9.6948e-05 | Elapse: 0.06s\n","Epoch 5 [100/158] | Train Loss: 0.2001 Grad: 467030.0000 LR: 9.4766e-05 | Elapse: 5.83s\n","Epoch 5 [157/158] | Train Loss: 0.1944 Grad: 263292.8438 LR: 9.3276e-05 | Elapse: 9.18s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ca545ee21b744adfb0138cf2144f62c9","version_major":2,"version_minor":0},"text/plain":["Valid [4]:   0%|          | 0/45 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 5 [0/45] | Valid Loss: 0.3361 | Elapse: 0.06s\n"]},{"name":"stderr","output_type":"stream","text":["----------------------------------------------------------------------------------------------------\n","Epoch 5 - Average Loss: (train) 0.1944; (valid) 0.5003 | Time: 11.40s\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 5 [44/45] | Valid Loss: 0.5003 | Elapse: 2.22s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6d9d19b1a48d4793875d5a87fea3e9a7","version_major":2,"version_minor":0},"text/plain":["Train [5]:   0%|          | 0/158 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 6 [0/158] | Train Loss: 0.2509 Grad: 410532.8750 LR: 9.3249e-05 | Elapse: 0.06s\n","Epoch 6 [100/158] | Train Loss: 0.1834 Grad: 438894.4375 LR: 9.0220e-05 | Elapse: 5.93s\n","Epoch 6 [157/158] | Train Loss: 0.1784 Grad: 294537.5312 LR: 8.8271e-05 | Elapse: 9.26s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8f6e1bd86b41447dad2c075399cc99d0","version_major":2,"version_minor":0},"text/plain":["Valid [5]:   0%|          | 0/45 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 6 [0/45] | Valid Loss: 0.3237 | Elapse: 0.06s\n"]},{"name":"stderr","output_type":"stream","text":["----------------------------------------------------------------------------------------------------\n","Epoch 6 - Average Loss: (train) 0.1784; (valid) 0.5027 | Time: 11.49s\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 6 [44/45] | Valid Loss: 0.5027 | Elapse: 2.23s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"256dceee5e32470caf2888a8eb76fb75","version_major":2,"version_minor":0},"text/plain":["Train [6]:   0%|          | 0/158 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 7 [0/158] | Train Loss: 0.2212 Grad: 396004.3125 LR: 8.8236e-05 | Elapse: 0.06s\n","Epoch 7 [100/158] | Train Loss: 0.1686 Grad: 356918.5000 LR: 8.4452e-05 | Elapse: 5.91s\n","Epoch 7 [157/158] | Train Loss: 0.1644 Grad: 423849.3125 LR: 8.2104e-05 | Elapse: 9.25s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6bae4b4d4351410fb44a83b967f7eee5","version_major":2,"version_minor":0},"text/plain":["Valid [6]:   0%|          | 0/45 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 7 [0/45] | Valid Loss: 0.3310 | Elapse: 0.06s\n"]},{"name":"stderr","output_type":"stream","text":["----------------------------------------------------------------------------------------------------\n","Epoch 7 - Average Loss: (train) 0.1644; (valid) 0.5052 | Time: 11.47s\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 7 [44/45] | Valid Loss: 0.5052 | Elapse: 2.22s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d63f65a9ab5f4ed2a434da479cb0aa41","version_major":2,"version_minor":0},"text/plain":["Train [7]:   0%|          | 0/158 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 8 [0/158] | Train Loss: 0.2091 Grad: 407337.9062 LR: 8.2062e-05 | Elapse: 0.06s\n","Epoch 8 [100/158] | Train Loss: 0.1569 Grad: 372094.2500 LR: 7.7638e-05 | Elapse: 5.91s\n","Epoch 8 [157/158] | Train Loss: 0.1532 Grad: 607934.7500 LR: 7.4962e-05 | Elapse: 9.25s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"532e3356368742c99a444ed1d62b779a","version_major":2,"version_minor":0},"text/plain":["Valid [7]:   0%|          | 0/45 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 8 [0/45] | Valid Loss: 0.3326 | Elapse: 0.05s\n"]},{"name":"stderr","output_type":"stream","text":["----------------------------------------------------------------------------------------------------\n","Epoch 8 - Average Loss: (train) 0.1532; (valid) 0.5120 | Time: 11.47s\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 8 [44/45] | Valid Loss: 0.5120 | Elapse: 2.22s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d713617ae7e14cbbb4bfab4f10c7558b","version_major":2,"version_minor":0},"text/plain":["Train [8]:   0%|          | 0/158 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 9 [0/158] | Train Loss: 0.1904 Grad: 385475.9375 LR: 7.4914e-05 | Elapse: 0.06s\n","Epoch 9 [100/158] | Train Loss: 0.1455 Grad: 306060.2188 LR: 6.9985e-05 | Elapse: 5.93s\n","Epoch 9 [157/158] | Train Loss: 0.1413 Grad: 488520.3750 LR: 6.7062e-05 | Elapse: 9.29s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"25127d77edd040e2a6f435a65fb7e98f","version_major":2,"version_minor":0},"text/plain":["Valid [8]:   0%|          | 0/45 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 9 [0/45] | Valid Loss: 0.3375 | Elapse: 0.06s\n"]},{"name":"stderr","output_type":"stream","text":["----------------------------------------------------------------------------------------------------\n","Epoch 9 - Average Loss: (train) 0.1413; (valid) 0.5190 | Time: 11.52s\n","Early stopping at epoch 9\n","====================================================================================================\n","Fold 2 Valid Loss: 0.5001062750816345\n","Elapse: 1.71 min \n","====================================================================================================\n","Fold 2 Elapse: 11.77 min\n","====================================================================================================\n","Fold: 3\n","====================================================================================================\n","- Stage 1 | Train: 16337; Valid: 3846 -\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 9 [44/45] | Valid Loss: 0.5190 | Elapse: 2.23s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2e7dedd108de4411bd94436f51a65605","version_major":2,"version_minor":0},"text/plain":["Train [0]:   0%|          | 0/510 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 1 [0/510] | Train Loss: 1.1912 Grad: 60922.4375 LR: 4.0002e-06 | Elapse: 0.07s\n","Epoch 1 [100/510] | Train Loss: 1.1562 Grad: 67459.1172 LR: 6.3083e-06 | Elapse: 5.89s\n","Epoch 1 [200/510] | Train Loss: 1.1493 Grad: 79558.8359 LR: 1.2925e-05 | Elapse: 11.76s\n","Epoch 1 [300/510] | Train Loss: 1.1402 Grad: 57920.4609 LR: 2.3227e-05 | Elapse: 17.61s\n","Epoch 1 [400/510] | Train Loss: 1.1282 Grad: 55223.5273 LR: 3.6241e-05 | Elapse: 23.45s\n","Epoch 1 [500/510] | Train Loss: 1.1120 Grad: 44679.5508 LR: 5.0742e-05 | Elapse: 29.27s\n","Epoch 1 [509/510] | Train Loss: 1.1108 Grad: 65284.4102 LR: 5.2074e-05 | Elapse: 29.79s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6f81e9518bc74c8f9cd5185b0937e1c0","version_major":2,"version_minor":0},"text/plain":["Valid [0]:   0%|          | 0/121 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 1 [0/121] | Valid Loss: 1.1624 | Elapse: 0.06s\n","Epoch 1 [100/121] | Valid Loss: 1.2900 | Elapse: 5.01s\n"]},{"name":"stderr","output_type":"stream","text":["----------------------------------------------------------------------------------------------------\n","Epoch 1 - Average Loss: (train) 1.1108; (valid) 1.2859 | Time: 35.77s\n","Best model found in epoch 1 | valid loss: 1.2859\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1 [120/121] | Valid Loss: 1.2859 | Elapse: 5.97s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6defdab16a684f1eb9d2111a133c9b03","version_major":2,"version_minor":0},"text/plain":["Train [1]:   0%|          | 0/510 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 2 [0/510] | Train Loss: 1.0882 Grad: 45621.6016 LR: 5.2222e-05 | Elapse: 0.06s\n","Epoch 2 [100/510] | Train Loss: 1.0158 Grad: 55301.7188 LR: 6.6777e-05 | Elapse: 5.87s\n","Epoch 2 [200/510] | Train Loss: 1.0119 Grad: 65561.6562 LR: 7.9938e-05 | Elapse: 11.70s\n","Epoch 2 [300/510] | Train Loss: 1.0017 Grad: 57075.3242 LR: 9.0464e-05 | Elapse: 17.52s\n","Epoch 2 [400/510] | Train Loss: 0.9879 Grad: 54085.3789 LR: 9.7364e-05 | Elapse: 23.33s\n","Epoch 2 [500/510] | Train Loss: 0.9740 Grad: 55806.6289 LR: 9.9985e-05 | Elapse: 29.13s\n","Epoch 2 [509/510] | Train Loss: 0.9733 Grad: 83727.1641 LR: 1.0000e-04 | Elapse: 29.66s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b2ca546b5c5c436ea7e5c7616e7ebb9d","version_major":2,"version_minor":0},"text/plain":["Valid [1]:   0%|          | 0/121 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 2 [0/121] | Valid Loss: 1.0870 | Elapse: 0.06s\n","Epoch 2 [100/121] | Valid Loss: 1.1592 | Elapse: 4.99s\n"]},{"name":"stderr","output_type":"stream","text":["----------------------------------------------------------------------------------------------------\n","Epoch 2 - Average Loss: (train) 0.9733; (valid) 1.1545 | Time: 35.60s\n","Best model found in epoch 2 | valid loss: 1.1545\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 2 [120/121] | Valid Loss: 1.1545 | Elapse: 5.94s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7f34c813912041ccbdefb2ff427cbd87","version_major":2,"version_minor":0},"text/plain":["Train [2]:   0%|          | 0/510 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 3 [0/510] | Train Loss: 1.0122 Grad: 63871.3359 LR: 1.0000e-04 | Elapse: 0.06s\n","Epoch 3 [100/510] | Train Loss: 0.8866 Grad: 123873.0625 LR: 9.9970e-05 | Elapse: 5.91s\n","Epoch 3 [200/510] | Train Loss: 0.8779 Grad: 128024.0469 LR: 9.9881e-05 | Elapse: 11.76s\n","Epoch 3 [300/510] | Train Loss: 0.8681 Grad: 119070.2891 LR: 9.9733e-05 | Elapse: 17.61s\n","Epoch 3 [400/510] | Train Loss: 0.8566 Grad: 83093.4453 LR: 9.9528e-05 | Elapse: 23.36s\n","Epoch 3 [500/510] | Train Loss: 0.8467 Grad: 76686.2969 LR: 9.9264e-05 | Elapse: 29.12s\n","Epoch 3 [509/510] | Train Loss: 0.8464 Grad: 122237.2344 LR: 9.9238e-05 | Elapse: 29.64s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"35a944a21ea24a4a88a06fe7b0dcecbf","version_major":2,"version_minor":0},"text/plain":["Valid [2]:   0%|          | 0/121 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 3 [0/121] | Valid Loss: 1.0273 | Elapse: 0.05s\n","Epoch 3 [100/121] | Valid Loss: 1.0454 | Elapse: 4.93s\n"]},{"name":"stderr","output_type":"stream","text":["----------------------------------------------------------------------------------------------------\n","Epoch 3 - Average Loss: (train) 0.8464; (valid) 1.0380 | Time: 35.52s\n","Best model found in epoch 3 | valid loss: 1.0380\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 3 [120/121] | Valid Loss: 1.0380 | Elapse: 5.88s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c23feffd041b420b92e6b48d53fce5c5","version_major":2,"version_minor":0},"text/plain":["Train [3]:   0%|          | 0/510 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 4 [0/510] | Train Loss: 0.9136 Grad: 90044.3750 LR: 9.9235e-05 | Elapse: 0.06s\n","Epoch 4 [100/510] | Train Loss: 0.7850 Grad: 119312.9766 LR: 9.8908e-05 | Elapse: 5.82s\n","Epoch 4 [200/510] | Train Loss: 0.7820 Grad: 198884.6562 LR: 9.8524e-05 | Elapse: 11.57s\n","Epoch 4 [300/510] | Train Loss: 0.7772 Grad: 178877.9531 LR: 9.8083e-05 | Elapse: 17.33s\n","Epoch 4 [400/510] | Train Loss: 0.7699 Grad: 122933.9219 LR: 9.7585e-05 | Elapse: 23.08s\n","Epoch 4 [500/510] | Train Loss: 0.7625 Grad: 108803.6797 LR: 9.7032e-05 | Elapse: 28.84s\n","Epoch 4 [509/510] | Train Loss: 0.7622 Grad: 164645.3594 LR: 9.6980e-05 | Elapse: 29.36s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9ef4b3debb594f07b82489032cdac148","version_major":2,"version_minor":0},"text/plain":["Valid [3]:   0%|          | 0/121 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 4 [0/121] | Valid Loss: 0.9820 | Elapse: 0.05s\n","Epoch 4 [100/121] | Valid Loss: 0.9644 | Elapse: 4.93s\n"]},{"name":"stderr","output_type":"stream","text":["----------------------------------------------------------------------------------------------------\n","Epoch 4 - Average Loss: (train) 0.7622; (valid) 0.9548 | Time: 35.23s\n","Best model found in epoch 4 | valid loss: 0.9548\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 4 [120/121] | Valid Loss: 0.9548 | Elapse: 5.87s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0d98fc7b9e224558a7136406c9028167","version_major":2,"version_minor":0},"text/plain":["Train [4]:   0%|          | 0/510 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 5 [0/510] | Train Loss: 0.8449 Grad: 119922.6094 LR: 9.6974e-05 | Elapse: 0.06s\n","Epoch 5 [100/510] | Train Loss: 0.7126 Grad: 146948.7500 LR: 9.6361e-05 | Elapse: 5.83s\n","Epoch 5 [200/510] | Train Loss: 0.7089 Grad: 201684.2188 LR: 9.5693e-05 | Elapse: 11.58s\n","Epoch 5 [300/510] | Train Loss: 0.7072 Grad: 205515.3750 LR: 9.4972e-05 | Elapse: 17.33s\n","Epoch 5 [400/510] | Train Loss: 0.7003 Grad: 167222.4062 LR: 9.4198e-05 | Elapse: 23.09s\n","Epoch 5 [500/510] | Train Loss: 0.6937 Grad: 155976.7188 LR: 9.3372e-05 | Elapse: 28.84s\n","Epoch 5 [509/510] | Train Loss: 0.6934 Grad: 187854.5469 LR: 9.3295e-05 | Elapse: 29.37s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"969743165f794dfd8e02db66650a3013","version_major":2,"version_minor":0},"text/plain":["Valid [4]:   0%|          | 0/121 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 5 [0/121] | Valid Loss: 0.9000 | Elapse: 0.05s\n","Epoch 5 [100/121] | Valid Loss: 0.9040 | Elapse: 4.93s\n"]},{"name":"stderr","output_type":"stream","text":["----------------------------------------------------------------------------------------------------\n","Epoch 5 - Average Loss: (train) 0.6934; (valid) 0.8934 | Time: 35.24s\n","Best model found in epoch 5 | valid loss: 0.8934\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 5 [120/121] | Valid Loss: 0.8934 | Elapse: 5.87s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8fd7c968df1c4b339b6abc864008214e","version_major":2,"version_minor":0},"text/plain":["Train [5]:   0%|          | 0/510 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 6 [0/510] | Train Loss: 0.7605 Grad: 150443.5625 LR: 9.3287e-05 | Elapse: 0.06s\n","Epoch 6 [100/510] | Train Loss: 0.6400 Grad: 104186.1875 LR: 9.2405e-05 | Elapse: 5.80s\n","Epoch 6 [200/510] | Train Loss: 0.6382 Grad: 125514.0000 LR: 9.1474e-05 | Elapse: 11.54s\n","Epoch 6 [300/510] | Train Loss: 0.6382 Grad: 114495.9375 LR: 9.0495e-05 | Elapse: 17.28s\n","Epoch 6 [400/510] | Train Loss: 0.6314 Grad: 116677.0938 LR: 8.9468e-05 | Elapse: 22.93s\n","Epoch 6 [500/510] | Train Loss: 0.6262 Grad: 106457.0000 LR: 8.8395e-05 | Elapse: 28.68s\n","Epoch 6 [509/510] | Train Loss: 0.6260 Grad: 130048.4688 LR: 8.8296e-05 | Elapse: 29.19s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"75313da9f4b440d79ee384f10a70b8f4","version_major":2,"version_minor":0},"text/plain":["Valid [5]:   0%|          | 0/121 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 6 [0/121] | Valid Loss: 0.8482 | Elapse: 0.05s\n","Epoch 6 [100/121] | Valid Loss: 0.8497 | Elapse: 4.93s\n"]},{"name":"stderr","output_type":"stream","text":["----------------------------------------------------------------------------------------------------\n","Epoch 6 - Average Loss: (train) 0.6260; (valid) 0.8398 | Time: 35.06s\n","Best model found in epoch 6 | valid loss: 0.8398\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 6 [120/121] | Valid Loss: 0.8398 | Elapse: 5.87s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5468f4cdbc994d09a8c6919bf87a34af","version_major":2,"version_minor":0},"text/plain":["Train [6]:   0%|          | 0/510 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 7 [0/510] | Train Loss: 0.6866 Grad: 186655.5625 LR: 8.8285e-05 | Elapse: 0.06s\n","Epoch 7 [100/510] | Train Loss: 0.5795 Grad: 251785.7344 LR: 8.7162e-05 | Elapse: 5.82s\n","Epoch 7 [200/510] | Train Loss: 0.5818 Grad: 276788.5625 LR: 8.5996e-05 | Elapse: 11.59s\n","Epoch 7 [300/510] | Train Loss: 0.5836 Grad: 264578.8750 LR: 8.4788e-05 | Elapse: 17.35s\n","Epoch 7 [400/510] | Train Loss: 0.5779 Grad: 248411.5469 LR: 8.3539e-05 | Elapse: 23.12s\n","Epoch 7 [500/510] | Train Loss: 0.5746 Grad: 258656.8125 LR: 8.2251e-05 | Elapse: 28.85s\n","Epoch 7 [509/510] | Train Loss: 0.5745 Grad: 292422.5625 LR: 8.2133e-05 | Elapse: 29.37s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7988b85d1a4e4d668dedf8a0e74b6fed","version_major":2,"version_minor":0},"text/plain":["Valid [6]:   0%|          | 0/121 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 7 [0/121] | Valid Loss: 0.8326 | Elapse: 0.05s\n","Epoch 7 [100/121] | Valid Loss: 0.8175 | Elapse: 4.92s\n"]},{"name":"stderr","output_type":"stream","text":["----------------------------------------------------------------------------------------------------\n","Epoch 7 - Average Loss: (train) 0.5745; (valid) 0.8072 | Time: 35.23s\n","Best model found in epoch 7 | valid loss: 0.8072\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 7 [120/121] | Valid Loss: 0.8072 | Elapse: 5.86s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"257f4fa300e6417fb7f8bdd275af337b","version_major":2,"version_minor":0},"text/plain":["Train [7]:   0%|          | 0/510 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 8 [0/510] | Train Loss: 0.6245 Grad: 204376.7500 LR: 8.2120e-05 | Elapse: 0.06s\n","Epoch 8 [100/510] | Train Loss: 0.5372 Grad: 148932.5156 LR: 8.0791e-05 | Elapse: 5.81s\n","Epoch 8 [200/510] | Train Loss: 0.5413 Grad: 145995.0781 LR: 7.9425e-05 | Elapse: 11.56s\n","Epoch 8 [300/510] | Train Loss: 0.5436 Grad: 148303.7656 LR: 7.8025e-05 | Elapse: 17.30s\n","Epoch 8 [400/510] | Train Loss: 0.5384 Grad: 135781.6094 LR: 7.6592e-05 | Elapse: 23.06s\n","Epoch 8 [500/510] | Train Loss: 0.5366 Grad: 138623.3438 LR: 7.5128e-05 | Elapse: 28.82s\n","Epoch 8 [509/510] | Train Loss: 0.5365 Grad: 172017.5156 LR: 7.4995e-05 | Elapse: 29.34s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"02e7c6ce32624497a4c82707842a5069","version_major":2,"version_minor":0},"text/plain":["Valid [7]:   0%|          | 0/121 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 8 [0/121] | Valid Loss: 0.8177 | Elapse: 0.06s\n","Epoch 8 [100/121] | Valid Loss: 0.8000 | Elapse: 4.94s\n"]},{"name":"stderr","output_type":"stream","text":["----------------------------------------------------------------------------------------------------\n","Epoch 8 - Average Loss: (train) 0.5365; (valid) 0.7894 | Time: 35.22s\n","Best model found in epoch 8 | valid loss: 0.7894\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 8 [120/121] | Valid Loss: 0.7894 | Elapse: 5.88s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a3c6e129ab394aebaf9c3725b7309e2d","version_major":2,"version_minor":0},"text/plain":["Train [8]:   0%|          | 0/510 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 9 [0/510] | Train Loss: 0.5777 Grad: 212821.1094 LR: 7.4980e-05 | Elapse: 0.06s\n","Epoch 9 [100/510] | Train Loss: 0.5042 Grad: 355092.5938 LR: 7.3484e-05 | Elapse: 5.83s\n","Epoch 9 [200/510] | Train Loss: 0.5098 Grad: 350463.8750 LR: 7.1961e-05 | Elapse: 11.63s\n","Epoch 9 [300/510] | Train Loss: 0.5123 Grad: 156534.9375 LR: 7.0411e-05 | Elapse: 17.40s\n","Epoch 9 [400/510] | Train Loss: 0.5075 Grad: 142440.9375 LR: 6.8838e-05 | Elapse: 23.18s\n","Epoch 9 [500/510] | Train Loss: 0.5069 Grad: 144911.4688 LR: 6.7243e-05 | Elapse: 28.92s\n","Epoch 9 [509/510] | Train Loss: 0.5067 Grad: 187289.7812 LR: 6.7098e-05 | Elapse: 29.44s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b54363fb045a48f9a56777e22034e966","version_major":2,"version_minor":0},"text/plain":["Valid [8]:   0%|          | 0/121 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 9 [0/121] | Valid Loss: 0.8059 | Elapse: 0.05s\n","Epoch 9 [100/121] | Valid Loss: 0.7888 | Elapse: 4.92s\n"]},{"name":"stderr","output_type":"stream","text":["----------------------------------------------------------------------------------------------------\n","Epoch 9 - Average Loss: (train) 0.5067; (valid) 0.7775 | Time: 35.30s\n","Best model found in epoch 9 | valid loss: 0.7775\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 9 [120/121] | Valid Loss: 0.7775 | Elapse: 5.86s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1692b3e13d684065a4551393554097f0","version_major":2,"version_minor":0},"text/plain":["Train [9]:   0%|          | 0/510 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 10 [0/510] | Train Loss: 0.5503 Grad: 230878.6094 LR: 6.7082e-05 | Elapse: 0.06s\n","Epoch 10 [100/510] | Train Loss: 0.4776 Grad: 385637.0000 LR: 6.5465e-05 | Elapse: 5.83s\n","Epoch 10 [200/510] | Train Loss: 0.4843 Grad: 324759.2188 LR: 6.3829e-05 | Elapse: 11.63s\n","Epoch 10 [300/510] | Train Loss: 0.4866 Grad: 166641.9375 LR: 6.2178e-05 | Elapse: 17.51s\n","Epoch 10 [400/510] | Train Loss: 0.4822 Grad: 154544.2188 LR: 6.0512e-05 | Elapse: 23.36s\n","Epoch 10 [500/510] | Train Loss: 0.4820 Grad: 150641.3750 LR: 5.8834e-05 | Elapse: 29.23s\n","Epoch 10 [509/510] | Train Loss: 0.4819 Grad: 204075.5781 LR: 5.8682e-05 | Elapse: 29.75s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e7d61d15598f4fa5a1db9913ec8de32d","version_major":2,"version_minor":0},"text/plain":["Valid [9]:   0%|          | 0/121 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 10 [0/121] | Valid Loss: 0.7973 | Elapse: 0.05s\n","Epoch 10 [100/121] | Valid Loss: 0.7825 | Elapse: 4.94s\n"]},{"name":"stderr","output_type":"stream","text":["----------------------------------------------------------------------------------------------------\n","Epoch 10 - Average Loss: (train) 0.4819; (valid) 0.7711 | Time: 35.64s\n","Best model found in epoch 10 | valid loss: 0.7711\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 10 [120/121] | Valid Loss: 0.7711 | Elapse: 5.88s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"793e357869a94f3a9c97e6673549613d","version_major":2,"version_minor":0},"text/plain":["Train [10]:   0%|          | 0/510 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 11 [0/510] | Train Loss: 0.5299 Grad: 270963.6875 LR: 5.8665e-05 | Elapse: 0.06s\n","Epoch 11 [100/510] | Train Loss: 0.4553 Grad: 399028.8750 LR: 5.6976e-05 | Elapse: 5.83s\n","Epoch 11 [200/510] | Train Loss: 0.4629 Grad: 351466.1875 LR: 5.5278e-05 | Elapse: 11.59s\n","Epoch 11 [300/510] | Train Loss: 0.4654 Grad: 370532.5625 LR: 5.3575e-05 | Elapse: 17.36s\n","Epoch 11 [400/510] | Train Loss: 0.4611 Grad: 339240.6875 LR: 5.1867e-05 | Elapse: 23.11s\n","Epoch 11 [500/510] | Train Loss: 0.4614 Grad: 310982.2500 LR: 5.0157e-05 | Elapse: 28.89s\n","Epoch 11 [509/510] | Train Loss: 0.4613 Grad: 465318.2188 LR: 5.0003e-05 | Elapse: 29.41s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f394d49830584821b4658ac584a1ad72","version_major":2,"version_minor":0},"text/plain":["Valid [10]:   0%|          | 0/121 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 11 [0/121] | Valid Loss: 0.7974 | Elapse: 0.05s\n","Epoch 11 [100/121] | Valid Loss: 0.7812 | Elapse: 4.99s\n"]},{"name":"stderr","output_type":"stream","text":["----------------------------------------------------------------------------------------------------\n","Epoch 11 - Average Loss: (train) 0.4613; (valid) 0.7695 | Time: 35.35s\n","Best model found in epoch 11 | valid loss: 0.7695\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 11 [120/121] | Valid Loss: 0.7695 | Elapse: 5.94s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ad1055de39974a08bc963ef565b95b0c","version_major":2,"version_minor":0},"text/plain":["Train [11]:   0%|          | 0/510 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 12 [0/510] | Train Loss: 0.5183 Grad: 296958.2500 LR: 4.9986e-05 | Elapse: 0.06s\n","Epoch 12 [100/510] | Train Loss: 0.4368 Grad: 421843.0625 LR: 4.8276e-05 | Elapse: 5.84s\n","Epoch 12 [200/510] | Train Loss: 0.4452 Grad: 339342.3438 LR: 4.6568e-05 | Elapse: 11.60s\n","Epoch 12 [300/510] | Train Loss: 0.4474 Grad: 379254.3125 LR: 4.4864e-05 | Elapse: 17.36s\n","Epoch 12 [400/510] | Train Loss: 0.4434 Grad: 360490.8750 LR: 4.3166e-05 | Elapse: 23.13s\n","Epoch 12 [500/510] | Train Loss: 0.4438 Grad: 337286.7188 LR: 4.1476e-05 | Elapse: 28.91s\n","Epoch 12 [509/510] | Train Loss: 0.4437 Grad: 497610.5625 LR: 4.1324e-05 | Elapse: 29.43s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ac671f5c92fd4a7ca6b9c2ed45a22e23","version_major":2,"version_minor":0},"text/plain":["Valid [11]:   0%|          | 0/121 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 12 [0/121] | Valid Loss: 0.7899 | Elapse: 0.05s\n","Epoch 12 [100/121] | Valid Loss: 0.7812 | Elapse: 4.95s\n"]},{"name":"stderr","output_type":"stream","text":["----------------------------------------------------------------------------------------------------\n","Epoch 12 - Average Loss: (train) 0.4437; (valid) 0.7691 | Time: 35.33s\n","Best model found in epoch 12 | valid loss: 0.7691\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 12 [120/121] | Valid Loss: 0.7691 | Elapse: 5.90s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"54fdba650d214749827e871ca3d81b3b","version_major":2,"version_minor":0},"text/plain":["Train [12]:   0%|          | 0/510 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 13 [0/510] | Train Loss: 0.5068 Grad: 299582.8750 LR: 4.1307e-05 | Elapse: 0.06s\n","Epoch 13 [100/510] | Train Loss: 0.4215 Grad: 422721.3125 LR: 3.9629e-05 | Elapse: 5.85s\n","Epoch 13 [200/510] | Train Loss: 0.4303 Grad: 319945.0938 LR: 3.7962e-05 | Elapse: 11.63s\n","Epoch 13 [300/510] | Train Loss: 0.4329 Grad: 408359.8125 LR: 3.6309e-05 | Elapse: 17.43s\n","Epoch 13 [400/510] | Train Loss: 0.4289 Grad: 360179.1875 LR: 3.4673e-05 | Elapse: 23.22s\n","Epoch 13 [500/510] | Train Loss: 0.4291 Grad: 359406.3438 LR: 3.3054e-05 | Elapse: 28.99s\n","Epoch 13 [509/510] | Train Loss: 0.4290 Grad: 493494.7188 LR: 3.2910e-05 | Elapse: 29.50s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"fcf511e0b2cf4bdb9837d73d488b5f88","version_major":2,"version_minor":0},"text/plain":["Valid [12]:   0%|          | 0/121 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 13 [0/121] | Valid Loss: 0.7838 | Elapse: 0.05s\n","Epoch 13 [100/121] | Valid Loss: 0.7844 | Elapse: 4.95s\n"]},{"name":"stderr","output_type":"stream","text":["----------------------------------------------------------------------------------------------------\n","Epoch 13 - Average Loss: (train) 0.4290; (valid) 0.7721 | Time: 35.40s\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 13 [120/121] | Valid Loss: 0.7721 | Elapse: 5.89s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0f0ffc5fba2e49c7ab68005a06004ade","version_major":2,"version_minor":0},"text/plain":["Train [13]:   0%|          | 0/510 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 14 [0/510] | Train Loss: 0.4945 Grad: 282226.1250 LR: 3.2894e-05 | Elapse: 0.06s\n","Epoch 14 [100/510] | Train Loss: 0.4096 Grad: 427398.6875 LR: 3.1297e-05 | Elapse: 5.82s\n","Epoch 14 [200/510] | Train Loss: 0.4186 Grad: 418905.4062 LR: 2.9723e-05 | Elapse: 11.58s\n","Epoch 14 [300/510] | Train Loss: 0.4211 Grad: 441375.1562 LR: 2.8172e-05 | Elapse: 17.35s\n","Epoch 14 [400/510] | Train Loss: 0.4170 Grad: 354981.9688 LR: 2.6646e-05 | Elapse: 23.11s\n","Epoch 14 [500/510] | Train Loss: 0.4171 Grad: 368083.3750 LR: 2.5149e-05 | Elapse: 28.87s\n","Epoch 14 [509/510] | Train Loss: 0.4171 Grad: 530054.2500 LR: 2.5015e-05 | Elapse: 29.39s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"631e1b961f25450a8d8d66e025ef2fe9","version_major":2,"version_minor":0},"text/plain":["Valid [13]:   0%|          | 0/121 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 14 [0/121] | Valid Loss: 0.7867 | Elapse: 0.05s\n","Epoch 14 [100/121] | Valid Loss: 0.7884 | Elapse: 4.93s\n"]},{"name":"stderr","output_type":"stream","text":["----------------------------------------------------------------------------------------------------\n","Epoch 14 - Average Loss: (train) 0.4171; (valid) 0.7764 | Time: 35.27s\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 14 [120/121] | Valid Loss: 0.7764 | Elapse: 5.87s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c817be070310402cbbd04f9beaadfad1","version_major":2,"version_minor":0},"text/plain":["Train [14]:   0%|          | 0/510 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 15 [0/510] | Train Loss: 0.4877 Grad: 307781.7500 LR: 2.5000e-05 | Elapse: 0.06s\n","Epoch 15 [100/510] | Train Loss: 0.3997 Grad: 408305.1875 LR: 2.3535e-05 | Elapse: 5.81s\n","Epoch 15 [200/510] | Train Loss: 0.4090 Grad: 453461.6875 LR: 2.2100e-05 | Elapse: 11.56s\n","Epoch 15 [300/510] | Train Loss: 0.4111 Grad: 447959.4062 LR: 2.0698e-05 | Elapse: 17.33s\n","Epoch 15 [400/510] | Train Loss: 0.4071 Grad: 348717.0000 LR: 1.9330e-05 | Elapse: 23.11s\n","Epoch 15 [500/510] | Train Loss: 0.4073 Grad: 388739.5000 LR: 1.7998e-05 | Elapse: 28.86s\n","Epoch 15 [509/510] | Train Loss: 0.4073 Grad: 617421.8125 LR: 1.7880e-05 | Elapse: 29.38s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"37893f2e389d416e8120d1c0c76b3c36","version_major":2,"version_minor":0},"text/plain":["Valid [14]:   0%|          | 0/121 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 15 [0/121] | Valid Loss: 0.7929 | Elapse: 0.05s\n","Epoch 15 [100/121] | Valid Loss: 0.7876 | Elapse: 4.93s\n"]},{"name":"stderr","output_type":"stream","text":["----------------------------------------------------------------------------------------------------\n","Epoch 15 - Average Loss: (train) 0.4073; (valid) 0.7754 | Time: 35.25s\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 15 [120/121] | Valid Loss: 0.7754 | Elapse: 5.87s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"bb2e32df06ce45cbbd3bcd32f2d0b8de","version_major":2,"version_minor":0},"text/plain":["Train [15]:   0%|          | 0/510 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 16 [0/510] | Train Loss: 0.4800 Grad: 336854.9375 LR: 1.7867e-05 | Elapse: 0.06s\n","Epoch 16 [100/510] | Train Loss: 0.3926 Grad: 412147.5938 LR: 1.6577e-05 | Elapse: 5.86s\n","Epoch 16 [200/510] | Train Loss: 0.4014 Grad: 387771.1250 LR: 1.5326e-05 | Elapse: 11.64s\n","Epoch 16 [300/510] | Train Loss: 0.4031 Grad: 427498.2188 LR: 1.4115e-05 | Elapse: 17.43s\n","Epoch 16 [400/510] | Train Loss: 0.3995 Grad: 339261.6875 LR: 1.2946e-05 | Elapse: 23.24s\n","Epoch 16 [500/510] | Train Loss: 0.3999 Grad: 402729.5000 LR: 1.1821e-05 | Elapse: 29.05s\n","Epoch 16 [509/510] | Train Loss: 0.3999 Grad: 684848.0625 LR: 1.1722e-05 | Elapse: 29.57s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"792595cc253346808d343a4c3a01a970","version_major":2,"version_minor":0},"text/plain":["Valid [15]:   0%|          | 0/121 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 16 [0/121] | Valid Loss: 0.7963 | Elapse: 0.05s\n","Epoch 16 [100/121] | Valid Loss: 0.7833 | Elapse: 4.94s\n"]},{"name":"stderr","output_type":"stream","text":["----------------------------------------------------------------------------------------------------\n","Epoch 16 - Average Loss: (train) 0.3999; (valid) 0.7708 | Time: 35.45s\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 16 [120/121] | Valid Loss: 0.7708 | Elapse: 5.88s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7f1724742f4347c89104ea8d33df12bb","version_major":2,"version_minor":0},"text/plain":["Train [16]:   0%|          | 0/510 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 17 [0/510] | Train Loss: 0.4755 Grad: 385755.8750 LR: 1.1711e-05 | Elapse: 0.06s\n","Epoch 17 [100/510] | Train Loss: 0.3860 Grad: 423177.6875 LR: 1.0635e-05 | Elapse: 5.82s\n","Epoch 17 [200/510] | Train Loss: 0.3948 Grad: 412214.2188 LR: 9.6054e-06 | Elapse: 11.50s\n","Epoch 17 [300/510] | Train Loss: 0.3967 Grad: 434398.5938 LR: 8.6230e-06 | Elapse: 17.17s\n","Epoch 17 [400/510] | Train Loss: 0.3933 Grad: 346305.0000 LR: 7.6890e-06 | Elapse: 22.85s\n","Epoch 17 [500/510] | Train Loss: 0.3940 Grad: 404521.5938 LR: 6.8046e-06 | Elapse: 28.51s\n","Epoch 17 [509/510] | Train Loss: 0.3940 Grad: 657405.4375 LR: 6.7275e-06 | Elapse: 29.02s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9b40cd0782df4f049f797eaae3ccbd44","version_major":2,"version_minor":0},"text/plain":["Valid [16]:   0%|          | 0/121 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 17 [0/121] | Valid Loss: 0.7946 | Elapse: 0.05s\n","Epoch 17 [100/121] | Valid Loss: 0.7808 | Elapse: 4.92s\n"]},{"name":"stderr","output_type":"stream","text":["----------------------------------------------------------------------------------------------------\n","Epoch 17 - Average Loss: (train) 0.3940; (valid) 0.7683 | Time: 34.89s\n","Best model found in epoch 17 | valid loss: 0.7683\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 17 [120/121] | Valid Loss: 0.7683 | Elapse: 5.86s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"16d2c6f85ba4442bb5de16e719727726","version_major":2,"version_minor":0},"text/plain":["Train [17]:   0%|          | 0/510 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 18 [0/510] | Train Loss: 0.4732 Grad: 397394.7812 LR: 6.7190e-06 | Elapse: 0.06s\n","Epoch 18 [100/510] | Train Loss: 0.3803 Grad: 434960.5938 LR: 5.8903e-06 | Elapse: 5.76s\n","Epoch 18 [200/510] | Train Loss: 0.3892 Grad: 485821.6875 LR: 5.1133e-06 | Elapse: 11.48s\n","Epoch 18 [300/510] | Train Loss: 0.3917 Grad: 457358.5625 LR: 4.3889e-06 | Elapse: 17.21s\n","Epoch 18 [400/510] | Train Loss: 0.3885 Grad: 340633.0625 LR: 3.7179e-06 | Elapse: 22.95s\n","Epoch 18 [500/510] | Train Loss: 0.3893 Grad: 402321.2812 LR: 3.1011e-06 | Elapse: 28.73s\n","Epoch 18 [509/510] | Train Loss: 0.3893 Grad: 610717.3125 LR: 3.0483e-06 | Elapse: 29.25s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ce01c0a7c6584c46b1d5906fec87fd0b","version_major":2,"version_minor":0},"text/plain":["Valid [17]:   0%|          | 0/121 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 18 [0/121] | Valid Loss: 0.7895 | Elapse: 0.05s\n","Epoch 18 [100/121] | Valid Loss: 0.7795 | Elapse: 4.98s\n"]},{"name":"stderr","output_type":"stream","text":["----------------------------------------------------------------------------------------------------\n","Epoch 18 - Average Loss: (train) 0.3893; (valid) 0.7671 | Time: 35.18s\n","Best model found in epoch 18 | valid loss: 0.7671\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 18 [120/121] | Valid Loss: 0.7671 | Elapse: 5.93s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9c3624819c584e61b03b7581af758596","version_major":2,"version_minor":0},"text/plain":["Train [18]:   0%|          | 0/510 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 19 [0/510] | Train Loss: 0.4671 Grad: 372038.7500 LR: 3.0425e-06 | Elapse: 0.06s\n","Epoch 19 [100/510] | Train Loss: 0.3765 Grad: 435571.7812 LR: 2.4862e-06 | Elapse: 5.86s\n","Epoch 19 [200/510] | Train Loss: 0.3855 Grad: 679221.5625 LR: 1.9856e-06 | Elapse: 11.68s\n","Epoch 19 [300/510] | Train Loss: 0.3879 Grad: 473599.2188 LR: 1.5412e-06 | Elapse: 17.49s\n","Epoch 19 [400/510] | Train Loss: 0.3852 Grad: 341168.7500 LR: 1.1536e-06 | Elapse: 23.30s\n","Epoch 19 [500/510] | Train Loss: 0.3860 Grad: 396767.2188 LR: 8.2325e-07 | Elapse: 29.08s\n","Epoch 19 [509/510] | Train Loss: 0.3860 Grad: 581818.7500 LR: 7.9634e-07 | Elapse: 29.60s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3958fffc5d9d4f43a2a7fa2a88e99c83","version_major":2,"version_minor":0},"text/plain":["Valid [18]:   0%|          | 0/121 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 19 [0/121] | Valid Loss: 0.7866 | Elapse: 0.05s\n","Epoch 19 [100/121] | Valid Loss: 0.7792 | Elapse: 4.92s\n"]},{"name":"stderr","output_type":"stream","text":["----------------------------------------------------------------------------------------------------\n","Epoch 19 - Average Loss: (train) 0.3860; (valid) 0.7670 | Time: 35.46s\n","Best model found in epoch 19 | valid loss: 0.7670\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 19 [120/121] | Valid Loss: 0.7670 | Elapse: 5.86s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"35d60673dcdb4a2883b9cf1e8fb4e2d8","version_major":2,"version_minor":0},"text/plain":["Train [19]:   0%|          | 0/510 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 20 [0/510] | Train Loss: 0.4640 Grad: 370561.9375 LR: 7.9338e-07 | Elapse: 0.06s\n","Epoch 20 [100/510] | Train Loss: 0.3741 Grad: 439385.0312 LR: 5.2640e-07 | Elapse: 5.83s\n","Epoch 20 [200/510] | Train Loss: 0.3833 Grad: 779277.4375 LR: 3.1738e-07 | Elapse: 11.63s\n","Epoch 20 [300/510] | Train Loss: 0.3857 Grad: 460105.1562 LR: 1.6657e-07 | Elapse: 17.43s\n","Epoch 20 [400/510] | Train Loss: 0.3832 Grad: 343395.4688 LR: 7.4133e-08 | Elapse: 23.23s\n","Epoch 20 [500/510] | Train Loss: 0.3843 Grad: 391990.2500 LR: 4.0187e-08 | Elapse: 29.06s\n","Epoch 20 [509/510] | Train Loss: 0.3842 Grad: 560095.3125 LR: 4.0003e-08 | Elapse: 29.58s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"569e58dc5e484bfc9692cc0ed3051d57","version_major":2,"version_minor":0},"text/plain":["Valid [19]:   0%|          | 0/121 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 20 [0/121] | Valid Loss: 0.7844 | Elapse: 0.05s\n","Epoch 20 [100/121] | Valid Loss: 0.7789 | Elapse: 5.00s\n"]},{"name":"stderr","output_type":"stream","text":["----------------------------------------------------------------------------------------------------\n","Epoch 20 - Average Loss: (train) 0.3842; (valid) 0.7667 | Time: 35.54s\n","Best model found in epoch 20 | valid loss: 0.7667\n","====================================================================================================\n","Fold 3 Valid Loss: 0.7667206525802612\n","Elapse: 11.78 min \n","====================================================================================================\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 20 [120/121] | Valid Loss: 0.7667 | Elapse: 5.95s\n"]},{"name":"stderr","output_type":"stream","text":["- Stage 2 | Train: 5266; Valid: 1226 -\n"]},{"name":"stdout","output_type":"stream","text":["Loading model from checkpoint: outputs/ResnetGRU_v1_LB048_fold_3_stage_1.pth\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c1442adb861847c98177b81d2ed2f1ec","version_major":2,"version_minor":0},"text/plain":["Train [0]:   0%|          | 0/164 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 1 [0/164] | Train Loss: 0.2902 Grad: 535465.8750 LR: 4.0022e-06 | Elapse: 0.07s\n","Epoch 1 [100/164] | Train Loss: 0.3348 Grad: 236197.8438 LR: 2.4879e-05 | Elapse: 5.91s\n","Epoch 1 [163/164] | Train Loss: 0.3253 Grad: 150339.5312 LR: 5.2231e-05 | Elapse: 9.57s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e3ed35760de64bd28279ec0b4bb5bc29","version_major":2,"version_minor":0},"text/plain":["Valid [0]:   0%|          | 0/39 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 1 [0/39] | Valid Loss: 0.5833 | Elapse: 0.06s\n"]},{"name":"stderr","output_type":"stream","text":["----------------------------------------------------------------------------------------------------\n","Epoch 1 - Average Loss: (train) 0.3253; (valid) 0.5017 | Time: 11.48s\n","Best model found in epoch 1 | valid loss: 0.5017\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1 [38/39] | Valid Loss: 0.5017 | Elapse: 1.91s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"bc66202a95ea4fdfbb8fc6d6939f5269","version_major":2,"version_minor":0},"text/plain":["Train [1]:   0%|          | 0/164 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 2 [0/164] | Train Loss: 0.2407 Grad: 434919.9375 LR: 5.2692e-05 | Elapse: 0.06s\n","Epoch 2 [100/164] | Train Loss: 0.2711 Grad: 143971.1406 LR: 9.1734e-05 | Elapse: 5.87s\n","Epoch 2 [163/164] | Train Loss: 0.2680 Grad: 154434.4688 LR: 1.0000e-04 | Elapse: 9.53s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2585d299ede74291a1e702c0b706bc65","version_major":2,"version_minor":0},"text/plain":["Valid [1]:   0%|          | 0/39 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 2 [0/39] | Valid Loss: 0.5289 | Elapse: 0.06s\n"]},{"name":"stderr","output_type":"stream","text":["----------------------------------------------------------------------------------------------------\n","Epoch 2 - Average Loss: (train) 0.2680; (valid) 0.4705 | Time: 11.42s\n","Best model found in epoch 2 | valid loss: 0.4705\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 2 [38/39] | Valid Loss: 0.4705 | Elapse: 1.89s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4f52405490d9432ab65834a9248b2021","version_major":2,"version_minor":0},"text/plain":["Train [2]:   0%|          | 0/164 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 3 [0/164] | Train Loss: 0.1902 Grad: 342110.3438 LR: 1.0000e-04 | Elapse: 0.06s\n","Epoch 3 [100/164] | Train Loss: 0.2309 Grad: 272212.4688 LR: 9.9706e-05 | Elapse: 5.85s\n","Epoch 3 [163/164] | Train Loss: 0.2296 Grad: 278964.7812 LR: 9.9231e-05 | Elapse: 9.50s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f5e5c272960341e695763315baa2df7e","version_major":2,"version_minor":0},"text/plain":["Valid [2]:   0%|          | 0/39 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 3 [0/39] | Valid Loss: 0.5107 | Elapse: 0.05s\n"]},{"name":"stderr","output_type":"stream","text":["----------------------------------------------------------------------------------------------------\n","Epoch 3 - Average Loss: (train) 0.2296; (valid) 0.4680 | Time: 11.40s\n","Best model found in epoch 3 | valid loss: 0.4680\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 3 [38/39] | Valid Loss: 0.4680 | Elapse: 1.89s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"362faef9d9ed422caec6e64bb24e6dce","version_major":2,"version_minor":0},"text/plain":["Train [3]:   0%|          | 0/164 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 4 [0/164] | Train Loss: 0.1692 Grad: 324733.9375 LR: 9.9222e-05 | Elapse: 0.06s\n","Epoch 4 [100/164] | Train Loss: 0.2030 Grad: 243679.7031 LR: 9.8011e-05 | Elapse: 5.85s\n","Epoch 4 [163/164] | Train Loss: 0.2037 Grad: 282995.0312 LR: 9.6968e-05 | Elapse: 9.51s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"37af6d0cb7104fb7b07c495d248758e0","version_major":2,"version_minor":0},"text/plain":["Valid [3]:   0%|          | 0/39 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 4 [0/39] | Valid Loss: 0.4989 | Elapse: 0.06s\n"]},{"name":"stderr","output_type":"stream","text":["----------------------------------------------------------------------------------------------------\n","Epoch 4 - Average Loss: (train) 0.2037; (valid) 0.4690 | Time: 11.43s\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 4 [38/39] | Valid Loss: 0.4690 | Elapse: 1.92s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1a0f079ede5c46dd92abf1f3c82e44b1","version_major":2,"version_minor":0},"text/plain":["Train [4]:   0%|          | 0/164 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 5 [0/164] | Train Loss: 0.1486 Grad: 307473.4375 LR: 9.6949e-05 | Elapse: 0.06s\n","Epoch 5 [100/164] | Train Loss: 0.1843 Grad: 250811.2969 LR: 9.4857e-05 | Elapse: 5.91s\n","Epoch 5 [163/164] | Train Loss: 0.1854 Grad: 291252.5938 LR: 9.3277e-05 | Elapse: 9.57s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c680e9a18ca44551a46e1968fb34f274","version_major":2,"version_minor":0},"text/plain":["Valid [4]:   0%|          | 0/39 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 5 [0/39] | Valid Loss: 0.4943 | Elapse: 0.05s\n"]},{"name":"stderr","output_type":"stream","text":["----------------------------------------------------------------------------------------------------\n","Epoch 5 - Average Loss: (train) 0.1854; (valid) 0.4725 | Time: 11.47s\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 5 [38/39] | Valid Loss: 0.4725 | Elapse: 1.89s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2c14db49abff4478887e46fb40c8812e","version_major":2,"version_minor":0},"text/plain":["Train [5]:   0%|          | 0/164 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 6 [0/164] | Train Loss: 0.1280 Grad: 305145.1250 LR: 9.3251e-05 | Elapse: 0.06s\n","Epoch 6 [100/164] | Train Loss: 0.1686 Grad: 224907.6719 LR: 9.0342e-05 | Elapse: 5.84s\n","Epoch 6 [163/164] | Train Loss: 0.1698 Grad: 300902.5312 LR: 8.8273e-05 | Elapse: 9.49s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"db2a5ceacf244d7eb01d485634b54235","version_major":2,"version_minor":0},"text/plain":["Valid [5]:   0%|          | 0/39 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 6 [0/39] | Valid Loss: 0.4879 | Elapse: 0.05s\n"]},{"name":"stderr","output_type":"stream","text":["----------------------------------------------------------------------------------------------------\n","Epoch 6 - Average Loss: (train) 0.1698; (valid) 0.4752 | Time: 11.39s\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 6 [38/39] | Valid Loss: 0.4752 | Elapse: 1.89s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"820f05ddd1904754a07814928595ba68","version_major":2,"version_minor":0},"text/plain":["Train [6]:   0%|          | 0/164 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 7 [0/164] | Train Loss: 0.1121 Grad: 290608.6562 LR: 8.8238e-05 | Elapse: 0.06s\n","Epoch 7 [100/164] | Train Loss: 0.1554 Grad: 327105.3750 LR: 8.4601e-05 | Elapse: 5.87s\n","Epoch 7 [163/164] | Train Loss: 0.1568 Grad: 293169.8125 LR: 8.2106e-05 | Elapse: 9.53s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"16ab170513404113a8b1eab5f09eebd0","version_major":2,"version_minor":0},"text/plain":["Valid [6]:   0%|          | 0/39 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 7 [0/39] | Valid Loss: 0.4880 | Elapse: 0.05s\n"]},{"name":"stderr","output_type":"stream","text":["----------------------------------------------------------------------------------------------------\n","Epoch 7 - Average Loss: (train) 0.1568; (valid) 0.4813 | Time: 11.43s\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 7 [38/39] | Valid Loss: 0.4813 | Elapse: 1.89s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"50ca59ba447d492db6709917f86b3866","version_major":2,"version_minor":0},"text/plain":["Train [7]:   0%|          | 0/164 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 8 [0/164] | Train Loss: 0.0978 Grad: 284911.6250 LR: 8.2065e-05 | Elapse: 0.06s\n","Epoch 8 [100/164] | Train Loss: 0.1439 Grad: 268008.1875 LR: 7.7810e-05 | Elapse: 5.88s\n","Epoch 8 [163/164] | Train Loss: 0.1454 Grad: 323816.1250 LR: 7.4964e-05 | Elapse: 9.56s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"56fc54a5baca4752955f91393f72e284","version_major":2,"version_minor":0},"text/plain":["Valid [7]:   0%|          | 0/39 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 8 [0/39] | Valid Loss: 0.4980 | Elapse: 0.05s\n"]},{"name":"stderr","output_type":"stream","text":["----------------------------------------------------------------------------------------------------\n","Epoch 8 - Average Loss: (train) 0.1454; (valid) 0.4823 | Time: 11.45s\n","Early stopping at epoch 8\n","====================================================================================================\n","Fold 3 Valid Loss: 0.46801629662513733\n","Elapse: 1.53 min \n","====================================================================================================\n","Fold 3 Elapse: 13.31 min\n","====================================================================================================\n","Fold: 4\n","====================================================================================================\n","- Stage 1 | Train: 15844; Valid: 4339 -\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 8 [38/39] | Valid Loss: 0.4823 | Elapse: 1.89s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a1378de52ab04e049d637b3b3df8c0f6","version_major":2,"version_minor":0},"text/plain":["Train [0]:   0%|          | 0/495 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 1 [0/495] | Train Loss: 1.1378 Grad: 70959.9141 LR: 4.0002e-06 | Elapse: 0.07s\n","Epoch 1 [100/495] | Train Loss: 1.1913 Grad: 61949.5859 LR: 6.4492e-06 | Elapse: 5.86s\n","Epoch 1 [200/495] | Train Loss: 1.1947 Grad: 78135.1406 LR: 1.3456e-05 | Elapse: 11.63s\n","Epoch 1 [300/495] | Train Loss: 1.1840 Grad: 85308.5859 LR: 2.4319e-05 | Elapse: 17.36s\n","Epoch 1 [400/495] | Train Loss: 1.1695 Grad: 91638.7500 LR: 3.7952e-05 | Elapse: 23.08s\n","Epoch 1 [494/495] | Train Loss: 1.1498 Grad: 58506.9141 LR: 5.2076e-05 | Elapse: 28.47s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"73dd734b8d4b4cdbb155eb30c5a8033f","version_major":2,"version_minor":0},"text/plain":["Valid [0]:   0%|          | 0/136 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 1 [0/136] | Valid Loss: 1.3279 | Elapse: 0.05s\n","Epoch 1 [100/136] | Valid Loss: 1.3359 | Elapse: 5.00s\n"]},{"name":"stderr","output_type":"stream","text":["----------------------------------------------------------------------------------------------------\n","Epoch 1 - Average Loss: (train) 1.1498; (valid) 1.3308 | Time: 35.20s\n","Best model found in epoch 1 | valid loss: 1.3308\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1 [135/136] | Valid Loss: 1.3308 | Elapse: 6.73s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"383d495269654f67b3628ea20edd40b1","version_major":2,"version_minor":0},"text/plain":["Train [1]:   0%|          | 0/495 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 2 [0/495] | Train Loss: 0.9929 Grad: 46580.5859 LR: 5.2229e-05 | Elapse: 0.06s\n","Epoch 2 [100/495] | Train Loss: 1.0253 Grad: 52452.1836 LR: 6.7209e-05 | Elapse: 5.87s\n","Epoch 2 [200/495] | Train Loss: 1.0213 Grad: 61218.9922 LR: 8.0668e-05 | Elapse: 11.67s\n","Epoch 2 [300/495] | Train Loss: 1.0113 Grad: 70403.7578 LR: 9.1258e-05 | Elapse: 17.48s\n","Epoch 2 [400/495] | Train Loss: 0.9999 Grad: 113860.7266 LR: 9.7921e-05 | Elapse: 23.29s\n","Epoch 2 [494/495] | Train Loss: 0.9851 Grad: 86356.7578 LR: 1.0000e-04 | Elapse: 28.77s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"cdf885e9704646a4a3d24abc45daf97b","version_major":2,"version_minor":0},"text/plain":["Valid [1]:   0%|          | 0/136 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 2 [0/136] | Valid Loss: 1.1792 | Elapse: 0.06s\n","Epoch 2 [100/136] | Valid Loss: 1.1962 | Elapse: 5.00s\n"]},{"name":"stderr","output_type":"stream","text":["----------------------------------------------------------------------------------------------------\n","Epoch 2 - Average Loss: (train) 0.9851; (valid) 1.1905 | Time: 35.48s\n","Best model found in epoch 2 | valid loss: 1.1905\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 2 [135/136] | Valid Loss: 1.1905 | Elapse: 6.70s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"cf6c2c206eb2497fb65d24673544bf38","version_major":2,"version_minor":0},"text/plain":["Train [2]:   0%|          | 0/495 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 3 [0/495] | Train Loss: 0.9398 Grad: 60034.8203 LR: 1.0000e-04 | Elapse: 0.06s\n","Epoch 3 [100/495] | Train Loss: 0.9006 Grad: 82733.0938 LR: 9.9968e-05 | Elapse: 5.77s\n","Epoch 3 [200/495] | Train Loss: 0.8941 Grad: 70377.2188 LR: 9.9873e-05 | Elapse: 11.54s\n","Epoch 3 [300/495] | Train Loss: 0.8781 Grad: 119018.0938 LR: 9.9717e-05 | Elapse: 17.31s\n","Epoch 3 [400/495] | Train Loss: 0.8644 Grad: 180631.2500 LR: 9.9499e-05 | Elapse: 23.08s\n","Epoch 3 [494/495] | Train Loss: 0.8488 Grad: 144917.6562 LR: 9.9238e-05 | Elapse: 28.51s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9068f1918f63406c92aa67c197704faf","version_major":2,"version_minor":0},"text/plain":["Valid [2]:   0%|          | 0/136 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 3 [0/136] | Valid Loss: 1.0467 | Elapse: 0.05s\n","Epoch 3 [100/136] | Valid Loss: 1.0552 | Elapse: 4.93s\n"]},{"name":"stderr","output_type":"stream","text":["----------------------------------------------------------------------------------------------------\n","Epoch 3 - Average Loss: (train) 0.8488; (valid) 1.0521 | Time: 35.13s\n","Best model found in epoch 3 | valid loss: 1.0521\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 3 [135/136] | Valid Loss: 1.0521 | Elapse: 6.62s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"729a6f2fcb844873ae726dffa123abcb","version_major":2,"version_minor":0},"text/plain":["Train [3]:   0%|          | 0/495 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 4 [0/495] | Train Loss: 0.7873 Grad: 91446.3203 LR: 9.9235e-05 | Elapse: 0.06s\n","Epoch 4 [100/495] | Train Loss: 0.7704 Grad: 134947.4375 LR: 9.8897e-05 | Elapse: 5.83s\n","Epoch 4 [200/495] | Train Loss: 0.7695 Grad: 131077.9375 LR: 9.8498e-05 | Elapse: 11.61s\n","Epoch 4 [300/495] | Train Loss: 0.7595 Grad: 182545.6875 LR: 9.8039e-05 | Elapse: 17.39s\n","Epoch 4 [400/495] | Train Loss: 0.7514 Grad: 145455.5469 LR: 9.7521e-05 | Elapse: 23.17s\n","Epoch 4 [494/495] | Train Loss: 0.7391 Grad: 198775.9688 LR: 9.6980e-05 | Elapse: 28.60s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"50821941163f451fb48d815c9f58e320","version_major":2,"version_minor":0},"text/plain":["Valid [3]:   0%|          | 0/136 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 4 [0/136] | Valid Loss: 0.9027 | Elapse: 0.06s\n","Epoch 4 [100/136] | Valid Loss: 0.9600 | Elapse: 4.93s\n"]},{"name":"stderr","output_type":"stream","text":["----------------------------------------------------------------------------------------------------\n","Epoch 4 - Average Loss: (train) 0.7391; (valid) 0.9598 | Time: 35.23s\n","Best model found in epoch 4 | valid loss: 0.9598\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 4 [135/136] | Valid Loss: 0.9598 | Elapse: 6.62s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1ed06a118fec4e88b828619061e88add","version_major":2,"version_minor":0},"text/plain":["Train [4]:   0%|          | 0/495 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 5 [0/495] | Train Loss: 0.6659 Grad: 132883.4375 LR: 9.6974e-05 | Elapse: 0.06s\n","Epoch 5 [100/495] | Train Loss: 0.6659 Grad: 160521.1250 LR: 9.6341e-05 | Elapse: 5.89s\n","Epoch 5 [200/495] | Train Loss: 0.6683 Grad: 183549.7031 LR: 9.5650e-05 | Elapse: 11.70s\n","Epoch 5 [300/495] | Train Loss: 0.6618 Grad: 182059.4062 LR: 9.4903e-05 | Elapse: 17.49s\n","Epoch 5 [400/495] | Train Loss: 0.6569 Grad: 155586.5000 LR: 9.4100e-05 | Elapse: 23.29s\n","Epoch 5 [494/495] | Train Loss: 0.6479 Grad: 248058.7344 LR: 9.3295e-05 | Elapse: 28.74s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7034b38fdb864b278965191ceb2adcea","version_major":2,"version_minor":0},"text/plain":["Valid [4]:   0%|          | 0/136 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 5 [0/136] | Valid Loss: 0.8227 | Elapse: 0.05s\n","Epoch 5 [100/136] | Valid Loss: 0.8604 | Elapse: 4.99s\n"]},{"name":"stderr","output_type":"stream","text":["----------------------------------------------------------------------------------------------------\n","Epoch 5 - Average Loss: (train) 0.6479; (valid) 0.8633 | Time: 35.44s\n","Best model found in epoch 5 | valid loss: 0.8633\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 5 [135/136] | Valid Loss: 0.8633 | Elapse: 6.70s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"543fe4f83e634dcca2b1498b077015d7","version_major":2,"version_minor":0},"text/plain":["Train [5]:   0%|          | 0/495 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 6 [0/495] | Train Loss: 0.5741 Grad: 167056.0781 LR: 9.3286e-05 | Elapse: 0.06s\n","Epoch 6 [100/495] | Train Loss: 0.5872 Grad: 217529.7812 LR: 9.2377e-05 | Elapse: 5.88s\n","Epoch 6 [200/495] | Train Loss: 0.5946 Grad: 274266.7500 LR: 9.1416e-05 | Elapse: 11.70s\n","Epoch 6 [300/495] | Train Loss: 0.5931 Grad: 208260.8906 LR: 9.0403e-05 | Elapse: 17.52s\n","Epoch 6 [400/495] | Train Loss: 0.5915 Grad: 197804.2969 LR: 8.9340e-05 | Elapse: 23.34s\n","Epoch 6 [494/495] | Train Loss: 0.5855 Grad: 291614.0312 LR: 8.8296e-05 | Elapse: 28.81s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ca400f4e21fb4655bb2c52c8267a7b22","version_major":2,"version_minor":0},"text/plain":["Valid [5]:   0%|          | 0/136 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 6 [0/136] | Valid Loss: 0.7574 | Elapse: 0.05s\n","Epoch 6 [100/136] | Valid Loss: 0.8207 | Elapse: 4.99s\n"]},{"name":"stderr","output_type":"stream","text":["----------------------------------------------------------------------------------------------------\n","Epoch 6 - Average Loss: (train) 0.5855; (valid) 0.8233 | Time: 35.52s\n","Best model found in epoch 6 | valid loss: 0.8233\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 6 [135/136] | Valid Loss: 0.8233 | Elapse: 6.70s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e31d72248e2c48439eeef47662181168","version_major":2,"version_minor":0},"text/plain":["Train [6]:   0%|          | 0/495 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 7 [0/495] | Train Loss: 0.5294 Grad: 185826.6406 LR: 8.8284e-05 | Elapse: 0.06s\n","Epoch 7 [100/495] | Train Loss: 0.5427 Grad: 254067.0938 LR: 8.7127e-05 | Elapse: 5.86s\n","Epoch 7 [200/495] | Train Loss: 0.5501 Grad: 282778.0312 LR: 8.5924e-05 | Elapse: 11.63s\n","Epoch 7 [300/495] | Train Loss: 0.5503 Grad: 238189.9688 LR: 8.4676e-05 | Elapse: 17.38s\n","Epoch 7 [400/495] | Train Loss: 0.5497 Grad: 236894.5781 LR: 8.3384e-05 | Elapse: 23.14s\n","Epoch 7 [494/495] | Train Loss: 0.5445 Grad: 350609.3125 LR: 8.2133e-05 | Elapse: 28.55s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d498b994c1124335b5b5ebe1150fb847","version_major":2,"version_minor":0},"text/plain":["Valid [6]:   0%|          | 0/136 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 7 [0/136] | Valid Loss: 0.7049 | Elapse: 0.06s\n","Epoch 7 [100/136] | Valid Loss: 0.7940 | Elapse: 4.95s\n"]},{"name":"stderr","output_type":"stream","text":["----------------------------------------------------------------------------------------------------\n","Epoch 7 - Average Loss: (train) 0.5445; (valid) 0.7962 | Time: 35.20s\n","Best model found in epoch 7 | valid loss: 0.7962\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 7 [135/136] | Valid Loss: 0.7962 | Elapse: 6.64s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"fceeafd23b2a4ca2b82c52c284872dd1","version_major":2,"version_minor":0},"text/plain":["Train [7]:   0%|          | 0/495 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 8 [0/495] | Train Loss: 0.4968 Grad: 233954.6094 LR: 8.2120e-05 | Elapse: 0.06s\n","Epoch 8 [100/495] | Train Loss: 0.5076 Grad: 293312.0625 LR: 8.0749e-05 | Elapse: 5.82s\n","Epoch 8 [200/495] | Train Loss: 0.5162 Grad: 296192.0312 LR: 7.9340e-05 | Elapse: 11.59s\n","Epoch 8 [300/495] | Train Loss: 0.5172 Grad: 262805.1562 LR: 7.7895e-05 | Elapse: 17.36s\n","Epoch 8 [400/495] | Train Loss: 0.5169 Grad: 299510.4688 LR: 7.6416e-05 | Elapse: 23.13s\n","Epoch 8 [494/495] | Train Loss: 0.5123 Grad: 387731.9688 LR: 7.4995e-05 | Elapse: 28.57s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6eebeb5cf5b44cc5a371c4756ab22677","version_major":2,"version_minor":0},"text/plain":["Valid [7]:   0%|          | 0/136 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 8 [0/136] | Valid Loss: 0.6906 | Elapse: 0.05s\n","Epoch 8 [100/136] | Valid Loss: 0.7784 | Elapse: 4.95s\n"]},{"name":"stderr","output_type":"stream","text":["----------------------------------------------------------------------------------------------------\n","Epoch 8 - Average Loss: (train) 0.5123; (valid) 0.7805 | Time: 35.22s\n","Best model found in epoch 8 | valid loss: 0.7805\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 8 [135/136] | Valid Loss: 0.7805 | Elapse: 6.64s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d103364439b6473fbe5b6674549a4abf","version_major":2,"version_minor":0},"text/plain":["Train [8]:   0%|          | 0/495 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 9 [0/495] | Train Loss: 0.4744 Grad: 280279.3125 LR: 7.4979e-05 | Elapse: 0.06s\n","Epoch 9 [100/495] | Train Loss: 0.4783 Grad: 310649.5000 LR: 7.3437e-05 | Elapse: 5.84s\n","Epoch 9 [200/495] | Train Loss: 0.4869 Grad: 311071.8125 LR: 7.1866e-05 | Elapse: 11.61s\n","Epoch 9 [300/495] | Train Loss: 0.4884 Grad: 282645.6562 LR: 7.0268e-05 | Elapse: 17.38s\n","Epoch 9 [400/495] | Train Loss: 0.4884 Grad: 344117.6562 LR: 6.8645e-05 | Elapse: 23.16s\n","Epoch 9 [494/495] | Train Loss: 0.4843 Grad: 428960.3750 LR: 6.7098e-05 | Elapse: 28.57s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"fafaf63e9cee4122a72168b8822a633e","version_major":2,"version_minor":0},"text/plain":["Valid [8]:   0%|          | 0/136 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 9 [0/136] | Valid Loss: 0.6764 | Elapse: 0.05s\n","Epoch 9 [100/136] | Valid Loss: 0.7692 | Elapse: 4.94s\n"]},{"name":"stderr","output_type":"stream","text":["----------------------------------------------------------------------------------------------------\n","Epoch 9 - Average Loss: (train) 0.4843; (valid) 0.7704 | Time: 35.22s\n","Best model found in epoch 9 | valid loss: 0.7704\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 9 [135/136] | Valid Loss: 0.7704 | Elapse: 6.64s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e40c786e917f4e9b964d0ed70cb03ad0","version_major":2,"version_minor":0},"text/plain":["Train [9]:   0%|          | 0/495 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 10 [0/495] | Train Loss: 0.4511 Grad: 321741.6875 LR: 6.7081e-05 | Elapse: 0.06s\n","Epoch 10 [100/495] | Train Loss: 0.4527 Grad: 307429.1250 LR: 6.5414e-05 | Elapse: 5.83s\n","Epoch 10 [200/495] | Train Loss: 0.4618 Grad: 304311.7812 LR: 6.3729e-05 | Elapse: 11.61s\n","Epoch 10 [300/495] | Train Loss: 0.4639 Grad: 311464.1875 LR: 6.2026e-05 | Elapse: 17.43s\n","Epoch 10 [400/495] | Train Loss: 0.4643 Grad: 381521.3125 LR: 6.0308e-05 | Elapse: 23.21s\n","Epoch 10 [494/495] | Train Loss: 0.4602 Grad: 424881.9688 LR: 5.8682e-05 | Elapse: 28.65s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d171aedb814d400eb8d91d066a8dbcd3","version_major":2,"version_minor":0},"text/plain":["Valid [9]:   0%|          | 0/136 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 10 [0/136] | Valid Loss: 0.6807 | Elapse: 0.05s\n","Epoch 10 [100/136] | Valid Loss: 0.7611 | Elapse: 4.96s\n"]},{"name":"stderr","output_type":"stream","text":["----------------------------------------------------------------------------------------------------\n","Epoch 10 - Average Loss: (train) 0.4602; (valid) 0.7625 | Time: 35.31s\n","Best model found in epoch 10 | valid loss: 0.7625\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 10 [135/136] | Valid Loss: 0.7625 | Elapse: 6.66s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d7a50f635522448fbbf067ee619d1b5b","version_major":2,"version_minor":0},"text/plain":["Train [10]:   0%|          | 0/495 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 11 [0/495] | Train Loss: 0.4380 Grad: 373436.0000 LR: 5.8664e-05 | Elapse: 0.06s\n","Epoch 11 [100/495] | Train Loss: 0.4328 Grad: 326146.3438 LR: 5.6924e-05 | Elapse: 5.82s\n","Epoch 11 [200/495] | Train Loss: 0.4410 Grad: 312188.2812 LR: 5.5174e-05 | Elapse: 11.62s\n","Epoch 11 [300/495] | Train Loss: 0.4434 Grad: 354561.5312 LR: 5.3419e-05 | Elapse: 17.39s\n","Epoch 11 [400/495] | Train Loss: 0.4440 Grad: 423039.9062 LR: 5.1659e-05 | Elapse: 23.16s\n","Epoch 11 [494/495] | Train Loss: 0.4397 Grad: 453616.9062 LR: 5.0002e-05 | Elapse: 28.57s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1ab8297c23b34ae9ad146c50ab87c20f","version_major":2,"version_minor":0},"text/plain":["Valid [10]:   0%|          | 0/136 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 11 [0/136] | Valid Loss: 0.7062 | Elapse: 0.05s\n","Epoch 11 [100/136] | Valid Loss: 0.7568 | Elapse: 4.93s\n"]},{"name":"stderr","output_type":"stream","text":["----------------------------------------------------------------------------------------------------\n","Epoch 11 - Average Loss: (train) 0.4397; (valid) 0.7587 | Time: 35.19s\n","Best model found in epoch 11 | valid loss: 0.7587\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 11 [135/136] | Valid Loss: 0.7587 | Elapse: 6.62s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6c301e365ce64898871077d8be670205","version_major":2,"version_minor":0},"text/plain":["Train [11]:   0%|          | 0/495 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 12 [0/495] | Train Loss: 0.4347 Grad: 412531.7812 LR: 4.9985e-05 | Elapse: 0.06s\n","Epoch 12 [100/495] | Train Loss: 0.4149 Grad: 339387.3438 LR: 4.8223e-05 | Elapse: 5.81s\n","Epoch 12 [200/495] | Train Loss: 0.4232 Grad: 314717.7188 LR: 4.6463e-05 | Elapse: 11.40s\n","Epoch 12 [300/495] | Train Loss: 0.4259 Grad: 402967.3750 LR: 4.4708e-05 | Elapse: 16.99s\n","Epoch 12 [400/495] | Train Loss: 0.4270 Grad: 465792.3438 LR: 4.2959e-05 | Elapse: 22.76s\n","Epoch 12 [494/495] | Train Loss: 0.4228 Grad: 393615.2500 LR: 4.1324e-05 | Elapse: 28.09s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"57123943edb54c5e9fee32a2b432b084","version_major":2,"version_minor":0},"text/plain":["Valid [11]:   0%|          | 0/136 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 12 [0/136] | Valid Loss: 0.7248 | Elapse: 0.05s\n","Epoch 12 [100/136] | Valid Loss: 0.7573 | Elapse: 4.94s\n"]},{"name":"stderr","output_type":"stream","text":["----------------------------------------------------------------------------------------------------\n","Epoch 12 - Average Loss: (train) 0.4228; (valid) 0.7591 | Time: 34.73s\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 12 [135/136] | Valid Loss: 0.7591 | Elapse: 6.63s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3095c4d719cd4eb6ba5ec63c7d467e75","version_major":2,"version_minor":0},"text/plain":["Train [12]:   0%|          | 0/495 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 13 [0/495] | Train Loss: 0.4251 Grad: 442117.0312 LR: 4.1306e-05 | Elapse: 0.06s\n","Epoch 13 [100/495] | Train Loss: 0.4005 Grad: 346860.8125 LR: 3.9577e-05 | Elapse: 5.76s\n","Epoch 13 [200/495] | Train Loss: 0.4084 Grad: 321197.3438 LR: 3.7860e-05 | Elapse: 11.44s\n","Epoch 13 [300/495] | Train Loss: 0.4109 Grad: 386141.8125 LR: 3.6159e-05 | Elapse: 17.11s\n","Epoch 13 [400/495] | Train Loss: 0.4120 Grad: 481603.5938 LR: 3.4475e-05 | Elapse: 22.79s\n","Epoch 13 [494/495] | Train Loss: 0.4080 Grad: 417299.2812 LR: 3.2909e-05 | Elapse: 28.13s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"87d38f7f75ce4e1081b05656f9ec1d9d","version_major":2,"version_minor":0},"text/plain":["Valid [12]:   0%|          | 0/136 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 13 [0/136] | Valid Loss: 0.7408 | Elapse: 0.05s\n","Epoch 13 [100/136] | Valid Loss: 0.7608 | Elapse: 4.94s\n"]},{"name":"stderr","output_type":"stream","text":["----------------------------------------------------------------------------------------------------\n","Epoch 13 - Average Loss: (train) 0.4080; (valid) 0.7629 | Time: 34.77s\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 13 [135/136] | Valid Loss: 0.7629 | Elapse: 6.63s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d2124f333e8a4d80a621b9aa88bedfdc","version_major":2,"version_minor":0},"text/plain":["Train [13]:   0%|          | 0/495 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 14 [0/495] | Train Loss: 0.4109 Grad: 451507.1250 LR: 3.2893e-05 | Elapse: 0.06s\n","Epoch 14 [100/495] | Train Loss: 0.3883 Grad: 357327.1562 LR: 3.1248e-05 | Elapse: 5.84s\n","Epoch 14 [200/495] | Train Loss: 0.3958 Grad: 333830.5625 LR: 2.9627e-05 | Elapse: 11.61s\n","Epoch 14 [300/495] | Train Loss: 0.3986 Grad: 418684.2812 LR: 2.8031e-05 | Elapse: 17.40s\n","Epoch 14 [400/495] | Train Loss: 0.4002 Grad: 491880.7812 LR: 2.6463e-05 | Elapse: 23.17s\n","Epoch 14 [494/495] | Train Loss: 0.3965 Grad: 415571.1250 LR: 2.5015e-05 | Elapse: 28.60s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2aeccc16aad64964bc9e0b77bae78dd2","version_major":2,"version_minor":0},"text/plain":["Valid [13]:   0%|          | 0/136 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 14 [0/136] | Valid Loss: 0.7317 | Elapse: 0.05s\n","Epoch 14 [100/136] | Valid Loss: 0.7639 | Elapse: 4.93s\n"]},{"name":"stderr","output_type":"stream","text":["----------------------------------------------------------------------------------------------------\n","Epoch 14 - Average Loss: (train) 0.3965; (valid) 0.7656 | Time: 35.22s\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 14 [135/136] | Valid Loss: 0.7656 | Elapse: 6.62s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c4bca844da03407d9e6c221161402611","version_major":2,"version_minor":0},"text/plain":["Train [14]:   0%|          | 0/495 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 15 [0/495] | Train Loss: 0.3939 Grad: 456592.9688 LR: 2.4999e-05 | Elapse: 0.06s\n","Epoch 15 [100/495] | Train Loss: 0.3790 Grad: 350363.1875 LR: 2.3490e-05 | Elapse: 5.85s\n","Epoch 15 [200/495] | Train Loss: 0.3854 Grad: 353319.6250 LR: 2.2013e-05 | Elapse: 11.64s\n","Epoch 15 [300/495] | Train Loss: 0.3887 Grad: 517433.7188 LR: 2.0571e-05 | Elapse: 17.41s\n","Epoch 15 [400/495] | Train Loss: 0.3910 Grad: 521955.9375 LR: 1.9166e-05 | Elapse: 23.17s\n","Epoch 15 [494/495] | Train Loss: 0.3877 Grad: 463358.0625 LR: 1.7880e-05 | Elapse: 28.63s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"296895fa296d4833ae99f9e1f44175df","version_major":2,"version_minor":0},"text/plain":["Valid [14]:   0%|          | 0/136 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 15 [0/136] | Valid Loss: 0.7327 | Elapse: 0.05s\n","Epoch 15 [100/136] | Valid Loss: 0.7682 | Elapse: 4.97s\n"]},{"name":"stderr","output_type":"stream","text":["----------------------------------------------------------------------------------------------------\n","Epoch 15 - Average Loss: (train) 0.3877; (valid) 0.7695 | Time: 35.30s\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 15 [135/136] | Valid Loss: 0.7695 | Elapse: 6.66s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b9f259cd32324808a0ef12674237b6b7","version_major":2,"version_minor":0},"text/plain":["Train [15]:   0%|          | 0/495 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 16 [0/495] | Train Loss: 0.3827 Grad: 477873.0000 LR: 1.7866e-05 | Elapse: 0.06s\n","Epoch 16 [100/495] | Train Loss: 0.3715 Grad: 354409.0625 LR: 1.6538e-05 | Elapse: 5.85s\n","Epoch 16 [200/495] | Train Loss: 0.3772 Grad: 395348.2812 LR: 1.5250e-05 | Elapse: 11.63s\n","Epoch 16 [300/495] | Train Loss: 0.3803 Grad: 552057.3750 LR: 1.4006e-05 | Elapse: 17.41s\n","Epoch 16 [400/495] | Train Loss: 0.3832 Grad: 278614.6250 LR: 1.2807e-05 | Elapse: 23.19s\n","Epoch 16 [494/495] | Train Loss: 0.3804 Grad: 241199.2188 LR: 1.1722e-05 | Elapse: 28.62s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"574cb5527bd2468bb1b0181bd04e4d1d","version_major":2,"version_minor":0},"text/plain":["Valid [15]:   0%|          | 0/136 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 16 [0/136] | Valid Loss: 0.7381 | Elapse: 0.06s\n","Epoch 16 [100/136] | Valid Loss: 0.7729 | Elapse: 4.95s\n"]},{"name":"stderr","output_type":"stream","text":["----------------------------------------------------------------------------------------------------\n","Epoch 16 - Average Loss: (train) 0.3804; (valid) 0.7733 | Time: 35.27s\n","Early stopping at epoch 16\n","====================================================================================================\n","Fold 4 Valid Loss: 0.7586690187454224\n","Elapse: 9.39 min \n","====================================================================================================\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 16 [135/136] | Valid Loss: 0.7733 | Elapse: 6.65s\n"]},{"name":"stderr","output_type":"stream","text":["- Stage 2 | Train: 5169; Valid: 1323 -\n"]},{"name":"stdout","output_type":"stream","text":["Loading model from checkpoint: outputs/ResnetGRU_v1_LB048_fold_4_stage_1.pth\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"49baca829f9044e98df71e9a5142c874","version_major":2,"version_minor":0},"text/plain":["Train [0]:   0%|          | 0/161 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 1 [0/161] | Train Loss: 0.3045 Grad: 529901.0625 LR: 4.0023e-06 | Elapse: 0.07s\n","Epoch 1 [100/161] | Train Loss: 0.3404 Grad: 706079.0000 LR: 2.5602e-05 | Elapse: 5.89s\n","Epoch 1 [160/161] | Train Loss: 0.3202 Grad: 156530.9219 LR: 5.2235e-05 | Elapse: 9.38s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"37be991d850747a8b613c31693173065","version_major":2,"version_minor":0},"text/plain":["Valid [0]:   0%|          | 0/42 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 1 [0/42] | Valid Loss: 0.5255 | Elapse: 0.06s\n"]},{"name":"stderr","output_type":"stream","text":["----------------------------------------------------------------------------------------------------\n","Epoch 1 - Average Loss: (train) 0.3202; (valid) 0.5380 | Time: 11.45s\n","Best model found in epoch 1 | valid loss: 0.5380\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1 [41/42] | Valid Loss: 0.5380 | Elapse: 2.06s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"aa5d1a0a5bd046b98025b061da0bb7ef","version_major":2,"version_minor":0},"text/plain":["Train [1]:   0%|          | 0/161 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 2 [0/161] | Train Loss: 0.2508 Grad: 462955.3125 LR: 5.2705e-05 | Elapse: 0.07s\n","Epoch 2 [100/161] | Train Loss: 0.2718 Grad: 373347.8125 LR: 9.2218e-05 | Elapse: 5.92s\n","Epoch 2 [160/161] | Train Loss: 0.2592 Grad: 121705.5234 LR: 1.0000e-04 | Elapse: 9.47s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e7a73296f22c4d03a2a587aa87b1e463","version_major":2,"version_minor":0},"text/plain":["Valid [1]:   0%|          | 0/42 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 2 [0/42] | Valid Loss: 0.4834 | Elapse: 0.05s\n"]},{"name":"stderr","output_type":"stream","text":["----------------------------------------------------------------------------------------------------\n","Epoch 2 - Average Loss: (train) 0.2592; (valid) 0.5006 | Time: 11.56s\n","Best model found in epoch 2 | valid loss: 0.5006\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 2 [41/42] | Valid Loss: 0.5006 | Elapse: 2.09s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"961b7dd34ac341b185acb25b3e5afc93","version_major":2,"version_minor":0},"text/plain":["Train [2]:   0%|          | 0/161 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 3 [0/161] | Train Loss: 0.2102 Grad: 356393.4062 LR: 1.0000e-04 | Elapse: 0.06s\n","Epoch 3 [100/161] | Train Loss: 0.2279 Grad: 498247.1250 LR: 9.9695e-05 | Elapse: 5.95s\n","Epoch 3 [160/161] | Train Loss: 0.2185 Grad: 242740.7031 LR: 9.9231e-05 | Elapse: 9.47s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"86dc93fb3f644129bd7ddb4d950e0609","version_major":2,"version_minor":0},"text/plain":["Valid [2]:   0%|          | 0/42 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 3 [0/42] | Valid Loss: 0.4703 | Elapse: 0.05s\n"]},{"name":"stderr","output_type":"stream","text":["----------------------------------------------------------------------------------------------------\n","Epoch 3 - Average Loss: (train) 0.2185; (valid) 0.4967 | Time: 11.55s\n","Best model found in epoch 3 | valid loss: 0.4967\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 3 [41/42] | Valid Loss: 0.4967 | Elapse: 2.08s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"289c6ef846f243b4af6ea29ddb6998ac","version_major":2,"version_minor":0},"text/plain":["Train [3]:   0%|          | 0/161 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 4 [0/161] | Train Loss: 0.2004 Grad: 423230.3750 LR: 9.9222e-05 | Elapse: 0.06s\n","Epoch 4 [100/161] | Train Loss: 0.2001 Grad: 514279.2500 LR: 9.7982e-05 | Elapse: 5.92s\n","Epoch 4 [160/161] | Train Loss: 0.1936 Grad: 247983.7344 LR: 9.6967e-05 | Elapse: 9.43s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"acd0d00275a4476eb32e7d9c073bbb6a","version_major":2,"version_minor":0},"text/plain":["Valid [3]:   0%|          | 0/42 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 4 [0/42] | Valid Loss: 0.4785 | Elapse: 0.05s\n"]},{"name":"stderr","output_type":"stream","text":["----------------------------------------------------------------------------------------------------\n","Epoch 4 - Average Loss: (train) 0.1936; (valid) 0.4970 | Time: 11.50s\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 4 [41/42] | Valid Loss: 0.4970 | Elapse: 2.07s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7babb0a11e3d4278a95eee19b89d9af5","version_major":2,"version_minor":0},"text/plain":["Train [4]:   0%|          | 0/161 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 5 [0/161] | Train Loss: 0.1744 Grad: 360317.0000 LR: 9.6949e-05 | Elapse: 0.06s\n","Epoch 5 [100/161] | Train Loss: 0.1796 Grad: 495203.3125 LR: 9.4813e-05 | Elapse: 5.93s\n","Epoch 5 [160/161] | Train Loss: 0.1741 Grad: 245975.1719 LR: 9.3277e-05 | Elapse: 9.44s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"163804d0183745b18af920cb3786295b","version_major":2,"version_minor":0},"text/plain":["Valid [4]:   0%|          | 0/42 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 5 [0/42] | Valid Loss: 0.4774 | Elapse: 0.06s\n"]},{"name":"stderr","output_type":"stream","text":["----------------------------------------------------------------------------------------------------\n","Epoch 5 - Average Loss: (train) 0.1741; (valid) 0.4944 | Time: 11.52s\n","Best model found in epoch 5 | valid loss: 0.4944\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 5 [41/42] | Valid Loss: 0.4944 | Elapse: 2.07s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"cc3e9fd5e304422cbf4a5d1cfd9f82d0","version_major":2,"version_minor":0},"text/plain":["Train [5]:   0%|          | 0/161 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 6 [0/161] | Train Loss: 0.1576 Grad: 349445.7188 LR: 9.3250e-05 | Elapse: 0.06s\n","Epoch 6 [100/161] | Train Loss: 0.1642 Grad: 442408.1562 LR: 9.0282e-05 | Elapse: 5.93s\n","Epoch 6 [160/161] | Train Loss: 0.1592 Grad: 231404.8125 LR: 8.8272e-05 | Elapse: 9.45s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"05aff8b9d43b411b80e47b95649b6420","version_major":2,"version_minor":0},"text/plain":["Valid [5]:   0%|          | 0/42 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 6 [0/42] | Valid Loss: 0.4854 | Elapse: 0.05s\n"]},{"name":"stderr","output_type":"stream","text":["----------------------------------------------------------------------------------------------------\n","Epoch 6 - Average Loss: (train) 0.1592; (valid) 0.4973 | Time: 11.52s\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 6 [41/42] | Valid Loss: 0.4973 | Elapse: 2.07s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ffc9f0e5d2904e4bb42d91acbe3711b8","version_major":2,"version_minor":0},"text/plain":["Train [6]:   0%|          | 0/161 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 7 [0/161] | Train Loss: 0.1323 Grad: 328263.5938 LR: 8.8237e-05 | Elapse: 0.06s\n","Epoch 7 [100/161] | Train Loss: 0.1509 Grad: 437924.0000 LR: 8.4528e-05 | Elapse: 5.99s\n","Epoch 7 [160/161] | Train Loss: 0.1468 Grad: 228293.7188 LR: 8.2105e-05 | Elapse: 9.53s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3eee0b8bb85c41dfbce4d25dbf7f0362","version_major":2,"version_minor":0},"text/plain":["Valid [6]:   0%|          | 0/42 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 7 [0/42] | Valid Loss: 0.4836 | Elapse: 0.06s\n"]},{"name":"stderr","output_type":"stream","text":["----------------------------------------------------------------------------------------------------\n","Epoch 7 - Average Loss: (train) 0.1468; (valid) 0.4975 | Time: 11.62s\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 7 [41/42] | Valid Loss: 0.4975 | Elapse: 2.09s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"15ea883ea517446fa32bddcd834d0032","version_major":2,"version_minor":0},"text/plain":["Train [7]:   0%|          | 0/161 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 8 [0/161] | Train Loss: 0.1271 Grad: 395002.6250 LR: 8.2063e-05 | Elapse: 0.06s\n","Epoch 8 [100/161] | Train Loss: 0.1419 Grad: 431699.7188 LR: 7.7725e-05 | Elapse: 5.95s\n","Epoch 8 [160/161] | Train Loss: 0.1374 Grad: 207642.9844 LR: 7.4963e-05 | Elapse: 9.48s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"874f7f232df245389083f85b28614664","version_major":2,"version_minor":0},"text/plain":["Valid [7]:   0%|          | 0/42 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 8 [0/42] | Valid Loss: 0.4878 | Elapse: 0.05s\n"]},{"name":"stderr","output_type":"stream","text":["----------------------------------------------------------------------------------------------------\n","Epoch 8 - Average Loss: (train) 0.1374; (valid) 0.5005 | Time: 11.58s\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 8 [41/42] | Valid Loss: 0.5005 | Elapse: 2.09s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"62d4fa90a8a54ebf9846d10b4452e4b8","version_major":2,"version_minor":0},"text/plain":["Train [8]:   0%|          | 0/161 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 9 [0/161] | Train Loss: 0.1077 Grad: 346575.1562 LR: 7.4916e-05 | Elapse: 0.06s\n","Epoch 9 [100/161] | Train Loss: 0.1318 Grad: 448134.5000 LR: 7.0081e-05 | Elapse: 5.97s\n","Epoch 9 [160/161] | Train Loss: 0.1276 Grad: 223301.1250 LR: 6.7063e-05 | Elapse: 9.52s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9fb02480b22c4360a904a82c5ed0fb03","version_major":2,"version_minor":0},"text/plain":["Valid [8]:   0%|          | 0/42 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 9 [0/42] | Valid Loss: 0.4831 | Elapse: 0.06s\n"]},{"name":"stderr","output_type":"stream","text":["----------------------------------------------------------------------------------------------------\n","Epoch 9 - Average Loss: (train) 0.1276; (valid) 0.5002 | Time: 11.62s\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 9 [41/42] | Valid Loss: 0.5002 | Elapse: 2.10s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4300bd8c5fd04ee68fc6554a6661ab82","version_major":2,"version_minor":0},"text/plain":["Train [9]:   0%|          | 0/161 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 10 [0/161] | Train Loss: 0.1158 Grad: 526689.6875 LR: 6.7012e-05 | Elapse: 0.06s\n","Epoch 10 [100/161] | Train Loss: 0.1227 Grad: 506529.1250 LR: 6.1827e-05 | Elapse: 5.96s\n","Epoch 10 [160/161] | Train Loss: 0.1191 Grad: 212251.1250 LR: 5.8646e-05 | Elapse: 9.50s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2d6b70a6d50542c09eccb23a168a6dae","version_major":2,"version_minor":0},"text/plain":["Valid [9]:   0%|          | 0/42 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 10 [0/42] | Valid Loss: 0.4817 | Elapse: 0.06s\n"]},{"name":"stderr","output_type":"stream","text":["----------------------------------------------------------------------------------------------------\n","Epoch 10 - Average Loss: (train) 0.1191; (valid) 0.5028 | Time: 11.60s\n","Early stopping at epoch 10\n","====================================================================================================\n","Fold 4 Valid Loss: 0.4943685233592987\n","Elapse: 1.93 min \n","====================================================================================================\n","Fold 4 Elapse: 11.32 min\n","====================================================================================================\n","Training Complete!\n","CV Result: Stage 1: 0.7565410733222961 | Stage 2: 0.48485204577445984\n","Elapse: 60.70 min \n","====================================================================================================\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 10 [41/42] | Valid Loss: 0.5028 | Elapse: 2.10s\n"]}],"source":["# Major Train Loop\n","# ================== Logger ==================\n","logger.info(f\"{'*' * 100}\")\n","logger.info(f\"Script Start: {ctime()}\")\n","logger.info(f\"Model Configurations:\")\n","for key, value in ModelConfig.__dict__.items():\n","    if not key.startswith(\"__\"):\n","        logger.info(f\"{key}: {value}\")\n","logger.info(f\"{'*' * 100}\")\n","\n","# ================== Prepare Training ==================\n","oof_stage_1, oof_stage_2 = pd.DataFrame(), pd.DataFrame()\n","loss_history_1, loss_history_2 = [], []\n","t_start = time()\n","\n","K_FOLDS = 5\n","train_all = prepare_k_fold(train_all, k_folds=K_FOLDS)\n","\n","for fold in range(0, K_FOLDS):\n","    tik_total = time()\n","    tik = time()\n","\n","    valid_folds = train_all[(train_all['fold'] == fold) ].reset_index(drop=True)\n","    train_folds = train_all[(train_all['fold'] != fold) ].reset_index(drop=True)\n","    train_size, valid_size = train_folds.shape[0], valid_folds.shape[0]\n","\n","    # ================== Stage 1: Train ====================\n","    # model = ResNetGRU(\n","    #     kernels=ModelConfig.RESNET_GRU_KERNELS, \n","    #     in_channels=8, \n","    #     fixed_kernel_size=ModelConfig.RESNET_GRU_FIXED_KERNEL_SIZE,\n","    #     hidden_size=ModelConfig.RESNET_GRU_HIDDEN_SIZE,\n","    #     num_classes=6\n","    #     )\n","    model = ResNetGRU(config=ModelConfig, num_classes=6)\n","\n","    ## STAGE 1\n","    logger.info(f\"{'=' * 100}\\nFold: {fold}\\n{'=' * 100}\")\n","    logger.info(f\"- Stage 1 | Train: {train_size}; Valid: {valid_size} -\")\n","    valid_predicts, loss_records = train_fold(\n","        model, fold, train_folds, valid_folds, logger, stage=1, checkpoint=None)\n","\n","    loss_history_1.append(loss_records)\n","    valid_folds[TARGETS_PRED] = valid_predicts\n","    kl_loss_torch = evaluate_oof(valid_folds)\n","    info = f\"{'=' * 100}\\nFold {fold} Valid Loss: {kl_loss_torch}\\n\"\n","    info += f\"Elapse: {(time() - tik) / 60:.2f} min \\n{'=' * 100}\"\n","    logger.info(info)\n","\n","    oof_stage_1 = pd.concat([oof_stage_1, valid_folds], axis=0).reset_index(drop=True)\n","    oof_stage_1.to_csv(os.path.join(PATHS.OUTPUT_DIR, f\"{ModelConfig.MODEL_NAME}_oof_1.csv\"), index=False)\n","\n","    # ================== Stage 2: Train ====================\n","    tik = time()\n","    # model = ResNetGRU(\n","    #     kernels=ModelConfig.RESNET_GRU_KERNELS, \n","    #     in_channels=8, \n","    #     fixed_kernel_size=ModelConfig.RESNET_GRU_FIXED_KERNEL_SIZE,\n","    #     hidden_size=ModelConfig.RESNET_GRU_HIDDEN_SIZE,\n","    #     num_classes=6\n","    #     )\n","    model = ResNetGRU(config=ModelConfig, num_classes=6)\n","    \n","    train_folds_2 = train_hard[~train_hard['eeg_id'].isin(valid_folds['eeg_id'])].reset_index(drop=True)\n","    valid_folds_2 = train_hard[ train_hard['eeg_id'].isin(valid_folds['eeg_id'])].reset_index(drop=True)\n","    train_size = train_folds_2.shape[0]\n","    valid_size = valid_folds_2.shape[0]\n","    \n","    ## STAGE 2\n","    logger.info(f\"- Stage 2 | Train: {train_size}; Valid: {valid_size} -\")\n","\n","    # model_dir = \"/home/shiyi/kaggle_hms/outputs/ResnetGRU_Originalsplit/Reg015\"\n","    # checkpoint = list(Path(model_dir).glob(f\"*_fold_{fold}_stage_1.pth\"))[0]\n","    checkpoint = list(Path(PATHS.OUTPUT_DIR).glob(f\"{ModelConfig.MODEL_NAME}_fold_{fold}_stage_1.pth\"))[0]\n","\n","    valid_predicts, loss_records = train_fold(\n","        model, fold, train_folds_2, valid_folds_2, logger, stage=2, checkpoint=checkpoint)\n","    \n","    loss_history_2.append(loss_records)\n","    valid_folds_2[TARGETS_PRED] = valid_predicts\n","    kl_loss_torch = evaluate_oof(valid_folds_2)\n","    info = f\"{'=' * 100}\\nFold {fold} Valid Loss: {kl_loss_torch}\\n\"\n","    info += f\"Elapse: {(time() - tik) / 60:.2f} min \\n{'=' * 100}\"\n","    logger.info(info)\n","\n","    oof_stage_2 = pd.concat([oof_stage_2, valid_folds_2], axis=0).reset_index(drop=True)\n","    oof_stage_2.to_csv(os.path.join(PATHS.OUTPUT_DIR, f\"{ModelConfig.MODEL_NAME}_oof_2.csv\"), index=False)\n","\n","    logger.info(f\"Fold {fold} Elapse: {(time() - tik_total) / 60:.2f} min\")\n","\n","info = f\"{'=' * 100}\\nTraining Complete!\\n\"\n","cv_results_1 = evaluate_oof(oof_stage_1)\n","cv_results_2 = evaluate_oof(oof_stage_2)\n","info += f\"CV Result: Stage 1: {cv_results_1} | Stage 2: {cv_results_2}\\n\"\n","info += f\"Elapse: {(time() - t_start) / 60:.2f} min \\n{'=' * 100}\"\n","logger.info(info)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# plot loss history\n","fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5), sharey=True)\n","\n","for i, loss in enumerate(loss_history_1):\n","    ax1.plot(loss['train'], marker=\"*\", ls=\"-\", label=f\"Fold {i} Train\")\n","    ax1.plot(loss['valid'], marker=\"o\", ls=\":\", label=f\"Fold {i} Valid\")\n","\n","for i, loss in enumerate(loss_history_2):\n","    ax2.plot(loss['train'], marker=\"*\", ls=\"-\", label=f\"Fold {i} Train\")\n","    ax2.plot(loss['valid'], marker=\"o\", ls=\":\", label=f\"Fold {i} Valid\")\n","\n","ax1.set_title(\"Stage 1 Loss\")\n","ax2.set_title(\"Stage 2 Loss\")\n","\n","for ax in (ax1, ax2):\n","    ax.set_xlabel(\"Epochs\")\n","    ax.set_ylabel(\"Loss\")\n","    ax.legend()\n","    ax.grid(True)\n","\n","fig.tight_layout()\n","fig.savefig(Path(PATHS.OUTPUT_DIR) / f\"{ModelConfig.MODEL_NAME}_loss_history.png\")\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["csv_path = f'./outputs/{ModelConfig.MODEL_NAME}_oof_1.csv'\n","print(\"CSV Path: \", csv_path)\n","\n","oof_df = analyze_oof(csv_path)\n","\n","print(\"Kaggle Score: \", calc_kaggle_score(oof_df))\n","print(\"Average KL Loss: \", oof_df[\"kl_loss\"].mean())\n","\n","display(oof_df.head())\n","\n","# plot confusion matrix\n","cm = confusion_matrix(oof_df['target_id'], oof_df['target_pred']) # (y_true, y_pred)\n","cm = cm / cm.sum(axis=1)[:, np.newaxis]\n","\n","fig = plt.figure(figsize=(6, 6))\n","sns.heatmap(cm, annot=True, cmap='Blues', xticklabels=TARGET2ID.keys(), yticklabels=TARGET2ID.keys())\n","plt.xlabel('Predicted', fontsize=12)\n","plt.ylabel('True', fontsize=12)\n","plt.title(csv_path.split('/')[-1].split('.')[0], fontsize=12)\n","fig.tight_layout()\n","fig.savefig(f\"./outputs/{csv_path.split('/')[-1].split('.')[0]}_CM.png\")\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["fig, axes = plt.subplots(5, 5, figsize=(15, 15), sharex=True, sharey=True)\n","oof_samples = oof_df.sample(axes.size)\n","\n","for i, ax in enumerate(axes.flatten()):\n","    row = oof_samples.iloc[i]\n","    x = np.arange(6)\n","    ax.plot(x, row[TARGETS].T, marker=\"o\", ls=\"-\", label=\"True\")\n","    ax.plot(x, row[TARGETS_PRED].T, marker=\"*\", ls=\"--\", label=\"Predicted\")\n","    ax.set_title(f\"{row['target']} | KL Loss: {row['kl_loss']:.4f}\")\n","    ax.legend()\n","    \n","fig.tight_layout()\n","fig.savefig(f\"./outputs/{csv_path.split('/')[-1].split('.')[0]}_samples.png\")\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["csv_path = f'./outputs/{ModelConfig.MODEL_NAME}_oof_2.csv'\n","print(\"CSV Path: \", csv_path)\n","\n","oof_df = analyze_oof(csv_path)\n","\n","print(\"Kaggle Score: \", calc_kaggle_score(oof_df))\n","print(\"Average KL Loss: \", oof_df[\"kl_loss\"].mean())\n","\n","display(oof_df.head())\n","\n","# plot confusion matrix\n","cm = confusion_matrix(oof_df['target_id'], oof_df['target_pred']) # (y_true, y_pred)\n","cm = cm / cm.sum(axis=1)[:, np.newaxis]\n","\n","fig = plt.figure(figsize=(6, 6))\n","sns.heatmap(cm, annot=True, cmap='Blues', xticklabels=TARGET2ID.keys(), yticklabels=TARGET2ID.keys())\n","plt.xlabel('Predicted', fontsize=12)\n","plt.ylabel('True', fontsize=12)\n","plt.title(csv_path.split('/')[-1].split('.')[0], fontsize=12)\n","fig.tight_layout()\n","fig.savefig(f\"./outputs/{csv_path.split('/')[-1].split('.')[0]}_CM.png\")\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["fig, axes = plt.subplots(5, 5, figsize=(15, 15), sharex=True, sharey=True)\n","oof_samples = oof_df.sample(axes.size)\n","\n","for i, ax in enumerate(axes.flatten()):\n","    row = oof_samples.iloc[i]\n","    x = np.arange(6)\n","    ax.plot(x, row[TARGETS].T, marker=\"o\", ls=\"-\", label=\"True\")\n","    ax.plot(x, row[TARGETS_PRED].T, marker=\"*\", ls=\"--\", label=\"Predicted\")\n","    ax.set_title(f\"{row['target']} | KL Loss: {row['kl_loss']:.4f}\")\n","    ax.legend()\n","    \n","fig.tight_layout()\n","fig.savefig(f\"./outputs/{csv_path.split('/')[-1].split('.')[0]}_samples.png\")\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["oof_stage_2_full = pd.DataFrame()\n","\n","for fold in range(1):\n","\n","    valid_folds = train_all[train_all['fold'] == fold].reset_index(drop=True)\n","\n","    # predict labels using stage-2 models\n","    model = ResNetGRU(\n","        kernels=ModelConfig.RESNET_GRU_KERNELS, \n","        in_channels=8, \n","        fixed_kernel_size=ModelConfig.RESNET_GRU_FIXED_KERNEL_SIZE,\n","        hidden_size=ModelConfig.RESNET_GRU_HIDDEN_SIZE,\n","        num_classes=6\n","        )\n","    \n","    check_point = os.path.join(\n","        PATHS.OUTPUT_DIR,\n","        f\"{ModelConfig.MODEL_NAME}_fold_{fold}_stage_2.pth\"\n","    )\n","\n","    model.load_state_dict(torch.load(check_point, map_location=DEVICE))\n","\n","    loader_kwargs = {\n","        \"batch_size\": ModelConfig.BATCH_SIZE,\n","        \"num_workers\": ModelConfig.NUM_WORKERS,\n","        \"pin_memory\": True,\n","        \"shuffle\": False,\n","    }\n","\n","    valid_dataset = EEGSeqDataset(\n","        valid_folds, ModelConfig, ALL_EEG_SIGNALS, mode=\"valid\", downsample=ModelConfig.RESNET_GRU_DOWNSAMPLE)\n","    valid_loader = DataLoader(valid_dataset, drop_last=False, collate_fn=None, **loader_kwargs)\n","\n","    model.to(DEVICE)\n","    model.eval()\n","\n","    valid_predicts = []\n","    with torch.no_grad():\n","        for X, y in valid_loader:\n","            X = X.to(DEVICE)\n","            y_pred = model(X)\n","            valid_predicts.append(y_pred.to('cpu').numpy())\n","\n","    valid_predicts = np.concatenate(valid_predicts)\n","    valid_folds[TARGETS_PRED] = valid_predicts\n","    oof_stage_2_full = pd.concat([oof_stage_2, valid_folds], axis=0).reset_index(drop=True)\n","\n","    del valid_dataset, valid_loader\n","    torch.cuda.empty_cache()\n","    gc.collect()\n","\n","    oof_stage_2_full.to_csv(os.path.join(PATHS.OUTPUT_DIR, f\"{ModelConfig.MODEL_NAME}_oof_2_full.csv\"), index=False)\n","\n","cv_results = evaluate_oof(oof_stage_2_full)\n","logger.info(f\"{'=' * 100}\\nCV Result (Stage 2 Full): {cv_results}\\n{'=' * 100}\")\n"]},{"cell_type":"markdown","metadata":{},"source":["Reg = 0.15, Downsample = 0, CV Result (Stage 2 Full): 0.639643669128418"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["csv_path = f'./outputs/Resnet_SeqGRU_ChrisNO_NoReg_oof_2_full.csv'\n","print(\"CSV Path: \", csv_path)\n","\n","oof_df = analyze_oof(csv_path)\n","\n","print(\"Kaggle Score: \", calc_kaggle_score(oof_df))\n","print(\"Average KL Loss: \", oof_df[\"kl_loss\"].mean())\n","\n","display(oof_df.head())\n","\n","# plot confusion matrix\n","cm = confusion_matrix(oof_df['target_id'], oof_df['target_pred']) # (y_true, y_pred)\n","cm = cm / cm.sum(axis=1)[:, np.newaxis]\n","\n","fig = plt.figure(figsize=(6, 6))\n","sns.heatmap(cm, annot=True, cmap='Blues', xticklabels=TARGET2ID.keys(), yticklabels=TARGET2ID.keys())\n","plt.xlabel('Predicted', fontsize=12)\n","plt.ylabel('True', fontsize=12)\n","plt.title(csv_path.split('/')[-1].split('.')[0], fontsize=12)\n","fig.tight_layout()\n","fig.savefig(f\"./outputs/{csv_path.split('/')[-1].split('.')[0]}_CM.png\")\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"databundleVersionId":7469972,"sourceId":59093,"sourceType":"competition"},{"sourceId":165461612,"sourceType":"kernelVersion"},{"sourceId":168718625,"sourceType":"kernelVersion"}],"dockerImageVersionId":30673,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.6"}},"nbformat":4,"nbformat_minor":4}
