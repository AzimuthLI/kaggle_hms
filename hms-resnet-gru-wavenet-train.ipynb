{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"trusted":true},"outputs":[],"source":["import os, gc, random\n","import numpy as np\n","import pandas as pd \n","from pathlib import Path\n","import matplotlib.pyplot as plt\n","from typing import List, Dict\n","from tqdm.notebook import tqdm\n","from time import time, ctime\n","\n","from sklearn.model_selection import KFold, GroupKFold\n","\n","import torch\n","from torch import nn\n","from torch.nn import functional as F\n","from torch.utils.data import DataLoader, Dataset\n","from torchvision.transforms import v2\n","from torch.optim.lr_scheduler import OneCycleLR\n","from torch.optim import Adam, AdamW\n","from torch.cuda.amp import autocast, GradScaler\n","\n","from scipy.signal import butter, lfilter, freqz\n","from scipy.stats import entropy\n","from scipy.special import rel_entr"]},{"cell_type":"code","execution_count":2,"metadata":{"trusted":true},"outputs":[],"source":["def get_logger(log_dir, logger_name=\"train_model.log\"):\n","    from logging import getLogger, INFO, StreamHandler, FileHandler, Formatter\n","    logger_file = os.path.join(log_dir, logger_name)\n","    logger = getLogger(__name__)\n","    logger.setLevel(INFO)\n","    handler1 = StreamHandler()\n","    handler1.setFormatter(Formatter(\"%(message)s\"))\n","    handler2 = FileHandler(filename=logger_file, mode=\"a+\")\n","    handler2.setFormatter(Formatter(\"%(message)s\"))\n","    logger.addHandler(handler1)\n","    logger.addHandler(handler2)\n","    return logger\n","\n","\n","def seed_everything(seed: int):\n","    random.seed(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)"]},{"cell_type":"code","execution_count":3,"metadata":{"trusted":true},"outputs":[],"source":["class ModelConfig:\n","    SEED = 20\n","    SPLIT_ENTROPY = 5.5\n","    MODEL_NAME = \"EEGSeq_DilatedResNet_Deep\"\n","    MODEL_BACKBONE = \"wavenet\"\n","    BATCH_SIZE = 32\n","    EPOCHS = 30\n","    EARLY_STOP_ROUNDS = 5\n","    GRADIENT_ACCUMULATION_STEPS = 1\n","    DROP_RATE = 0.15 # default: 0.1\n","    DROP_PATH_RATE = 0.25 # default: 0.2\n","    WEIGHT_DECAY = 0.01\n","    AMP = True\n","    PRINT_FREQ = 100\n","    NUM_WORKERS = 0 \n","    MAX_GRAD_NORM = 1e7"]},{"cell_type":"code","execution_count":4,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Use Device:  cuda:0\n"]}],"source":["N_GPU = torch.cuda.device_count()\n","if N_GPU > 1:\n","    DEVICE = torch.device(\"cuda\")\n","    os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1\"\n","elif N_GPU == 1:\n","    DEVICE = torch.device(\"cuda:0\")\n","else:\n","    DEVICE = torch.device(\"cpu\")\n","\n","print(\"Use Device: \", DEVICE)"]},{"cell_type":"code","execution_count":5,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Output Dir:  ./outputs/\n"]}],"source":["class KagglePaths:\n","    OUTPUT_DIR = \"/kaggle/working/\"\n","    PRE_LOADED_EEGS = '/kaggle/input/brain-eeg-spectrograms/eeg_specs.npy'\n","    PRE_LOADED_SPECTROGRAMS = '/kaggle/input/brain-spectrograms/specs.npy'\n","    TRAIN_CSV = \"/kaggle/input/hms-harmful-brain-activity-classification/train.csv\"\n","    TRAIN_EEGS = \"/kaggle/input/hms-harmful-brain-activity-classification/train_eegs/\"\n","    TRAIN_SPECTROGRAMS = \"/kaggle/input/hms-harmful-brain-activity-classification/train_spectrograms/\"\n","    TEST_CSV = \"/kaggle/input/hms-harmful-brain-activity-classification/test.csv\"\n","    TEST_SPECTROGRAMS = \"/kaggle/input/hms-harmful-brain-activity-classification/test_spectrograms/\"\n","    TEST_EEGS = \"/kaggle/input/hms-harmful-brain-activity-classification/test_eegs/\"\n","\n","\n","class LocalPaths:\n","    OUTPUT_DIR = \"./outputs/\"\n","    PRE_LOADED_EEGS = './inputs/brain-eeg-spectrograms/eeg_specs.npy'\n","    PRE_LOADED_SPECTROGRAMS = './inputs/brain-spectrograms/specs.npy'\n","    TRAIN_CSV = \"./inputs/hms-harmful-brain-activity-classification/train.csv\"\n","    TRAIN_EEGS = \"./inputs/hms-harmful-brain-activity-classification/train_eegs\"\n","    TRAIN_SPECTROGRAMS = \"./inputs/hms-harmful-brain-activity-classification/train_spectrograms\"\n","    TEST_CSV = \"./inputs/hms-harmful-brain-activity-classification/test.csv\"\n","    TEST_SPECTROGRAMS = \"./inputs/hms-harmful-brain-activity-classification/test_spectrograms\"\n","    TEST_EEGS = \"./inputs/hms-harmful-brain-activity-classification/test_eegs\"\n","\n","PATHS = KagglePaths if os.path.exists(\"/kaggle\") else LocalPaths\n","\n","print(\"Output Dir: \", PATHS.OUTPUT_DIR)\n","\n","EEG_FEAT_ALL = [\n","    'Fp1', 'F3', 'C3', 'P3', \n","    'F7', 'T3', 'T5', 'O1', \n","    'Fz', 'Cz', 'Pz', 'Fp2', \n","    'F4', 'C4', 'P4', 'F8', \n","    'T4', 'T6', 'O2', 'EKG'\n","    ]\n","\n","EEG_FEAT_USE =  ['Fp1','T3','C3','O1','Fp2','C4','T4','O2']\n","EEF_FEAT_INDEX = {x:y for x,y in zip(EEG_FEAT_USE, range(len(EEG_FEAT_USE)))}\n","\n","BRAIN_ACTIVITY = ['seizure', 'lpd', 'gpd', 'lrda', 'grda', 'other']\n","TARGETS = [f\"{lb}_vote\" for lb in BRAIN_ACTIVITY]\n","TARGETS_PRED = [f\"{lb}_pred\" for lb in BRAIN_ACTIVITY]\n","\n","seed_everything(ModelConfig.SEED)"]},{"cell_type":"code","execution_count":6,"metadata":{"trusted":true},"outputs":[],"source":["logger = get_logger(PATHS.OUTPUT_DIR, f\"{ModelConfig.MODEL_NAME}_train.log\")"]},{"cell_type":"markdown","metadata":{},"source":["# Load Data"]},{"cell_type":"code","execution_count":7,"metadata":{"trusted":true},"outputs":[],"source":["def eeg_from_parquet(parquet_path: str, use_feature=EEG_FEAT_USE, display: bool = False) -> np.ndarray:\n","    # === Extract full length EEG Sequence ===\n","    # fill missing values with mean\n","    # first fill missing values with mean of each column\n","    # then if all values are missing, fill with 0\n","    eeg = pd.read_parquet(parquet_path, columns=use_feature)\n","    eeg = eeg.fillna(eeg.mean(skipna=True)).fillna(0)\n","    data = eeg.values.astype(np.float32)\n","\n","    if display:\n","        fig, ax = plt.subplots(len(use_feature), 1, figsize=(10, 2*len(use_feature)), sharex=True)\n","        \n","        for i, feat in enumerate(use_feature):\n","            ax[i].plot(data[:, i], label=feat)\n","            ax[i].legend()\n","            ax[i].grid()\n","       \n","        name = parquet_path.split('/')[-1].split('.')[0]\n","        ax[0].set_title(f'EEG {name}',size=16)\n","        fig.tight_layout()\n","        plt.show()    \n","    return data"]},{"cell_type":"code","execution_count":8,"metadata":{"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b085f25bea274b659cd118ade6988e08","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/17300 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["CPU times: user 1min 19s, sys: 12.9 s, total: 1min 32s\n","Wall time: 1min 3s\n"]}],"source":["%%time\n","CREATE_EEGS = True\n","ALL_EEG_SIGNALS = {}\n","eeg_paths = list(Path(PATHS.TRAIN_EEGS).glob('*.parquet'))\n","preload_eegs_path = Path('./inputs/eegs_full.npy')\n","\n","if CREATE_EEGS:\n","    count = 0\n","    for parquet_path in tqdm(eeg_paths, total=len(eeg_paths)):\n","        eeg_id = int(parquet_path.stem)\n","        eeg_path = str(parquet_path)\n","        data = eeg_from_parquet(eeg_path, display=False)\n","        ALL_EEG_SIGNALS[eeg_id] = data\n","        count += 1\n","    np.save(\"./inputs/eegs_full.npy\", ALL_EEG_SIGNALS)\n","else:\n","    ALL_EEG_SIGNALS = np.load(preload_eegs_path, allow_pickle=True).item()"]},{"cell_type":"code","execution_count":9,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["targets:  ['seizure_vote', 'lpd_vote', 'gpd_vote', 'lrda_vote', 'grda_vote', 'other_vote']\n","train_all:  (19763, 20)\n","Fold 0: All Size: 15754 | 4009, Hard Size: 9248 | 2364\n","Fold 1: All Size: 15812 | 3951, Hard Size: 9284 | 2328\n","Fold 2: All Size: 15844 | 3919, Hard Size: 9299 | 2313\n","Fold 3: All Size: 15805 | 3958, Hard Size: 9298 | 2314\n","Fold 4: All Size: 15837 | 3926, Hard Size: 9319 | 2293\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>eeg_id</th>\n","      <th>spectrogram_id</th>\n","      <th>min</th>\n","      <th>max</th>\n","      <th>eeg_off_min</th>\n","      <th>eeg_off_max</th>\n","      <th>eeg_off_sample</th>\n","      <th>patient_id</th>\n","      <th>target</th>\n","      <th>total_votes</th>\n","      <th>entropy</th>\n","      <th>is_hard</th>\n","      <th>seizure_vote</th>\n","      <th>lpd_vote</th>\n","      <th>gpd_vote</th>\n","      <th>lrda_vote</th>\n","      <th>grda_vote</th>\n","      <th>other_vote</th>\n","      <th>is_stage</th>\n","      <th>fold</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>568657</td>\n","      <td>789577333</td>\n","      <td>0.0</td>\n","      <td>16.0</td>\n","      <td>0.0</td>\n","      <td>16.0</td>\n","      <td>0.0</td>\n","      <td>20654</td>\n","      <td>Other</td>\n","      <td>48</td>\n","      <td>4.584192</td>\n","      <td>1.0</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.250000</td>\n","      <td>0.000000</td>\n","      <td>0.166667</td>\n","      <td>0.583333</td>\n","      <td>2</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>582999</td>\n","      <td>1552638400</td>\n","      <td>0.0</td>\n","      <td>38.0</td>\n","      <td>0.0</td>\n","      <td>38.0</td>\n","      <td>22.0</td>\n","      <td>20230</td>\n","      <td>LPD</td>\n","      <td>154</td>\n","      <td>4.870032</td>\n","      <td>1.0</td>\n","      <td>0.000000</td>\n","      <td>0.857143</td>\n","      <td>0.000000</td>\n","      <td>0.071429</td>\n","      <td>0.000000</td>\n","      <td>0.071429</td>\n","      <td>2</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>642382</td>\n","      <td>14960202</td>\n","      <td>1008.0</td>\n","      <td>1032.0</td>\n","      <td>0.0</td>\n","      <td>24.0</td>\n","      <td>24.0</td>\n","      <td>5955</td>\n","      <td>Other</td>\n","      <td>2</td>\n","      <td>7.802343</td>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>1.000000</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>751790</td>\n","      <td>618728447</td>\n","      <td>908.0</td>\n","      <td>908.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>38549</td>\n","      <td>GPD</td>\n","      <td>1</td>\n","      <td>7.802343</td>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>1.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>778705</td>\n","      <td>52296320</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>40955</td>\n","      <td>Other</td>\n","      <td>2</td>\n","      <td>7.802343</td>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>1.000000</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>1629671</td>\n","      <td>2036345030</td>\n","      <td>0.0</td>\n","      <td>160.0</td>\n","      <td>0.0</td>\n","      <td>160.0</td>\n","      <td>126.0</td>\n","      <td>37481</td>\n","      <td>Seizure</td>\n","      <td>51</td>\n","      <td>7.802343</td>\n","      <td>0.0</td>\n","      <td>1.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>2</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>1895581</td>\n","      <td>128369999</td>\n","      <td>1138.0</td>\n","      <td>1138.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>47999</td>\n","      <td>Other</td>\n","      <td>13</td>\n","      <td>4.847483</td>\n","      <td>1.0</td>\n","      <td>0.076923</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.076923</td>\n","      <td>0.846154</td>\n","      <td>2</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>2061593</td>\n","      <td>320962633</td>\n","      <td>1450.0</td>\n","      <td>1450.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>23828</td>\n","      <td>Other</td>\n","      <td>1</td>\n","      <td>7.802343</td>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>1.000000</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>2078097</td>\n","      <td>2074135650</td>\n","      <td>3342.0</td>\n","      <td>3342.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>61174</td>\n","      <td>Other</td>\n","      <td>2</td>\n","      <td>7.802343</td>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>1.000000</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>2366870</td>\n","      <td>1232582129</td>\n","      <td>0.0</td>\n","      <td>30.0</td>\n","      <td>0.0</td>\n","      <td>30.0</td>\n","      <td>0.0</td>\n","      <td>23633</td>\n","      <td>Other</td>\n","      <td>18</td>\n","      <td>6.134196</td>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","      <td>0.333333</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.666667</td>\n","      <td>2</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>2482631</td>\n","      <td>978166025</td>\n","      <td>1902.0</td>\n","      <td>1944.0</td>\n","      <td>0.0</td>\n","      <td>42.0</td>\n","      <td>34.0</td>\n","      <td>20606</td>\n","      <td>Other</td>\n","      <td>105</td>\n","      <td>3.236383</td>\n","      <td>1.0</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.133333</td>\n","      <td>0.066667</td>\n","      <td>0.133333</td>\n","      <td>0.666667</td>\n","      <td>2</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>2521897</td>\n","      <td>673742515</td>\n","      <td>0.0</td>\n","      <td>4.0</td>\n","      <td>0.0</td>\n","      <td>4.0</td>\n","      <td>4.0</td>\n","      <td>62117</td>\n","      <td>Other</td>\n","      <td>24</td>\n","      <td>3.172763</td>\n","      <td>1.0</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.083333</td>\n","      <td>0.083333</td>\n","      <td>0.333333</td>\n","      <td>0.500000</td>\n","      <td>2</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>2918824</td>\n","      <td>1211648246</td>\n","      <td>3462.0</td>\n","      <td>3462.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>14965</td>\n","      <td>Seizure</td>\n","      <td>2</td>\n","      <td>7.802343</td>\n","      <td>0.0</td>\n","      <td>1.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>3108700</td>\n","      <td>223960986</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>55677</td>\n","      <td>Other</td>\n","      <td>3</td>\n","      <td>7.802343</td>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>1.000000</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>3625731</td>\n","      <td>2091405434</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>6935</td>\n","      <td>GRDA</td>\n","      <td>1</td>\n","      <td>7.802343</td>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>1.000000</td>\n","      <td>0.000000</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["     eeg_id  spectrogram_id     min     max  eeg_off_min  eeg_off_max  \\\n","0    568657       789577333     0.0    16.0          0.0         16.0   \n","1    582999      1552638400     0.0    38.0          0.0         38.0   \n","2    642382        14960202  1008.0  1032.0          0.0         24.0   \n","3    751790       618728447   908.0   908.0          0.0          0.0   \n","4    778705        52296320     0.0     0.0          0.0          0.0   \n","5   1629671      2036345030     0.0   160.0          0.0        160.0   \n","6   1895581       128369999  1138.0  1138.0          0.0          0.0   \n","7   2061593       320962633  1450.0  1450.0          0.0          0.0   \n","8   2078097      2074135650  3342.0  3342.0          0.0          0.0   \n","9   2366870      1232582129     0.0    30.0          0.0         30.0   \n","10  2482631       978166025  1902.0  1944.0          0.0         42.0   \n","11  2521897       673742515     0.0     4.0          0.0          4.0   \n","12  2918824      1211648246  3462.0  3462.0          0.0          0.0   \n","13  3108700       223960986     0.0     0.0          0.0          0.0   \n","14  3625731      2091405434     0.0     0.0          0.0          0.0   \n","\n","    eeg_off_sample  patient_id   target  total_votes   entropy  is_hard  \\\n","0              0.0       20654    Other           48  4.584192      1.0   \n","1             22.0       20230      LPD          154  4.870032      1.0   \n","2             24.0        5955    Other            2  7.802343      0.0   \n","3              0.0       38549      GPD            1  7.802343      0.0   \n","4              0.0       40955    Other            2  7.802343      0.0   \n","5            126.0       37481  Seizure           51  7.802343      0.0   \n","6              0.0       47999    Other           13  4.847483      1.0   \n","7              0.0       23828    Other            1  7.802343      0.0   \n","8              0.0       61174    Other            2  7.802343      0.0   \n","9              0.0       23633    Other           18  6.134196      0.0   \n","10            34.0       20606    Other          105  3.236383      1.0   \n","11             4.0       62117    Other           24  3.172763      1.0   \n","12             0.0       14965  Seizure            2  7.802343      0.0   \n","13             0.0       55677    Other            3  7.802343      0.0   \n","14             0.0        6935     GRDA            1  7.802343      0.0   \n","\n","    seizure_vote  lpd_vote  gpd_vote  lrda_vote  grda_vote  other_vote  \\\n","0       0.000000  0.000000  0.250000   0.000000   0.166667    0.583333   \n","1       0.000000  0.857143  0.000000   0.071429   0.000000    0.071429   \n","2       0.000000  0.000000  0.000000   0.000000   0.000000    1.000000   \n","3       0.000000  0.000000  1.000000   0.000000   0.000000    0.000000   \n","4       0.000000  0.000000  0.000000   0.000000   0.000000    1.000000   \n","5       1.000000  0.000000  0.000000   0.000000   0.000000    0.000000   \n","6       0.076923  0.000000  0.000000   0.000000   0.076923    0.846154   \n","7       0.000000  0.000000  0.000000   0.000000   0.000000    1.000000   \n","8       0.000000  0.000000  0.000000   0.000000   0.000000    1.000000   \n","9       0.000000  0.333333  0.000000   0.000000   0.000000    0.666667   \n","10      0.000000  0.000000  0.133333   0.066667   0.133333    0.666667   \n","11      0.000000  0.000000  0.083333   0.083333   0.333333    0.500000   \n","12      1.000000  0.000000  0.000000   0.000000   0.000000    0.000000   \n","13      0.000000  0.000000  0.000000   0.000000   0.000000    1.000000   \n","14      0.000000  0.000000  0.000000   0.000000   1.000000    0.000000   \n","\n","    is_stage  fold  \n","0          2     0  \n","1          2     0  \n","2          1     0  \n","3          1     0  \n","4          1     0  \n","5          2     0  \n","6          2     0  \n","7          1     0  \n","8          1     0  \n","9          2     0  \n","10         2     0  \n","11         2     0  \n","12         1     0  \n","13         1     0  \n","14         1     0  "]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["train_csv = pd.read_csv(PATHS.TRAIN_CSV)\n","targets = train_csv.columns[-6:].tolist()\n","\n","print(\"targets: \", targets)\n","\n","train_csv['total_votes'] = train_csv[targets].sum(axis=1)\n","\n","targets_prob = [f\"{t.split('_')[0]}_prob\" for t in targets]\n","train_csv[targets_prob] = train_csv[targets].div(train_csv['total_votes'], axis=0)\n","\n","train_csv['entropy'] = train_csv[targets_prob].apply(lambda row: sum(rel_entr([1/6]*6, row.values+1e-5)), axis=1)\n","train_csv['is_hard'] = (train_csv['entropy'] < 5.5).astype(int)\n","\n","agg_dicts = {\n","    'spectrogram_id': 'first',\n","    'spectrogram_label_offset_seconds': ['min', 'max'],\n","    'eeg_label_offset_seconds': ['min', 'max', lambda x: x.sample(1)],\n","    'patient_id': 'first',\n","    'expert_consensus': 'first',\n","    'total_votes': 'sum',\n","    'entropy': 'mean',\n","    'is_hard': 'mean'\n","}\n","\n","for col in targets:\n","    agg_dicts[col] = 'sum'\n","\n","train_all = train_csv.groupby(['eeg_id']+targets_prob).agg(agg_dicts).reset_index()\n","\n","col_names = [\n","    'spectrogram_id', 'min', 'max', 'eeg_off_min', 'eeg_off_max', 'eeg_off_sample', \n","    'patient_id', 'target', 'total_votes', 'entropy', 'is_hard'\n","    ] + targets\n","\n","train_all.columns = [\"eeg_id\"] + targets_prob + col_names\n","train_all.drop(targets_prob, axis=1, inplace=True)\n","train_all[targets] = train_all[targets].div(train_all['total_votes'], axis=0)\n","train_all['is_stage'] = 1\n","train_all.loc[(train_all['total_votes']>10) | (train_all['entropy']<5.5), 'is_stage'] = 2\n","\n","K_FOLDS = 5\n","unique_eegs = train_all['eeg_id'].unique()\n","kf = KFold(n_splits=K_FOLDS)\n","\n","train_all['fold'] = -1\n","\n","for fold, (train_index, valid_index) in enumerate(kf.split(unique_eegs)):\n","    train_all.loc[train_all['eeg_id'].isin(unique_eegs[valid_index]), 'fold'] = fold\n","\n","print(\"train_all: \", train_all.shape)\n","for fold in range(K_FOLDS):\n","    train_size = train_all[train_all['fold'] != fold].shape[0]\n","    valid_size = train_all[train_all['fold'] == fold].shape[0]\n","    train_hard_size = train_all[(train_all['fold'] != fold) & (train_all['is_stage'] == 2)].shape[0]\n","    valid_hard_size = train_all[(train_all['fold'] == fold) & (train_all['is_stage'] == 2)].shape[0]\n","    print(f\"Fold {fold}: All Size: {train_size} | {valid_size}, Hard Size: {train_hard_size} | {valid_hard_size}\")\n","\n","train_all.head(15)"]},{"cell_type":"markdown","metadata":{},"source":["# Dataset"]},{"cell_type":"code","execution_count":10,"metadata":{"trusted":true},"outputs":[],"source":["# Functional Utils\n","def butter_bandpass_filter(data, lowcut, highcut, fs, order=5):\n","    b, a = butter(order, [lowcut, highcut], fs=fs, btype='band')\n","    y = lfilter(b, a, data)\n","    return y\n","\n","def denoise_filter(x):\n","    # Sample rate and desired cutoff frequencies (in Hz).\n","    fs = 200.0\n","    lowcut = 1.0\n","    highcut = 25.0\n","    \n","    # Filter a noisy signal.\n","    T = 50\n","    nsamples = T * fs\n","    t = np.arange(0, nsamples) / fs\n","    y = butter_bandpass_filter(x, lowcut, highcut, fs, order=6)\n","    y = (y + np.roll(y,-1)+ np.roll(y,-2)+ np.roll(y,-3))/4\n","    y = y[0:-1:4]\n","    \n","    return y\n","\n","def mu_law_encoding(data, mu):\n","    mu_x = np.sign(data) * np.log(1 + mu * np.abs(data)) / np.log(mu + 1)\n","    return mu_x\n","\n","def mu_law_expansion(data, mu):\n","    s = np.sign(data) * (np.exp(np.abs(data) * np.log(mu + 1)) - 1) / mu\n","    return s\n","\n","def quantize_data(data, classes):\n","    mu_x = mu_law_encoding(data, classes)\n","    return mu_x #quantized\n","\n","def butter_lowpass_filter(data, cutoff_freq=20, sampling_rate=200, order=4):\n","    nyquist = 0.5 * sampling_rate\n","    normal_cutoff = cutoff_freq / nyquist\n","    b, a = butter(order, normal_cutoff, btype='low', analog=False)\n","    filtered_data = lfilter(b, a, data, axis=0)\n","    return filtered_data\n"]},{"cell_type":"code","execution_count":11,"metadata":{"trusted":true},"outputs":[],"source":["class EEGSeqDataset(Dataset):\n","    def __init__(self, df, config, eegs, mode='train', verbose=False):\n","        self.df = df\n","        self.mode = mode\n","        self.eegs = eegs\n","        self.verbose = verbose\n","    \n","    def __len__(self):\n","        return len(self.df)\n","\n","    def __getitem__(self, idx):\n","        \n","        X, y_prob = self.__data_generation(idx)\n","        \n","        return torch.tensor(X, dtype=torch.float32), torch.tensor(y_prob, dtype=torch.float32)\n","    \n","    def __data_generation(self, index):\n","        row = self.df.iloc[index]\n","\n","        if self.verbose:\n","            print(f\"Row {index}\", row[['eeg_id', 'eeg_off_min', 'eeg_off_max', 'target']].tolist())\n","\n","        X = np.zeros((10_000, 8), dtype='float32')\n","        \n","        # start_sec = int((row['eeg_off_min'] + row['eeg_off_max']) // 2)\n","        # !!! use randomly sampled offset !!!\n","        start_sec = int(row['eeg_off_sample']) \n","        data = self.eegs[row.eeg_id][start_sec*200 : (start_sec+50)*200]\n","\n","        # === Feature engineering ===\n","        X[:,0] = data[:,EEF_FEAT_INDEX['Fp1']] - data[:,EEF_FEAT_INDEX['T3']]\n","        X[:,1] = data[:,EEF_FEAT_INDEX['T3']] - data[:,EEF_FEAT_INDEX['O1']]\n","\n","        X[:,2] = data[:,EEF_FEAT_INDEX['Fp1']] - data[:,EEF_FEAT_INDEX['C3']]\n","        X[:,3] = data[:,EEF_FEAT_INDEX['C3']] - data[:,EEF_FEAT_INDEX['O1']]\n","\n","        X[:,4] = data[:,EEF_FEAT_INDEX['Fp2']] - data[:,EEF_FEAT_INDEX['C4']]\n","        X[:,5] = data[:,EEF_FEAT_INDEX['C4']] - data[:,EEF_FEAT_INDEX['O2']]\n","\n","        X[:,6] = data[:,EEF_FEAT_INDEX['Fp2']] - data[:,EEF_FEAT_INDEX['T4']]\n","        X[:,7] = data[:,EEF_FEAT_INDEX['T4']] - data[:,EEF_FEAT_INDEX['O2']]\n","\n","        # === Standarize ===\n","        X = np.clip(X,-1024, 1024)\n","        X = np.nan_to_num(X, nan=0) / 32.0\n","\n","        # === Butter Low-pass Filter ===\n","        # !!! change to bandpass filter (low=0.5, hight=20, order=2) !!!\n","        # X = butter_lowpass_filter(X)\n","        X = butter_bandpass_filter(X, .5, 20, 200, order=2)\n","\n","        if self.mode != 'test':\n","            y_prob = row[TARGETS].values.astype(np.float32)\n","        else:\n","            y_prob = np.zeros(6, dtype='float32')\n","\n","        # downsample by 5\n","        return X[::5, :], y_prob\n"]},{"cell_type":"code","execution_count":12,"metadata":{"trusted":true},"outputs":[],"source":["# visualize the dataset\n","\n","# train_dataset = EEGSeqDataset(train_all, ModelConfig, ALL_EEG_SIGNALS, mode=\"train\")\n","# train_loader = DataLoader(train_dataset, drop_last=True, batch_size=16, num_workers=4, pin_memory=True, shuffle=False)\n","\n","# for batch in train_loader:\n","#     X, y = batch\n","#     print(f\"X shape: {X.shape}\")\n","#     print(f\"y shape: {y.shape}\")\n","    \n","#     fig, axes = plt.subplots(4, 1, figsize=(20, 20))\n","#     for item in range(4):\n","#         offset = 0\n","#         for col in range(X.shape[-1]):\n","#             if col != 0:\n","#                 offset -= X[item,:,col].min()\n","#             axes[item].plot(np.arange(X.shape[1]), X[item,:,col]+offset, label=f'feature {col+1}')\n","#             offset += X[item,:,col].max()\n","#         tt = f'{y[col][0]:0.1f}'\n","#         for t in y[col][1:]:\n","#             tt += f', {t:0.1f}'\n","#         axes[item].set_title(f'Target = {tt}',size=14)\n","#         axes[item].legend()\n","#     fig.tight_layout()\n","#     plt.show()\n","#     break\n","# del train_dataset, train_loader\n","# torch.cuda.empty_cache()\n","# gc.collect()"]},{"cell_type":"markdown","metadata":{},"source":["# Model"]},{"cell_type":"markdown","metadata":{},"source":["### Sequencial GRU Encoder"]},{"cell_type":"code","execution_count":13,"metadata":{"jupyter":{"source_hidden":true},"trusted":true},"outputs":[],"source":["# class SeqGRUEncoder(nn.Module):\n","#     def __init__(self, in_channels, hidden_size=128, num_layers=2, bidirectional=True):\n","#         super(SeqGRUEncoder, self).__init__()\n","\n","#         self.in_channels = in_channels\n","\n","#         # Initialize the GRU to have 128 hidden units per direction and to be bidirectional\n","#         self.rnn = nn.GRU(\n","#             input_size=in_channels, \n","#             hidden_size=hidden_size, \n","#             num_layers=num_layers,\n","#             bidirectional=bidirectional, \n","#             batch_first=True\n","#         )\n","        \n","#         # Initialize the attention mechanism\n","#         if bidirectional:\n","#             emb_dim = 2 * hidden_size\n","#         else:\n","#             emb_dim = hidden_size\n","        \n","#         self.attention_dense = nn.Linear(emb_dim, 1)\n","#         self.softmax = nn.Softmax(dim=-1)\n","\n","#     def forward(self, x):\n","#         # x shape: [batch, seq_len, in_channels]\n","#         rnn_out, _ = self.rnn(x)  # -> [batch, seq_len, emb_dim]\n","#         identity = rnn_out\n","#         scores = self.attention_dense(rnn_out).squeeze(-1)\n","#         scores = self.softmax(scores).unsqueeze(1)\n","#         pooled_out = torch.matmul(scores, identity).squeeze(1)\n","#         # -> [batch_size, emb_dim]\n","#         return pooled_out"]},{"cell_type":"markdown","metadata":{},"source":["### Resnet 1D Encoder"]},{"cell_type":"code","execution_count":14,"metadata":{"jupyter":{"source_hidden":true},"trusted":true},"outputs":[],"source":["# class ResNet_1D_Block(nn.Module):\n","#     def __init__(self, in_channels, out_channels, kernel_size, stride, padding, downsampling, dropout=0.0):\n","#         super(ResNet_1D_Block, self).__init__()\n","#         self.block = nn.Sequential(\n","#             nn.BatchNorm1d(num_features=in_channels),\n","#             nn.ReLU(),\n","#             nn.Dropout(p=dropout),\n","#             nn.Conv1d(in_channels, out_channels, kernel_size, stride, padding, bias=False),\n","#             nn.BatchNorm1d(num_features=out_channels),\n","#             nn.ReLU(),\n","#             nn.Dropout(p=dropout),\n","#             nn.Conv1d(out_channels, out_channels, kernel_size, stride, padding, bias=False),\n","#             nn.MaxPool1d(kernel_size=2, stride=2, padding=0)\n","#         )\n","#         self.downsampling = downsampling\n","#         self._initialize_weights()\n","        \n","#     def _initialize_weights(self):\n","#         for m in self.modules():\n","#             if isinstance(m, nn.Conv1d):\n","#                 nn.init.kaiming_uniform_(m.weight, mode='fan_in', nonlinearity='relu')\n","#             elif isinstance(m, nn.BatchNorm1d):\n","#                 nn.init.constant_(m.weight, 1)\n","#                 nn.init.constant_(m.bias, 0)\n","\n","#     def forward(self, x):\n","#         identity = self.downsampling(x)\n","#         out = self.block(x)\n","#         out += identity\n","#         return out\n","    \n","    \n","# class ResNet_1D_Encoder(nn.Module):\n","#     def __init__(self, kernels=[3,7,9,11], planes=24, in_channels=8, fixed_kernel_size=5, n_blocks=9, dropout=0.0):\n","#         super(ResNet_1D_Encoder, self).__init__()\n","\n","#         self.parallel_conv = nn.ModuleList([\n","#             nn.Conv1d(\n","#                 in_channels=in_channels, \n","#                 out_channels=planes, \n","#                 kernel_size=kernel_size,\n","#                 stride=1, \n","#                 padding=0, \n","#                 bias=False\n","#             ) for kernel_size in kernels\n","#         ])\n","\n","#         self.resnet_layer = ResNet_1D_Block(\n","#             in_channels=planes, \n","#             out_channels=planes, \n","#             kernel_size=fixed_kernel_size,\n","#             stride=1, \n","#             padding=fixed_kernel_size//2, \n","#             downsampling=nn.MaxPool1d(kernel_size=2, stride=2, padding=0),\n","#             dropout=dropout\n","#         )\n","        \n","#         self.resnet_part = nn.Sequential(\n","#             nn.BatchNorm1d(num_features=planes),\n","#             nn.ReLU(inplace=False),\n","#             nn.Conv1d(\n","#                 in_channels=planes, \n","#                 out_channels=planes, \n","#                 kernel_size=fixed_kernel_size, \n","#                 stride=2, \n","#                 padding=2, \n","#                 bias=False\n","#             ),\n","#             *[\n","#                 ResNet_1D_Block(\n","#                     in_channels=planes,\n","#                     out_channels=planes,\n","#                     kernel_size=fixed_kernel_size,\n","#                     stride=1,\n","#                     padding=fixed_kernel_size//2,\n","#                     downsampling=nn.MaxPool1d(kernel_size=2, stride=2, padding=0),\n","#                     dropout=dropout\n","#                     ) \n","#                 for _ in range(n_blocks)\n","#             ],\n","#             nn.BatchNorm1d(num_features=planes),\n","#             nn.ReLU(),\n","#             nn.AvgPool1d(kernel_size=6, stride=6, padding=2)\n","#         )\n","\n","#     def forward(self, x):\n","#         # x shape: [batch, seq_len, in_channels]\n","#         # print(\"Resnet Input Shape: \", x.shape)\n","#         x = x.permute(0, 2, 1)  # (batch, channels, seq_len)\n","       \n","#         out_sep = [conv(x) for conv in self.parallel_conv]\n","#         out = torch.cat(out_sep, dim=2)\n","#         out = self.resnet_part(out)\n","        \n","#         # Return the flattened features from the last convolutional layer\n","#         features = out.reshape(out.shape[0], -1)\n","#         return features\n"]},{"cell_type":"markdown","metadata":{},"source":["### Dilated Inception Wavenet Encoder"]},{"cell_type":"code","execution_count":15,"metadata":{"trusted":true},"outputs":[],"source":["# from typing import List\n","\n","# class DilatedInception(nn.Module):\n","#     def __init__(self, in_channels: int, out_channels: int, kernel_sizes: List[int], dilation: int) -> None:\n","#         super().__init__()\n","#         assert out_channels % len(kernel_sizes) == 0, \"`out_channels` must be divisible by the number of kernel sizes.\"\n","#         hidden_dim = out_channels // len(kernel_sizes)\n","#         self.convs = nn.ModuleList([\n","#             nn.Conv1d(in_channels, hidden_dim, k, padding='same', dilation=dilation)\n","#             for k in kernel_sizes\n","#         ])\n","\n","#     def forward(self, x):\n","#         outputs = [conv(x) for conv in self.convs]\n","#         out = torch.cat(outputs, dim=1)\n","#         return out\n","\n","# class GatedTCN(nn.Module):\n","#     def __init__(self, in_dim: int, h_dim: int, kernel_sizes: List[int], dilation_factor: int, dropout: float = 0.0) -> None:\n","#         super().__init__()\n","#         self.filt = DilatedInception(in_dim, h_dim, kernel_sizes, dilation=dilation_factor)\n","#         self.gate = DilatedInception(in_dim, h_dim, kernel_sizes, dilation=dilation_factor)\n","#         self.dropout = nn.Dropout(dropout)\n","\n","#     def forward(self, x):\n","#         x_filt = torch.tanh(self.filt(x))\n","#         x_gate = torch.sigmoid(self.gate(x))\n","#         h = x_filt * x_gate\n","#         h = self.dropout(h)\n","#         return h\n","\n","# class WaveBlock(nn.Module):\n","#     def __init__(self, n_layers: int, in_dim: int, h_dim: int, kernel_sizes: List[int]) -> None:\n","#         super().__init__()\n","#         self.dilation_rates = [2**i for i in range(n_layers)]\n","#         self.in_conv = nn.Conv1d(in_dim, h_dim, kernel_size=1)\n","#         self.gated_tcns = nn.ModuleList([\n","#             GatedTCN(h_dim, h_dim, kernel_sizes, dilation)\n","#             for dilation in self.dilation_rates\n","#         ])\n","#         self.skip_convs = nn.ModuleList([\n","#             nn.Conv1d(h_dim, h_dim, kernel_size=1)\n","#             for _ in range(n_layers)\n","#             ])\n","#         self._initialize_weights()\n","\n","#     def _initialize_weights(self):\n","#         nn.init.xavier_uniform_(self.in_conv.weight, gain=nn.init.calculate_gain('relu'))\n","#         nn.init.zeros_(self.in_conv.bias)\n","#         for conv in self.skip_convs:\n","#             nn.init.xavier_uniform_(conv.weight, gain=nn.init.calculate_gain('relu'))\n","#             nn.init.zeros_(conv.bias)\n","\n","#     def forward(self, x):\n","#         # x: (B, C, L)\n","#         x = self.in_conv(x)\n","#         x_skip = x\n","#         for gated_tcn, skip_conv in zip(self.gated_tcns, self.skip_convs):\n","#             x = gated_tcn(x)\n","#             x = skip_conv(x)\n","#             x_skip = x_skip + x\n","#         return x_skip\n","\n","# class DilatedWaveNet(nn.Module):\n","#     \"\"\"WaveNet architecture with dilated inception conv, enhanced with list comprehension for input processing.\"\"\"\n","\n","#     def __init__(self, kernel_sizes: List[int]) -> None:\n","#         super().__init__()\n","#         self.kernel_sizes = kernel_sizes\n","        \n","#         # Initialize wave blocks with specified kernel sizes\n","#         self.wave_module = nn.Sequential(\n","#             WaveBlock(9, 8, 128, self.kernel_sizes), #12\n","#             WaveBlock(6, 128, 256, self.kernel_sizes), #8\n","#             WaveBlock(3, 256, 512, self.kernel_sizes), #4\n","#             WaveBlock(1, 512, 512, self.kernel_sizes), #1\n","#         )\n","#         self.pool_layer = nn.AdaptiveAvgPool1d(1)\n","\n","#     def forward(self, x) -> torch.Tensor:\n","#         # x: (B, L, C)\n","#         bs, seq_len, n_channels = x.shape\n","#         x = x.permute(0, 2, 1) # -> (B, C, L)\n","#         # Process different parts of the input with list comprehension\n","#         x = self.wave_module(x)\n","#         x = self.pool_layer(x) # ->(B, 512, 1)\n","#         x = x.reshape(bs, n_channels, -1).reshape(bs, n_channels//2, 2, 64)\n","#         features = x.mean(dim=2).reshape(bs, -1) # -> (16, 256)\n","# #         pooled_outputs = [(x[:, i:i+64] + x[:, i+64:i+128]) / 2 for i in range(0, n_channels, 2)]\n","# #         # Combine the pooled features and reshape for classification\n","# #         features = torch.cat(pooled_outputs, dim=1).reshape(bs, -1)\n","       \n","#         return features"]},{"cell_type":"markdown","metadata":{},"source":["### Dilated ResNet 1D Encoder"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[],"source":["class ResnetBlock(nn.Module):\n","    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, dilation=1, dropout=0.0):\n","        super(ResnetBlock, self).__init__()\n","\n","        self.bn1 = nn.BatchNorm1d(in_channels)\n","        self.relu1 = nn.ReLU()\n","        self.conv1 = nn.Conv1d(\n","            in_channels, out_channels, kernel_size, \n","            stride=stride, \n","            padding=dilation*(kernel_size//2), \n","            dilation=dilation, \n","            bias=False)\n","        self.drop1 = nn.Dropout(p=dropout)\n","        self.bn2 = nn.BatchNorm1d(out_channels)\n","        self.relu2 = nn.ReLU()\n","        self.drop2 = nn.Dropout(p=dropout)\n","        self.conv2 = nn.Conv1d(\n","            out_channels, out_channels, kernel_size, \n","            stride=stride, \n","            padding=dilation*(kernel_size//2), \n","            dilation=dilation, \n","            bias=False)\n","        \n","        self.bn3 = nn.BatchNorm1d(out_channels)\n","        self.relu3 = nn.ReLU()\n","        self.downsample = nn.MaxPool1d(kernel_size=2, stride=2, padding=0)\n","\n","    def forward(self, x):\n","        identity = x\n","        identity = self.downsample(identity)\n","\n","        out = self.bn1(x)\n","        out = self.relu1(out)\n","        out = self.drop1(out)\n","        out = self.conv1(out)\n","\n","        out = self.bn2(out)\n","        out = self.relu2(out)\n","        out = self.drop2(out)\n","        out = self.conv2(out)\n","\n","        out = self.downsample(out)\n","\n","        out += identity\n","        out = self.bn3(out)\n","        out = self.relu3(out)\n","\n","        return out\n","\n","class DilatedResnet(nn.Module):\n","    def __init__(self, in_channels, out_channels, kernel_size, n_layers, expansion_factor=4):\n","        super(DilatedResnet, self).__init__()\n","\n","        self.in_channels = in_channels\n","        self.kernel_size = kernel_size\n","        self.h_dim = out_channels // n_layers\n","        \n","        fix_kernel_size = 5\n","        self.conv1 = nn.Conv1d(\n","            self.in_channels, self.h_dim, kernel_size=fix_kernel_size, stride=1, padding=fix_kernel_size//2\n","            )\n","\n","        dilation_rates = [expansion_factor**i for i in range(n_layers)]\n","\n","        self.blocks = nn.ModuleList([\n","            ResnetBlock(self.h_dim, self.h_dim, self.kernel_size, dilation=dilation)\n","            for dilation in dilation_rates\n","        ])\n","\n","    def forward(self, x):\n","        x = self.conv1(x)\n","        outputs = [ block(x) for block in self.blocks ]\n","        output = torch.cat(outputs, dim=1)\n","        \n","        return output\n","\n","class DilatedResnetEncoder(nn.Module):\n","    def __init__(self, kernel_sizes=[3, 5, 7, 9], in_channels=8, planes=24, dilate_layers=[6,3,1], expansion_factor=4):\n","        super(DilatedResnetEncoder, self).__init__()\n","\n","        self.in_channels = in_channels\n","        self.planes = planes\n","        self.kernel_sizes = kernel_sizes\n","        self.dilate_layers = dilate_layers # must be 3 layers\n","        self.expansion_factor = expansion_factor\n","\n","        # out_channels = self.planes * self.in_channels\n","        # fix_kernel_size = 5\n","        # self.conv1 = nn.Conv1d(\n","        #     self.in_channels, out_channels, kernel_size=fix_kernel_size, stride=1, padding=fix_kernel_size//2\n","        #     )\n","        \n","        self.blocks = nn.ModuleList([\n","            self._make_dilated_block(kernel_size)\n","            for kernel_size in self.kernel_sizes\n","        ])\n","\n","        bottleneck_in_channels = self.in_channels * self.planes * self.dilate_layers[1] * self.dilate_layers[2]\n","        bottoleneck_out_channels = self.in_channels * self.planes\n","        self.bottleneck = nn.Sequential(\n","            nn.BatchNorm1d(num_features=bottleneck_in_channels),\n","            nn.ReLU(),\n","            nn.Conv1d(\n","                in_channels=bottleneck_in_channels,\n","                out_channels=bottoleneck_out_channels,\n","                kernel_size=1,\n","                stride=1,\n","                padding=0,\n","                bias=False\n","            )\n","        )\n","        \n","        self.pooling = nn.AdaptiveAvgPool1d(1)\n","        # self.blocks = nn.ModuleList([\n","        #     nn.Sequential(*[\n","        #         ResidualBlock(\n","        #             out_channels, out_channels, kernel_size, dilation=dilation\n","        #         ) for dilation in self.dilate_layers\n","        #     ])\n","        #     for kernel_size in self.kernel_sizes\n","        # ])\n","\n","    def _make_dilated_block(self, kernel_size):\n","        out_channel_1 = self.in_channels * self.planes\n","        block_1 = DilatedResnet(self.in_channels, out_channel_1, kernel_size, self.dilate_layers[0], self.expansion_factor)\n","\n","        out_channel_2 = out_channel_1 * self.dilate_layers[1]\n","        block_2 = DilatedResnet(out_channel_1, out_channel_2, kernel_size, self.dilate_layers[1], self.expansion_factor)\n","\n","        out_channel_3 = out_channel_2 * self.dilate_layers[2]\n","        block_3 = DilatedResnet(out_channel_2, out_channel_3, kernel_size, self.dilate_layers[2], self.expansion_factor)\n","\n","        return nn.Sequential(block_1, block_2, block_3)\n","        \n","    \n","    def forward(self, x):\n","        # <- # [batch_size, seq_len=2000, in_channels=8]\n","        x = x.permute(0, 2, 1)\n","        # x = self.conv1(x)\n","        outputs = [ block(x) for block in self.blocks ]\n","        output = torch.cat(outputs, dim=1)\n","        output = self.bottleneck(output)\n","        output = self.pooling(output).squeeze(-1)\n","        \n","        return output"]},{"cell_type":"markdown","metadata":{},"source":["### EEGSeqClassifier "]},{"cell_type":"code","execution_count":20,"metadata":{"trusted":true},"outputs":[],"source":["class EEGSeqClassifier(nn.Module):\n","    def __init__(self, config, num_classes=6):\n","        super(EEGSeqClassifier, self).__init__()\n","\n","        # self.seqgru = SeqGRUEncoder(in_channels=8, hidden_size=128, num_layers=2, bidirectional=True)\n","        # self.resnet = ResNet_1D_Encoder(\n","        #     kernels=[3, 5, 7, 9, 11], \n","        #     planes=24, \n","        #     in_channels=8, \n","        #     fixed_kernel_size=5, \n","        #     n_blocks=8, \n","        #     dropout=0.0\n","        # )\n","        # self.wavenet = DilatedWaveNet(kernel_sizes=[2, 3, 6, 7])\n","        self.dilated_resnet = DilatedResnetEncoder(\n","            kernel_sizes=[3, 5, 7, 9], \n","            in_channels=8, \n","            planes=24, \n","            dilate_layers=[6,3,1], \n","            expansion_factor=4\n","        )\n","\n","        hidden_dim = 768 #72 + 256 #+ 256\n","        self.predict_head = nn.Linear(hidden_dim, num_classes)\n","\n","    def forward(self, x):\n","        # x shape: [batch, seq_len, in_channels]\n","\n","        # resnet_out = self.resnet(x)\n","        # seqgru_out = self.seqgru(x)\n","        # wavenet_out = self.wavenet(x)\n","        # features = torch.cat([seqgru_out, resnet_out], dim=1)\n","        features = self.dilated_resnet(x)\n","        logits = self.predict_head(features)\n","        return logits"]},{"cell_type":"code","execution_count":21,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["X shape: torch.Size([16, 2000, 8])\n","y shape: torch.Size([16, 6])\n"]},{"ename":"RuntimeError","evalue":"running_mean should contain 192 elements not 32","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","Cell \u001b[0;32mIn[21], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mX\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 13\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(y_pred\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mbreak\u001b[39;00m \n","File \u001b[0;32m~/miniconda3/envs/kaggle/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/miniconda3/envs/kaggle/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","Cell \u001b[0;32mIn[20], line 33\u001b[0m, in \u001b[0;36mEEGSeqClassifier.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;66;03m# x shape: [batch, seq_len, in_channels]\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;66;03m# wavenet_out = self.wavenet(x)\u001b[39;00m\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;66;03m# features = torch.cat([seqgru_out, resnet_out], dim=1)\u001b[39;00m\n\u001b[0;32m---> 33\u001b[0m     features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilated_resnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m     logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict_head(features)\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m logits\n","File \u001b[0;32m~/miniconda3/envs/kaggle/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/miniconda3/envs/kaggle/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","Cell \u001b[0;32mIn[19], line 140\u001b[0m, in \u001b[0;36mDilatedResnetEncoder.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    138\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    139\u001b[0m \u001b[38;5;66;03m# x = self.conv1(x)\u001b[39;00m\n\u001b[0;32m--> 140\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[43m \u001b[49m\u001b[43mblock\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mblock\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mblocks\u001b[49m\u001b[43m \u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    141\u001b[0m output \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat(outputs, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    142\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbottleneck(output)\n","Cell \u001b[0;32mIn[19], line 140\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    138\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    139\u001b[0m \u001b[38;5;66;03m# x = self.conv1(x)\u001b[39;00m\n\u001b[0;32m--> 140\u001b[0m outputs \u001b[38;5;241m=\u001b[39m [ \u001b[43mblock\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m block \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks ]\n\u001b[1;32m    141\u001b[0m output \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat(outputs, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    142\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbottleneck(output)\n","File \u001b[0;32m~/miniconda3/envs/kaggle/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/miniconda3/envs/kaggle/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m~/miniconda3/envs/kaggle/lib/python3.11/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n","File \u001b[0;32m~/miniconda3/envs/kaggle/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/miniconda3/envs/kaggle/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","Cell \u001b[0;32mIn[19], line 72\u001b[0m, in \u001b[0;36mDilatedResnet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m     71\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv1(x)\n\u001b[0;32m---> 72\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[43m \u001b[49m\u001b[43mblock\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mblock\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mblocks\u001b[49m\u001b[43m \u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     73\u001b[0m     output \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat(outputs, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output\n","Cell \u001b[0;32mIn[19], line 72\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m     71\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv1(x)\n\u001b[0;32m---> 72\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m [ \u001b[43mblock\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m block \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks ]\n\u001b[1;32m     73\u001b[0m     output \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat(outputs, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output\n","File \u001b[0;32m~/miniconda3/envs/kaggle/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/miniconda3/envs/kaggle/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","Cell \u001b[0;32mIn[19], line 32\u001b[0m, in \u001b[0;36mResnetBlock.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     29\u001b[0m identity \u001b[38;5;241m=\u001b[39m x\n\u001b[1;32m     30\u001b[0m identity \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdownsample(identity)\n\u001b[0;32m---> 32\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbn1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu1(out)\n\u001b[1;32m     34\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdrop1(out)\n","File \u001b[0;32m~/miniconda3/envs/kaggle/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/miniconda3/envs/kaggle/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m~/miniconda3/envs/kaggle/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py:175\u001b[0m, in \u001b[0;36m_BatchNorm.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    168\u001b[0m     bn_training \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_mean \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_var \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    170\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;124;03mBuffers are only updated if they are to be tracked and we are in training mode. Thus they only need to be\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;124;03mpassed when the update should occur (i.e. in training mode when they are tracked), or when buffer stats are\u001b[39;00m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;124;03mused for normalization (i.e. in eval mode when buffers are not None).\u001b[39;00m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 175\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# If buffers are not to be tracked, ensure that they won't be updated\u001b[39;49;00m\n\u001b[1;32m    178\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunning_mean\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack_running_stats\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    181\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunning_var\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack_running_stats\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    183\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    184\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbn_training\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    185\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexponential_average_factor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    186\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    187\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/miniconda3/envs/kaggle/lib/python3.11/site-packages/torch/nn/functional.py:2482\u001b[0m, in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   2479\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m training:\n\u001b[1;32m   2480\u001b[0m     _verify_batch_size(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize())\n\u001b[0;32m-> 2482\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2483\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrunning_mean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrunning_var\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmomentum\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackends\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcudnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menabled\u001b[49m\n\u001b[1;32m   2484\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[0;31mRuntimeError\u001b[0m: running_mean should contain 192 elements not 32"]}],"source":["train_dataset = EEGSeqDataset(train_all, ModelConfig, ALL_EEG_SIGNALS, mode=\"train\")\n","train_loader = DataLoader(train_dataset, drop_last=True, batch_size=16, num_workers=4, pin_memory=True, shuffle=False)\n","\n","model = EEGSeqClassifier(ModelConfig, num_classes=6)\n","model.to(DEVICE)\n","for i, batch in enumerate(train_loader):\n","    X, y = batch\n","    X = X.to(DEVICE)\n","    y = y.to(DEVICE)\n","    print(f\"X shape: {X.shape}\")\n","    print(f\"y shape: {y.shape}\")\n","    \n","    y_pred = model(X)\n","    print(y_pred.shape)\n","    break \n","\n","del model, train_dataset, train_loader, X, y\n","torch.cuda.empty_cache()\n","gc.collect()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["!nvidia-smi"]},{"cell_type":"markdown","metadata":{},"source":["# Train"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","class AverageMeter(object):\n","    \"\"\"Computes and stores the average and current value\"\"\"\n","\n","    def __init__(self):\n","        self.reset()\n","\n","    def reset(self):\n","        self.val = 0\n","        self.avg = 0\n","        self.sum = 0\n","        self.count = 0\n","\n","    def update(self, val, n=1):\n","        self.val = val\n","        self.sum += val * n\n","        self.count += n\n","        self.avg = self.sum / self.count\n","        \n","class Trainer:\n","\n","    def __init__(self, model, config, logger):\n","\n","        self.model = model\n","        self.logger = logger\n","        self.config = config\n","        \n","        self.early_stop_rounds = config.EARLY_STOP_ROUNDS\n","        self.early_stop_counter = 0\n","        \n","        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","        self.criterion = nn.KLDivLoss(reduction=\"batchmean\")\n","\n","    def train(self, train_loader, valid_loader, from_checkpoint=None):\n","\n","        self.optimizer = AdamW(self.model.parameters(), lr=1e-3, weight_decay=self.config.WEIGHT_DECAY)\n","\n","        self.scheduler = OneCycleLR(\n","            self.optimizer,\n","            max_lr=1e-4,\n","            epochs=self.config.EPOCHS,\n","            steps_per_epoch=len(train_loader),\n","            pct_start=0.1,\n","            anneal_strategy=\"cos\",\n","            final_div_factor=100,\n","        )\n","\n","        if from_checkpoint is not None:\n","            self.model.load_state_dict(torch.load(from_checkpoint, map_location=self.device))\n","\n","        self.model.to(self.device)\n","        best_weights, best_preds, best_loss = None, None, float(\"inf\")\n","        loss_records = {\"train\": [], \"valid\": []}\n","\n","        for epoch in range(self.config.EPOCHS):\n","            start_epoch = time()\n","\n","            train_loss, _ = self._train_or_valid_epoch(epoch, train_loader, is_train=True)\n","            valid_loss, valid_preds = self._train_or_valid_epoch(epoch, valid_loader, is_train=False)\n","\n","            loss_records[\"train\"].append(train_loss)\n","            loss_records[\"valid\"].append(valid_loss)\n","\n","            elapsed = time() - start_epoch\n","\n","            info = f\"{'-' * 100}\\nEpoch {epoch + 1} - \"\n","            info += f\"Average Loss: (train) {train_loss:.4f}; (valid) {valid_loss:.4f} | Time: {elapsed:.2f}s\"\n","            self.logger.info(info)\n","\n","            if valid_loss < best_loss:\n","                best_loss = valid_loss\n","                best_weights = self.model.state_dict()\n","                best_preds = valid_preds\n","                self.logger.info(f\"Best model found in epoch {epoch + 1} | valid loss: {best_loss:.4f}\")\n","                self.early_stop_counter = 0\n","            \n","            else:\n","                self.early_stop_counter += 1\n","                if self.early_stop_counter >= self.early_stop_rounds:\n","                    self.logger.info(f\"Early stopping at epoch {epoch + 1}\")\n","                    break\n","\n","        return best_weights, best_preds, loss_records\n","\n","    def _train_or_valid_epoch(self, epoch_id, dataloader, is_train=True):\n","\n","        self.model.train() if is_train else self.model.eval()\n","        mode = \"Train\" if is_train else \"Valid\"\n","\n","        len_loader = len(dataloader)\n","        scaler = GradScaler(enabled=self.config.AMP)\n","        loss_meter, predicts_record = AverageMeter(), []\n","\n","        start = time()\n","        pbar = tqdm(dataloader, total=len(dataloader), unit=\"batch\", desc=f\"{mode} [{epoch_id}]\")\n","        for step, (X, y) in enumerate(pbar):\n","            X, y = X.to(self.device), y.to(self.device)\n","\n","            if is_train:\n","                with autocast(enabled=self.config.AMP):\n","                    y_pred = self.model(X)\n","                    loss = self.criterion(F.log_softmax(y_pred, dim=1), y)\n","                if self.config.GRADIENT_ACCUMULATION_STEPS > 1:\n","                    loss = loss / self.config.GRADIENT_ACCUMULATION_STEPS\n","                scaler.scale(loss).backward()\n","                grad_norm = torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.config.MAX_GRAD_NORM)\n","                if (step + 1) % self.config.GRADIENT_ACCUMULATION_STEPS == 0:\n","                    scaler.step(self.optimizer)\n","                    scaler.update()\n","                    self.optimizer.zero_grad()\n","                    self.scheduler.step()\n","            else:\n","                with torch.no_grad():\n","                    y_pred = self.model(X)\n","                    loss = self.criterion(F.log_softmax(y_pred, dim=1), y)\n","                if self.config.GRADIENT_ACCUMULATION_STEPS > 1:\n","                    loss = loss / self.config.GRADIENT_ACCUMULATION_STEPS\n","                \n","                predicts_record.append(y_pred.to('cpu').numpy())\n","            \n","            loss_meter.update(loss.item(), y.size(0))\n","            end = time()\n","\n","            if (step % self.config.PRINT_FREQ == 0) or (step == (len_loader - 1)):\n","                lr = self.scheduler.get_last_lr()[0]\n","                info = f\"Epoch {epoch_id + 1} [{step}/{len_loader}] | {mode} Loss: {loss_meter.avg:.4f}\"\n","                if is_train:\n","                    info += f\" Grad: {grad_norm:.4f} LR: {lr:.4e}\"\n","                info += f\" | Elapse: {end - start:.2f}s\"\n","                print(info)\n","\n","        if not is_train:\n","            predicts_record = np.concatenate(predicts_record)\n","            \n","        return loss_meter.avg, predicts_record\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def train_fold(model, fold_id, train_folds, valid_folds, logger, stage=1, checkpoint=None):\n","\n","    train_dataset = EEGSeqDataset(train_folds, ModelConfig, ALL_EEG_SIGNALS, mode=\"train\")\n","    valid_dataset = EEGSeqDataset(valid_folds, ModelConfig, ALL_EEG_SIGNALS, mode=\"valid\")\n","\n","    # ======== DATALOADERS ==========\n","    loader_kwargs = {\n","        \"batch_size\": ModelConfig.BATCH_SIZE,\n","        \"num_workers\": ModelConfig.NUM_WORKERS,\n","        \"pin_memory\": True,\n","        \"shuffle\": False,\n","    }\n","\n","    train_loader = DataLoader(train_dataset, drop_last=True, collate_fn=None, **loader_kwargs)\n","    valid_loader = DataLoader(valid_dataset, drop_last=False, collate_fn=None, **loader_kwargs)\n","\n","    trainer = Trainer(model, ModelConfig, logger)\n","    best_weights, best_preds, loss_records = trainer.train(\n","        train_loader, valid_loader, from_checkpoint=checkpoint)\n","\n","    save_model_name = f\"{ModelConfig.MODEL_NAME}_fold_{fold_id}_stage_{stage}.pth\"\n","    torch.save(best_weights, os.path.join(PATHS.OUTPUT_DIR, save_model_name))\n","\n","    del train_dataset, valid_dataset, train_loader, valid_loader\n","    torch.cuda.empty_cache()\n","    gc.collect()\n","\n","    return best_preds, loss_records"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def evaluate_oof(oof_df):\n","    '''\n","    Evaluate the out-of-fold dataframe using KL Divergence (torch and kaggle)\n","    '''\n","    kl_loss = nn.KLDivLoss(reduction=\"batchmean\")\n","    labels = torch.tensor(oof_df[TARGETS].values.astype('float32'))\n","    preds = F.log_softmax(\n","        torch.tensor(oof_df[TARGETS_PRED].values.astype('float32'), requires_grad=False),\n","        dim=1\n","    )\n","    kl_torch = kl_loss(preds, labels).item()\n","\n","    return kl_torch"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Major Train Loop\n","# ================== Logger ==================\n","logger.info(f\"{'*' * 100}\")\n","logger.info(f\"Script Start: {ctime()}\")\n","logger.info(f\"Model Configurations:\")\n","for key, value in ModelConfig.__dict__.items():\n","    if not key.startswith(\"__\"):\n","        logger.info(f\"{key}: {value}\")\n","logger.info(f\"{'*' * 100}\")\n","\n","# ================== Prepare Training ==================\n","oof_stage_1 = pd.DataFrame()\n","loss_history_1 = []\n","tik_total = time()\n","\n","# ================== Stage 1: Train ====================\n","logger.info(f\"{'=' * 100}\\nStage 1: Train ResNetGRU\\n{'=' * 100}\")\n","for fold in range(K_FOLDS):\n","    tik = time()\n","\n","    ModelConfig.RESNET_GRU_DROPOUT = 0.0\n","\n","    # model = ResNetGRU( ModelConfig, num_classes=6 )\n","    model = EEGSeqClassifier(ModelConfig, num_classes=6)\n","    \n","    valid_folds = train_all[train_all['fold'] == fold].reset_index(drop=True)\n","    train_folds = train_all[train_all['fold'] != fold].reset_index(drop=True)\n","\n","    ## STAGE 1\n","    logger.info(f\"{'=' * 100}\\nFold: {fold} || Valid: {valid_folds.shape[0]}; \\n{'=' * 100}\")\n","    logger.info(f\"- Train: {train_folds.shape[0]}; Epoch = {ModelConfig.EPOCHS}; Dropout = {ModelConfig.RESNET_GRU_DROPOUT} -\")\n","    valid_predicts, loss_records = train_fold(\n","        model, fold, train_folds, valid_folds, logger, stage=1, checkpoint=None)\n","\n","    loss_history_1.append(loss_records)\n","    valid_folds[TARGETS_PRED] = valid_predicts\n","    oof_stage_1 = pd.concat([oof_stage_1, valid_folds], axis=0).reset_index(drop=True)\n","    kl_loss_torch = evaluate_oof(valid_folds)\n","    info = f\"{'=' * 100}\\nFold {fold} Valid Loss: {kl_loss_torch}\\n\"\n","    info += f\"Elapse: {(time() - tik) / 60:.2f} min \\n{'=' * 100}\"\n","    logger.info(info)\n","    oof_stage_1.to_csv(os.path.join(PATHS.OUTPUT_DIR, f\"{ModelConfig.MODEL_NAME}_oof_1.csv\"), index=False)\n","\n","info = f\"{'=' * 100}\\nStage 1 Training Complete!\\n\"\n","cv_results = evaluate_oof(oof_stage_1)\n","info += f\"CV Result (Stage 1): {cv_results}\\n\"\n","info += f\"Elapse: {(time() - tik_total) / 60:.2f} min \\n{'=' * 100}\"\n","logger.info(info)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# plot loss history\n","fig, ax = plt.subplots(1, 1, figsize=(8, 5))\n","for i, loss in enumerate(loss_history_1):\n","    ax.plot(loss['train'], marker=\"*\", ls=\"-\", label=f\"Fold {i} Train\")\n","    ax.plot(loss['valid'], marker=\"o\", ls=\":\", label=f\"Fold {i} Valid\")\n","\n","ax.grid()\n","fig.tight_layout()\n","plt.legend()\n","fig.savefig(Path(PATHS.OUTPUT_DIR) / f\"{ModelConfig.MODEL_NAME}_stage_1_loss.png\")\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# tmp = train_all[(train_all['fold'] != fold) & (train_all['is_stage']==2)] \n","# print(len(tmp))\n","# print(tmp['target'].value_counts())\n","# other_drop = tmp[tmp['target']=='Other'].sample(frac=0.4)\n","# tmp = tmp.drop(other_drop.index)\n","# print(len(tmp))\n","# print(tmp['target'].value_counts())"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["## STAGE 2\n","# ================== Prepare Training ==================\n","oof_stage_2 = pd.DataFrame()\n","loss_history_2 = []\n","tik_total = time()\n","\n","# ================== Stage 2: Train ====================\n","logger.info(f\"{'=' * 100}\\nStage 2: Train ResNetGRU\\n{'=' * 100}\")\n","for fold in range(K_FOLDS):\n","    tik = time()\n","    \n","    ModelConfig.EARLY_STOP_ROUNDS = 3\n","    ModelConfig.RESNET_GRU_DROPOUT = 0.0\n","\n","    train_folds = train_all[(train_all['fold'] != fold) & (train_all['is_stage']==2)].reset_index(drop=True)\n","    valid_folds = train_all[(train_all['fold'] == fold) & (train_all['is_stage']==2)].reset_index(drop=True)\n","    \n","    # randomly drop half of the samples within 'Other' class (fix imbalance)\n","    # other_drop = train_folds[train_folds['target']=='Other'].sample(frac=0.5)\n","    # train_folds = train_folds.drop(other_drop.index)\n","    \n","    logger.info(f\"- Hard: {train_folds.shape[0]}; Epoch: {ModelConfig.EPOCHS}; Dropout: {ModelConfig.RESNET_GRU_DROPOUT} -\")\n","    logger.info(f\"Leakage: {train_folds['eeg_id'].isin(valid_folds['eeg_id']).sum()}\")\n","    \n","    check_point = os.path.join(\n","        PATHS.OUTPUT_DIR,\n","        f\"{ModelConfig.MODEL_NAME}_fold_{fold}_stage_1.pth\"\n","    )\n","    logger.info(f\"Use Checkpoint: {check_point.split('/')[-1]}\")\n","\n","    model = EEGSeqClassifier(ModelConfig, num_classes=6)\n","\n","    valid_predicts, loss_records = train_fold(\n","        model, fold, train_folds, valid_folds, logger, stage=2, checkpoint=check_point)\n","\n","    loss_history_2.append(loss_records)\n","    valid_folds[TARGETS_PRED] = valid_predicts\n","    oof_stage_2 = pd.concat([oof_stage_2, valid_folds], axis=0).reset_index(drop=True)\n","    kl_loss_torch = evaluate_oof(valid_folds)\n","    info = f\"{'=' * 100}\\nFold {fold} Valid Loss: {kl_loss_torch}\\n\"\n","    info += f\"Elapse: {(time() - tik) / 60:.2f} min \\n{'=' * 100}\"\n","    logger.info(info)\n","    oof_stage_2.to_csv(os.path.join(PATHS.OUTPUT_DIR, f\"{ModelConfig.MODEL_NAME}_oof_2.csv\"), index=False)\n","\n","info = f\"{'=' * 100}\\nStage 2 Training Complete!\\n\"\n","cv_results = evaluate_oof(oof_stage_2)\n","info += f\"CV Result (Stage 2): {cv_results}\\n\"\n","info += f\"Elapse: {(time() - tik_total) / 60:.2f} min \\n{'=' * 100}\"\n","logger.info(info)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# plot loss history\n","fig, ax = plt.subplots(1, 1, figsize=(8, 5))\n","for i, loss in enumerate(loss_history_2):\n","    ax.plot(loss['train'], marker=\"*\", ls=\"-\", label=f\"Fold {i} Train\")\n","    ax.plot(loss['valid'], marker=\"o\", ls=\":\", label=f\"Fold {i} Valid\")\n","\n","ax.grid()\n","fig.tight_layout()\n","plt.legend()\n","fig.savefig(Path(PATHS.OUTPUT_DIR) / f\"{ModelConfig.MODEL_NAME}_stage_2_loss.png\")\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["oof_stage_2_full = pd.DataFrame()\n","\n","for fold in range(5):\n","\n","    valid_folds = train_all[train_all['fold'] == fold].reset_index(drop=True)\n","\n","    # predict labels using stage-2 models\n","    model = EEGSeqClassifier(ModelConfig, num_classes=6)\n","    check_point = os.path.join(\n","        PATHS.OUTPUT_DIR,\n","        f\"{ModelConfig.MODEL_NAME}_fold_{fold}_stage_2.pth\"\n","    )\n","\n","    model.load_state_dict(torch.load(check_point, map_location=DEVICE))\n","\n","    loader_kwargs = {\n","        \"batch_size\": ModelConfig.BATCH_SIZE,\n","        \"num_workers\": ModelConfig.NUM_WORKERS,\n","        \"pin_memory\": True,\n","        \"shuffle\": False,\n","    }\n","\n","    valid_dataset = EEGSeqDataset(valid_folds, ModelConfig, ALL_EEG_SIGNALS, mode=\"valid\")\n","    valid_loader = DataLoader(valid_dataset, drop_last=False, collate_fn=None, **loader_kwargs)\n","\n","    model.to(DEVICE)\n","    model.eval()\n","\n","    valid_predicts = []\n","    with torch.no_grad():\n","        for X, y in valid_loader:\n","            X = X.to(DEVICE)\n","            y_pred = model(X)\n","            valid_predicts.append(y_pred.to('cpu').numpy())\n","\n","    valid_predicts = np.concatenate(valid_predicts)\n","    valid_folds[TARGETS_PRED] = valid_predicts\n","    oof_stage_2_full = pd.concat([oof_stage_2, valid_folds], axis=0).reset_index(drop=True)\n","\n","    del valid_dataset, valid_loader\n","    torch.cuda.empty_cache()\n","    gc.collect()\n","\n","    oof_stage_2_full.to_csv(os.path.join(PATHS.OUTPUT_DIR, f\"{ModelConfig.MODEL_NAME}_oof_2_full.csv\"), index=False)\n","\n","cv_results = evaluate_oof(oof_stage_2_full)\n","logger.info(f\"{'=' * 100}\\nCV Result (Stage 2 Full): {cv_results}\\n{'=' * 100}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from kl_divergence import score as kaggle_score \n","from sklearn.metrics import confusion_matrix\n","import seaborn as sns\n","\n","TARGET2ID = {'Seizure': 0, 'LPD': 1, 'GPD': 2, 'LRDA': 3, 'GRDA': 4, 'Other': 5}\n","\n","def calc_kaggle_score(oof_df):\n","    submission_df = oof_df[['eeg_id']+TARGETS_PRED].copy()\n","    submission_df.columns = ['eeg_id'] + TARGETS\n","    solution_df = oof_df[['eeg_id']+TARGETS].copy()\n","    return kaggle_score(solution_df, submission_df, 'eeg_id')\n","\n","def analyze_oof(oof_csv):\n","\n","    kl_criteria = nn.KLDivLoss(reduction='batchmean')\n","    softmax = nn.Softmax(dim=1)\n","\n","    oof_df = pd.read_csv(oof_csv)\n","    oof_df['target_pred'] = oof_df[TARGETS_PRED].apply(lambda x: np.argmax(x), axis=1)\n","    oof_df['target_id'] = oof_df[TARGETS].apply(lambda x: np.argmax(x), axis=1)\n","    \n","    oof_df[\"kl_loss\"] = oof_df.apply(\n","    lambda row: \n","        kl_criteria(\n","            F.log_softmax(\n","                    torch.tensor(row[TARGETS_PRED].values.astype(np.float32)).unsqueeze(0)\n","                , dim=1\n","                ), \n","            torch.tensor(row[TARGETS].values.astype(np.float32))\n","            ).numpy(),\n","    axis=1)\n","\n","    oof_df[\"kl_loss\"] = oof_df['kl_loss'].astype(np.float32)\n","\n","    oof_df[TARGETS_PRED] = softmax( torch.tensor(oof_df[TARGETS_PRED].values.astype(np.float32)) )\n","\n","    oof_df.head()\n","\n","    return oof_df"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["csv_path = f'./outputs/{ModelConfig.MODEL_NAME}_oof_1.csv'\n","print(\"CSV Path: \", csv_path)\n","\n","oof_df = analyze_oof(csv_path)\n","\n","print(\"Kaggle Score: \", calc_kaggle_score(oof_df))\n","print(\"Average KL Loss: \", oof_df[\"kl_loss\"].mean())\n","\n","display(oof_df.head())\n","\n","# plot confusion matrix\n","cm = confusion_matrix(oof_df['target_id'], oof_df['target_pred']) # (y_true, y_pred)\n","cm = cm / cm.sum(axis=1)[:, np.newaxis]\n","\n","fig = plt.figure(figsize=(6, 6))\n","sns.heatmap(cm, annot=True, cmap='Blues', xticklabels=TARGET2ID.keys(), yticklabels=TARGET2ID.keys())\n","plt.xlabel('Predicted', fontsize=12)\n","plt.ylabel('True', fontsize=12)\n","plt.title(csv_path.split('/')[-1].split('.')[0], fontsize=12)\n","fig.tight_layout()\n","fig.savefig(f\"./outputs/{csv_path.split('/')[-1].split('.')[0]}_CM.png\")\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["csv_path = f'./outputs/EEGSeq_Dilated_ResNet_Resplit_oof_1_full.csv'\n","print(\"CSV Path: \", csv_path)\n","\n","oof_df = analyze_oof(csv_path)\n","\n","print(\"Kaggle Score: \", calc_kaggle_score(oof_df))\n","print(\"Average KL Loss: \", oof_df[\"kl_loss\"].mean())\n","\n","display(oof_df.head())\n","\n","# plot confusion matrix\n","cm = confusion_matrix(oof_df['target_id'], oof_df['target_pred']) # (y_true, y_pred)\n","cm = cm / cm.sum(axis=1)[:, np.newaxis]\n","\n","fig = plt.figure(figsize=(6, 6))\n","sns.heatmap(cm, annot=True, cmap='Blues', xticklabels=TARGET2ID.keys(), yticklabels=TARGET2ID.keys())\n","plt.xlabel('Predicted', fontsize=12)\n","plt.ylabel('True', fontsize=12)\n","plt.title(csv_path.split('/')[-1].split('.')[0], fontsize=12)\n","fig.tight_layout()\n","fig.savefig(f\"./outputs/{csv_path.split('/')[-1].split('.')[0]}_CM.png\")\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"databundleVersionId":7469972,"sourceId":59093,"sourceType":"competition"},{"sourceId":165461612,"sourceType":"kernelVersion"},{"sourceId":168718625,"sourceType":"kernelVersion"}],"dockerImageVersionId":30673,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.6"}},"nbformat":4,"nbformat_minor":4}
