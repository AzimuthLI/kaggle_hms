{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"trusted":true},"outputs":[],"source":["import os, gc, random\n","import numpy as np\n","import pandas as pd \n","from pathlib import Path\n","import matplotlib.pyplot as plt\n","from typing import List, Dict\n","from tqdm.notebook import tqdm\n","from time import time, ctime\n","\n","from sklearn.model_selection import KFold, GroupKFold\n","\n","import torch\n","from torch import nn\n","from torch.nn import functional as F\n","from torch.utils.data import DataLoader, Dataset\n","from torchvision.transforms import v2\n","from torch.optim.lr_scheduler import OneCycleLR,  CosineAnnealingWarmRestarts\n","from torch.optim import Adam, AdamW\n","from torch.cuda.amp import autocast, GradScaler\n","\n","from scipy.signal import butter, lfilter, freqz\n","from scipy.stats import entropy\n","from scipy.special import rel_entr, softmax"]},{"cell_type":"code","execution_count":2,"metadata":{"trusted":true},"outputs":[],"source":["def get_logger(log_dir, logger_name=\"train_model.log\"):\n","    from logging import getLogger, INFO, StreamHandler, FileHandler, Formatter\n","    logger_file = os.path.join(log_dir, logger_name)\n","    logger = getLogger(__name__)\n","    logger.setLevel(INFO)\n","    handler1 = StreamHandler()\n","    handler1.setFormatter(Formatter(\"%(message)s\"))\n","    handler2 = FileHandler(filename=logger_file, mode=\"a+\")\n","    handler2.setFormatter(Formatter(\"%(message)s\"))\n","    logger.addHandler(handler1)\n","    logger.addHandler(handler2)\n","    return logger\n","\n","\n","def seed_everything(seed: int):\n","    random.seed(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)"]},{"cell_type":"code","execution_count":3,"metadata":{"trusted":true},"outputs":[],"source":["class ModelConfig:\n","    SEED = 20\n","    SPLIT_ENTROPY = 5.5\n","    MODEL_NAME = \"ResnetGRU_v1_LB048\"\n","    MODEL_BACKBONE = \"reset_gru\"\n","    BATCH_SIZE = 32\n","    EPOCHS = 20\n","    EARLY_STOP_ROUNDS = 5\n","    GRADIENT_ACCUMULATION_STEPS = 1\n","    DROP_RATE = 0.15 # default: 0.1\n","    DROP_PATH_RATE = 0.25 # default: 0.2\n","    WEIGHT_DECAY = 0.01\n","    AMP = True\n","    PRINT_FREQ = 100\n","    NUM_WORKERS = 0 \n","    MAX_GRAD_NORM = 1e7\n","    REGULARIZATION = 0.15\n","    RESNET_GRU_BANDPASS = None #(0.5, 20)\n","    RESNET_GRU_IN_CHANNELS = 8\n","    RESNET_GRU_KERNELS = [3, 5, 7, 9, 11]\n","    RESNET_GRU_FIXED_KERNEL_SIZE = 5\n","    RESNET_GRU_DOWNSAMPLE = 5 # None #5\n","    RESNET_GRU_HIDDEN_SIZE = 304 #448 #304\n","    RESNET_GRU_DILATED = False"]},{"cell_type":"code","execution_count":4,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Use Device:  cuda:0\n"]}],"source":["N_GPU = torch.cuda.device_count()\n","if N_GPU > 1:\n","    DEVICE = torch.device(\"cuda\")\n","    os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1\"\n","elif N_GPU == 1:\n","    DEVICE = torch.device(\"cuda:0\")\n","else:\n","    DEVICE = torch.device(\"cpu\")\n","\n","print(\"Use Device: \", DEVICE)"]},{"cell_type":"code","execution_count":5,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Output Dir:  ./outputs/\n","{'Fp1': 0, 'T3': 1, 'C3': 2, 'O1': 3, 'Fp2': 4, 'C4': 5, 'T4': 6, 'O2': 7}\n"]}],"source":["class KagglePaths:\n","    OUTPUT_DIR = \"/kaggle/working/\"\n","    PRE_LOADED_EEGS = '/kaggle/input/brain-eeg-spectrograms/eeg_specs.npy'\n","    PRE_LOADED_SPECTROGRAMS = '/kaggle/input/brain-spectrograms/specs.npy'\n","    TRAIN_CSV = \"/kaggle/input/hms-harmful-brain-activity-classification/train.csv\"\n","    TRAIN_EEGS = \"/kaggle/input/hms-harmful-brain-activity-classification/train_eegs/\"\n","    TRAIN_SPECTROGRAMS = \"/kaggle/input/hms-harmful-brain-activity-classification/train_spectrograms/\"\n","    TEST_CSV = \"/kaggle/input/hms-harmful-brain-activity-classification/test.csv\"\n","    TEST_SPECTROGRAMS = \"/kaggle/input/hms-harmful-brain-activity-classification/test_spectrograms/\"\n","    TEST_EEGS = \"/kaggle/input/hms-harmful-brain-activity-classification/test_eegs/\"\n","\n","\n","class LocalPaths:\n","    OUTPUT_DIR = \"./outputs/\"\n","    PRE_LOADED_EEGS = './inputs/brain-eeg-spectrograms/eeg_specs.npy'\n","    PRE_LOADED_SPECTROGRAMS = './inputs/brain-spectrograms/specs.npy'\n","    TRAIN_CSV = \"./inputs/hms-harmful-brain-activity-classification/train.csv\"\n","    TRAIN_EEGS = \"./inputs/hms-harmful-brain-activity-classification/train_eegs\"\n","    TRAIN_SPECTROGRAMS = \"./inputs/hms-harmful-brain-activity-classification/train_spectrograms\"\n","    TEST_CSV = \"./inputs/hms-harmful-brain-activity-classification/test.csv\"\n","    TEST_SPECTROGRAMS = \"./inputs/hms-harmful-brain-activity-classification/test_spectrograms\"\n","    TEST_EEGS = \"./inputs/hms-harmful-brain-activity-classification/test_eegs\"\n","\n","PATHS = KagglePaths if os.path.exists(\"/kaggle\") else LocalPaths\n","\n","print(\"Output Dir: \", PATHS.OUTPUT_DIR)\n","\n","EEG_FEAT_ALL = [\n","    'Fp1', 'F3', 'C3', 'P3', \n","    'F7', 'T3', 'T5', 'O1', \n","    'Fz', 'Cz', 'Pz', 'Fp2', \n","    'F4', 'C4', 'P4', 'F8', \n","    'T4', 'T6', 'O2', 'EKG'\n","    ]\n","\n","EEG_FEAT_USE =  ['Fp1','T3','C3','O1','Fp2','C4','T4','O2']\n","EEG_FEAT_INDEX = {x:y for x,y in zip(EEG_FEAT_USE, range(len(EEG_FEAT_USE)))}\n","\n","BRAIN_ACTIVITY = ['seizure', 'lpd', 'gpd', 'lrda', 'grda', 'other']\n","TARGETS = [f\"{lb}_vote\" for lb in BRAIN_ACTIVITY]\n","TARGETS_PRED = [f\"{lb}_pred\" for lb in BRAIN_ACTIVITY]\n","\n","seed_everything(ModelConfig.SEED)\n","\n","print(EEG_FEAT_INDEX)"]},{"cell_type":"code","execution_count":6,"metadata":{"trusted":true},"outputs":[],"source":["logger = get_logger(PATHS.OUTPUT_DIR, f\"{ModelConfig.MODEL_NAME}_train.log\")"]},{"cell_type":"markdown","metadata":{},"source":["# Load Data"]},{"cell_type":"code","execution_count":7,"metadata":{"trusted":true},"outputs":[],"source":["def eeg_from_parquet(parquet_path: str, use_feature=EEG_FEAT_USE, display: bool = False) -> np.ndarray:\n","    # === Extract full length EEG Sequence ===\n","    # fill missing values with mean\n","    # first fill missing values with mean of each column\n","    # then if all values are missing, fill with 0\n","    eeg = pd.read_parquet(parquet_path, columns=use_feature)\n","    eeg = eeg.fillna(eeg.mean(skipna=True)).fillna(0)\n","    data = eeg.values.astype(np.float32)\n","    \n","    rows = len(eeg)\n","    offset = (rows - 10_000) // 2 # 50 * 200 = 10_000\n","    data = data[offset:offset+10_000, :]\n","\n","    if display:\n","        fig, ax = plt.subplots(len(use_feature), 1, figsize=(10, 2*len(use_feature)), sharex=True)\n","        \n","        for i, feat in enumerate(use_feature):\n","            ax[i].plot(data[:, i], label=feat)\n","            ax[i].legend()\n","            ax[i].grid()\n","       \n","        name = parquet_path.split('/')[-1].split('.')[0]\n","        ax[0].set_title(f'EEG {name}',size=16)\n","        fig.tight_layout()\n","        plt.show()    \n","    return data"]},{"cell_type":"code","execution_count":8,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["CPU times: user 178 ms, sys: 1.27 s, total: 1.45 s\n","Wall time: 1.45 s\n"]}],"source":["%%time\n","CREATE_EEGS = False\n","ALL_EEG_SIGNALS = {}\n","eeg_paths = list(Path(PATHS.TRAIN_EEGS).glob('*.parquet'))\n","preload_eegs_path = Path('./inputs/eegs_full.npy')\n","\n","if CREATE_EEGS:\n","    count = 0\n","    for parquet_path in tqdm(eeg_paths, total=len(eeg_paths)):\n","        eeg_id = int(parquet_path.stem)\n","        eeg_path = str(parquet_path)\n","        data = eeg_from_parquet(eeg_path, display=False)\n","        ALL_EEG_SIGNALS[eeg_id] = data\n","        count += 1\n","    np.save(\"./inputs/eegs_full.npy\", ALL_EEG_SIGNALS)\n","else:\n","    ALL_EEG_SIGNALS = np.load(preload_eegs_path, allow_pickle=True).item()"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["def gen_non_overlap_samples(df_csv, targets):\n","    # Reference Discussion:\n","    # https://www.kaggle.com/competitions/hms-harmful-brain-activity-classification/discussion/467021\n","\n","    tgt_list = targets.tolist()\n","    brain_activity = ['seizure', 'lpd', 'gpd', 'lrda', 'grda', 'other']\n","\n","    agg_dict = {\n","        'spectrogram_id': 'first',\n","        'spectrogram_label_offset_seconds': ['min', 'max'],\n","        'patient_id': 'first',\n","        'expert_consensus': 'first'\n","    }\n","\n","    groupby = df_csv.groupby(['eeg_id'] + tgt_list)\n","    train = groupby.agg(agg_dict)\n","    train = train.reset_index()\n","    train.columns = ['_'.join(col).strip() for col in train.columns.values]\n","    train.columns = [\"eeg_id\"] + tgt_list + ['spectrogram_id', 'min', 'max', 'patient_id', 'target']\n","    \n","    train['total_votes'] = train[tgt_list].sum(axis=1)\n","    train[tgt_list] = train[tgt_list].div(train['total_votes'], axis=0)\n","    \n","    return train"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["# # Enhanced Samples Split \n","\n","# train_csv = pd.read_csv(PATHS.TRAIN_CSV)\n","# targets = train_csv.columns[-6:].tolist()\n","\n","# raw_csv_len = len(train_csv)\n","\n","# subset_counts = train_csv.groupby(['eeg_id']+targets).size().reset_index(name='subset_counts')\n","# train_csv = train_csv.merge(subset_counts, on=['eeg_id']+targets, how='left')\n","\n","# tmp_cols = ['expert_consensus', 'eeg_label_offset_seconds', 'subset_counts']\n","\n","# def sample_rule(x):\n","#     if (x['subset_counts'].min() > 3) & ((x['expert_consensus']!='Other').any()):\n","#         return x['eeg_label_offset_seconds'].sample(n=(x['subset_counts'].min()//3))\n","#     else:\n","#         return x['eeg_label_offset_seconds'].sample(n=1)\n","\n","# train_samples = train_csv.groupby(['eeg_id']+targets)[tmp_cols].apply(sample_rule).reset_index()\n","# train_samples = train_samples.rename(columns={'eeg_label_offset_seconds': 'eeg_off_seconds'})\n","# train_samples.drop(columns=['level_7'], inplace=True)\n","\n","# train_meta = train_csv.groupby(['eeg_id']+targets).agg({\n","#     'spectrogram_id': 'first',\n","#     'spectrogram_label_offset_seconds': ['min', 'max'],\n","#     'eeg_sub_id': 'count',\n","#     'eeg_label_offset_seconds': ['min', 'max'],\n","#     'patient_id': 'first',\n","# }).reset_index()\n","\n","# agged_cols = [\n","#     'spectrogram_id', 'min', 'max', 'subset_counts', 'eeg_off_min', 'eeg_off_max', 'patient_id'\n","# ]\n","# train_meta.columns = ['eeg_id'] + targets + agged_cols\n","# train_meta = train_meta[['eeg_id'] + agged_cols + targets]\n","\n","# train_meta['total_votes'] = train_meta[targets].sum(axis=1)\n","# train_meta['target'] = train_meta[targets].idxmax(axis=1).apply(lambda x: x.split('_')[0])\n","# train_meta['fold'] = -1\n","\n","# K_FOLDS = 5\n","# kf = KFold(n_splits=K_FOLDS, shuffle=False)\n","# unique_eegs = train_meta['eeg_id'].unique()\n","# for fold, (_, valid_idx) in enumerate(kf.split(unique_eegs)):\n","#     train_meta.loc[train_meta['eeg_id'].isin(unique_eegs[valid_idx]), 'fold'] = fold\n","\n","# train_all = train_samples.merge(train_meta, on=['eeg_id']+targets, how='left')\n","\n","# train_all[targets] = train_all[targets].div(train_all['total_votes'], axis=0)\n","\n","# train_all['stage'] = train_all['total_votes'].apply(lambda x: 1 if x < 10 else 2)\n","\n","# train_all"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["targets:  ['seizure_vote', 'lpd_vote', 'gpd_vote', 'lrda_vote', 'grda_vote', 'other_vote']\n","train_all.shape =  (20183, 13)\n","train_all nan_count:  0\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>eeg_id</th>\n","      <th>seizure_vote</th>\n","      <th>lpd_vote</th>\n","      <th>gpd_vote</th>\n","      <th>lrda_vote</th>\n","      <th>grda_vote</th>\n","      <th>other_vote</th>\n","      <th>spectrogram_id</th>\n","      <th>min</th>\n","      <th>max</th>\n","      <th>patient_id</th>\n","      <th>target</th>\n","      <th>total_votes</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>568657</td>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","      <td>0.25</td>\n","      <td>0.000000</td>\n","      <td>0.166667</td>\n","      <td>0.583333</td>\n","      <td>789577333</td>\n","      <td>0.0</td>\n","      <td>16.0</td>\n","      <td>20654</td>\n","      <td>Other</td>\n","      <td>12.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>582999</td>\n","      <td>0.0</td>\n","      <td>0.857143</td>\n","      <td>0.00</td>\n","      <td>0.071429</td>\n","      <td>0.000000</td>\n","      <td>0.071429</td>\n","      <td>1552638400</td>\n","      <td>0.0</td>\n","      <td>38.0</td>\n","      <td>20230</td>\n","      <td>LPD</td>\n","      <td>14.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>642382</td>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","      <td>0.00</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>1.000000</td>\n","      <td>14960202</td>\n","      <td>1008.0</td>\n","      <td>1032.0</td>\n","      <td>5955</td>\n","      <td>Other</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>751790</td>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","      <td>1.00</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>618728447</td>\n","      <td>908.0</td>\n","      <td>908.0</td>\n","      <td>38549</td>\n","      <td>GPD</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>778705</td>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","      <td>0.00</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>1.000000</td>\n","      <td>52296320</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>40955</td>\n","      <td>Other</td>\n","      <td>2.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   eeg_id  seizure_vote  lpd_vote  gpd_vote  lrda_vote  grda_vote  other_vote  \\\n","0  568657           0.0  0.000000      0.25   0.000000   0.166667    0.583333   \n","1  582999           0.0  0.857143      0.00   0.071429   0.000000    0.071429   \n","2  642382           0.0  0.000000      0.00   0.000000   0.000000    1.000000   \n","3  751790           0.0  0.000000      1.00   0.000000   0.000000    0.000000   \n","4  778705           0.0  0.000000      0.00   0.000000   0.000000    1.000000   \n","\n","   spectrogram_id     min     max  patient_id target  total_votes  \n","0       789577333     0.0    16.0       20654  Other         12.0  \n","1      1552638400     0.0    38.0       20230    LPD         14.0  \n","2        14960202  1008.0  1032.0        5955  Other          1.0  \n","3       618728447   908.0   908.0       38549    GPD          1.0  \n","4        52296320     0.0     0.0       40955  Other          2.0  "]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":[" \n","train_hard.shape =  (6492, 13)\n","train_hard nan_count:  0\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>eeg_id</th>\n","      <th>seizure_vote</th>\n","      <th>lpd_vote</th>\n","      <th>gpd_vote</th>\n","      <th>lrda_vote</th>\n","      <th>grda_vote</th>\n","      <th>other_vote</th>\n","      <th>spectrogram_id</th>\n","      <th>min</th>\n","      <th>max</th>\n","      <th>patient_id</th>\n","      <th>target</th>\n","      <th>total_votes</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>568657</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.250000</td>\n","      <td>0.000000</td>\n","      <td>0.166667</td>\n","      <td>0.583333</td>\n","      <td>789577333</td>\n","      <td>0.0</td>\n","      <td>16.0</td>\n","      <td>20654</td>\n","      <td>Other</td>\n","      <td>12.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>582999</td>\n","      <td>0.000000</td>\n","      <td>0.857143</td>\n","      <td>0.000000</td>\n","      <td>0.071429</td>\n","      <td>0.000000</td>\n","      <td>0.071429</td>\n","      <td>1552638400</td>\n","      <td>0.0</td>\n","      <td>38.0</td>\n","      <td>20230</td>\n","      <td>LPD</td>\n","      <td>14.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1895581</td>\n","      <td>0.076923</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.076923</td>\n","      <td>0.846154</td>\n","      <td>128369999</td>\n","      <td>1138.0</td>\n","      <td>1138.0</td>\n","      <td>47999</td>\n","      <td>Other</td>\n","      <td>13.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>2482631</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.133333</td>\n","      <td>0.066667</td>\n","      <td>0.133333</td>\n","      <td>0.666667</td>\n","      <td>978166025</td>\n","      <td>1902.0</td>\n","      <td>1944.0</td>\n","      <td>20606</td>\n","      <td>Other</td>\n","      <td>15.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>2521897</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.083333</td>\n","      <td>0.083333</td>\n","      <td>0.333333</td>\n","      <td>0.500000</td>\n","      <td>673742515</td>\n","      <td>0.0</td>\n","      <td>4.0</td>\n","      <td>62117</td>\n","      <td>Other</td>\n","      <td>12.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["    eeg_id  seizure_vote  lpd_vote  gpd_vote  lrda_vote  grda_vote  \\\n","0   568657      0.000000  0.000000  0.250000   0.000000   0.166667   \n","1   582999      0.000000  0.857143  0.000000   0.071429   0.000000   \n","2  1895581      0.076923  0.000000  0.000000   0.000000   0.076923   \n","3  2482631      0.000000  0.000000  0.133333   0.066667   0.133333   \n","4  2521897      0.000000  0.000000  0.083333   0.083333   0.333333   \n","\n","   other_vote  spectrogram_id     min     max  patient_id target  total_votes  \n","0    0.583333       789577333     0.0    16.0       20654  Other         12.0  \n","1    0.071429      1552638400     0.0    38.0       20230    LPD         14.0  \n","2    0.846154       128369999  1138.0  1138.0       47999  Other         13.0  \n","3    0.666667       978166025  1902.0  1944.0       20606  Other         15.0  \n","4    0.500000       673742515     0.0     4.0       62117  Other         12.0  "]},"metadata":{},"output_type":"display_data"}],"source":["# Original Split \n","\n","train_csv = pd.read_csv(PATHS.TRAIN_CSV)\n","targets = train_csv.columns[-6:]\n","\n","print(\"targets: \", targets.to_list())\n","\n","train_csv['total_votes'] = train_csv[targets].sum(axis=1)\n","train_csv[targets] = train_csv[targets].astype('float32')\n","\n","targets_prob = [f\"{t.split('_')[0]}_prob\" for t in targets]\n","train_csv[targets_prob] = train_csv[targets].div(train_csv['total_votes'], axis=0)\n","# train_csv['rel_entropy'] = train_csv[targets_prob].apply(lambda row: sum(rel_entr([1/6]*6, row.values+1e-5)), axis=1)\n","# train_csv['entropy'] = train_csv[targets_prob].apply(lambda row: entropy(row.values), axis=1)\n","\n","# hard_csv = train_csv[train_csv['entropy'] < ModelConfig.SPLIT_ENTROPY].copy().reset_index(drop=True)\n","# hard_csv = train_csv[train_csv['entropy'] >= 0.75].copy().reset_index(drop=True)\n","hard_csv = train_csv[train_csv['total_votes'] >= 6].copy().reset_index(drop=True)\n","\n","\n","train_all = gen_non_overlap_samples(train_csv, targets)\n","train_hard = gen_non_overlap_samples(hard_csv, targets)\n","\n","print(\"train_all.shape = \", train_all.shape)\n","print(\"train_all nan_count: \", train_all.isnull().sum().sum())\n","display(train_all.head())\n","\n","print(\" \")\n","\n","print(\"train_hard.shape = \", train_hard.shape)\n","print(\"train_hard nan_count: \", train_hard.isnull().sum().sum())\n","display(train_hard.head())"]},{"cell_type":"markdown","metadata":{},"source":["# Dataset"]},{"cell_type":"code","execution_count":12,"metadata":{"trusted":true},"outputs":[],"source":["# Functional Utils\n","def butter_bandpass_filter(data, lowcut, highcut, fs, order=5):\n","    b, a = butter(order, [lowcut, highcut], fs=fs, btype='band')\n","    y = lfilter(b, a, data)\n","    return y\n","\n","def denoise_filter(x):\n","    # Sample rate and desired cutoff frequencies (in Hz).\n","    fs = 200.0\n","    lowcut = 1.0\n","    highcut = 25.0\n","    \n","    # Filter a noisy signal.\n","    T = 50\n","    nsamples = T * fs\n","    t = np.arange(0, nsamples) / fs\n","    y = butter_bandpass_filter(x, lowcut, highcut, fs, order=6)\n","    y = (y + np.roll(y,-1)+ np.roll(y,-2)+ np.roll(y,-3))/4\n","    y = y[0:-1:4]\n","    \n","    return y\n","\n","def mu_law_encoding(data, mu):\n","    mu_x = np.sign(data) * np.log(1 + mu * np.abs(data)) / np.log(mu + 1)\n","    return mu_x\n","\n","def mu_law_expansion(data, mu):\n","    s = np.sign(data) * (np.exp(np.abs(data) * np.log(mu + 1)) - 1) / mu\n","    return s\n","\n","def quantize_data(data, classes):\n","    mu_x = mu_law_encoding(data, classes)\n","    return mu_x #quantized\n","\n","def butter_lowpass_filter(data, cutoff_freq=20, sampling_rate=200, order=4):\n","    nyquist = 0.5 * sampling_rate\n","    normal_cutoff = cutoff_freq / nyquist\n","    b, a = butter(order, normal_cutoff, btype='low', analog=False)\n","    filtered_data = lfilter(b, a, data, axis=0)\n","    return filtered_data\n"]},{"cell_type":"code","execution_count":13,"metadata":{"trusted":true},"outputs":[],"source":["class EEGSeqDataset(Dataset):\n","    def __init__(self, df, config, eegs, mode='train', verbose=False):\n","        self.df = df\n","        self.mode = mode\n","        self.eegs = eegs\n","        self.verbose = verbose\n","        self.downsample = config.RESNET_GRU_DOWNSAMPLE\n","        self.use_bandpass = config.RESNET_GRU_BANDPASS\n","    \n","    def __len__(self):\n","        return len(self.df)\n","\n","    def __getitem__(self, idx):\n","        \n","        X, y_prob = self.__data_generation(idx)\n","        \n","        if self.downsample is not None:\n","            X = X[::self.downsample,:]\n","        \n","        return torch.tensor(X, dtype=torch.float32), torch.tensor(y_prob, dtype=torch.float32)\n","    \n","    def __data_generation(self, index):\n","        row = self.df.iloc[index]\n","        \n","        if self.verbose:\n","            print(f\"Row {index}\", row[['eeg_id', 'eeg_off_min', 'target']].tolist())\n","\n","        X = np.zeros((10_000, 8), dtype='float32')\n","        \n","        # # start_sec = int((row['eeg_off_min'] + row['eeg_off_max']) // 2)\n","        # eeg_seq = self.eegs[row.eeg_id]\n","        # len_seq = eeg_seq.shape[0]\n","        # start_at = int(row['eeg_off_min']) + (len_seq - 10_000) // 2 \n","        # # !!! use randomly sampled offset !!!\n","        # # start_sec = int(row['eeg_off_sample']) \n","        # data = eeg_seq[start_at:start_at+10_000, :]\n","        \n","        data = self.eegs[row.eeg_id]\n","\n","        # === Feature engineering ===\n","        X[:,0] = data[:,EEG_FEAT_INDEX['Fp1']] - data[:,EEG_FEAT_INDEX['T3']]\n","        X[:,1] = data[:,EEG_FEAT_INDEX['T3']] - data[:,EEG_FEAT_INDEX['O1']]\n","\n","        X[:,2] = data[:,EEG_FEAT_INDEX['Fp1']] - data[:,EEG_FEAT_INDEX['C3']]\n","        X[:,3] = data[:,EEG_FEAT_INDEX['C3']] - data[:,EEG_FEAT_INDEX['O1']]\n","\n","        X[:,4] = data[:,EEG_FEAT_INDEX['Fp2']] - data[:,EEG_FEAT_INDEX['C4']]\n","        X[:,5] = data[:,EEG_FEAT_INDEX['C4']] - data[:,EEG_FEAT_INDEX['O2']]\n","\n","        X[:,6] = data[:,EEG_FEAT_INDEX['Fp2']] - data[:,EEG_FEAT_INDEX['T4']]\n","        X[:,7] = data[:,EEG_FEAT_INDEX['T4']] - data[:,EEG_FEAT_INDEX['O2']]\n","\n","        # === Standarize ===\n","        X = np.clip(X,-1024, 1024)\n","        X = np.nan_to_num(X, nan=0) / 32.0\n","\n","        # === Butter Low-pass Filter ===\n","        # ??? change to bandpass filter (low=0.5, hight=20, order=2) ???\n","        if self.use_bandpass is not None:\n","            X = butter_lowpass_filter(X, self.use_bandpass[0], self.use_bandpass[1], order=2)\n","            \n","        X = butter_lowpass_filter(X) \n","        \n","        if self.mode != 'test':\n","            y_prob = row[TARGETS].values.astype(np.float32)\n","        else:\n","            y_prob = np.zeros(6, dtype='float32')\n","\n","        return X, y_prob "]},{"cell_type":"code","execution_count":14,"metadata":{"trusted":true},"outputs":[],"source":["# # visualize the dataset\n","# train_dataset = EEGSeqDataset(train_all, ModelConfig, ALL_EEG_SIGNALS, mode=\"train\")\n","# train_loader = DataLoader(train_dataset, drop_last=True, batch_size=16, num_workers=4, pin_memory=True, shuffle=False)\n","\n","# for batch in train_loader:\n","#     X, y = batch\n","#     print(f\"X shape: {X.shape}\")\n","#     print(f\"y shape: {y.shape}\")\n","    \n","#     fig, axes = plt.subplots(4, 1, figsize=(20, 20))\n","#     ax_idx = 0\n","#     for item in np.random.choice(range(X.shape[0]), 4):\n","#         offset = 0\n","#         for col in range(X.shape[-1]):\n","#             if col != 0:\n","#                 offset -= X[item,:,col].min()\n","#             axes[ax_idx].plot(np.arange(X.shape[1]), X[item,:,col]+offset, label=f'feature {col+1}')\n","#             offset += X[item,:,col].max()\n","#         print(y[item])\n","#         # axes[ax_idx].set_title(f'Weight = {weights[item]}',size=14)\n","#         axes[ax_idx].legend()\n","#         ax_idx += 1\n","#     fig.tight_layout()\n","#     plt.show()\n","#     break\n","\n","# del train_dataset, train_loader\n","# torch.cuda.empty_cache()\n","# gc.collect()"]},{"cell_type":"markdown","metadata":{},"source":["# Model"]},{"cell_type":"markdown","metadata":{},"source":["### Resnet 1D Encoder"]},{"cell_type":"code","execution_count":15,"metadata":{"jupyter":{"source_hidden":true},"trusted":true},"outputs":[],"source":["class ResNet_1D_Block(nn.Module):\n","    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, downsampling, dropout=0.0, dilation=1):\n","        super(ResNet_1D_Block, self).__init__()\n","        self.block = nn.Sequential(\n","            nn.BatchNorm1d(num_features=in_channels),\n","            nn.Hardswish(), #nn.ReLU(),\n","            nn.Dropout(p=dropout),\n","            nn.Conv1d(in_channels, out_channels, kernel_size, stride, padding, dilation=dilation, bias=False),\n","            nn.BatchNorm1d(num_features=out_channels),\n","            nn.Hardswish(), #nn.ReLU(),\n","            nn.Dropout(p=dropout),\n","            nn.Conv1d(out_channels, out_channels, kernel_size, stride, padding, dilation=dilation, bias=False),\n","            nn.MaxPool1d(kernel_size=2, stride=2, padding=0)\n","        )\n","        self.downsampling = downsampling\n","\n","    def forward(self, x):\n","        identity = self.downsampling(x)\n","        out = self.block(x)\n","        out += identity\n","        return out\n","\n","class SelfAttentionPooling(nn.Module):\n","    \"\"\"\n","    Implementation of SelfAttentionPooling \n","    Original Paper: Self-Attention Encoding and Pooling for Speaker Recognition\n","    https://arxiv.org/pdf/2008.01077v1.pdf\n","    \"\"\"\n","    def __init__(self, input_dim):\n","        super(SelfAttentionPooling, self).__init__()\n","        self.W = nn.Linear(input_dim, 1)\n","        self.softmax = nn.Softmax(dim=1)\n","        \n","    def forward(self, batch_rep):\n","        \"\"\"\n","        input:\n","            batch_rep : size (N, T, H), N: batch size, T: sequence length, H: Hidden dimension\n","        attention_weight:\n","            att_w : size (N, T, 1)\n","        return:\n","            utter_rep: size (N, H)\n","        \"\"\"\n","        att_w = self.softmax(self.W(batch_rep).squeeze(-1)).unsqueeze(-1)\n","        utter_rep = torch.sum(batch_rep * att_w, dim=1)\n","\n","        return utter_rep\n","\n","class ResNetGRU(nn.Module):\n","    def __init__(self, config=ModelConfig, num_classes=6):\n","        super(ResNetGRU, self).__init__()\n","\n","        self.planes = 24\n","        self.kernels = config.RESNET_GRU_KERNELS\n","        self.in_channels = config.RESNET_GRU_IN_CHANNELS\n","        self.use_dilation = config.RESNET_GRU_DILATED\n","\n","        fixed_kernel_size = config.RESNET_GRU_FIXED_KERNEL_SIZE\n","        hidden_size = config.RESNET_GRU_HIDDEN_SIZE\n","\n","        # Define the separate convolutional layers\n","        self.parallel_conv = self._make_parallel_conv_layers()\n","        # Define the ResNet part of the model\n","        self.resnet_part = self._make_resnet_part(fixed_kernel_size, n_blocks=9)\n","        # Define the GRU part of the model\n","        self.rnn = nn.GRU(input_size=self.in_channels, hidden_size=128, num_layers=1, bidirectional=True)\n","        self.pooling = SelfAttentionPooling(256)\n","        # Define the final fully connected layer\n","        self.fc = nn.Linear(in_features=hidden_size, out_features=num_classes)\n","\n","    def _make_parallel_conv_layers(self):\n","        return nn.ModuleList([\n","            nn.Conv1d(\n","                in_channels=self.in_channels, \n","                out_channels=self.planes, \n","                kernel_size=kernel_size,\n","                stride=1, \n","                padding=0, \n","                bias=False\n","            ) for kernel_size in self.kernels\n","        ])\n","\n","    def _make_resnet_part(self, fixed_kernel_size, n_blocks=9):\n","        # prepare resnet layers\n","        downsampling = nn.MaxPool1d(kernel_size=2, stride=2, padding=0)\n","\n","        if self.use_dilation:\n","            dilation_rates = [1, 2, 2, 2, 2, 4, 4, 4, 4] #[1] * n_blocks\n","        else:\n","            dilation_rates = [1] * n_blocks\n","\n","        paddings = [fixed_kernel_size//2 * rate for rate in dilation_rates]\n","        resnet_layers = [\n","            ResNet_1D_Block(\n","                in_channels=self.planes, \n","                out_channels=self.planes, \n","                kernel_size=fixed_kernel_size, \n","                stride=1, \n","                padding=paddings[i], \n","                downsampling=downsampling,\n","                dropout=0.0,\n","                dilation=dilation_rates[i])\n","            for i in range(n_blocks)\n","        ]\n","        # return the resnet encoder\n","        return nn.Sequential(\n","            nn.BatchNorm1d(num_features=self.planes),\n","            nn.SiLU(), #nn.ReLU(inplace=False),\n","            nn.Conv1d(\n","                in_channels=self.planes, \n","                out_channels=self.planes, \n","                kernel_size=fixed_kernel_size, \n","                stride=2, \n","                padding=2, \n","                bias=False\n","            ),\n","            *resnet_layers,\n","            nn.BatchNorm1d(num_features=self.planes),\n","            nn.SiLU(), #nn.ReLU(inplace=False),\n","            nn.AvgPool1d(kernel_size=6, stride=6, padding=2)\n","        )\n","    \n","    def forward(self, x):\n","        # extract features using resnet \n","        x = x.permute(0, 2, 1)\n","        out_sep = [conv(x) for conv in self.parallel_conv]\n","        out = torch.cat(out_sep, dim=2)\n","        out = self.resnet_part(out)\n","        out = out.reshape(out.shape[0], -1)\n","        # extract features using rnn\n","        rnn_out, _ = self.rnn(x.permute(0, 2, 1))\n","        new_rnn_h = self.pooling(rnn_out)\n","        # concatenate the features\n","        new_out = torch.cat([out, new_rnn_h], dim=1) \n","        # total features = 424 = 24*6 + 128*2 \n","        # pass through the final fully connected layer\n","        result = self.fc(new_out)  \n","        \n","        return result\n"]},{"cell_type":"markdown","metadata":{},"source":["### Dilated Inception Wavenet Encoder"]},{"cell_type":"code","execution_count":16,"metadata":{"trusted":true},"outputs":[],"source":["# from typing import List\n","\n","# class DilatedInception(nn.Module):\n","#     def __init__(self, in_channels: int, out_channels: int, kernel_sizes: List[int], dilation: int) -> None:\n","#         super().__init__()\n","#         assert out_channels % len(kernel_sizes) == 0, \"`out_channels` must be divisible by the number of kernel sizes.\"\n","#         hidden_dim = out_channels // len(kernel_sizes)\n","#         self.convs = nn.ModuleList([\n","#             nn.Conv1d(in_channels, hidden_dim, k, padding='same', dilation=dilation)\n","#             for k in kernel_sizes\n","#         ])\n","\n","#     def forward(self, x):\n","#         outputs = [conv(x) for conv in self.convs]\n","#         out = torch.cat(outputs, dim=1)\n","#         return out\n","\n","# class GatedTCN(nn.Module):\n","#     def __init__(self, in_dim: int, h_dim: int, kernel_sizes: List[int], dilation_factor: int, dropout: float = 0.0) -> None:\n","#         super().__init__()\n","#         self.filt = DilatedInception(in_dim, h_dim, kernel_sizes, dilation=dilation_factor)\n","#         self.gate = DilatedInception(in_dim, h_dim, kernel_sizes, dilation=dilation_factor)\n","#         self.dropout = nn.Dropout(dropout)\n","\n","#     def forward(self, x):\n","#         x_filt = torch.tanh(self.filt(x))\n","#         x_gate = torch.sigmoid(self.gate(x))\n","#         h = x_filt * x_gate\n","#         h = self.dropout(h)\n","#         return h\n","\n","# class WaveBlock(nn.Module):\n","#     def __init__(self, n_layers: int, in_dim: int, h_dim: int, kernel_sizes: List[int]) -> None:\n","#         super().__init__()\n","#         self.dilation_rates = [2**i for i in range(n_layers)]\n","#         self.in_conv = nn.Conv1d(in_dim, h_dim, kernel_size=1)\n","#         self.gated_tcns = nn.ModuleList([\n","#             GatedTCN(h_dim, h_dim, kernel_sizes, dilation)\n","#             for dilation in self.dilation_rates\n","#         ])\n","#         self.skip_convs = nn.ModuleList([\n","#             nn.Conv1d(h_dim, h_dim, kernel_size=1)\n","#             for _ in range(n_layers)\n","#             ])\n","#         self._initialize_weights()\n","\n","#     def _initialize_weights(self):\n","#         nn.init.xavier_uniform_(self.in_conv.weight, gain=nn.init.calculate_gain('relu'))\n","#         nn.init.zeros_(self.in_conv.bias)\n","#         for conv in self.skip_convs:\n","#             nn.init.xavier_uniform_(conv.weight, gain=nn.init.calculate_gain('relu'))\n","#             nn.init.zeros_(conv.bias)\n","\n","#     def forward(self, x):\n","#         # x: (B, C, L)\n","#         x = self.in_conv(x)\n","#         x_skip = x\n","#         for gated_tcn, skip_conv in zip(self.gated_tcns, self.skip_convs):\n","#             x = gated_tcn(x)\n","#             x = skip_conv(x)\n","#             x_skip = x_skip + x\n","#         return x_skip\n","\n","# class DilatedWaveNet(nn.Module):\n","#     \"\"\"WaveNet architecture with dilated inception conv, enhanced with list comprehension for input processing.\"\"\"\n","\n","#     def __init__(self, kernel_sizes: List[int]) -> None:\n","#         super().__init__()\n","#         self.kernel_sizes = kernel_sizes\n","        \n","#         # Initialize wave blocks with specified kernel sizes\n","#         self.wave_module = nn.Sequential(\n","#             WaveBlock(9, 8, 128, self.kernel_sizes), #12\n","#             WaveBlock(6, 128, 256, self.kernel_sizes), #8\n","#             WaveBlock(3, 256, 512, self.kernel_sizes), #4\n","#             WaveBlock(1, 512, 512, self.kernel_sizes), #1\n","#         )\n","#         self.pool_layer = nn.AdaptiveAvgPool1d(1)\n","\n","#     def forward(self, x) -> torch.Tensor:\n","#         # x: (B, L, C)\n","#         bs, seq_len, n_channels = x.shape\n","#         x = x.permute(0, 2, 1) # -> (B, C, L)\n","#         # Process different parts of the input with list comprehension\n","#         x = self.wave_module(x)\n","#         x = self.pool_layer(x) # ->(B, 512, 1)\n","#         x = x.reshape(bs, n_channels, -1).reshape(bs, n_channels//2, 2, 64)\n","#         features = x.mean(dim=2).reshape(bs, -1) # -> (16, 256)\n","# #         pooled_outputs = [(x[:, i:i+64] + x[:, i+64:i+128]) / 2 for i in range(0, n_channels, 2)]\n","# #         # Combine the pooled features and reshape for classification\n","# #         features = torch.cat(pooled_outputs, dim=1).reshape(bs, -1)\n","       \n","#         return features"]},{"cell_type":"markdown","metadata":{},"source":["### Dilated ResNet 1D Encoder"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[],"source":["# class ResnetBlock(nn.Module):\n","#     def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, dilation=1, dropout=0.0):\n","#         super(ResnetBlock, self).__init__()\n","\n","#         self.bn1 = nn.BatchNorm1d(in_channels)\n","#         self.relu1 = nn.ReLU()\n","#         self.conv1 = nn.Conv1d(\n","#             in_channels, out_channels, kernel_size, \n","#             stride=stride, \n","#             padding=dilation*(kernel_size//2), \n","#             dilation=dilation, \n","#             bias=False)\n","#         self.drop1 = nn.Dropout(p=dropout)\n","#         self.bn2 = nn.BatchNorm1d(out_channels)\n","#         self.relu2 = nn.ReLU()\n","#         self.drop2 = nn.Dropout(p=dropout)\n","#         self.conv2 = nn.Conv1d(\n","#             out_channels, out_channels, kernel_size, \n","#             stride=stride, \n","#             padding=dilation*(kernel_size//2), \n","#             dilation=dilation, \n","#             bias=False)\n","        \n","#         self.bn3 = nn.BatchNorm1d(out_channels)\n","#         self.relu3 = nn.ReLU()\n","#         self.downsample = nn.MaxPool1d(kernel_size=2, stride=2, padding=0)\n","\n","#     def forward(self, x):\n","#         identity = x\n","#         identity = self.downsample(identity)\n","\n","#         out = self.bn1(x)\n","#         out = self.relu1(out)\n","#         out = self.drop1(out)\n","#         out = self.conv1(out)\n","\n","#         out = self.bn2(out)\n","#         out = self.relu2(out)\n","#         out = self.drop2(out)\n","#         out = self.conv2(out)\n","\n","#         out = self.downsample(out)\n","\n","#         out += identity\n","#         out = self.bn3(out)\n","#         out = self.relu3(out)\n","\n","#         return out\n","\n","# class DilatedResnet(nn.Module):\n","#     def __init__(self, in_channels, out_channels, kernel_size, n_layers, expansion_factor=4):\n","#         super(DilatedResnet, self).__init__()\n","\n","#         self.in_channels = in_channels\n","#         self.kernel_size = kernel_size\n","#         self.h_dim = out_channels // n_layers\n","        \n","#         fix_kernel_size = 5\n","#         self.conv1 = nn.Conv1d(\n","#             self.in_channels, self.h_dim, kernel_size=fix_kernel_size, stride=1, padding=fix_kernel_size//2\n","#             )\n","\n","#         dilation_rates = [expansion_factor**i for i in range(n_layers)]\n","\n","#         self.blocks = nn.ModuleList([\n","#             ResnetBlock(self.h_dim, self.h_dim, self.kernel_size, dilation=dilation)\n","#             for dilation in dilation_rates\n","#         ])\n","\n","#     def forward(self, x):\n","#         x = self.conv1(x)\n","#         outputs = [ block(x) for block in self.blocks ]\n","#         output = torch.cat(outputs, dim=1)\n","        \n","#         return output\n","\n","# class DilatedResnetEncoder(nn.Module):\n","#     def __init__(self, kernel_sizes=[3, 5, 7, 9], in_channels=8, planes=24, dilate_layers=[6,3,1], expansion_factor=4):\n","#         super(DilatedResnetEncoder, self).__init__()\n","\n","#         self.in_channels = in_channels\n","#         self.planes = planes\n","#         self.kernel_sizes = kernel_sizes\n","#         self.dilate_layers = dilate_layers # must be 3 layers\n","#         self.expansion_factor = expansion_factor\n","        \n","#         # out_channels = self.planes * self.in_channels\n","#         # fix_kernel_size = 5\n","#         # self.conv1 = nn.Conv1d(\n","#         #     self.in_channels, out_channels, kernel_size=fix_kernel_size, stride=1, padding=fix_kernel_size//2\n","#         #     )\n","        \n","#         self.blocks = nn.ModuleList([\n","#             self._make_dilated_block(kernel_size)\n","#             for kernel_size in self.kernel_sizes\n","#         ])\n","\n","#         bottleneck_in_channels = self.in_channels * self.planes * self.dilate_layers[1] * self.dilate_layers[2]\n","#         bottoleneck_out_channels = self.in_channels * self.planes\n","\n","#         self.bottleneck = nn.Sequential(\n","#             nn.BatchNorm1d(num_features=bottleneck_in_channels),\n","#             nn.ReLU(),\n","#             nn.Conv1d(\n","#                 in_channels=bottleneck_in_channels,\n","#                 out_channels=bottoleneck_out_channels,\n","#                 kernel_size=1,\n","#                 stride=1,\n","#                 padding=0,\n","#                 bias=False\n","#             )\n","#         )\n","        \n","#         self.pooling = nn.AdaptiveAvgPool1d(1)\n","#         # self.blocks = nn.ModuleList([\n","#         #     nn.Sequential(*[\n","#         #         ResidualBlock(\n","#         #             out_channels, out_channels, kernel_size, dilation=dilation\n","#         #         ) for dilation in self.dilate_layers\n","#         #     ])\n","#         #     for kernel_size in self.kernel_sizes\n","#         # ])\n","\n","#     def _make_dilated_block(self, kernel_size):\n","#         out_channel_1 = self.in_channels * self.planes\n","#         block_1 = DilatedResnet(self.in_channels, out_channel_1, kernel_size, self.dilate_layers[0], self.expansion_factor)\n","\n","#         out_channel_2 = out_channel_1 * self.dilate_layers[1]\n","#         block_2 = DilatedResnet(out_channel_1, out_channel_2, kernel_size, self.dilate_layers[1], self.expansion_factor)\n","\n","#         out_channel_3 = out_channel_2 * self.dilate_layers[2]\n","#         block_3 = DilatedResnet(out_channel_2, out_channel_3, kernel_size, self.dilate_layers[2], self.expansion_factor)\n","\n","#         return nn.Sequential(block_1, block_2, block_3)\n","        \n","    \n","#     def forward(self, x):\n","#         # <- # [batch_size, seq_len=2000, in_channels=8]\n","#         x = x.permute(0, 2, 1)\n","#         # x = self.conv1(x)\n","#         outputs = [ block(x) for block in self.blocks ]\n","#         outputs = [ self.bottleneck(out) for out in outputs ]\n","#         output = torch.cat(outputs, dim=1)\n","#         output = self.pooling(output).squeeze(-1)\n","        \n","#         return output"]},{"cell_type":"code","execution_count":18,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["X shape: torch.Size([16, 2000, 8])\n","y shape: torch.Size([16, 6])\n","torch.Size([16, 6])\n"]},{"data":{"text/plain":["0"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["train_dataset = EEGSeqDataset(train_all, ModelConfig, ALL_EEG_SIGNALS, mode=\"train\")\n","train_loader = DataLoader(train_dataset, drop_last=True, batch_size=16, num_workers=4, pin_memory=True, shuffle=False)\n","\n","model = ResNetGRU(config=ModelConfig, num_classes=6)\n","\n","model.to(DEVICE)\n","for i, batch in enumerate(train_loader):\n","    X, y = batch\n","    X = X.to(DEVICE)\n","    y = y.to(DEVICE)\n","    print(f\"X shape: {X.shape}\")\n","    print(f\"y shape: {y.shape}\")\n","    \n","    y_pred = model(X)\n","    print(y_pred.shape)\n","    break \n","\n","del model, train_dataset, train_loader, X, y\n","torch.cuda.empty_cache()\n","gc.collect()"]},{"cell_type":"code","execution_count":19,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Fri Apr  5 14:16:19 2024       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 470.239.06   Driver Version: 470.239.06   CUDA Version: 11.4     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  NVIDIA GeForce ...  Off  | 00000000:0B:00.0 Off |                  N/A |\n","| 26%   36C    P2    55W / 260W |   1605MiB / 11019MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|    0   N/A  N/A      1423      G   /usr/lib/xorg/Xorg                  9MiB |\n","|    0   N/A  N/A      1822      G   /usr/bin/gnome-shell                4MiB |\n","|    0   N/A  N/A    477648      C   ...a3/envs/kaggle/bin/python     1587MiB |\n","+-----------------------------------------------------------------------------+\n"]}],"source":["!nvidia-smi"]},{"cell_type":"markdown","metadata":{},"source":["# Train"]},{"cell_type":"code","execution_count":20,"metadata":{"trusted":true},"outputs":[],"source":["import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","class AverageMeter(object):\n","    \"\"\"Computes and stores the average and current value\"\"\"\n","\n","    def __init__(self):\n","        self.reset()\n","\n","    def reset(self):\n","        self.val = 0\n","        self.avg = 0\n","        self.sum = 0\n","        self.count = 0\n","\n","    def update(self, val, n=1):\n","        self.val = val\n","        self.sum += val * n\n","        self.count += n\n","        self.avg = self.sum / self.count\n","        \n","class Trainer:\n","\n","    def __init__(self, model, config, logger):\n","\n","        self.model = model\n","        self.logger = logger\n","        self.config = config\n","        \n","        self.early_stop_rounds = config.EARLY_STOP_ROUNDS\n","        self.early_stop_counter = 0\n","        \n","        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","        self.kl_div_loss = nn.KLDivLoss(reduction='batchmean')\n","        self.ce_loss = nn.CrossEntropyLoss()\n","        self.gamma = config.REGULARIZATION\n","        \n","        # self.criterion = nn.KLDivLoss(reduction=\"batchmean\")\n","    \n","    def criterion(self, y_pred, y_true, weights=None, mode='train'):\n","        kl_loss = self.kl_div_loss(F.log_softmax(y_pred, dim=1), y_true)\n","        if (self.gamma is not None) & (mode == 'train'):\n","            softmax_probs = F.softmax(y_pred, dim=1)  # Compute softmax probabilities\n","            entropy_loss = -(softmax_probs * torch.log(softmax_probs + 1e-9)).sum(dim=1).mean(dim=0) # Compute entropy, add epsilon to avoid log(0)\n","            return kl_loss - self.gamma * entropy_loss\n","        else:\n","            return kl_loss\n","        \n","    def train(self, train_loader, valid_loader, from_checkpoint=None):\n","\n","        self.optimizer = AdamW(self.model.parameters(), lr=8e-3, weight_decay=self.config.WEIGHT_DECAY)\n","\n","        # CosineAnnealingWarmRestarts( \n","        #     self.optimizer,\n","        #     T_0=20,\n","        #     eta_min=1e-6,\n","        #     T_mult=1,\n","        #     last_epoch=-1\n","        # )\n","        self.scheduler =  OneCycleLR(\n","            self.optimizer,\n","            max_lr=1e-4,\n","            epochs=self.config.EPOCHS,\n","            steps_per_epoch=len(train_loader),\n","            pct_start=0.1,\n","            anneal_strategy=\"cos\",\n","            final_div_factor=100,\n","        )\n","\n","        if from_checkpoint is not None:\n","            self.model.load_state_dict(torch.load(from_checkpoint, map_location=self.device))\n","\n","        self.model.to(self.device)\n","        best_weights, best_preds, best_loss = None, None, float(\"inf\")\n","        loss_records = {\"train\": [], \"valid\": []}\n","\n","        for epoch in range(self.config.EPOCHS):\n","            start_epoch = time()\n","\n","            train_loss, _ = self._train_or_valid_epoch(epoch, train_loader, is_train=True)\n","            valid_loss, valid_preds = self._train_or_valid_epoch(epoch, valid_loader, is_train=False)\n","\n","            loss_records[\"train\"].append(train_loss)\n","            loss_records[\"valid\"].append(valid_loss)\n","\n","            elapsed = time() - start_epoch\n","\n","            info = f\"{'-' * 100}\\nEpoch {epoch + 1} - \"\n","            info += f\"Average Loss: (train) {train_loss:.4f}; (valid) {valid_loss:.4f} | Time: {elapsed:.2f}s\"\n","            self.logger.info(info)\n","\n","            if valid_loss < best_loss:\n","                best_loss = valid_loss\n","                best_weights = self.model.state_dict()\n","                best_preds = valid_preds\n","                self.logger.info(f\"Best model found in epoch {epoch + 1} | valid loss: {best_loss:.4f}\")\n","                self.early_stop_counter = 0\n","            \n","            else:\n","                self.early_stop_counter += 1\n","                if self.early_stop_counter >= self.early_stop_rounds:\n","                    self.logger.info(f\"Early stopping at epoch {epoch + 1}\")\n","                    break\n","\n","        return best_weights, best_preds, loss_records\n","\n","    def _train_or_valid_epoch(self, epoch_id, dataloader, is_train=True):\n","\n","        self.model.train() if is_train else self.model.eval()\n","        mode = \"Train\" if is_train else \"Valid\"\n","\n","        len_loader = len(dataloader)\n","        scaler = GradScaler(enabled=self.config.AMP)\n","        loss_meter, predicts_record = AverageMeter(), []\n","\n","        start = time()\n","        pbar = tqdm(dataloader, total=len(dataloader), unit=\"batch\", desc=f\"{mode} [{epoch_id}]\")\n","        for step, (X, y) in enumerate(pbar):\n","            X, y = X.to(self.device), y.to(self.device)\n","\n","            if is_train:\n","                with autocast(enabled=self.config.AMP):\n","                    y_pred = self.model(X)\n","                    loss = self.criterion(y_pred, y)\n","                if self.config.GRADIENT_ACCUMULATION_STEPS > 1:\n","                    loss = loss / self.config.GRADIENT_ACCUMULATION_STEPS\n","                scaler.scale(loss).backward()\n","                grad_norm = torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.config.MAX_GRAD_NORM)\n","                if (step + 1) % self.config.GRADIENT_ACCUMULATION_STEPS == 0:\n","                    scaler.step(self.optimizer)\n","                    scaler.update()\n","                    self.optimizer.zero_grad()\n","                    self.scheduler.step()\n","            else:\n","                with torch.no_grad():\n","                    y_pred = self.model(X)\n","                    loss = self.criterion(y_pred, y, mode='valid')\n","                if self.config.GRADIENT_ACCUMULATION_STEPS > 1:\n","                    loss = loss / self.config.GRADIENT_ACCUMULATION_STEPS\n","                \n","                predicts_record.append(y_pred.to('cpu').numpy())\n","            \n","            loss_meter.update(loss.item(), y.size(0))\n","            end = time()\n","\n","            if (step % self.config.PRINT_FREQ == 0) or (step == (len_loader - 1)):\n","                lr = self.scheduler.get_last_lr()[0]\n","                info = f\"Epoch {epoch_id + 1} [{step}/{len_loader}] | {mode} Loss: {loss_meter.avg:.4f}\"\n","                if is_train:\n","                    info += f\" Grad: {grad_norm:.4f} LR: {lr:.4e}\"\n","                info += f\" | Elapse: {end - start:.2f}s\"\n","                print(info)\n","\n","        if not is_train:\n","            predicts_record = np.concatenate(predicts_record)\n","            \n","        return loss_meter.avg, predicts_record\n"]},{"cell_type":"code","execution_count":21,"metadata":{"trusted":true},"outputs":[],"source":["def train_fold(model, fold_id, train_folds, valid_folds, logger, stage=1, checkpoint=None):\n","\n","    train_dataset = EEGSeqDataset(train_folds, ModelConfig, ALL_EEG_SIGNALS, mode=\"train\")\n","    valid_dataset = EEGSeqDataset(valid_folds, ModelConfig, ALL_EEG_SIGNALS, mode=\"valid\")\n","\n","    # ======== DATALOADERS ==========\n","    loader_kwargs = {\n","        \"batch_size\": ModelConfig.BATCH_SIZE,\n","        \"num_workers\": ModelConfig.NUM_WORKERS,\n","        \"pin_memory\": True,\n","        \"shuffle\": False,\n","    }\n","\n","    train_loader = DataLoader(train_dataset, drop_last=True, collate_fn=None, **loader_kwargs)\n","    valid_loader = DataLoader(valid_dataset, drop_last=False, collate_fn=None, **loader_kwargs)\n","\n","    if checkpoint is not None:\n","        print(f\"Loading model from checkpoint: {checkpoint}\")\n","\n","    trainer = Trainer(model, ModelConfig, logger)\n","    best_weights, best_preds, loss_records = trainer.train(\n","        train_loader, valid_loader, from_checkpoint=checkpoint)\n","\n","    save_model_name = f\"{ModelConfig.MODEL_NAME}_fold_{fold_id}_stage_{stage}.pth\"\n","    torch.save(best_weights, os.path.join(PATHS.OUTPUT_DIR, save_model_name))\n","\n","    del train_dataset, valid_dataset, train_loader, valid_loader\n","    torch.cuda.empty_cache()\n","    gc.collect()\n","\n","    return best_preds, loss_records"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[],"source":["def evaluate_oof(oof_df):\n","    '''\n","    Evaluate the out-of-fold dataframe using KL Divergence (torch and kaggle)\n","    '''\n","    kl_loss = nn.KLDivLoss(reduction=\"batchmean\")\n","    labels = torch.tensor(oof_df[TARGETS].values.astype('float32'))\n","    preds = F.log_softmax(\n","        torch.tensor(oof_df[TARGETS_PRED].values.astype('float32'), requires_grad=False),\n","        dim=1\n","    )\n","    kl_torch = kl_loss(preds, labels).item()\n","\n","    return kl_torch"]},{"cell_type":"code","execution_count":23,"metadata":{"trusted":true},"outputs":[],"source":["from kl_divergence import score as kaggle_score \n","from sklearn.metrics import confusion_matrix\n","import seaborn as sns\n","\n","TARGET2ID = {'Seizure': 0, 'LPD': 1, 'GPD': 2, 'LRDA': 3, 'GRDA': 4, 'Other': 5}\n","\n","def calc_kaggle_score(oof_df):\n","    submission_df = oof_df[['eeg_id']+TARGETS_PRED].copy()\n","    submission_df.columns = ['eeg_id'] + TARGETS\n","    solution_df = oof_df[['eeg_id']+TARGETS].copy()\n","    return kaggle_score(solution_df, submission_df, 'eeg_id')\n","\n","def analyze_oof(oof_csv):\n","\n","    kl_criteria = nn.KLDivLoss(reduction='batchmean')\n","    softmax = nn.Softmax(dim=1)\n","\n","    oof_df = pd.read_csv(oof_csv)\n","    oof_df['target_pred'] = oof_df[TARGETS_PRED].apply(lambda x: np.argmax(x), axis=1)\n","    oof_df['target_id'] = oof_df[TARGETS].apply(lambda x: np.argmax(x), axis=1)\n","    \n","    oof_df[\"kl_loss\"] = oof_df.apply(\n","    lambda row: \n","        kl_criteria(\n","            F.log_softmax(\n","                    torch.tensor(row[TARGETS_PRED].values.astype(np.float32)).unsqueeze(0)\n","                , dim=1\n","                ), \n","            torch.tensor(row[TARGETS].values.astype(np.float32))\n","            ).numpy(),\n","    axis=1)\n","\n","    oof_df[\"kl_loss\"] = oof_df['kl_loss'].astype(np.float32)\n","\n","    oof_df[TARGETS_PRED] = softmax( torch.tensor(oof_df[TARGETS_PRED].values.astype(np.float32)) )\n","\n","    oof_df.head()\n","\n","    return oof_df"]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[],"source":["def prepare_k_fold(df, k_folds=5):\n","\n","    kf = KFold(n_splits=k_folds, shuffle=True, random_state=ModelConfig.SEED)\n","    unique_spec_id = df['spectrogram_id'].unique()\n","    df['fold'] = k_folds\n","\n","    for fold, (train_index, valid_index) in enumerate(kf.split(unique_spec_id)):\n","        df.loc[df['spectrogram_id'].isin(unique_spec_id[valid_index]), 'fold'] = fold\n","\n","    return df"]},{"cell_type":"code","execution_count":25,"metadata":{"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["****************************************************************************************************\n","Script Start: Fri Apr  5 14:16:28 2024\n","Model Configurations:\n","SEED: 20\n","SPLIT_ENTROPY: 5.5\n","MODEL_NAME: ResnetGRU_v1_LB048\n","MODEL_BACKBONE: reset_gru\n","BATCH_SIZE: 32\n","EPOCHS: 20\n","EARLY_STOP_ROUNDS: 5\n","GRADIENT_ACCUMULATION_STEPS: 1\n","DROP_RATE: 0.15\n","DROP_PATH_RATE: 0.25\n","WEIGHT_DECAY: 0.01\n","AMP: True\n","PRINT_FREQ: 100\n","NUM_WORKERS: 0\n","MAX_GRAD_NORM: 10000000.0\n","REGULARIZATION: 0.15\n","RESNET_GRU_BANDPASS: None\n","RESNET_GRU_IN_CHANNELS: 8\n","RESNET_GRU_KERNELS: [3, 5, 7, 9, 11]\n","RESNET_GRU_FIXED_KERNEL_SIZE: 5\n","RESNET_GRU_DOWNSAMPLE: 5\n","RESNET_GRU_HIDDEN_SIZE: 304\n","RESNET_GRU_DILATED: False\n","****************************************************************************************************\n","====================================================================================================\n","Fold: 0\n","====================================================================================================\n","- Stage 1 | Train: 16195; Valid: 3988 -\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"96e310eb6de74c41a0bde26874b2c2a0","version_major":2,"version_minor":0},"text/plain":["Train [0]:   0%|          | 0/506 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 1 [0/506] | Train Loss: 1.2684 Grad: 80195.3828 LR: 4.0002e-06 | Elapse: 0.23s\n","Epoch 1 [100/506] | Train Loss: 1.1780 Grad: 91877.4531 LR: 6.3447e-06 | Elapse: 6.03s\n","Epoch 1 [200/506] | Train Loss: 1.1851 Grad: 78362.3906 LR: 1.3062e-05 | Elapse: 11.85s\n","Epoch 1 [300/506] | Train Loss: 1.1739 Grad: 52261.8555 LR: 2.3509e-05 | Elapse: 17.65s\n","Epoch 1 [400/506] | Train Loss: 1.1569 Grad: 65165.1328 LR: 3.6686e-05 | Elapse: 23.46s\n","Epoch 1 [500/506] | Train Loss: 1.1345 Grad: 50491.7734 LR: 5.1329e-05 | Elapse: 29.27s\n","Epoch 1 [505/506] | Train Loss: 1.1335 Grad: 49006.5547 LR: 5.2075e-05 | Elapse: 29.56s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"726a1e7b123349a89d4290fd3856e023","version_major":2,"version_minor":0},"text/plain":["Valid [0]:   0%|          | 0/125 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 1 [0/125] | Valid Loss: 1.2688 | Elapse: 0.07s\n","Epoch 1 [100/125] | Valid Loss: 1.3073 | Elapse: 5.09s\n"]},{"name":"stderr","output_type":"stream","text":["----------------------------------------------------------------------------------------------------\n","Epoch 1 - Average Loss: (train) 1.1335; (valid) 1.3002 | Time: 35.85s\n","Best model found in epoch 1 | valid loss: 1.3002\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1 [124/125] | Valid Loss: 1.3002 | Elapse: 6.28s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5e63e29ea634426eafc959af573cc774","version_major":2,"version_minor":0},"text/plain":["Train [1]:   0%|          | 0/506 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 2 [0/506] | Train Loss: 1.0906 Grad: 53102.0742 LR: 5.2224e-05 | Elapse: 0.06s\n","Epoch 2 [100/506] | Train Loss: 1.0051 Grad: 114642.4766 LR: 6.6890e-05 | Elapse: 5.93s\n","Epoch 2 [200/506] | Train Loss: 1.0109 Grad: 54453.7422 LR: 8.0129e-05 | Elapse: 11.80s\n","Epoch 2 [300/506] | Train Loss: 1.0020 Grad: 49530.3711 LR: 9.0674e-05 | Elapse: 17.65s\n","Epoch 2 [400/506] | Train Loss: 0.9903 Grad: 42100.6680 LR: 9.7515e-05 | Elapse: 23.48s\n","Epoch 2 [500/506] | Train Loss: 0.9761 Grad: 49098.9688 LR: 9.9996e-05 | Elapse: 29.30s\n","Epoch 2 [505/506] | Train Loss: 0.9753 Grad: 72887.2188 LR: 1.0000e-04 | Elapse: 29.59s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"da3109a0e6e842bb84688d003c544fa0","version_major":2,"version_minor":0},"text/plain":["Valid [1]:   0%|          | 0/125 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 2 [0/125] | Valid Loss: 0.9886 | Elapse: 0.05s\n","Epoch 2 [100/125] | Valid Loss: 1.1559 | Elapse: 5.03s\n"]},{"name":"stderr","output_type":"stream","text":["----------------------------------------------------------------------------------------------------\n","Epoch 2 - Average Loss: (train) 0.9753; (valid) 1.1520 | Time: 35.80s\n","Best model found in epoch 2 | valid loss: 1.1520\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 2 [124/125] | Valid Loss: 1.1520 | Elapse: 6.21s\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"58b8cb3374884250a3c50f6fb006bfc1","version_major":2,"version_minor":0},"text/plain":["Train [2]:   0%|          | 0/506 [00:00<?, ?batch/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 3 [0/506] | Train Loss: 1.0148 Grad: 54527.7500 LR: 1.0000e-04 | Elapse: 0.06s\n","Epoch 3 [100/506] | Train Loss: 0.8859 Grad: 143155.5938 LR: 9.9969e-05 | Elapse: 5.90s\n","Epoch 3 [200/506] | Train Loss: 0.8889 Grad: 76853.5703 LR: 9.9879e-05 | Elapse: 11.75s\n","Epoch 3 [300/506] | Train Loss: 0.8759 Grad: 64058.4180 LR: 9.9729e-05 | Elapse: 17.59s\n","Epoch 3 [400/506] | Train Loss: 0.8652 Grad: 101814.7109 LR: 9.9520e-05 | Elapse: 23.43s\n"]}],"source":["# Major Train Loop\n","# ================== Logger ==================\n","logger.info(f\"{'*' * 100}\")\n","logger.info(f\"Script Start: {ctime()}\")\n","logger.info(f\"Model Configurations:\")\n","for key, value in ModelConfig.__dict__.items():\n","    if not key.startswith(\"__\"):\n","        logger.info(f\"{key}: {value}\")\n","logger.info(f\"{'*' * 100}\")\n","\n","# ================== Prepare Training ==================\n","oof_stage_1, oof_stage_2 = pd.DataFrame(), pd.DataFrame()\n","loss_history_1, loss_history_2 = [], []\n","t_start = time()\n","\n","K_FOLDS = 5\n","train_all = prepare_k_fold(train_all, k_folds=K_FOLDS)\n","\n","for fold in range(0, K_FOLDS):\n","    tik_total = time()\n","    tik = time()\n","\n","    valid_folds = train_all[(train_all['fold'] == fold) ].reset_index(drop=True)\n","    train_folds = train_all[(train_all['fold'] != fold) ].reset_index(drop=True)\n","    train_size, valid_size = train_folds.shape[0], valid_folds.shape[0]\n","\n","    # ================== Stage 1: Train ====================\n","    # model = ResNetGRU(\n","    #     kernels=ModelConfig.RESNET_GRU_KERNELS, \n","    #     in_channels=8, \n","    #     fixed_kernel_size=ModelConfig.RESNET_GRU_FIXED_KERNEL_SIZE,\n","    #     hidden_size=ModelConfig.RESNET_GRU_HIDDEN_SIZE,\n","    #     num_classes=6\n","    #     )\n","    model = ResNetGRU(config=ModelConfig, num_classes=6)\n","\n","    ## STAGE 1\n","    logger.info(f\"{'=' * 100}\\nFold: {fold}\\n{'=' * 100}\")\n","    logger.info(f\"- Stage 1 | Train: {train_size}; Valid: {valid_size} -\")\n","    valid_predicts, loss_records = train_fold(\n","        model, fold, train_folds, valid_folds, logger, stage=1, checkpoint=None)\n","\n","    loss_history_1.append(loss_records)\n","    valid_folds[TARGETS_PRED] = valid_predicts\n","    kl_loss_torch = evaluate_oof(valid_folds)\n","    info = f\"{'=' * 100}\\nFold {fold} Valid Loss: {kl_loss_torch}\\n\"\n","    info += f\"Elapse: {(time() - tik) / 60:.2f} min \\n{'=' * 100}\"\n","    logger.info(info)\n","\n","    oof_stage_1 = pd.concat([oof_stage_1, valid_folds], axis=0).reset_index(drop=True)\n","    oof_stage_1.to_csv(os.path.join(PATHS.OUTPUT_DIR, f\"{ModelConfig.MODEL_NAME}_oof_1.csv\"), index=False)\n","\n","    # ================== Stage 2: Train ====================\n","    tik = time()\n","    # model = ResNetGRU(\n","    #     kernels=ModelConfig.RESNET_GRU_KERNELS, \n","    #     in_channels=8, \n","    #     fixed_kernel_size=ModelConfig.RESNET_GRU_FIXED_KERNEL_SIZE,\n","    #     hidden_size=ModelConfig.RESNET_GRU_HIDDEN_SIZE,\n","    #     num_classes=6\n","    #     )\n","    model = ResNetGRU(config=ModelConfig, num_classes=6)\n","    \n","    train_folds_2 = train_hard[~train_hard['eeg_id'].isin(valid_folds['eeg_id'])].reset_index(drop=True)\n","    valid_folds_2 = train_hard[ train_hard['eeg_id'].isin(valid_folds['eeg_id'])].reset_index(drop=True)\n","    train_size = train_folds_2.shape[0]\n","    valid_size = valid_folds_2.shape[0]\n","    \n","    ## STAGE 2\n","    logger.info(f\"- Stage 2 | Train: {train_size}; Valid: {valid_size} -\")\n","\n","    # model_dir = \"/home/shiyi/kaggle_hms/outputs/ResnetGRU_Originalsplit/Reg015\"\n","    # checkpoint = list(Path(model_dir).glob(f\"*_fold_{fold}_stage_1.pth\"))[0]\n","    checkpoint = list(Path(PATHS.OUTPUT_DIR).glob(f\"{ModelConfig.MODEL_NAME}_fold_{fold}_stage_1.pth\"))[0]\n","\n","    valid_predicts, loss_records = train_fold(\n","        model, fold, train_folds_2, valid_folds_2, logger, stage=2, checkpoint=checkpoint)\n","    \n","    loss_history_2.append(loss_records)\n","    valid_folds_2[TARGETS_PRED] = valid_predicts\n","    kl_loss_torch = evaluate_oof(valid_folds_2)\n","    info = f\"{'=' * 100}\\nFold {fold} Valid Loss: {kl_loss_torch}\\n\"\n","    info += f\"Elapse: {(time() - tik) / 60:.2f} min \\n{'=' * 100}\"\n","    logger.info(info)\n","\n","    oof_stage_2 = pd.concat([oof_stage_2, valid_folds_2], axis=0).reset_index(drop=True)\n","    oof_stage_2.to_csv(os.path.join(PATHS.OUTPUT_DIR, f\"{ModelConfig.MODEL_NAME}_oof_2.csv\"), index=False)\n","\n","    logger.info(f\"Fold {fold} Elapse: {(time() - tik_total) / 60:.2f} min\")\n","\n","info = f\"{'=' * 100}\\nTraining Complete!\\n\"\n","cv_results_1 = evaluate_oof(oof_stage_1)\n","cv_results_2 = evaluate_oof(oof_stage_2)\n","info += f\"CV Result: Stage 1: {cv_results_1} | Stage 2: {cv_results_2}\\n\"\n","info += f\"Elapse: {(time() - t_start) / 60:.2f} min \\n{'=' * 100}\"\n","logger.info(info)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# plot loss history\n","fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5), sharey=True)\n","\n","for i, loss in enumerate(loss_history_1):\n","    ax1.plot(loss['train'], marker=\"*\", ls=\"-\", label=f\"Fold {i} Train\")\n","    ax1.plot(loss['valid'], marker=\"o\", ls=\":\", label=f\"Fold {i} Valid\")\n","\n","for i, loss in enumerate(loss_history_2):\n","    ax2.plot(loss['train'], marker=\"*\", ls=\"-\", label=f\"Fold {i} Train\")\n","    ax2.plot(loss['valid'], marker=\"o\", ls=\":\", label=f\"Fold {i} Valid\")\n","\n","ax1.set_title(\"Stage 1 Loss\")\n","ax2.set_title(\"Stage 2 Loss\")\n","\n","for ax in (ax1, ax2):\n","    ax.set_xlabel(\"Epochs\")\n","    ax.set_ylabel(\"Loss\")\n","    ax.legend()\n","    ax.grid(True)\n","\n","fig.tight_layout()\n","fig.savefig(Path(PATHS.OUTPUT_DIR) / f\"{ModelConfig.MODEL_NAME}_loss_history.png\")\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["csv_path = f'./outputs/{ModelConfig.MODEL_NAME}_oof_1.csv'\n","print(\"CSV Path: \", csv_path)\n","\n","oof_df = analyze_oof(csv_path)\n","\n","print(\"Kaggle Score: \", calc_kaggle_score(oof_df))\n","print(\"Average KL Loss: \", oof_df[\"kl_loss\"].mean())\n","\n","display(oof_df.head())\n","\n","# plot confusion matrix\n","cm = confusion_matrix(oof_df['target_id'], oof_df['target_pred']) # (y_true, y_pred)\n","cm = cm / cm.sum(axis=1)[:, np.newaxis]\n","\n","fig = plt.figure(figsize=(6, 6))\n","sns.heatmap(cm, annot=True, cmap='Blues', xticklabels=TARGET2ID.keys(), yticklabels=TARGET2ID.keys())\n","plt.xlabel('Predicted', fontsize=12)\n","plt.ylabel('True', fontsize=12)\n","plt.title(csv_path.split('/')[-1].split('.')[0], fontsize=12)\n","fig.tight_layout()\n","fig.savefig(f\"./outputs/{csv_path.split('/')[-1].split('.')[0]}_CM.png\")\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["fig, axes = plt.subplots(5, 5, figsize=(15, 15), sharex=True, sharey=True)\n","oof_samples = oof_df.sample(axes.size)\n","\n","for i, ax in enumerate(axes.flatten()):\n","    row = oof_samples.iloc[i]\n","    x = np.arange(6)\n","    ax.plot(x, row[TARGETS].T, marker=\"o\", ls=\"-\", label=\"True\")\n","    ax.plot(x, row[TARGETS_PRED].T, marker=\"*\", ls=\"--\", label=\"Predicted\")\n","    ax.set_title(f\"{row['target']} | KL Loss: {row['kl_loss']:.4f}\")\n","    ax.legend()\n","    \n","fig.tight_layout()\n","fig.savefig(f\"./outputs/{csv_path.split('/')[-1].split('.')[0]}_samples.png\")\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["csv_path = f'./outputs/{ModelConfig.MODEL_NAME}_oof_2.csv'\n","print(\"CSV Path: \", csv_path)\n","\n","oof_df = analyze_oof(csv_path)\n","\n","print(\"Kaggle Score: \", calc_kaggle_score(oof_df))\n","print(\"Average KL Loss: \", oof_df[\"kl_loss\"].mean())\n","\n","display(oof_df.head())\n","\n","# plot confusion matrix\n","cm = confusion_matrix(oof_df['target_id'], oof_df['target_pred']) # (y_true, y_pred)\n","cm = cm / cm.sum(axis=1)[:, np.newaxis]\n","\n","fig = plt.figure(figsize=(6, 6))\n","sns.heatmap(cm, annot=True, cmap='Blues', xticklabels=TARGET2ID.keys(), yticklabels=TARGET2ID.keys())\n","plt.xlabel('Predicted', fontsize=12)\n","plt.ylabel('True', fontsize=12)\n","plt.title(csv_path.split('/')[-1].split('.')[0], fontsize=12)\n","fig.tight_layout()\n","fig.savefig(f\"./outputs/{csv_path.split('/')[-1].split('.')[0]}_CM.png\")\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["fig, axes = plt.subplots(5, 5, figsize=(15, 15), sharex=True, sharey=True)\n","oof_samples = oof_df.sample(axes.size)\n","\n","for i, ax in enumerate(axes.flatten()):\n","    row = oof_samples.iloc[i]\n","    x = np.arange(6)\n","    ax.plot(x, row[TARGETS].T, marker=\"o\", ls=\"-\", label=\"True\")\n","    ax.plot(x, row[TARGETS_PRED].T, marker=\"*\", ls=\"--\", label=\"Predicted\")\n","    ax.set_title(f\"{row['target']} | KL Loss: {row['kl_loss']:.4f}\")\n","    ax.legend()\n","    \n","fig.tight_layout()\n","fig.savefig(f\"./outputs/{csv_path.split('/')[-1].split('.')[0]}_samples.png\")\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["oof_stage_2_full = pd.DataFrame()\n","\n","for fold in range(1):\n","\n","    valid_folds = train_all[train_all['fold'] == fold].reset_index(drop=True)\n","\n","    # predict labels using stage-2 models\n","    model = ResNetGRU(\n","        kernels=ModelConfig.RESNET_GRU_KERNELS, \n","        in_channels=8, \n","        fixed_kernel_size=ModelConfig.RESNET_GRU_FIXED_KERNEL_SIZE,\n","        hidden_size=ModelConfig.RESNET_GRU_HIDDEN_SIZE,\n","        num_classes=6\n","        )\n","    \n","    check_point = os.path.join(\n","        PATHS.OUTPUT_DIR,\n","        f\"{ModelConfig.MODEL_NAME}_fold_{fold}_stage_2.pth\"\n","    )\n","\n","    model.load_state_dict(torch.load(check_point, map_location=DEVICE))\n","\n","    loader_kwargs = {\n","        \"batch_size\": ModelConfig.BATCH_SIZE,\n","        \"num_workers\": ModelConfig.NUM_WORKERS,\n","        \"pin_memory\": True,\n","        \"shuffle\": False,\n","    }\n","\n","    valid_dataset = EEGSeqDataset(\n","        valid_folds, ModelConfig, ALL_EEG_SIGNALS, mode=\"valid\", downsample=ModelConfig.RESNET_GRU_DOWNSAMPLE)\n","    valid_loader = DataLoader(valid_dataset, drop_last=False, collate_fn=None, **loader_kwargs)\n","\n","    model.to(DEVICE)\n","    model.eval()\n","\n","    valid_predicts = []\n","    with torch.no_grad():\n","        for X, y in valid_loader:\n","            X = X.to(DEVICE)\n","            y_pred = model(X)\n","            valid_predicts.append(y_pred.to('cpu').numpy())\n","\n","    valid_predicts = np.concatenate(valid_predicts)\n","    valid_folds[TARGETS_PRED] = valid_predicts\n","    oof_stage_2_full = pd.concat([oof_stage_2, valid_folds], axis=0).reset_index(drop=True)\n","\n","    del valid_dataset, valid_loader\n","    torch.cuda.empty_cache()\n","    gc.collect()\n","\n","    oof_stage_2_full.to_csv(os.path.join(PATHS.OUTPUT_DIR, f\"{ModelConfig.MODEL_NAME}_oof_2_full.csv\"), index=False)\n","\n","cv_results = evaluate_oof(oof_stage_2_full)\n","logger.info(f\"{'=' * 100}\\nCV Result (Stage 2 Full): {cv_results}\\n{'=' * 100}\")\n"]},{"cell_type":"markdown","metadata":{},"source":["Reg = 0.15, Downsample = 0, CV Result (Stage 2 Full): 0.639643669128418"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["csv_path = f'./outputs/Resnet_SeqGRU_ChrisNO_NoReg_oof_2_full.csv'\n","print(\"CSV Path: \", csv_path)\n","\n","oof_df = analyze_oof(csv_path)\n","\n","print(\"Kaggle Score: \", calc_kaggle_score(oof_df))\n","print(\"Average KL Loss: \", oof_df[\"kl_loss\"].mean())\n","\n","display(oof_df.head())\n","\n","# plot confusion matrix\n","cm = confusion_matrix(oof_df['target_id'], oof_df['target_pred']) # (y_true, y_pred)\n","cm = cm / cm.sum(axis=1)[:, np.newaxis]\n","\n","fig = plt.figure(figsize=(6, 6))\n","sns.heatmap(cm, annot=True, cmap='Blues', xticklabels=TARGET2ID.keys(), yticklabels=TARGET2ID.keys())\n","plt.xlabel('Predicted', fontsize=12)\n","plt.ylabel('True', fontsize=12)\n","plt.title(csv_path.split('/')[-1].split('.')[0], fontsize=12)\n","fig.tight_layout()\n","fig.savefig(f\"./outputs/{csv_path.split('/')[-1].split('.')[0]}_CM.png\")\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"databundleVersionId":7469972,"sourceId":59093,"sourceType":"competition"},{"sourceId":165461612,"sourceType":"kernelVersion"},{"sourceId":168718625,"sourceType":"kernelVersion"}],"dockerImageVersionId":30673,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.6"}},"nbformat":4,"nbformat_minor":4}
