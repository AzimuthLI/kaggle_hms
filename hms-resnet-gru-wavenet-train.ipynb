{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import os, gc, random\n","import numpy as np\n","import pandas as pd \n","from pathlib import Path\n","import matplotlib.pyplot as plt\n","from typing import List, Dict\n","from tqdm.notebook import tqdm\n","from time import time, ctime\n","\n","from sklearn.model_selection import KFold, GroupKFold\n","\n","import torch\n","from torch import nn\n","from torch.nn import functional as F\n","from torch.utils.data import DataLoader, Dataset\n","from torchvision.transforms import v2\n","from torch.optim.lr_scheduler import OneCycleLR,  CosineAnnealingWarmRestarts\n","from torch.optim import Adam, AdamW\n","from torch.cuda.amp import autocast, GradScaler\n","\n","from scipy.signal import butter, lfilter, freqz\n","from scipy.stats import entropy\n","from scipy.special import rel_entr, softmax"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def get_logger(log_dir, logger_name=\"train_model.log\"):\n","    from logging import getLogger, INFO, StreamHandler, FileHandler, Formatter\n","    logger_file = os.path.join(log_dir, logger_name)\n","    logger = getLogger(__name__)\n","    logger.setLevel(INFO)\n","    handler1 = StreamHandler()\n","    handler1.setFormatter(Formatter(\"%(message)s\"))\n","    handler2 = FileHandler(filename=logger_file, mode=\"a+\")\n","    handler2.setFormatter(Formatter(\"%(message)s\"))\n","    logger.addHandler(handler1)\n","    logger.addHandler(handler2)\n","    return logger\n","\n","\n","def seed_everything(seed: int):\n","    random.seed(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["class ModelConfig:\n","    SEED = 20\n","    SPLIT_ENTROPY = 5.5\n","    MODEL_NAME = \"ResnetGRU_Reg015_SplVote_6_DS5_SiLU_BPF\"\n","    MODEL_BACKBONE = \"reset_gru\"\n","    BATCH_SIZE = 32\n","    EPOCHS = 20\n","    EARLY_STOP_ROUNDS = 5\n","    GRADIENT_ACCUMULATION_STEPS = 1\n","    DROP_RATE = 0.15 # default: 0.1\n","    DROP_PATH_RATE = 0.25 # default: 0.2\n","    WEIGHT_DECAY = 0.01\n","    AMP = True\n","    PRINT_FREQ = 100\n","    NUM_WORKERS = 0 \n","    MAX_GRAD_NORM = 1e7\n","    REGULARIZATION = 0.15\n","    RESNET_GRU_BANDPASS = (0.5, 20)\n","    RESNET_GRU_IN_CHANNELS = 8\n","    RESNET_GRU_KERNELS = [3, 5, 7, 9, 11]\n","    RESNET_GRU_FIXED_KERNEL_SIZE = 5\n","    RESNET_GRU_DOWNSAMPLE = 5 # None #5\n","    RESNET_GRU_HIDDEN_SIZE = 304 #448 #304\n","    RESNET_GRU_DILATED = False"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["N_GPU = torch.cuda.device_count()\n","if N_GPU > 1:\n","    DEVICE = torch.device(\"cuda\")\n","    os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1\"\n","elif N_GPU == 1:\n","    DEVICE = torch.device(\"cuda:0\")\n","else:\n","    DEVICE = torch.device(\"cpu\")\n","\n","print(\"Use Device: \", DEVICE)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["class KagglePaths:\n","    OUTPUT_DIR = \"/kaggle/working/\"\n","    PRE_LOADED_EEGS = '/kaggle/input/brain-eeg-spectrograms/eeg_specs.npy'\n","    PRE_LOADED_SPECTROGRAMS = '/kaggle/input/brain-spectrograms/specs.npy'\n","    TRAIN_CSV = \"/kaggle/input/hms-harmful-brain-activity-classification/train.csv\"\n","    TRAIN_EEGS = \"/kaggle/input/hms-harmful-brain-activity-classification/train_eegs/\"\n","    TRAIN_SPECTROGRAMS = \"/kaggle/input/hms-harmful-brain-activity-classification/train_spectrograms/\"\n","    TEST_CSV = \"/kaggle/input/hms-harmful-brain-activity-classification/test.csv\"\n","    TEST_SPECTROGRAMS = \"/kaggle/input/hms-harmful-brain-activity-classification/test_spectrograms/\"\n","    TEST_EEGS = \"/kaggle/input/hms-harmful-brain-activity-classification/test_eegs/\"\n","\n","\n","class LocalPaths:\n","    OUTPUT_DIR = \"./outputs/\"\n","    PRE_LOADED_EEGS = './inputs/brain-eeg-spectrograms/eeg_specs.npy'\n","    PRE_LOADED_SPECTROGRAMS = './inputs/brain-spectrograms/specs.npy'\n","    TRAIN_CSV = \"./inputs/hms-harmful-brain-activity-classification/train.csv\"\n","    TRAIN_EEGS = \"./inputs/hms-harmful-brain-activity-classification/train_eegs\"\n","    TRAIN_SPECTROGRAMS = \"./inputs/hms-harmful-brain-activity-classification/train_spectrograms\"\n","    TEST_CSV = \"./inputs/hms-harmful-brain-activity-classification/test.csv\"\n","    TEST_SPECTROGRAMS = \"./inputs/hms-harmful-brain-activity-classification/test_spectrograms\"\n","    TEST_EEGS = \"./inputs/hms-harmful-brain-activity-classification/test_eegs\"\n","\n","PATHS = KagglePaths if os.path.exists(\"/kaggle\") else LocalPaths\n","\n","print(\"Output Dir: \", PATHS.OUTPUT_DIR)\n","\n","EEG_FEAT_ALL = [\n","    'Fp1', 'F3', 'C3', 'P3', \n","    'F7', 'T3', 'T5', 'O1', \n","    'Fz', 'Cz', 'Pz', 'Fp2', \n","    'F4', 'C4', 'P4', 'F8', \n","    'T4', 'T6', 'O2', 'EKG'\n","    ]\n","\n","EEG_FEAT_USE =  ['Fp1','T3','C3','O1','Fp2','C4','T4','O2']\n","EEG_FEAT_INDEX = {x:y for x,y in zip(EEG_FEAT_USE, range(len(EEG_FEAT_USE)))}\n","\n","BRAIN_ACTIVITY = ['seizure', 'lpd', 'gpd', 'lrda', 'grda', 'other']\n","TARGETS = [f\"{lb}_vote\" for lb in BRAIN_ACTIVITY]\n","TARGETS_PRED = [f\"{lb}_pred\" for lb in BRAIN_ACTIVITY]\n","\n","seed_everything(ModelConfig.SEED)\n","\n","print(EEG_FEAT_INDEX)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["logger = get_logger(PATHS.OUTPUT_DIR, f\"{ModelConfig.MODEL_NAME}_train.log\")"]},{"cell_type":"markdown","metadata":{},"source":["# Load Data"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def eeg_from_parquet(parquet_path: str, use_feature=EEG_FEAT_USE, display: bool = False) -> np.ndarray:\n","    # === Extract full length EEG Sequence ===\n","    # fill missing values with mean\n","    # first fill missing values with mean of each column\n","    # then if all values are missing, fill with 0\n","    eeg = pd.read_parquet(parquet_path, columns=use_feature)\n","    eeg = eeg.fillna(eeg.mean(skipna=True)).fillna(0)\n","    data = eeg.values.astype(np.float32)\n","    \n","    rows = len(eeg)\n","    offset = (rows - 10_000) // 2 # 50 * 200 = 10_000\n","    data = data[offset:offset+10_000, :]\n","\n","    if display:\n","        fig, ax = plt.subplots(len(use_feature), 1, figsize=(10, 2*len(use_feature)), sharex=True)\n","        \n","        for i, feat in enumerate(use_feature):\n","            ax[i].plot(data[:, i], label=feat)\n","            ax[i].legend()\n","            ax[i].grid()\n","       \n","        name = parquet_path.split('/')[-1].split('.')[0]\n","        ax[0].set_title(f'EEG {name}',size=16)\n","        fig.tight_layout()\n","        plt.show()    \n","    return data"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["%%time\n","CREATE_EEGS = False\n","ALL_EEG_SIGNALS = {}\n","eeg_paths = list(Path(PATHS.TRAIN_EEGS).glob('*.parquet'))\n","preload_eegs_path = Path('./inputs/eegs_full.npy')\n","\n","if CREATE_EEGS:\n","    count = 0\n","    for parquet_path in tqdm(eeg_paths, total=len(eeg_paths)):\n","        eeg_id = int(parquet_path.stem)\n","        eeg_path = str(parquet_path)\n","        data = eeg_from_parquet(eeg_path, display=False)\n","        ALL_EEG_SIGNALS[eeg_id] = data\n","        count += 1\n","    np.save(\"./inputs/eegs_full.npy\", ALL_EEG_SIGNALS)\n","else:\n","    ALL_EEG_SIGNALS = np.load(preload_eegs_path, allow_pickle=True).item()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def gen_non_overlap_samples(df_csv, targets):\n","    # Reference Discussion:\n","    # https://www.kaggle.com/competitions/hms-harmful-brain-activity-classification/discussion/467021\n","\n","    tgt_list = targets.tolist()\n","    brain_activity = ['seizure', 'lpd', 'gpd', 'lrda', 'grda', 'other']\n","\n","    agg_dict = {\n","        'spectrogram_id': 'first',\n","        'spectrogram_label_offset_seconds': ['min', 'max'],\n","        'patient_id': 'first',\n","        'expert_consensus': 'first'\n","    }\n","\n","    groupby = df_csv.groupby(['eeg_id'] + tgt_list)\n","    train = groupby.agg(agg_dict)\n","    train = train.reset_index()\n","    train.columns = ['_'.join(col).strip() for col in train.columns.values]\n","    train.columns = [\"eeg_id\"] + tgt_list + ['spectrogram_id', 'min', 'max', 'patient_id', 'target']\n","    \n","    train['total_votes'] = train[tgt_list].sum(axis=1)\n","    train[tgt_list] = train[tgt_list].div(train['total_votes'], axis=0)\n","    \n","    return train"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# # Enhanced Samples Split \n","\n","# train_csv = pd.read_csv(PATHS.TRAIN_CSV)\n","# targets = train_csv.columns[-6:].tolist()\n","\n","# raw_csv_len = len(train_csv)\n","\n","# subset_counts = train_csv.groupby(['eeg_id']+targets).size().reset_index(name='subset_counts')\n","# train_csv = train_csv.merge(subset_counts, on=['eeg_id']+targets, how='left')\n","\n","# tmp_cols = ['expert_consensus', 'eeg_label_offset_seconds', 'subset_counts']\n","\n","# def sample_rule(x):\n","#     if (x['subset_counts'].min() > 3) & ((x['expert_consensus']!='Other').any()):\n","#         return x['eeg_label_offset_seconds'].sample(n=(x['subset_counts'].min()//3))\n","#     else:\n","#         return x['eeg_label_offset_seconds'].sample(n=1)\n","\n","# train_samples = train_csv.groupby(['eeg_id']+targets)[tmp_cols].apply(sample_rule).reset_index()\n","# train_samples = train_samples.rename(columns={'eeg_label_offset_seconds': 'eeg_off_seconds'})\n","# train_samples.drop(columns=['level_7'], inplace=True)\n","\n","# train_meta = train_csv.groupby(['eeg_id']+targets).agg({\n","#     'spectrogram_id': 'first',\n","#     'spectrogram_label_offset_seconds': ['min', 'max'],\n","#     'eeg_sub_id': 'count',\n","#     'eeg_label_offset_seconds': ['min', 'max'],\n","#     'patient_id': 'first',\n","# }).reset_index()\n","\n","# agged_cols = [\n","#     'spectrogram_id', 'min', 'max', 'subset_counts', 'eeg_off_min', 'eeg_off_max', 'patient_id'\n","# ]\n","# train_meta.columns = ['eeg_id'] + targets + agged_cols\n","# train_meta = train_meta[['eeg_id'] + agged_cols + targets]\n","\n","# train_meta['total_votes'] = train_meta[targets].sum(axis=1)\n","# train_meta['target'] = train_meta[targets].idxmax(axis=1).apply(lambda x: x.split('_')[0])\n","# train_meta['fold'] = -1\n","\n","# K_FOLDS = 5\n","# kf = KFold(n_splits=K_FOLDS, shuffle=False)\n","# unique_eegs = train_meta['eeg_id'].unique()\n","# for fold, (_, valid_idx) in enumerate(kf.split(unique_eegs)):\n","#     train_meta.loc[train_meta['eeg_id'].isin(unique_eegs[valid_idx]), 'fold'] = fold\n","\n","# train_all = train_samples.merge(train_meta, on=['eeg_id']+targets, how='left')\n","\n","# train_all[targets] = train_all[targets].div(train_all['total_votes'], axis=0)\n","\n","# train_all['stage'] = train_all['total_votes'].apply(lambda x: 1 if x < 10 else 2)\n","\n","# train_all"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# # Konsantin's Split\n","\n","# train_csv = pd.read_csv(PATHS.TRAIN_CSV)\n","# targets = train_csv.columns[-6:].tolist()\n","\n","# raw_csv_len = len(train_csv)\n","\n","# train_all = train_csv.drop_duplicates(subset=[\"eeg_id\"] + targets).reset_index(drop=True)\n","# print(f\"Raw CSV: {raw_csv_len} | Unique CSV: {len(train_all)}\")\n","\n","# train_all['total_votes'] = train_all[targets].sum(axis=1)\n","\n","# train_all.rename(columns={'eeg_label_offset_seconds': 'eeg_off_min', 'expert_consensus': 'target'}, inplace=True)\n","# train_all.drop(columns=['eeg_sub_id', 'spectrogram_label_offset_seconds', 'spectrogram_sub_id', 'label_id'], inplace=True)\n","\n","# train_all[targets] = train_all[targets].div(train_all['total_votes'], axis=0)\n","\n","# pop_bands = [(1, 3), (4, 4), (5, 5), (6, 28)]\n","# def classify_pops(x):\n","#     for i, (lb, ub) in enumerate(pop_bands):\n","#         if (x >= lb) & (x <= ub):\n","#             return i\n","\n","# train_all['pop_id'] = train_all['total_votes'].apply(classify_pops)\n","\n","# K_FOLDS = 5\n","# train_all['fold'] = -1\n","# gkf = GroupKFold(n_splits=K_FOLDS)\n","# gkf_split = gkf.split(train_all, y=train_all['target'], groups=train_all['patient_id'])\n","# for fold, (_, valid_idx) in enumerate(gkf_split):\n","#     train_all.loc[valid_idx, 'fold'] = fold\n","    \n","# train_pop2 = train_all[train_all['pop_id'] == 3].copy().reset_index(drop=True)\n","\n","# gkf = GroupKFold(n_splits=K_FOLDS)\n","# gkf_split = gkf.split(train_pop2, y=train_pop2['target'], groups=train_pop2['patient_id'])\n","# for fold, (_, valid_idx) in enumerate(gkf_split):\n","#     train_pop2.loc[valid_idx, 'fold'] = fold\n","    \n","# print(train_all.shape, train_pop2.shape)\n","\n","# train_all.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Data Split\n","# train_csv = pd.read_csv(PATHS.TRAIN_CSV)\n","# targets = train_csv.columns[-6:].tolist()\n","\n","# print(\"targets: \", targets)\n","\n","# train_csv['total_votes'] = train_csv[targets].sum(axis=1)\n","\n","# targets_prob = [f\"{t.split('_')[0]}_prob\" for t in targets]\n","# train_csv[targets_prob] = train_csv[targets].div(train_csv['total_votes'], axis=0)\n","\n","# train_csv['entropy'] = train_csv[targets_prob].apply(lambda row: sum(rel_entr([1/6]*6, row.values+1e-5)), axis=1)\n","# train_csv['is_hard'] = (train_csv['entropy'] < 5.5).astype(int)\n","\n","# agg_dicts = {\n","#     'spectrogram_id': 'first',\n","#     'spectrogram_label_offset_seconds': ['min', 'max'],\n","#     'eeg_label_offset_seconds': ['min', 'max', lambda x: x.sample(1)],\n","#     'patient_id': 'first',\n","#     'expert_consensus': 'first',\n","#     'total_votes': 'sum',\n","#     'entropy': 'mean',\n","#     'is_hard': 'mean'\n","# }\n","\n","# for col in targets:\n","#     agg_dicts[col] = 'sum'\n","\n","# train_all = train_csv.groupby(['eeg_id']+targets_prob).agg(agg_dicts).reset_index()\n","\n","# col_names = [\n","#     'spectrogram_id', 'min', 'max', 'eeg_off_min', 'eeg_off_max', 'eeg_off_sample', \n","#     'patient_id', 'target', 'total_votes', 'entropy', 'is_hard'\n","#     ] + targets\n","\n","# train_all.columns = [\"eeg_id\"] + targets_prob + col_names\n","# train_all.drop(targets_prob, axis=1, inplace=True)\n","# train_all[targets] = train_all[targets].div(train_all['total_votes'], axis=0)\n","# train_all['is_stage'] = 1\n","# train_all.loc[(train_all['total_votes']>10) | (train_all['entropy']<5.5), 'is_stage'] = 2\n","\n","# train_all['sample_weight'] = 1.0\n","\n","# print(\"train_all: \", train_all.shape)\n","# print(\"hard samples ratio: \", train_all[train_all['is_hard']==1].shape[0] / train_all.shape[0])\n","# print(\"easy samples ratio: \", train_all[train_all['is_hard']==0].shape[0] / train_all.shape[0])\n","\n","# K_FOLDS = 5\n","# unique_eegs = train_all['eeg_id'].unique()\n","# kf = KFold(n_splits=K_FOLDS)\n","\n","# train_all['fold'] = -1\n","\n","# for fold, (train_index, valid_index) in enumerate(kf.split(unique_eegs)):\n","#     train_all.loc[train_all['eeg_id'].isin(unique_eegs[valid_index]), 'fold'] = fold\n","\n","# print(\"train_all: \", train_all.shape)\n","# for fold in range(K_FOLDS):\n","#     train_size = train_all[train_all['fold'] != fold].shape[0]\n","#     valid_size = train_all[train_all['fold'] == fold].shape[0]\n","#     train_hard_size = train_all[(train_all['fold'] != fold) & (train_all['is_stage'] == 2)].shape[0]\n","#     valid_hard_size = train_all[(train_all['fold'] == fold) & (train_all['is_stage'] == 2)].shape[0]\n","#     print(f\"Fold {fold}: All Size: {train_size} | {valid_size}, Hard Size: {train_hard_size} | {valid_hard_size}\")\n","\n","# train_all.head(15)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Original Split \n","\n","train_csv = pd.read_csv(PATHS.TRAIN_CSV)\n","targets = train_csv.columns[-6:]\n","\n","print(\"targets: \", targets.to_list())\n","\n","train_csv['total_votes'] = train_csv[targets].sum(axis=1)\n","train_csv[targets] = train_csv[targets].astype('float32')\n","\n","targets_prob = [f\"{t.split('_')[0]}_prob\" for t in targets]\n","train_csv[targets_prob] = train_csv[targets].div(train_csv['total_votes'], axis=0)\n","# train_csv['rel_entropy'] = train_csv[targets_prob].apply(lambda row: sum(rel_entr([1/6]*6, row.values+1e-5)), axis=1)\n","# train_csv['entropy'] = train_csv[targets_prob].apply(lambda row: entropy(row.values), axis=1)\n","\n","# hard_csv = train_csv[train_csv['entropy'] < ModelConfig.SPLIT_ENTROPY].copy().reset_index(drop=True)\n","# hard_csv = train_csv[train_csv['entropy'] >= 0.75].copy().reset_index(drop=True)\n","hard_csv = train_csv[train_csv['total_votes'] >= 6].copy().reset_index(drop=True)\n","\n","\n","train_all = gen_non_overlap_samples(train_csv, targets)\n","train_hard = gen_non_overlap_samples(hard_csv, targets)\n","\n","print(\"train_all.shape = \", train_all.shape)\n","print(\"train_all nan_count: \", train_all.isnull().sum().sum())\n","display(train_all.head())\n","\n","print(\" \")\n","\n","print(\"train_hard.shape = \", train_hard.shape)\n","print(\"train_hard nan_count: \", train_hard.isnull().sum().sum())\n","display(train_hard.head())"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# for fold in range(K_FOLDS):\n","#     train_eegs = train_all[train_all['fold'] != fold]['eeg_id']\n","#     valid_eegs = train_all[train_all['fold'] == fold]['eeg_id']\n","    \n","#     print(f\"Leakage in Fold {fold}: \", train_eegs.isin(valid_eegs).sum())"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# fig, axes = plt.subplots(1, 5, figsize=(15, 3), sharey=True)\n","# for i in range(5):\n","#     tmp = train_all[train_all['fold']==i]\n","#     (tmp['target'].value_counts() / len(tmp)).plot(kind='bar', ax=axes[i])\n","#     axes[i].set_title(f'Fold {i} | {len(tmp)} samples')\n","#     axes[i].grid()\n","# plt.tight_layout()\n","# plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# fig, axes = plt.subplots(1, 5, figsize=(15, 3), sharey=True)\n","# for i in range(5):\n","#     tmp = train_pop2[(train_pop2['fold']==i)]\n","#     (tmp['target'].value_counts() / len(tmp)).plot(kind='bar', ax=axes[i])\n","#     axes[i].set_title(f'Fold {i} | {len(tmp)} samples')\n","#     axes[i].grid()\n","# plt.tight_layout()\n","# plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# train_all[train_all['eeg_id']==2259539799] #['eeg_label_offset_seconds']#.groupby(['eeg_id']+targets).size().reset_index(name='subset_counts').sort_values('subset_counts')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# eeg_df = pd.read_parquet(f\"{PATHS.TRAIN_EEGS}/2259539799.parquet\")\n","# eeg_subset = eeg_df[EEG_FEAT_USE].values\n","\n","# start_offsets = train_all[train_all['eeg_id']==2259539799]['eeg_off_seconds'].values\n","\n","# fig, axes = plt.subplots(10, 1, figsize=(10, 30), sharex=True)\n","\n","# idx = 1\n","# for i, ax in enumerate(axes):\n","#     data = eeg_subset[int(start_offsets[idx]*200):int(start_offsets[idx]*200)+10000, :]\n","#     seq = data[:,EEG_FEAT_INDEX['Fp1']] - data[:,EEG_FEAT_INDEX['T3']]\n","#     ax.plot(seq[::5], label=f'Fp1 - T3 ({idx})')\n","#     ax.legend()\n","#     idx += 20\n","\n","# fig.tight_layout()\n","# plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# # Chris Deotte's Method for Get_non_overlap\n","\n","# train_csv = pd.read_csv(PATHS.TRAIN_CSV)\n","# targets = train_csv.columns[-6:].tolist()\n","\n","# print(\"targets: \", targets)\n","\n","# train_csv['total_votes'] = train_csv[targets].sum(axis=1)\n","\n","# targets_prob = [f\"{t.split('_')[0]}_prob\" for t in targets]\n","# train_csv[targets_prob] = train_csv[targets].div(train_csv['total_votes'], axis=0)\n","# train_csv['entropy'] = train_csv[targets_prob].apply(lambda row: entropy(row.values+1e-5), axis=1)\n","\n","# # split into easy and hard using totoal_votes\n","# train_csv['is_hard'] = (train_csv['total_votes']>10).astype(int) #(train_csv['entropy'] > 0.875).astype(int)\n","\n","# train_all = get_non_overlap(train_csv, targets)\n","# print(\"train_all: \", train_all.shape)\n","\n","# K_FOLDS = 5\n","\n","# gkf = GroupKFold(n_splits=K_FOLDS)\n","# for fold, (train_idx, valid_idx) in enumerate(gkf.split(train_all, groups=train_all['patient_id'])):\n","#     train_all.loc[valid_idx, 'fold'] = fold\n","\n","# print(\"train_all: \", train_all.shape)\n","# for fold in range(K_FOLDS):\n","#     train_size = train_all[train_all['fold'] != fold].shape[0]\n","#     valid_size = train_all[train_all['fold'] == fold].shape[0]\n","#     print(f\"Fold {fold}: Train Size: {train_size}, Valid Size: {valid_size}\")\n","\n","# train_all.head(15)\n","\n","# # Get Non Overlap for Hard EEGs\n","\n","# hard_csv = train_csv[train_csv['is_hard'] == 1].copy().reset_index(drop=True)\n","\n","# agg_dicts = {\n","#     'spectrogram_id': 'first',\n","#     'spectrogram_label_offset_seconds': ['min', 'max'],\n","#     'eeg_label_offset_seconds': ['min', 'max', lambda x: x.sample(1).values[0]],\n","#     'patient_id': 'first',\n","#     'total_votes': 'sum',\n","#     'entropy': 'mean',\n","#     'is_hard': 'mean'\n","# }\n","\n","# for col in targets:\n","#     agg_dicts[col] = 'sum'\n","\n","# train_hard = hard_csv.groupby(['eeg_id']+targets_prob).agg(agg_dicts).reset_index()\n","\n","# col_names = [\n","#     'spectrogram_id', 'min', 'max', 'eeg_off_min', 'eeg_off_max', 'eeg_off_sample',\n","#     'patient_id', 'total_votes', 'entropy', 'is_hard'\n","#     ] + targets\n","\n","# train_hard.columns = [\"eeg_id\"] + targets_prob + col_names\n","# train_hard[targets] = train_hard[targets].div(train_hard['total_votes'], axis=0)\n","# train_hard.drop(targets_prob, axis=1, inplace=True)\n","\n","# train_hard['target'] = train_hard[targets].idxmax(axis=1)\n","# train_hard['target'] = train_hard['target'].apply(lambda x: x.split('_')[0])\n","# train_hard['fold'] = -1\n","\n","# print(\"train_hard: \", train_hard.shape)\n","\n","# train_hard.head()\n","\n","# K_FOLDS = 5\n","\n","# for fold in range(K_FOLDS):\n","#     train_hard.loc[train_hard['eeg_id'].isin(train_all[train_all['fold'] == fold]['eeg_id']), 'fold'] = fold\n","    \n","# print(train_hard['fold'].value_counts())"]},{"cell_type":"markdown","metadata":{},"source":["# Dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Functional Utils\n","def butter_bandpass_filter(data, lowcut, highcut, fs, order=5):\n","    b, a = butter(order, [lowcut, highcut], fs=fs, btype='band')\n","    y = lfilter(b, a, data)\n","    return y\n","\n","def denoise_filter(x):\n","    # Sample rate and desired cutoff frequencies (in Hz).\n","    fs = 200.0\n","    lowcut = 1.0\n","    highcut = 25.0\n","    \n","    # Filter a noisy signal.\n","    T = 50\n","    nsamples = T * fs\n","    t = np.arange(0, nsamples) / fs\n","    y = butter_bandpass_filter(x, lowcut, highcut, fs, order=6)\n","    y = (y + np.roll(y,-1)+ np.roll(y,-2)+ np.roll(y,-3))/4\n","    y = y[0:-1:4]\n","    \n","    return y\n","\n","def mu_law_encoding(data, mu):\n","    mu_x = np.sign(data) * np.log(1 + mu * np.abs(data)) / np.log(mu + 1)\n","    return mu_x\n","\n","def mu_law_expansion(data, mu):\n","    s = np.sign(data) * (np.exp(np.abs(data) * np.log(mu + 1)) - 1) / mu\n","    return s\n","\n","def quantize_data(data, classes):\n","    mu_x = mu_law_encoding(data, classes)\n","    return mu_x #quantized\n","\n","def butter_lowpass_filter(data, cutoff_freq=20, sampling_rate=200, order=4):\n","    nyquist = 0.5 * sampling_rate\n","    normal_cutoff = cutoff_freq / nyquist\n","    b, a = butter(order, normal_cutoff, btype='low', analog=False)\n","    filtered_data = lfilter(b, a, data, axis=0)\n","    return filtered_data\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["class EEGSeqDataset(Dataset):\n","    def __init__(self, df, config, eegs, mode='train', verbose=False):\n","        self.df = df\n","        self.mode = mode\n","        self.eegs = eegs\n","        self.verbose = verbose\n","        self.downsample = config.RESNET_GRU_DOWNSAMPLE\n","        self.use_bandpass = config.RESNET_GRU_BANDPASS\n","    \n","    def __len__(self):\n","        return len(self.df)\n","\n","    def __getitem__(self, idx):\n","        \n","        X, y_prob = self.__data_generation(idx)\n","        \n","        if self.downsample is not None:\n","            X = X[::self.downsample,:]\n","        \n","        return torch.tensor(X, dtype=torch.float32), torch.tensor(y_prob, dtype=torch.float32)\n","    \n","    def __data_generation(self, index):\n","        row = self.df.iloc[index]\n","        \n","        if self.verbose:\n","            print(f\"Row {index}\", row[['eeg_id', 'eeg_off_min', 'target']].tolist())\n","\n","        X = np.zeros((10_000, 8), dtype='float32')\n","        \n","        # # start_sec = int((row['eeg_off_min'] + row['eeg_off_max']) // 2)\n","        # eeg_seq = self.eegs[row.eeg_id]\n","        # len_seq = eeg_seq.shape[0]\n","        # start_at = int(row['eeg_off_min']) + (len_seq - 10_000) // 2 \n","        # # !!! use randomly sampled offset !!!\n","        # # start_sec = int(row['eeg_off_sample']) \n","        # data = eeg_seq[start_at:start_at+10_000, :]\n","        \n","        data = self.eegs[row.eeg_id]\n","\n","        # === Feature engineering ===\n","        X[:,0] = data[:,EEG_FEAT_INDEX['Fp1']] - data[:,EEG_FEAT_INDEX['T3']]\n","        X[:,1] = data[:,EEG_FEAT_INDEX['T3']] - data[:,EEG_FEAT_INDEX['O1']]\n","\n","        X[:,2] = data[:,EEG_FEAT_INDEX['Fp1']] - data[:,EEG_FEAT_INDEX['C3']]\n","        X[:,3] = data[:,EEG_FEAT_INDEX['C3']] - data[:,EEG_FEAT_INDEX['O1']]\n","\n","        X[:,4] = data[:,EEG_FEAT_INDEX['Fp2']] - data[:,EEG_FEAT_INDEX['C4']]\n","        X[:,5] = data[:,EEG_FEAT_INDEX['C4']] - data[:,EEG_FEAT_INDEX['O2']]\n","\n","        X[:,6] = data[:,EEG_FEAT_INDEX['Fp2']] - data[:,EEG_FEAT_INDEX['T4']]\n","        X[:,7] = data[:,EEG_FEAT_INDEX['T4']] - data[:,EEG_FEAT_INDEX['O2']]\n","\n","        # === Standarize ===\n","        X = np.clip(X,-1024, 1024)\n","        X = np.nan_to_num(X, nan=0) / 32.0\n","\n","        # === Butter Low-pass Filter ===\n","        # ??? change to bandpass filter (low=0.5, hight=20, order=2) ???\n","        if self.use_bandpass is not None:\n","            X = butter_lowpass_filter(X, self.use_bandpass[0], self.use_bandpass[1], order=2)\n","            \n","        X = butter_lowpass_filter(X) \n","        \n","        if self.mode != 'test':\n","            y_prob = row[TARGETS].values.astype(np.float32)\n","        else:\n","            y_prob = np.zeros(6, dtype='float32')\n","\n","        return X, y_prob "]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# visualize the dataset\n","train_dataset = EEGSeqDataset(train_all, ModelConfig, ALL_EEG_SIGNALS, mode=\"train\")\n","train_loader = DataLoader(train_dataset, drop_last=True, batch_size=16, num_workers=4, pin_memory=True, shuffle=False)\n","\n","for batch in train_loader:\n","    X, y = batch\n","    print(f\"X shape: {X.shape}\")\n","    print(f\"y shape: {y.shape}\")\n","    \n","    fig, axes = plt.subplots(4, 1, figsize=(20, 20))\n","    ax_idx = 0\n","    for item in np.random.choice(range(X.shape[0]), 4):\n","        offset = 0\n","        for col in range(X.shape[-1]):\n","            if col != 0:\n","                offset -= X[item,:,col].min()\n","            axes[ax_idx].plot(np.arange(X.shape[1]), X[item,:,col]+offset, label=f'feature {col+1}')\n","            offset += X[item,:,col].max()\n","        print(y[item])\n","        # axes[ax_idx].set_title(f'Weight = {weights[item]}',size=14)\n","        axes[ax_idx].legend()\n","        ax_idx += 1\n","    fig.tight_layout()\n","    plt.show()\n","    break\n","\n","del train_dataset, train_loader\n","torch.cuda.empty_cache()\n","gc.collect()"]},{"cell_type":"markdown","metadata":{},"source":["# Model"]},{"cell_type":"markdown","metadata":{},"source":["### Sequencial GRU Encoder"]},{"cell_type":"code","execution_count":null,"metadata":{"jupyter":{"source_hidden":true},"trusted":true},"outputs":[],"source":["class SeqGRUEncoder(nn.Module):\n","    def __init__(self, in_channels, hidden_size=128, num_layers=2, bidirectional=True):\n","        super(SeqGRUEncoder, self).__init__()\n","\n","        self.in_channels = in_channels\n","\n","        # Initialize the GRU to have 128 hidden units per direction and to be bidirectional\n","        self.rnn = nn.GRU(\n","            input_size=in_channels, \n","            hidden_size=hidden_size, \n","            num_layers=num_layers,\n","            bidirectional=bidirectional, \n","            batch_first=True\n","        )\n","        \n","        # Initialize the attention mechanism\n","        if bidirectional:\n","            emb_dim = 2 * hidden_size\n","        else:\n","            emb_dim = hidden_size\n","        \n","        # self.attention_dense = nn.Linear(emb_dim, 1)\n","        # self.softmax = nn.Softmax(dim=-1)\n","\n","    def forward(self, x):\n","        # x shape: [batch, seq_len, in_channels]\n","        rnn_out, _ = self.rnn(x)  # -> [batch, seq_len, emb_dim]\n","        identity = rnn_out[:, -1, :].squeeze(1)\n","        # scores = self.attention_dense(rnn_out).squeeze(-1)\n","        # scores = self.softmax(scores).unsqueeze(1)\n","        # pooled_out = torch.matmul(scores, identity).squeeze(1)\n","        # -> [batch_size, emb_dim]\n","        return identity"]},{"cell_type":"markdown","metadata":{},"source":["### Resnet 1D Encoder"]},{"cell_type":"code","execution_count":null,"metadata":{"jupyter":{"source_hidden":true},"trusted":true},"outputs":[],"source":["class ResNet_1D_Block(nn.Module):\n","    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, downsampling, dropout=0.0, dilation=1):\n","        super(ResNet_1D_Block, self).__init__()\n","        self.block = nn.Sequential(\n","            nn.BatchNorm1d(num_features=in_channels),\n","            nn.Hardswish(), #nn.ReLU(),\n","            nn.Dropout(p=dropout),\n","            nn.Conv1d(in_channels, out_channels, kernel_size, stride, padding, dilation=dilation, bias=False),\n","            nn.BatchNorm1d(num_features=out_channels),\n","            nn.Hardswish(), #nn.ReLU(),\n","            nn.Dropout(p=dropout),\n","            nn.Conv1d(out_channels, out_channels, kernel_size, stride, padding, dilation=dilation, bias=False),\n","            nn.MaxPool1d(kernel_size=2, stride=2, padding=0)\n","        )\n","        self.downsampling = downsampling\n","\n","    def forward(self, x):\n","        identity = self.downsampling(x)\n","        out = self.block(x)\n","        out += identity\n","        return out\n","\n","class SelfAttentionPooling(nn.Module):\n","    \"\"\"\n","    Implementation of SelfAttentionPooling \n","    Original Paper: Self-Attention Encoding and Pooling for Speaker Recognition\n","    https://arxiv.org/pdf/2008.01077v1.pdf\n","    \"\"\"\n","    def __init__(self, input_dim):\n","        super(SelfAttentionPooling, self).__init__()\n","        self.W = nn.Linear(input_dim, 1)\n","        self.softmax = nn.Softmax(dim=1)\n","        \n","    def forward(self, batch_rep):\n","        \"\"\"\n","        input:\n","            batch_rep : size (N, T, H), N: batch size, T: sequence length, H: Hidden dimension\n","        \n","        attention_weight:\n","            att_w : size (N, T, 1)\n","        \n","        return:\n","            utter_rep: size (N, H)\n","        \"\"\"\n","        softmax = nn.functional.softmax\n","        att_w = self.softmax(self.W(batch_rep).squeeze(-1)).unsqueeze(-1)\n","        utter_rep = torch.sum(batch_rep * att_w, dim=1)\n","\n","        return utter_rep\n","\n","class ResNetGRU(nn.Module):\n","    def __init__(self, config=ModelConfig, num_classes=6):\n","        super(ResNetGRU, self).__init__()\n","\n","        self.planes = 24\n","        self.kernels = config.RESNET_GRU_KERNELS\n","        self.in_channels = config.RESNET_GRU_IN_CHANNELS\n","        self.use_dilation = config.RESNET_GRU_DILATED\n","\n","        fixed_kernel_size = config.RESNET_GRU_FIXED_KERNEL_SIZE\n","        hidden_size = config.RESNET_GRU_HIDDEN_SIZE\n","\n","        # Define the separate convolutional layers\n","        self.parallel_conv = self._make_parallel_conv_layers()\n","        # Define the ResNet part of the model\n","        self.resnet_part = self._make_resnet_part(fixed_kernel_size, n_blocks=9)\n","        # Define the GRU part of the model\n","        self.rnn = nn.GRU(input_size=self.in_channels, hidden_size=128, num_layers=1, bidirectional=True)\n","        self.pooling = SelfAttentionPooling(256)\n","        # Define the final fully connected layer\n","        self.fc = nn.Linear(in_features=hidden_size, out_features=num_classes)\n","\n","    def _make_parallel_conv_layers(self):\n","        return nn.ModuleList([\n","            nn.Conv1d(\n","                in_channels=self.in_channels, \n","                out_channels=self.planes, \n","                kernel_size=kernel_size,\n","                stride=1, \n","                padding=0, \n","                bias=False\n","            ) for kernel_size in self.kernels\n","        ])\n","\n","    def _make_resnet_part(self, fixed_kernel_size, n_blocks=9):\n","        # prepare resnet layers\n","        downsampling = nn.MaxPool1d(kernel_size=2, stride=2, padding=0)\n","\n","        if self.use_dilation:\n","            dilation_rates = [1, 2, 2, 2, 2, 4, 4, 4, 4] #[1] * n_blocks\n","        else:\n","            dilation_rates = [1] * n_blocks\n","\n","        paddings = [fixed_kernel_size//2 * rate for rate in dilation_rates]\n","        resnet_layers = [\n","            ResNet_1D_Block(\n","                in_channels=self.planes, \n","                out_channels=self.planes, \n","                kernel_size=fixed_kernel_size, \n","                stride=1, \n","                padding=paddings[i], \n","                downsampling=downsampling,\n","                dropout=0.0,\n","                dilation=dilation_rates[i])\n","            for i in range(n_blocks)\n","        ]\n","        # return the resnet encoder\n","        return nn.Sequential(\n","            nn.BatchNorm1d(num_features=self.planes),\n","            nn.SiLU(), #nn.ReLU(inplace=False),\n","            nn.Conv1d(\n","                in_channels=self.planes, \n","                out_channels=self.planes, \n","                kernel_size=fixed_kernel_size, \n","                stride=2, \n","                padding=2, \n","                bias=False\n","            ),\n","            *resnet_layers,\n","            nn.BatchNorm1d(num_features=self.planes),\n","            nn.SiLU(), #nn.ReLU(inplace=False),\n","            nn.AvgPool1d(kernel_size=6, stride=6, padding=2)\n","        )\n","    \n","    def forward(self, x):\n","        # extract features using resnet \n","        x = x.permute(0, 2, 1)\n","        out_sep = [conv(x) for conv in self.parallel_conv]\n","        out = torch.cat(out_sep, dim=2)\n","        out = self.resnet_part(out)\n","        out = out.reshape(out.shape[0], -1)\n","        # extract features using rnn\n","        rnn_out, _ = self.rnn(x.permute(0, 2, 1))\n","        new_rnn_h = self.pooling(rnn_out)\n","        # concatenate the features\n","        new_out = torch.cat([out, new_rnn_h], dim=1) \n","        # total features = 424 = 24*6 + 128*2 \n","        # pass through the final fully connected layer\n","        result = self.fc(new_out)  \n","        \n","        return result\n"]},{"cell_type":"markdown","metadata":{},"source":["### Dilated Inception Wavenet Encoder"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# from typing import List\n","\n","# class DilatedInception(nn.Module):\n","#     def __init__(self, in_channels: int, out_channels: int, kernel_sizes: List[int], dilation: int) -> None:\n","#         super().__init__()\n","#         assert out_channels % len(kernel_sizes) == 0, \"`out_channels` must be divisible by the number of kernel sizes.\"\n","#         hidden_dim = out_channels // len(kernel_sizes)\n","#         self.convs = nn.ModuleList([\n","#             nn.Conv1d(in_channels, hidden_dim, k, padding='same', dilation=dilation)\n","#             for k in kernel_sizes\n","#         ])\n","\n","#     def forward(self, x):\n","#         outputs = [conv(x) for conv in self.convs]\n","#         out = torch.cat(outputs, dim=1)\n","#         return out\n","\n","# class GatedTCN(nn.Module):\n","#     def __init__(self, in_dim: int, h_dim: int, kernel_sizes: List[int], dilation_factor: int, dropout: float = 0.0) -> None:\n","#         super().__init__()\n","#         self.filt = DilatedInception(in_dim, h_dim, kernel_sizes, dilation=dilation_factor)\n","#         self.gate = DilatedInception(in_dim, h_dim, kernel_sizes, dilation=dilation_factor)\n","#         self.dropout = nn.Dropout(dropout)\n","\n","#     def forward(self, x):\n","#         x_filt = torch.tanh(self.filt(x))\n","#         x_gate = torch.sigmoid(self.gate(x))\n","#         h = x_filt * x_gate\n","#         h = self.dropout(h)\n","#         return h\n","\n","# class WaveBlock(nn.Module):\n","#     def __init__(self, n_layers: int, in_dim: int, h_dim: int, kernel_sizes: List[int]) -> None:\n","#         super().__init__()\n","#         self.dilation_rates = [2**i for i in range(n_layers)]\n","#         self.in_conv = nn.Conv1d(in_dim, h_dim, kernel_size=1)\n","#         self.gated_tcns = nn.ModuleList([\n","#             GatedTCN(h_dim, h_dim, kernel_sizes, dilation)\n","#             for dilation in self.dilation_rates\n","#         ])\n","#         self.skip_convs = nn.ModuleList([\n","#             nn.Conv1d(h_dim, h_dim, kernel_size=1)\n","#             for _ in range(n_layers)\n","#             ])\n","#         self._initialize_weights()\n","\n","#     def _initialize_weights(self):\n","#         nn.init.xavier_uniform_(self.in_conv.weight, gain=nn.init.calculate_gain('relu'))\n","#         nn.init.zeros_(self.in_conv.bias)\n","#         for conv in self.skip_convs:\n","#             nn.init.xavier_uniform_(conv.weight, gain=nn.init.calculate_gain('relu'))\n","#             nn.init.zeros_(conv.bias)\n","\n","#     def forward(self, x):\n","#         # x: (B, C, L)\n","#         x = self.in_conv(x)\n","#         x_skip = x\n","#         for gated_tcn, skip_conv in zip(self.gated_tcns, self.skip_convs):\n","#             x = gated_tcn(x)\n","#             x = skip_conv(x)\n","#             x_skip = x_skip + x\n","#         return x_skip\n","\n","# class DilatedWaveNet(nn.Module):\n","#     \"\"\"WaveNet architecture with dilated inception conv, enhanced with list comprehension for input processing.\"\"\"\n","\n","#     def __init__(self, kernel_sizes: List[int]) -> None:\n","#         super().__init__()\n","#         self.kernel_sizes = kernel_sizes\n","        \n","#         # Initialize wave blocks with specified kernel sizes\n","#         self.wave_module = nn.Sequential(\n","#             WaveBlock(9, 8, 128, self.kernel_sizes), #12\n","#             WaveBlock(6, 128, 256, self.kernel_sizes), #8\n","#             WaveBlock(3, 256, 512, self.kernel_sizes), #4\n","#             WaveBlock(1, 512, 512, self.kernel_sizes), #1\n","#         )\n","#         self.pool_layer = nn.AdaptiveAvgPool1d(1)\n","\n","#     def forward(self, x) -> torch.Tensor:\n","#         # x: (B, L, C)\n","#         bs, seq_len, n_channels = x.shape\n","#         x = x.permute(0, 2, 1) # -> (B, C, L)\n","#         # Process different parts of the input with list comprehension\n","#         x = self.wave_module(x)\n","#         x = self.pool_layer(x) # ->(B, 512, 1)\n","#         x = x.reshape(bs, n_channels, -1).reshape(bs, n_channels//2, 2, 64)\n","#         features = x.mean(dim=2).reshape(bs, -1) # -> (16, 256)\n","# #         pooled_outputs = [(x[:, i:i+64] + x[:, i+64:i+128]) / 2 for i in range(0, n_channels, 2)]\n","# #         # Combine the pooled features and reshape for classification\n","# #         features = torch.cat(pooled_outputs, dim=1).reshape(bs, -1)\n","       \n","#         return features"]},{"cell_type":"markdown","metadata":{},"source":["### Dilated ResNet 1D Encoder"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# class ResnetBlock(nn.Module):\n","#     def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, dilation=1, dropout=0.0):\n","#         super(ResnetBlock, self).__init__()\n","\n","#         self.bn1 = nn.BatchNorm1d(in_channels)\n","#         self.relu1 = nn.ReLU()\n","#         self.conv1 = nn.Conv1d(\n","#             in_channels, out_channels, kernel_size, \n","#             stride=stride, \n","#             padding=dilation*(kernel_size//2), \n","#             dilation=dilation, \n","#             bias=False)\n","#         self.drop1 = nn.Dropout(p=dropout)\n","#         self.bn2 = nn.BatchNorm1d(out_channels)\n","#         self.relu2 = nn.ReLU()\n","#         self.drop2 = nn.Dropout(p=dropout)\n","#         self.conv2 = nn.Conv1d(\n","#             out_channels, out_channels, kernel_size, \n","#             stride=stride, \n","#             padding=dilation*(kernel_size//2), \n","#             dilation=dilation, \n","#             bias=False)\n","        \n","#         self.bn3 = nn.BatchNorm1d(out_channels)\n","#         self.relu3 = nn.ReLU()\n","#         self.downsample = nn.MaxPool1d(kernel_size=2, stride=2, padding=0)\n","\n","#     def forward(self, x):\n","#         identity = x\n","#         identity = self.downsample(identity)\n","\n","#         out = self.bn1(x)\n","#         out = self.relu1(out)\n","#         out = self.drop1(out)\n","#         out = self.conv1(out)\n","\n","#         out = self.bn2(out)\n","#         out = self.relu2(out)\n","#         out = self.drop2(out)\n","#         out = self.conv2(out)\n","\n","#         out = self.downsample(out)\n","\n","#         out += identity\n","#         out = self.bn3(out)\n","#         out = self.relu3(out)\n","\n","#         return out\n","\n","# class DilatedResnet(nn.Module):\n","#     def __init__(self, in_channels, out_channels, kernel_size, n_layers, expansion_factor=4):\n","#         super(DilatedResnet, self).__init__()\n","\n","#         self.in_channels = in_channels\n","#         self.kernel_size = kernel_size\n","#         self.h_dim = out_channels // n_layers\n","        \n","#         fix_kernel_size = 5\n","#         self.conv1 = nn.Conv1d(\n","#             self.in_channels, self.h_dim, kernel_size=fix_kernel_size, stride=1, padding=fix_kernel_size//2\n","#             )\n","\n","#         dilation_rates = [expansion_factor**i for i in range(n_layers)]\n","\n","#         self.blocks = nn.ModuleList([\n","#             ResnetBlock(self.h_dim, self.h_dim, self.kernel_size, dilation=dilation)\n","#             for dilation in dilation_rates\n","#         ])\n","\n","#     def forward(self, x):\n","#         x = self.conv1(x)\n","#         outputs = [ block(x) for block in self.blocks ]\n","#         output = torch.cat(outputs, dim=1)\n","        \n","#         return output\n","\n","# class DilatedResnetEncoder(nn.Module):\n","#     def __init__(self, kernel_sizes=[3, 5, 7, 9], in_channels=8, planes=24, dilate_layers=[6,3,1], expansion_factor=4):\n","#         super(DilatedResnetEncoder, self).__init__()\n","\n","#         self.in_channels = in_channels\n","#         self.planes = planes\n","#         self.kernel_sizes = kernel_sizes\n","#         self.dilate_layers = dilate_layers # must be 3 layers\n","#         self.expansion_factor = expansion_factor\n","        \n","#         # out_channels = self.planes * self.in_channels\n","#         # fix_kernel_size = 5\n","#         # self.conv1 = nn.Conv1d(\n","#         #     self.in_channels, out_channels, kernel_size=fix_kernel_size, stride=1, padding=fix_kernel_size//2\n","#         #     )\n","        \n","#         self.blocks = nn.ModuleList([\n","#             self._make_dilated_block(kernel_size)\n","#             for kernel_size in self.kernel_sizes\n","#         ])\n","\n","#         bottleneck_in_channels = self.in_channels * self.planes * self.dilate_layers[1] * self.dilate_layers[2]\n","#         bottoleneck_out_channels = self.in_channels * self.planes\n","\n","#         self.bottleneck = nn.Sequential(\n","#             nn.BatchNorm1d(num_features=bottleneck_in_channels),\n","#             nn.ReLU(),\n","#             nn.Conv1d(\n","#                 in_channels=bottleneck_in_channels,\n","#                 out_channels=bottoleneck_out_channels,\n","#                 kernel_size=1,\n","#                 stride=1,\n","#                 padding=0,\n","#                 bias=False\n","#             )\n","#         )\n","        \n","#         self.pooling = nn.AdaptiveAvgPool1d(1)\n","#         # self.blocks = nn.ModuleList([\n","#         #     nn.Sequential(*[\n","#         #         ResidualBlock(\n","#         #             out_channels, out_channels, kernel_size, dilation=dilation\n","#         #         ) for dilation in self.dilate_layers\n","#         #     ])\n","#         #     for kernel_size in self.kernel_sizes\n","#         # ])\n","\n","#     def _make_dilated_block(self, kernel_size):\n","#         out_channel_1 = self.in_channels * self.planes\n","#         block_1 = DilatedResnet(self.in_channels, out_channel_1, kernel_size, self.dilate_layers[0], self.expansion_factor)\n","\n","#         out_channel_2 = out_channel_1 * self.dilate_layers[1]\n","#         block_2 = DilatedResnet(out_channel_1, out_channel_2, kernel_size, self.dilate_layers[1], self.expansion_factor)\n","\n","#         out_channel_3 = out_channel_2 * self.dilate_layers[2]\n","#         block_3 = DilatedResnet(out_channel_2, out_channel_3, kernel_size, self.dilate_layers[2], self.expansion_factor)\n","\n","#         return nn.Sequential(block_1, block_2, block_3)\n","        \n","    \n","#     def forward(self, x):\n","#         # <- # [batch_size, seq_len=2000, in_channels=8]\n","#         x = x.permute(0, 2, 1)\n","#         # x = self.conv1(x)\n","#         outputs = [ block(x) for block in self.blocks ]\n","#         outputs = [ self.bottleneck(out) for out in outputs ]\n","#         output = torch.cat(outputs, dim=1)\n","#         output = self.pooling(output).squeeze(-1)\n","        \n","#         return output"]},{"cell_type":"markdown","metadata":{},"source":["### EEGSeqClassifier "]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# class EEGSeqClassifier(nn.Module):\n","#     def __init__(self, config, num_classes=6):\n","#         super(EEGSeqClassifier, self).__init__()\n","\n","#         self.seqgru = SeqGRUEncoder(in_channels=8, hidden_size=128, num_layers=2, bidirectional=True)\n","#         self.resnet = ResNet_1D_Encoder(\n","#             kernels=[3, 5, 7, 9, 11], \n","#             planes=24, \n","#             in_channels=8, \n","#             fixed_kernel_size=5, \n","#             n_blocks=9, \n","#             dropout=0.0\n","#         )\n","#         # self.wavenet = DilatedWaveNet(kernel_sizes=[2, 3, 6, 7])\n","#         # self.dilated_resnet = DilatedResnetEncoder(\n","#         #     kernel_sizes=[3, 5, 7, 9], \n","#         #     in_channels=8, \n","#         #     planes=24, \n","#         #     dilate_layers=[6,3,1], \n","#         #     expansion_factor=4\n","#         # )\n","\n","#         hidden_dim = 304   #768 #72 + 256 #+ 256\n","#         self.predict_head = nn.Linear(hidden_dim, num_classes)\n","\n","#     def forward(self, x):\n","#         # x shape: [batch, seq_len, in_channels]\n","\n","#         resnet_out = self.resnet(x)\n","#         seqgru_out = self.seqgru(x)\n","#         # wavenet_out = self.wavenet(x)\n","#         features = torch.cat([seqgru_out, resnet_out], dim=1)\n","#         # features = self.dilated_resnet(x)\n","#         logits = self.predict_head(features)\n","#         return logits"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["train_dataset = EEGSeqDataset(train_all, ModelConfig, ALL_EEG_SIGNALS, mode=\"train\")\n","train_loader = DataLoader(train_dataset, drop_last=True, batch_size=16, num_workers=4, pin_memory=True, shuffle=False)\n","\n","model = ResNetGRU(config=ModelConfig, num_classes=6)\n","\n","model.to(DEVICE)\n","for i, batch in enumerate(train_loader):\n","    X, y = batch\n","    X = X.to(DEVICE)\n","    y = y.to(DEVICE)\n","    print(f\"X shape: {X.shape}\")\n","    print(f\"y shape: {y.shape}\")\n","    \n","    y_pred = model(X)\n","    print(y_pred.shape)\n","    break \n","\n","del model, train_dataset, train_loader, X, y\n","torch.cuda.empty_cache()\n","gc.collect()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["!nvidia-smi"]},{"cell_type":"markdown","metadata":{},"source":["# Train"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","class AverageMeter(object):\n","    \"\"\"Computes and stores the average and current value\"\"\"\n","\n","    def __init__(self):\n","        self.reset()\n","\n","    def reset(self):\n","        self.val = 0\n","        self.avg = 0\n","        self.sum = 0\n","        self.count = 0\n","\n","    def update(self, val, n=1):\n","        self.val = val\n","        self.sum += val * n\n","        self.count += n\n","        self.avg = self.sum / self.count\n","        \n","class Trainer:\n","\n","    def __init__(self, model, config, logger):\n","\n","        self.model = model\n","        self.logger = logger\n","        self.config = config\n","        \n","        self.early_stop_rounds = config.EARLY_STOP_ROUNDS\n","        self.early_stop_counter = 0\n","        \n","        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","        self.kl_div_loss = nn.KLDivLoss(reduction='batchmean')\n","        self.ce_loss = nn.CrossEntropyLoss()\n","        self.gamma = config.REGULARIZATION\n","        \n","        # self.criterion = nn.KLDivLoss(reduction=\"batchmean\")\n","    \n","    def criterion(self, y_pred, y_true, weights=None, mode='train'):\n","        kl_loss = self.kl_div_loss(F.log_softmax(y_pred, dim=1), y_true)\n","        if (self.gamma is not None) & (mode == 'train'):\n","            softmax_probs = F.softmax(y_pred, dim=1)  # Compute softmax probabilities\n","            entropy_loss = -(softmax_probs * torch.log(softmax_probs + 1e-9)).sum(dim=1).mean(dim=0) # Compute entropy, add epsilon to avoid log(0)\n","            return kl_loss - self.gamma * entropy_loss\n","        else:\n","            return kl_loss\n","        \n","        #.sum(dim=1)  # Compute KL divergence\n","        # if (self.gamma is not None) & (mode == 'train'):\n","        #     softmax_probs = F.softmax(y_pred, dim=1)  # Compute softmax probabilities\n","        #     self_entropy_loss = -(softmax_probs * torch.log(softmax_probs + 1e-9)).sum(dim=1) # Compute entropy, add epsilon to avoid log(0)\n","        #     return (weights * (kl_loss - self.gamma * self_entropy_loss)).sum() / weights.sum()\n","        # else:\n","        #     return (weights * kl_loss).sum() / weights.sum()\n","        \n","    def train(self, train_loader, valid_loader, from_checkpoint=None):\n","\n","        self.optimizer = AdamW(self.model.parameters(), lr=8e-3, weight_decay=self.config.WEIGHT_DECAY)\n","\n","        # CosineAnnealingWarmRestarts( \n","        #     self.optimizer,\n","        #     T_0=20,\n","        #     eta_min=1e-6,\n","        #     T_mult=1,\n","        #     last_epoch=-1\n","        # )\n","        self.scheduler =  OneCycleLR(\n","            self.optimizer,\n","            max_lr=1e-4,\n","            epochs=self.config.EPOCHS,\n","            steps_per_epoch=len(train_loader),\n","            pct_start=0.1,\n","            anneal_strategy=\"cos\",\n","            final_div_factor=100,\n","        )\n","\n","        if from_checkpoint is not None:\n","            self.model.load_state_dict(torch.load(from_checkpoint, map_location=self.device))\n","\n","        self.model.to(self.device)\n","        best_weights, best_preds, best_loss = None, None, float(\"inf\")\n","        loss_records = {\"train\": [], \"valid\": []}\n","\n","        for epoch in range(self.config.EPOCHS):\n","            start_epoch = time()\n","\n","            train_loss, _ = self._train_or_valid_epoch(epoch, train_loader, is_train=True)\n","            valid_loss, valid_preds = self._train_or_valid_epoch(epoch, valid_loader, is_train=False)\n","\n","            loss_records[\"train\"].append(train_loss)\n","            loss_records[\"valid\"].append(valid_loss)\n","\n","            elapsed = time() - start_epoch\n","\n","            info = f\"{'-' * 100}\\nEpoch {epoch + 1} - \"\n","            info += f\"Average Loss: (train) {train_loss:.4f}; (valid) {valid_loss:.4f} | Time: {elapsed:.2f}s\"\n","            self.logger.info(info)\n","\n","            if valid_loss < best_loss:\n","                best_loss = valid_loss\n","                best_weights = self.model.state_dict()\n","                best_preds = valid_preds\n","                self.logger.info(f\"Best model found in epoch {epoch + 1} | valid loss: {best_loss:.4f}\")\n","                self.early_stop_counter = 0\n","            \n","            else:\n","                self.early_stop_counter += 1\n","                if self.early_stop_counter >= self.early_stop_rounds:\n","                    self.logger.info(f\"Early stopping at epoch {epoch + 1}\")\n","                    break\n","\n","        return best_weights, best_preds, loss_records\n","\n","    def _train_or_valid_epoch(self, epoch_id, dataloader, is_train=True):\n","\n","        self.model.train() if is_train else self.model.eval()\n","        mode = \"Train\" if is_train else \"Valid\"\n","\n","        len_loader = len(dataloader)\n","        scaler = GradScaler(enabled=self.config.AMP)\n","        loss_meter, predicts_record = AverageMeter(), []\n","\n","        start = time()\n","        pbar = tqdm(dataloader, total=len(dataloader), unit=\"batch\", desc=f\"{mode} [{epoch_id}]\")\n","        for step, (X, y) in enumerate(pbar):\n","            X, y = X.to(self.device), y.to(self.device)\n","\n","            if is_train:\n","                with autocast(enabled=self.config.AMP):\n","                    y_pred = self.model(X)\n","                    loss = self.criterion(y_pred, y)\n","                if self.config.GRADIENT_ACCUMULATION_STEPS > 1:\n","                    loss = loss / self.config.GRADIENT_ACCUMULATION_STEPS\n","                scaler.scale(loss).backward()\n","                grad_norm = torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.config.MAX_GRAD_NORM)\n","                if (step + 1) % self.config.GRADIENT_ACCUMULATION_STEPS == 0:\n","                    scaler.step(self.optimizer)\n","                    scaler.update()\n","                    self.optimizer.zero_grad()\n","                    self.scheduler.step()\n","            else:\n","                with torch.no_grad():\n","                    y_pred = self.model(X)\n","                    loss = self.criterion(y_pred, y, mode='valid')\n","                if self.config.GRADIENT_ACCUMULATION_STEPS > 1:\n","                    loss = loss / self.config.GRADIENT_ACCUMULATION_STEPS\n","                \n","                predicts_record.append(y_pred.to('cpu').numpy())\n","            \n","            loss_meter.update(loss.item(), y.size(0))\n","            end = time()\n","\n","            if (step % self.config.PRINT_FREQ == 0) or (step == (len_loader - 1)):\n","                lr = self.scheduler.get_last_lr()[0]\n","                info = f\"Epoch {epoch_id + 1} [{step}/{len_loader}] | {mode} Loss: {loss_meter.avg:.4f}\"\n","                if is_train:\n","                    info += f\" Grad: {grad_norm:.4f} LR: {lr:.4e}\"\n","                info += f\" | Elapse: {end - start:.2f}s\"\n","                print(info)\n","\n","        if not is_train:\n","            predicts_record = np.concatenate(predicts_record)\n","            \n","        return loss_meter.avg, predicts_record\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def train_fold(model, fold_id, train_folds, valid_folds, logger, stage=1, checkpoint=None):\n","\n","    train_dataset = EEGSeqDataset(train_folds, ModelConfig, ALL_EEG_SIGNALS, mode=\"train\")\n","    valid_dataset = EEGSeqDataset(valid_folds, ModelConfig, ALL_EEG_SIGNALS, mode=\"valid\")\n","\n","    # ======== DATALOADERS ==========\n","    loader_kwargs = {\n","        \"batch_size\": ModelConfig.BATCH_SIZE,\n","        \"num_workers\": ModelConfig.NUM_WORKERS,\n","        \"pin_memory\": True,\n","        \"shuffle\": False,\n","    }\n","\n","    train_loader = DataLoader(train_dataset, drop_last=True, collate_fn=None, **loader_kwargs)\n","    valid_loader = DataLoader(valid_dataset, drop_last=False, collate_fn=None, **loader_kwargs)\n","\n","    if checkpoint is not None:\n","        print(f\"Loading model from checkpoint: {checkpoint}\")\n","\n","    trainer = Trainer(model, ModelConfig, logger)\n","    best_weights, best_preds, loss_records = trainer.train(\n","        train_loader, valid_loader, from_checkpoint=checkpoint)\n","\n","    save_model_name = f\"{ModelConfig.MODEL_NAME}_fold_{fold_id}_stage_{stage}.pth\"\n","    torch.save(best_weights, os.path.join(PATHS.OUTPUT_DIR, save_model_name))\n","\n","    del train_dataset, valid_dataset, train_loader, valid_loader\n","    torch.cuda.empty_cache()\n","    gc.collect()\n","\n","    return best_preds, loss_records"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def evaluate_oof(oof_df):\n","    '''\n","    Evaluate the out-of-fold dataframe using KL Divergence (torch and kaggle)\n","    '''\n","    kl_loss = nn.KLDivLoss(reduction=\"batchmean\")\n","    labels = torch.tensor(oof_df[TARGETS].values.astype('float32'))\n","    preds = F.log_softmax(\n","        torch.tensor(oof_df[TARGETS_PRED].values.astype('float32'), requires_grad=False),\n","        dim=1\n","    )\n","    kl_torch = kl_loss(preds, labels).item()\n","\n","    return kl_torch"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from kl_divergence import score as kaggle_score \n","from sklearn.metrics import confusion_matrix\n","import seaborn as sns\n","\n","TARGET2ID = {'Seizure': 0, 'LPD': 1, 'GPD': 2, 'LRDA': 3, 'GRDA': 4, 'Other': 5}\n","\n","def calc_kaggle_score(oof_df):\n","    submission_df = oof_df[['eeg_id']+TARGETS_PRED].copy()\n","    submission_df.columns = ['eeg_id'] + TARGETS\n","    solution_df = oof_df[['eeg_id']+TARGETS].copy()\n","    return kaggle_score(solution_df, submission_df, 'eeg_id')\n","\n","def analyze_oof(oof_csv):\n","\n","    kl_criteria = nn.KLDivLoss(reduction='batchmean')\n","    softmax = nn.Softmax(dim=1)\n","\n","    oof_df = pd.read_csv(oof_csv)\n","    oof_df['target_pred'] = oof_df[TARGETS_PRED].apply(lambda x: np.argmax(x), axis=1)\n","    oof_df['target_id'] = oof_df[TARGETS].apply(lambda x: np.argmax(x), axis=1)\n","    \n","    oof_df[\"kl_loss\"] = oof_df.apply(\n","    lambda row: \n","        kl_criteria(\n","            F.log_softmax(\n","                    torch.tensor(row[TARGETS_PRED].values.astype(np.float32)).unsqueeze(0)\n","                , dim=1\n","                ), \n","            torch.tensor(row[TARGETS].values.astype(np.float32))\n","            ).numpy(),\n","    axis=1)\n","\n","    oof_df[\"kl_loss\"] = oof_df['kl_loss'].astype(np.float32)\n","\n","    oof_df[TARGETS_PRED] = softmax( torch.tensor(oof_df[TARGETS_PRED].values.astype(np.float32)) )\n","\n","    oof_df.head()\n","\n","    return oof_df"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def prepare_k_fold(df, k_folds=5):\n","\n","    kf = KFold(n_splits=k_folds, shuffle=True, random_state=ModelConfig.SEED)\n","    unique_spec_id = df['spectrogram_id'].unique()\n","    df['fold'] = k_folds\n","\n","    for fold, (train_index, valid_index) in enumerate(kf.split(unique_spec_id)):\n","        df.loc[df['spectrogram_id'].isin(unique_spec_id[valid_index]), 'fold'] = fold\n","\n","    return df"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Major Train Loop\n","# ================== Logger ==================\n","logger.info(f\"{'*' * 100}\")\n","logger.info(f\"Script Start: {ctime()}\")\n","logger.info(f\"Model Configurations:\")\n","for key, value in ModelConfig.__dict__.items():\n","    if not key.startswith(\"__\"):\n","        logger.info(f\"{key}: {value}\")\n","logger.info(f\"{'*' * 100}\")\n","\n","# ================== Prepare Training ==================\n","oof_stage_1, oof_stage_2 = pd.DataFrame(), pd.DataFrame()\n","loss_history_1, loss_history_2 = [], []\n","t_start = time()\n","\n","K_FOLDS = 5\n","train_all = prepare_k_fold(train_all, k_folds=K_FOLDS)\n","\n","for fold in range(0, K_FOLDS):\n","    tik_total = time()\n","    tik = time()\n","\n","    valid_folds = train_all[(train_all['fold'] == fold) ].reset_index(drop=True)\n","    train_folds = train_all[(train_all['fold'] != fold) ].reset_index(drop=True)\n","    train_size, valid_size = train_folds.shape[0], valid_folds.shape[0]\n","\n","    # ================== Stage 1: Train ====================\n","    # model = ResNetGRU(\n","    #     kernels=ModelConfig.RESNET_GRU_KERNELS, \n","    #     in_channels=8, \n","    #     fixed_kernel_size=ModelConfig.RESNET_GRU_FIXED_KERNEL_SIZE,\n","    #     hidden_size=ModelConfig.RESNET_GRU_HIDDEN_SIZE,\n","    #     num_classes=6\n","    #     )\n","    model = ResNetGRU(config=ModelConfig, num_classes=6)\n","\n","    \n","    ## STAGE 1\n","    logger.info(f\"{'=' * 100}\\nFold: {fold}\\n{'=' * 100}\")\n","    logger.info(f\"- Stage 1 | Train: {train_size}; Valid: {valid_size} -\")\n","    valid_predicts, loss_records = train_fold(\n","        model, fold, train_folds, valid_folds, logger, stage=1, checkpoint=None)\n","\n","    loss_history_1.append(loss_records)\n","    valid_folds[TARGETS_PRED] = valid_predicts\n","    kl_loss_torch = evaluate_oof(valid_folds)\n","    info = f\"{'=' * 100}\\nFold {fold} Valid Loss: {kl_loss_torch}\\n\"\n","    info += f\"Elapse: {(time() - tik) / 60:.2f} min \\n{'=' * 100}\"\n","    logger.info(info)\n","\n","    oof_stage_1 = pd.concat([oof_stage_1, valid_folds], axis=0).reset_index(drop=True)\n","    oof_stage_1.to_csv(os.path.join(PATHS.OUTPUT_DIR, f\"{ModelConfig.MODEL_NAME}_oof_1.csv\"), index=False)\n","\n","    # ================== Stage 2: Train ====================\n","    tik = time()\n","    # model = ResNetGRU(\n","    #     kernels=ModelConfig.RESNET_GRU_KERNELS, \n","    #     in_channels=8, \n","    #     fixed_kernel_size=ModelConfig.RESNET_GRU_FIXED_KERNEL_SIZE,\n","    #     hidden_size=ModelConfig.RESNET_GRU_HIDDEN_SIZE,\n","    #     num_classes=6\n","    #     )\n","    model = ResNetGRU(config=ModelConfig, num_classes=6)\n","    \n","    train_folds_2 = train_hard[~train_hard['eeg_id'].isin(valid_folds['eeg_id'])].reset_index(drop=True)\n","    valid_folds_2 = train_hard[ train_hard['eeg_id'].isin(valid_folds['eeg_id'])].reset_index(drop=True)\n","    train_size = train_folds_2.shape[0]\n","    valid_size = valid_folds_2.shape[0]\n","    \n","    ## STAGE 2\n","    logger.info(f\"- Stage 2 | Train: {train_size}; Valid: {valid_size} -\")\n","\n","    # model_dir = \"/home/shiyi/kaggle_hms/outputs/ResnetGRU_Originalsplit/Reg015\"\n","    # checkpoint = list(Path(model_dir).glob(f\"*_fold_{fold}_stage_1.pth\"))[0]\n","    checkpoint = list(Path(PATHS.OUTPUT_DIR).glob(f\"{ModelConfig.MODEL_NAME}_fold_{fold}_stage_1.pth\"))[0]\n","\n","    valid_predicts, loss_records = train_fold(\n","        model, fold, train_folds_2, valid_folds_2, logger, stage=2, checkpoint=checkpoint)\n","    \n","    loss_history_2.append(loss_records)\n","    valid_folds_2[TARGETS_PRED] = valid_predicts\n","    kl_loss_torch = evaluate_oof(valid_folds_2)\n","    info = f\"{'=' * 100}\\nFold {fold} Valid Loss: {kl_loss_torch}\\n\"\n","    info += f\"Elapse: {(time() - tik) / 60:.2f} min \\n{'=' * 100}\"\n","    logger.info(info)\n","\n","    oof_stage_2 = pd.concat([oof_stage_2, valid_folds_2], axis=0).reset_index(drop=True)\n","    oof_stage_2.to_csv(os.path.join(PATHS.OUTPUT_DIR, f\"{ModelConfig.MODEL_NAME}_oof_2.csv\"), index=False)\n","\n","    logger.info(f\"Fold {fold} Elapse: {(time() - tik_total) / 60:.2f} min\")\n","\n","info = f\"{'=' * 100}\\nTraining Complete!\\n\"\n","cv_results_1 = evaluate_oof(oof_stage_1)\n","cv_results_2 = evaluate_oof(oof_stage_2)\n","info += f\"CV Result: Stage 1: {cv_results_1} | Stage 2: {cv_results_2}\\n\"\n","info += f\"Elapse: {(time() - t_start) / 60:.2f} min \\n{'=' * 100}\"\n","logger.info(info)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# plot loss history\n","fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5), sharey=True)\n","\n","for i, loss in enumerate(loss_history_1):\n","    ax1.plot(loss['train'], marker=\"*\", ls=\"-\", label=f\"Fold {i} Train\")\n","    ax1.plot(loss['valid'], marker=\"o\", ls=\":\", label=f\"Fold {i} Valid\")\n","\n","for i, loss in enumerate(loss_history_2):\n","    ax2.plot(loss['train'], marker=\"*\", ls=\"-\", label=f\"Fold {i} Train\")\n","    ax2.plot(loss['valid'], marker=\"o\", ls=\":\", label=f\"Fold {i} Valid\")\n","\n","ax1.set_title(\"Stage 1 Loss\")\n","ax2.set_title(\"Stage 2 Loss\")\n","\n","for ax in (ax1, ax2):\n","    ax.set_xlabel(\"Epochs\")\n","    ax.set_ylabel(\"Loss\")\n","    ax.legend()\n","    ax.grid(True)\n","\n","fig.tight_layout()\n","fig.savefig(Path(PATHS.OUTPUT_DIR) / f\"{ModelConfig.MODEL_NAME}_loss_history.png\")\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["csv_path = f'./outputs/{ModelConfig.MODEL_NAME}_oof_1.csv'\n","print(\"CSV Path: \", csv_path)\n","\n","oof_df = analyze_oof(csv_path)\n","\n","print(\"Kaggle Score: \", calc_kaggle_score(oof_df))\n","print(\"Average KL Loss: \", oof_df[\"kl_loss\"].mean())\n","\n","display(oof_df.head())\n","\n","# plot confusion matrix\n","cm = confusion_matrix(oof_df['target_id'], oof_df['target_pred']) # (y_true, y_pred)\n","cm = cm / cm.sum(axis=1)[:, np.newaxis]\n","\n","fig = plt.figure(figsize=(6, 6))\n","sns.heatmap(cm, annot=True, cmap='Blues', xticklabels=TARGET2ID.keys(), yticklabels=TARGET2ID.keys())\n","plt.xlabel('Predicted', fontsize=12)\n","plt.ylabel('True', fontsize=12)\n","plt.title(csv_path.split('/')[-1].split('.')[0], fontsize=12)\n","fig.tight_layout()\n","fig.savefig(f\"./outputs/{csv_path.split('/')[-1].split('.')[0]}_CM.png\")\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["fig, axes = plt.subplots(5, 5, figsize=(15, 15), sharex=True, sharey=True)\n","oof_samples = oof_df.sample(axes.size)\n","\n","for i, ax in enumerate(axes.flatten()):\n","    row = oof_samples.iloc[i]\n","    x = np.arange(6)\n","    ax.plot(x, row[TARGETS].T, marker=\"o\", ls=\"-\", label=\"True\")\n","    ax.plot(x, row[TARGETS_PRED].T, marker=\"*\", ls=\"--\", label=\"Predicted\")\n","    ax.set_title(f\"{row['target']} | KL Loss: {row['kl_loss']:.4f}\")\n","    ax.legend()\n","    \n","fig.tight_layout()\n","fig.savefig(f\"./outputs/{csv_path.split('/')[-1].split('.')[0]}_samples.png\")\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["csv_path = f'./outputs/{ModelConfig.MODEL_NAME}_oof_2.csv'\n","print(\"CSV Path: \", csv_path)\n","\n","oof_df = analyze_oof(csv_path)\n","\n","print(\"Kaggle Score: \", calc_kaggle_score(oof_df))\n","print(\"Average KL Loss: \", oof_df[\"kl_loss\"].mean())\n","\n","display(oof_df.head())\n","\n","# plot confusion matrix\n","cm = confusion_matrix(oof_df['target_id'], oof_df['target_pred']) # (y_true, y_pred)\n","cm = cm / cm.sum(axis=1)[:, np.newaxis]\n","\n","fig = plt.figure(figsize=(6, 6))\n","sns.heatmap(cm, annot=True, cmap='Blues', xticklabels=TARGET2ID.keys(), yticklabels=TARGET2ID.keys())\n","plt.xlabel('Predicted', fontsize=12)\n","plt.ylabel('True', fontsize=12)\n","plt.title(csv_path.split('/')[-1].split('.')[0], fontsize=12)\n","fig.tight_layout()\n","fig.savefig(f\"./outputs/{csv_path.split('/')[-1].split('.')[0]}_CM.png\")\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["fig, axes = plt.subplots(5, 5, figsize=(15, 15), sharex=True, sharey=True)\n","oof_samples = oof_df.sample(axes.size)\n","\n","for i, ax in enumerate(axes.flatten()):\n","    row = oof_samples.iloc[i]\n","    x = np.arange(6)\n","    ax.plot(x, row[TARGETS].T, marker=\"o\", ls=\"-\", label=\"True\")\n","    ax.plot(x, row[TARGETS_PRED].T, marker=\"*\", ls=\"--\", label=\"Predicted\")\n","    ax.set_title(f\"{row['target']} | KL Loss: {row['kl_loss']:.4f}\")\n","    ax.legend()\n","    \n","fig.tight_layout()\n","fig.savefig(f\"./outputs/{csv_path.split('/')[-1].split('.')[0]}_samples.png\")\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["oof_stage_2_full = pd.DataFrame()\n","\n","for fold in range(1):\n","\n","    valid_folds = train_all[train_all['fold'] == fold].reset_index(drop=True)\n","\n","    # predict labels using stage-2 models\n","    model = ResNetGRU(\n","        kernels=ModelConfig.RESNET_GRU_KERNELS, \n","        in_channels=8, \n","        fixed_kernel_size=ModelConfig.RESNET_GRU_FIXED_KERNEL_SIZE,\n","        hidden_size=ModelConfig.RESNET_GRU_HIDDEN_SIZE,\n","        num_classes=6\n","        )\n","    \n","    check_point = os.path.join(\n","        PATHS.OUTPUT_DIR,\n","        f\"{ModelConfig.MODEL_NAME}_fold_{fold}_stage_2.pth\"\n","    )\n","\n","    model.load_state_dict(torch.load(check_point, map_location=DEVICE))\n","\n","    loader_kwargs = {\n","        \"batch_size\": ModelConfig.BATCH_SIZE,\n","        \"num_workers\": ModelConfig.NUM_WORKERS,\n","        \"pin_memory\": True,\n","        \"shuffle\": False,\n","    }\n","\n","    valid_dataset = EEGSeqDataset(\n","        valid_folds, ModelConfig, ALL_EEG_SIGNALS, mode=\"valid\", downsample=ModelConfig.RESNET_GRU_DOWNSAMPLE)\n","    valid_loader = DataLoader(valid_dataset, drop_last=False, collate_fn=None, **loader_kwargs)\n","\n","    model.to(DEVICE)\n","    model.eval()\n","\n","    valid_predicts = []\n","    with torch.no_grad():\n","        for X, y in valid_loader:\n","            X = X.to(DEVICE)\n","            y_pred = model(X)\n","            valid_predicts.append(y_pred.to('cpu').numpy())\n","\n","    valid_predicts = np.concatenate(valid_predicts)\n","    valid_folds[TARGETS_PRED] = valid_predicts\n","    oof_stage_2_full = pd.concat([oof_stage_2, valid_folds], axis=0).reset_index(drop=True)\n","\n","    del valid_dataset, valid_loader\n","    torch.cuda.empty_cache()\n","    gc.collect()\n","\n","    oof_stage_2_full.to_csv(os.path.join(PATHS.OUTPUT_DIR, f\"{ModelConfig.MODEL_NAME}_oof_2_full.csv\"), index=False)\n","\n","cv_results = evaluate_oof(oof_stage_2_full)\n","logger.info(f\"{'=' * 100}\\nCV Result (Stage 2 Full): {cv_results}\\n{'=' * 100}\")\n"]},{"cell_type":"markdown","metadata":{},"source":["Reg = 0.15, Downsample = 0, CV Result (Stage 2 Full): 0.639643669128418"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["csv_path = f'./outputs/Resnet_SeqGRU_ChrisNO_NoReg_oof_2_full.csv'\n","print(\"CSV Path: \", csv_path)\n","\n","oof_df = analyze_oof(csv_path)\n","\n","print(\"Kaggle Score: \", calc_kaggle_score(oof_df))\n","print(\"Average KL Loss: \", oof_df[\"kl_loss\"].mean())\n","\n","display(oof_df.head())\n","\n","# plot confusion matrix\n","cm = confusion_matrix(oof_df['target_id'], oof_df['target_pred']) # (y_true, y_pred)\n","cm = cm / cm.sum(axis=1)[:, np.newaxis]\n","\n","fig = plt.figure(figsize=(6, 6))\n","sns.heatmap(cm, annot=True, cmap='Blues', xticklabels=TARGET2ID.keys(), yticklabels=TARGET2ID.keys())\n","plt.xlabel('Predicted', fontsize=12)\n","plt.ylabel('True', fontsize=12)\n","plt.title(csv_path.split('/')[-1].split('.')[0], fontsize=12)\n","fig.tight_layout()\n","fig.savefig(f\"./outputs/{csv_path.split('/')[-1].split('.')[0]}_CM.png\")\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"databundleVersionId":7469972,"sourceId":59093,"sourceType":"competition"},{"sourceId":165461612,"sourceType":"kernelVersion"},{"sourceId":168718625,"sourceType":"kernelVersion"}],"dockerImageVersionId":30673,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.6"}},"nbformat":4,"nbformat_minor":4}
