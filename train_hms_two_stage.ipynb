{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/home/shiyi/miniconda3/envs/kaggle/lib/python3.11/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
                        "  _torch_pytree._register_pytree_node(\n"
                    ]
                }
            ],
            "source": [
                "import pandas as pd \n",
                "import numpy as np \n",
                "from scipy.stats import entropy\n",
                "from sklearn.model_selection import GroupKFold\n",
                "import matplotlib.pyplot as plt\n",
                "\n",
                "from engine_hms_trainer import *\n",
                "from engine_hms_model import CustomModel, JobConfig, ModelConfig\n",
                "\n",
                "import torch\n",
                "from torch import nn\n",
                "import torch.nn.functional as F"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "****************************************************************************************************\n",
                        "Script Start: Sat Mar  9 19:40:08 2024\n",
                        "Initializing HMS Predictor...\n",
                        "Model Name: ENet_b2_xymask_cutmix\n",
                        "Drop Rate: 0.15\n",
                        "Drop Path Rate: 0.25\n",
                        "Augment: True\n",
                        "Augmentations: ['xy_masking', 'cut_mix']\n",
                        "Enropy Split: 5.5\n",
                        "Device: cuda\n",
                        "Output Dir: ./outputs/\n",
                        "****************************************************************************************************\n"
                    ]
                }
            ],
            "source": [
                "seed_everything(JobConfig.SEED)\n",
                "\n",
                "ModelConfig.EPOCHS = 6\n",
                "ModelConfig.USE_EEG_SPECTROGRAMS = False\n",
                "ModelConfig.MODEL_BACKBONE = 'tf_efficientnet_b2'\n",
                "ModelConfig.MODEL_NAME = \"ENet_b2_xymask_cutmix\"\n",
                "ModelConfig.AUGMENT = True\n",
                "ModelConfig.USE_KAGGLE_SPECTROGRAMS = True\n",
                "ModelConfig.USE_EEG_SPECTROGRAMS = True\n",
                "\n",
                "ModelConfig.AUGMENTATIONS = ['xy_masking', 'cut_mix']\n",
                "\n",
                "hms_predictor = HMSPredictor(JobConfig, ModelConfig)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "(11999, 14)\n",
                        "(5090, 14)\n",
                        "0\n",
                        "0\n"
                    ]
                },
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>eeg_id</th>\n",
                            "      <th>spectrogram_id</th>\n",
                            "      <th>min</th>\n",
                            "      <th>max</th>\n",
                            "      <th>patient_id</th>\n",
                            "      <th>target</th>\n",
                            "      <th>total_votes</th>\n",
                            "      <th>entropy</th>\n",
                            "      <th>seizure_vote</th>\n",
                            "      <th>lpd_vote</th>\n",
                            "      <th>gpd_vote</th>\n",
                            "      <th>lrda_vote</th>\n",
                            "      <th>grda_vote</th>\n",
                            "      <th>other_vote</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>0</th>\n",
                            "      <td>642382</td>\n",
                            "      <td>14960202</td>\n",
                            "      <td>1008.0</td>\n",
                            "      <td>1032.0</td>\n",
                            "      <td>5955</td>\n",
                            "      <td>Other</td>\n",
                            "      <td>2</td>\n",
                            "      <td>7.802343</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>1.0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1</th>\n",
                            "      <td>751790</td>\n",
                            "      <td>618728447</td>\n",
                            "      <td>908.0</td>\n",
                            "      <td>908.0</td>\n",
                            "      <td>38549</td>\n",
                            "      <td>GPD</td>\n",
                            "      <td>1</td>\n",
                            "      <td>7.802343</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>1.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>2</th>\n",
                            "      <td>778705</td>\n",
                            "      <td>52296320</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>40955</td>\n",
                            "      <td>Other</td>\n",
                            "      <td>2</td>\n",
                            "      <td>7.686820</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>1.0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>3</th>\n",
                            "      <td>1629671</td>\n",
                            "      <td>2036345030</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>160.0</td>\n",
                            "      <td>37481</td>\n",
                            "      <td>Seizure</td>\n",
                            "      <td>51</td>\n",
                            "      <td>7.619243</td>\n",
                            "      <td>1.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>4</th>\n",
                            "      <td>2061593</td>\n",
                            "      <td>320962633</td>\n",
                            "      <td>1450.0</td>\n",
                            "      <td>1450.0</td>\n",
                            "      <td>23828</td>\n",
                            "      <td>Other</td>\n",
                            "      <td>1</td>\n",
                            "      <td>7.802343</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>1.0</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "    eeg_id  spectrogram_id     min     max  patient_id   target  total_votes  \\\n",
                            "0   642382        14960202  1008.0  1032.0        5955    Other            2   \n",
                            "1   751790       618728447   908.0   908.0       38549      GPD            1   \n",
                            "2   778705        52296320     0.0     0.0       40955    Other            2   \n",
                            "3  1629671      2036345030     0.0   160.0       37481  Seizure           51   \n",
                            "4  2061593       320962633  1450.0  1450.0       23828    Other            1   \n",
                            "\n",
                            "    entropy  seizure_vote  lpd_vote  gpd_vote  lrda_vote  grda_vote  \\\n",
                            "0  7.802343           0.0       0.0       0.0        0.0        0.0   \n",
                            "1  7.802343           0.0       0.0       1.0        0.0        0.0   \n",
                            "2  7.686820           0.0       0.0       0.0        0.0        0.0   \n",
                            "3  7.619243           1.0       0.0       0.0        0.0        0.0   \n",
                            "4  7.802343           0.0       0.0       0.0        0.0        0.0   \n",
                            "\n",
                            "   other_vote  \n",
                            "0         1.0  \n",
                            "1         0.0  \n",
                            "2         1.0  \n",
                            "3         0.0  \n",
                            "4         1.0  "
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        " \n"
                    ]
                },
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>eeg_id</th>\n",
                            "      <th>spectrogram_id</th>\n",
                            "      <th>min</th>\n",
                            "      <th>max</th>\n",
                            "      <th>patient_id</th>\n",
                            "      <th>target</th>\n",
                            "      <th>total_votes</th>\n",
                            "      <th>entropy</th>\n",
                            "      <th>seizure_vote</th>\n",
                            "      <th>lpd_vote</th>\n",
                            "      <th>gpd_vote</th>\n",
                            "      <th>lrda_vote</th>\n",
                            "      <th>grda_vote</th>\n",
                            "      <th>other_vote</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>0</th>\n",
                            "      <td>568657</td>\n",
                            "      <td>789577333</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>16.0</td>\n",
                            "      <td>20654</td>\n",
                            "      <td>Other</td>\n",
                            "      <td>48</td>\n",
                            "      <td>3.341757</td>\n",
                            "      <td>0.000000</td>\n",
                            "      <td>0.000000</td>\n",
                            "      <td>0.250000</td>\n",
                            "      <td>0.000000</td>\n",
                            "      <td>0.166667</td>\n",
                            "      <td>0.583333</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1</th>\n",
                            "      <td>582999</td>\n",
                            "      <td>1552638400</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>38.0</td>\n",
                            "      <td>20230</td>\n",
                            "      <td>LPD</td>\n",
                            "      <td>154</td>\n",
                            "      <td>3.550549</td>\n",
                            "      <td>0.000000</td>\n",
                            "      <td>0.857143</td>\n",
                            "      <td>0.000000</td>\n",
                            "      <td>0.071429</td>\n",
                            "      <td>0.000000</td>\n",
                            "      <td>0.071429</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>2</th>\n",
                            "      <td>1895581</td>\n",
                            "      <td>128369999</td>\n",
                            "      <td>1138.0</td>\n",
                            "      <td>1138.0</td>\n",
                            "      <td>47999</td>\n",
                            "      <td>Other</td>\n",
                            "      <td>13</td>\n",
                            "      <td>3.565051</td>\n",
                            "      <td>0.076923</td>\n",
                            "      <td>0.000000</td>\n",
                            "      <td>0.000000</td>\n",
                            "      <td>0.000000</td>\n",
                            "      <td>0.076923</td>\n",
                            "      <td>0.846154</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>3</th>\n",
                            "      <td>2482631</td>\n",
                            "      <td>978166025</td>\n",
                            "      <td>1902.0</td>\n",
                            "      <td>1944.0</td>\n",
                            "      <td>20606</td>\n",
                            "      <td>Other</td>\n",
                            "      <td>105</td>\n",
                            "      <td>1.431066</td>\n",
                            "      <td>0.000000</td>\n",
                            "      <td>0.000000</td>\n",
                            "      <td>0.133333</td>\n",
                            "      <td>0.066667</td>\n",
                            "      <td>0.133333</td>\n",
                            "      <td>0.666667</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>4</th>\n",
                            "      <td>2521897</td>\n",
                            "      <td>673742515</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>4.0</td>\n",
                            "      <td>62117</td>\n",
                            "      <td>Other</td>\n",
                            "      <td>24</td>\n",
                            "      <td>1.516203</td>\n",
                            "      <td>0.000000</td>\n",
                            "      <td>0.000000</td>\n",
                            "      <td>0.083333</td>\n",
                            "      <td>0.083333</td>\n",
                            "      <td>0.333333</td>\n",
                            "      <td>0.500000</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "    eeg_id  spectrogram_id     min     max  patient_id target  total_votes  \\\n",
                            "0   568657       789577333     0.0    16.0       20654  Other           48   \n",
                            "1   582999      1552638400     0.0    38.0       20230    LPD          154   \n",
                            "2  1895581       128369999  1138.0  1138.0       47999  Other           13   \n",
                            "3  2482631       978166025  1902.0  1944.0       20606  Other          105   \n",
                            "4  2521897       673742515     0.0     4.0       62117  Other           24   \n",
                            "\n",
                            "    entropy  seizure_vote  lpd_vote  gpd_vote  lrda_vote  grda_vote  \\\n",
                            "0  3.341757      0.000000  0.000000  0.250000   0.000000   0.166667   \n",
                            "1  3.550549      0.000000  0.857143  0.000000   0.071429   0.000000   \n",
                            "2  3.565051      0.076923  0.000000  0.000000   0.000000   0.076923   \n",
                            "3  1.431066      0.000000  0.000000  0.133333   0.066667   0.133333   \n",
                            "4  1.516203      0.000000  0.000000  0.083333   0.083333   0.333333   \n",
                            "\n",
                            "   other_vote  \n",
                            "0    0.583333  \n",
                            "1    0.071429  \n",
                            "2    0.846154  \n",
                            "3    0.666667  \n",
                            "4    0.500000  "
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                }
            ],
            "source": [
                "train_easy, train_hard, all_specs, all_eegs = hms_predictor.load_train_data()\n",
                "\n",
                "print(train_easy.shape)\n",
                "print(train_hard.shape)\n",
                "\n",
                "# check if contain NaN\n",
                "print(train_easy.isnull().sum().sum())\n",
                "print(train_hard.isnull().sum().sum())\n",
                "\n",
                "display(train_easy.head())\n",
                "print(\" \")\n",
                "display(train_hard.head())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "====================================================================================================\n",
                        "Fold: 0 First Training\n",
                        "====================================================================================================\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "932f8a1b2cb440ca9e4ece9aa1711fa3",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Train:   0%|          | 0/599 [00:00<?, ?batch/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: [1][0/599]Elapsed 1.07s | Loss: 0.8345 Grad: 69042.6250 LR: 4.0000e-06\n",
                        "Epoch: [1][50/599]Elapsed 8.23s | Loss: 0.8308 Grad: 75636.1328 LR: 5.1479e-06\n",
                        "Epoch: [1][100/599]Elapsed 15.30s | Loss: 0.8226 Grad: 61634.6484 LR: 8.5368e-06\n",
                        "Epoch: [1][150/599]Elapsed 22.38s | Loss: 0.8171 Grad: 57516.7031 LR: 1.4005e-05\n",
                        "Epoch: [1][200/599]Elapsed 29.47s | Loss: 0.8091 Grad: 70790.9766 LR: 2.1290e-05\n",
                        "Epoch: [1][250/599]Elapsed 36.56s | Loss: 0.7969 Grad: 69634.0078 LR: 3.0044e-05\n",
                        "Epoch: [1][300/599]Elapsed 43.66s | Loss: 0.7804 Grad: 79607.8828 LR: 3.9848e-05\n",
                        "Epoch: [1][350/599]Elapsed 50.78s | Loss: 0.7615 Grad: 129872.3438 LR: 5.0233e-05\n",
                        "Epoch: [1][400/599]Elapsed 57.89s | Loss: 0.7422 Grad: 53024.8203 LR: 6.0703e-05\n",
                        "Epoch: [1][450/599]Elapsed 65.03s | Loss: 0.7222 Grad: 71614.6484 LR: 7.0757e-05\n",
                        "Epoch: [1][500/599]Elapsed 72.17s | Loss: 0.7026 Grad: 67804.5078 LR: 7.9913e-05\n",
                        "Epoch: [1][550/599]Elapsed 79.32s | Loss: 0.6828 Grad: 75003.4922 LR: 8.7735e-05\n",
                        "Epoch: [1][598/599]Elapsed 86.21s | Loss: 0.6654 Grad: 118546.4531 LR: 9.3639e-05\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "bf037601c43b491bacdb665ff53d6d29",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Valid:   0%|          | 0/150 [00:00<?, ?batch/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: [1][0/150]Elapsed 0.10s | Loss: 0.7545\n",
                        "Epoch: [1][50/150]Elapsed 4.85s | Loss: 0.4970\n",
                        "Epoch: [1][100/150]Elapsed 9.59s | Loss: 0.5004\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "----------------------------------------------------------------------------------------------------\n",
                        "Epoch 1 - Average Train Loss: 0.6654 | Average Valid Loss: 0.4962 | Time: 100.69s\n",
                        "Best model found in epoch 1 | valid loss: 0.4962\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "b679a1c5ec404cf6bbea515f175c3ffc",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Train:   0%|          | 0/599 [00:00<?, ?batch/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: [2][0/599]Elapsed 0.10s | Loss: 0.3842 Grad: 142093.0469 LR: 9.3639e-05\n",
                        "Epoch: [2][50/599]Elapsed 7.29s | Loss: 0.4178 Grad: 46330.9102 LR: 9.7834e-05\n",
                        "Epoch: [2][100/599]Elapsed 14.49s | Loss: 0.4063 Grad: 33928.4258 LR: 9.9837e-05\n",
                        "Epoch: [2][150/599]Elapsed 21.70s | Loss: 0.4143 Grad: 89391.2266 LR: 9.9994e-05\n",
                        "Epoch: [2][200/599]Elapsed 28.95s | Loss: 0.4045 Grad: 31731.7090 LR: 9.9961e-05\n",
                        "Epoch: [2][250/599]Elapsed 36.17s | Loss: 0.3976 Grad: 41026.5625 LR: 9.9899e-05\n",
                        "Epoch: [2][300/599]Elapsed 43.41s | Loss: 0.3959 Grad: 60293.5391 LR: 9.9807e-05\n",
                        "Epoch: [2][350/599]Elapsed 50.66s | Loss: 0.3928 Grad: 25876.3184 LR: 9.9685e-05\n",
                        "Epoch: [2][400/599]Elapsed 57.91s | Loss: 0.3892 Grad: 30222.4316 LR: 9.9535e-05\n",
                        "Epoch: [2][450/599]Elapsed 65.16s | Loss: 0.3836 Grad: 47859.9648 LR: 9.9355e-05\n",
                        "Epoch: [2][500/599]Elapsed 72.42s | Loss: 0.3812 Grad: 43956.9141 LR: 9.9146e-05\n",
                        "Epoch: [2][550/599]Elapsed 79.66s | Loss: 0.3775 Grad: 68269.3828 LR: 9.8908e-05\n",
                        "Epoch: [2][598/599]Elapsed 86.62s | Loss: 0.3741 Grad: 46237.2617 LR: 9.8653e-05\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "f8006b693f4b43e9923f668160307f88",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Valid:   0%|          | 0/150 [00:00<?, ?batch/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: [2][0/150]Elapsed 0.10s | Loss: 0.6648\n",
                        "Epoch: [2][50/150]Elapsed 4.85s | Loss: 0.4353\n",
                        "Epoch: [2][100/150]Elapsed 9.60s | Loss: 0.4526\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "----------------------------------------------------------------------------------------------------\n",
                        "Epoch 2 - Average Train Loss: 0.3741 | Average Valid Loss: 0.4538 | Time: 101.11s\n",
                        "Best model found in epoch 2 | valid loss: 0.4538\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "17056876b99441b1b4927137e2bb2861",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Train:   0%|          | 0/599 [00:00<?, ?batch/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: [3][0/599]Elapsed 0.11s | Loss: 0.2464 Grad: 109735.1641 LR: 9.8653e-05\n",
                        "Epoch: [3][50/599]Elapsed 7.34s | Loss: 0.2902 Grad: 126770.3516 LR: 9.8359e-05\n",
                        "Epoch: [3][100/599]Elapsed 14.67s | Loss: 0.2907 Grad: 28631.8047 LR: 9.8036e-05\n",
                        "Epoch: [3][150/599]Elapsed 22.02s | Loss: 0.3047 Grad: 37765.5352 LR: 9.7685e-05\n",
                        "Epoch: [3][200/599]Elapsed 29.37s | Loss: 0.3014 Grad: 37428.9531 LR: 9.7306e-05\n",
                        "Epoch: [3][250/599]Elapsed 36.72s | Loss: 0.2984 Grad: 36949.7891 LR: 9.6899e-05\n",
                        "Epoch: [3][300/599]Elapsed 44.08s | Loss: 0.3000 Grad: 36849.8672 LR: 9.6464e-05\n",
                        "Epoch: [3][350/599]Elapsed 51.42s | Loss: 0.2989 Grad: 49472.4336 LR: 9.6002e-05\n",
                        "Epoch: [3][400/599]Elapsed 58.76s | Loss: 0.2971 Grad: 30841.2441 LR: 9.5513e-05\n",
                        "Epoch: [3][450/599]Elapsed 66.12s | Loss: 0.2947 Grad: 46519.9570 LR: 9.4997e-05\n",
                        "Epoch: [3][500/599]Elapsed 73.48s | Loss: 0.2944 Grad: 26111.7148 LR: 9.4455e-05\n",
                        "Epoch: [3][550/599]Elapsed 80.85s | Loss: 0.2919 Grad: 55629.1445 LR: 9.3886e-05\n",
                        "Epoch: [3][598/599]Elapsed 87.92s | Loss: 0.2912 Grad: 41145.1719 LR: 9.3316e-05\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "fbe3e55b8dcc4772aa0ec5619ae99a3c",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Valid:   0%|          | 0/150 [00:00<?, ?batch/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: [3][0/150]Elapsed 0.10s | Loss: 0.6345\n",
                        "Epoch: [3][50/150]Elapsed 4.87s | Loss: 0.4356\n",
                        "Epoch: [3][100/150]Elapsed 9.63s | Loss: 0.4567\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "----------------------------------------------------------------------------------------------------\n",
                        "Epoch 3 - Average Train Loss: 0.2912 | Average Valid Loss: 0.4587 | Time: 102.46s\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "babdf894e4f740709d83088dc7283583",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Train:   0%|          | 0/599 [00:00<?, ?batch/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: [4][0/599]Elapsed 0.10s | Loss: 0.2141 Grad: 123974.9453 LR: 9.3316e-05\n",
                        "Epoch: [4][50/599]Elapsed 7.40s | Loss: 0.2411 Grad: 79364.4219 LR: 9.2697e-05\n",
                        "Epoch: [4][100/599]Elapsed 14.78s | Loss: 0.2421 Grad: 30797.0547 LR: 9.2053e-05\n",
                        "Epoch: [4][150/599]Elapsed 22.19s | Loss: 0.2558 Grad: 39875.2695 LR: 9.1384e-05\n",
                        "Epoch: [4][200/599]Elapsed 29.59s | Loss: 0.2524 Grad: 27349.4492 LR: 9.0691e-05\n",
                        "Epoch: [4][250/599]Elapsed 36.94s | Loss: 0.2509 Grad: 24700.2266 LR: 8.9973e-05\n",
                        "Epoch: [4][300/599]Elapsed 44.29s | Loss: 0.2504 Grad: 33373.4922 LR: 8.9233e-05\n",
                        "Epoch: [4][350/599]Elapsed 51.62s | Loss: 0.2494 Grad: 30650.9355 LR: 8.8469e-05\n",
                        "Epoch: [4][400/599]Elapsed 58.93s | Loss: 0.2485 Grad: 62647.5078 LR: 8.7682e-05\n",
                        "Epoch: [4][450/599]Elapsed 66.23s | Loss: 0.2457 Grad: 58746.7539 LR: 8.6873e-05\n",
                        "Epoch: [4][500/599]Elapsed 73.53s | Loss: 0.2468 Grad: 35471.3125 LR: 8.6043e-05\n",
                        "Epoch: [4][550/599]Elapsed 80.84s | Loss: 0.2455 Grad: 63155.4219 LR: 8.5191e-05\n",
                        "Epoch: [4][598/599]Elapsed 87.84s | Loss: 0.2450 Grad: 53089.2227 LR: 8.4354e-05\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "43733de69cdb4f31a186e1fbd9f03f43",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Valid:   0%|          | 0/150 [00:00<?, ?batch/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: [4][0/150]Elapsed 0.10s | Loss: 0.5775\n",
                        "Epoch: [4][50/150]Elapsed 4.87s | Loss: 0.4239\n",
                        "Epoch: [4][100/150]Elapsed 9.63s | Loss: 0.4504\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "----------------------------------------------------------------------------------------------------\n",
                        "Epoch 4 - Average Train Loss: 0.2450 | Average Valid Loss: 0.4561 | Time: 102.37s\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "fd860eb392964953b056b12d6b627b4b",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Train:   0%|          | 0/599 [00:00<?, ?batch/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: [5][0/599]Elapsed 0.10s | Loss: 0.1996 Grad: 141908.5156 LR: 8.4354e-05\n",
                        "Epoch: [5][50/599]Elapsed 7.36s | Loss: 0.2061 Grad: 95460.1484 LR: 8.3462e-05\n",
                        "Epoch: [5][100/599]Elapsed 14.74s | Loss: 0.2032 Grad: 50888.0391 LR: 8.2550e-05\n",
                        "Epoch: [5][150/599]Elapsed 22.10s | Loss: 0.2116 Grad: 30870.4570 LR: 8.1619e-05\n",
                        "Epoch: [5][200/599]Elapsed 29.47s | Loss: 0.2079 Grad: 34410.8750 LR: 8.0670e-05\n",
                        "Epoch: [5][250/599]Elapsed 36.80s | Loss: 0.2070 Grad: 26766.7988 LR: 7.9702e-05\n",
                        "Epoch: [5][300/599]Elapsed 44.11s | Loss: 0.2075 Grad: 60561.5820 LR: 7.8717e-05\n",
                        "Epoch: [5][350/599]Elapsed 51.42s | Loss: 0.2089 Grad: 37366.2695 LR: 7.7715e-05\n",
                        "Epoch: [5][400/599]Elapsed 58.73s | Loss: 0.2076 Grad: 22367.2188 LR: 7.6697e-05\n",
                        "Epoch: [5][450/599]Elapsed 66.05s | Loss: 0.2054 Grad: 45877.0000 LR: 7.5663e-05\n",
                        "Epoch: [5][500/599]Elapsed 73.36s | Loss: 0.2057 Grad: 56285.5156 LR: 7.4614e-05\n",
                        "Epoch: [5][550/599]Elapsed 80.70s | Loss: 0.2037 Grad: 75790.4531 LR: 7.3550e-05\n",
                        "Epoch: [5][598/599]Elapsed 87.75s | Loss: 0.2033 Grad: 68147.6172 LR: 7.2516e-05\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "6a2e9d5fbb674e3d9fc0434b977c1753",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Valid:   0%|          | 0/150 [00:00<?, ?batch/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: [5][0/150]Elapsed 0.11s | Loss: 0.6307\n",
                        "Epoch: [5][50/150]Elapsed 4.87s | Loss: 0.4379\n",
                        "Epoch: [5][100/150]Elapsed 9.62s | Loss: 0.4559\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "----------------------------------------------------------------------------------------------------\n",
                        "Epoch 5 - Average Train Loss: 0.2033 | Average Valid Loss: 0.4626 | Time: 102.26s\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "b90fdf676d5843efb996efbddad1ef27",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Train:   0%|          | 0/599 [00:00<?, ?batch/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: [6][0/599]Elapsed 0.10s | Loss: 0.2046 Grad: inf LR: 7.2516e-05\n",
                        "Epoch: [6][50/599]Elapsed 7.40s | Loss: 0.1709 Grad: 65081.3008 LR: 7.1426e-05\n",
                        "Epoch: [6][100/599]Elapsed 14.82s | Loss: 0.1697 Grad: 56867.7539 LR: 7.0323e-05\n",
                        "Epoch: [6][150/599]Elapsed 22.21s | Loss: 0.1770 Grad: 46316.9141 LR: 6.9208e-05\n",
                        "Epoch: [6][200/599]Elapsed 29.64s | Loss: 0.1752 Grad: 31888.0469 LR: 6.8082e-05\n",
                        "Epoch: [6][250/599]Elapsed 37.04s | Loss: 0.1748 Grad: 27573.3027 LR: 6.6945e-05\n",
                        "Epoch: [6][300/599]Elapsed 44.41s | Loss: 0.1743 Grad: 29712.3477 LR: 6.5799e-05\n",
                        "Epoch: [6][350/599]Elapsed 51.77s | Loss: 0.1733 Grad: 54139.2969 LR: 6.4642e-05\n",
                        "Epoch: [6][400/599]Elapsed 59.13s | Loss: 0.1729 Grad: 20577.5410 LR: 6.3478e-05\n",
                        "Epoch: [6][450/599]Elapsed 66.47s | Loss: 0.1702 Grad: 42005.5234 LR: 6.2305e-05\n",
                        "Epoch: [6][500/599]Elapsed 73.80s | Loss: 0.1710 Grad: 29141.4336 LR: 6.1125e-05\n",
                        "Epoch: [6][550/599]Elapsed 81.15s | Loss: 0.1693 Grad: 43241.3789 LR: 5.9939e-05\n",
                        "Epoch: [6][598/599]Elapsed 88.20s | Loss: 0.1696 Grad: 54734.7305 LR: 5.8795e-05\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "1bd857e797474e94930142a33c426cdb",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Valid:   0%|          | 0/150 [00:00<?, ?batch/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: [6][0/150]Elapsed 0.11s | Loss: 0.5734\n",
                        "Epoch: [6][50/150]Elapsed 4.88s | Loss: 0.4446\n",
                        "Epoch: [6][100/150]Elapsed 9.65s | Loss: 0.4778\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "----------------------------------------------------------------------------------------------------\n",
                        "Epoch 6 - Average Train Loss: 0.1696 | Average Valid Loss: 0.4815 | Time: 102.75s\n",
                        "====================================================================================================\n",
                        "Fold: 1 First Training\n",
                        "====================================================================================================\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "e49c3b5587e34a018f395498fa883985",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Train:   0%|          | 0/599 [00:00<?, ?batch/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: [1][0/599]Elapsed 0.10s | Loss: 0.8187 Grad: 90367.3984 LR: 4.0000e-06\n",
                        "Epoch: [1][50/599]Elapsed 7.40s | Loss: 0.8193 Grad: 61856.2148 LR: 5.1479e-06\n",
                        "Epoch: [1][100/599]Elapsed 14.77s | Loss: 0.8062 Grad: 69708.6875 LR: 8.5368e-06\n",
                        "Epoch: [1][150/599]Elapsed 22.18s | Loss: 0.8008 Grad: 65168.4062 LR: 1.4005e-05\n",
                        "Epoch: [1][200/599]Elapsed 29.58s | Loss: 0.7945 Grad: 60428.7070 LR: 2.1290e-05\n",
                        "Epoch: [1][250/599]Elapsed 36.97s | Loss: 0.7847 Grad: 65722.2031 LR: 3.0044e-05\n",
                        "Epoch: [1][300/599]Elapsed 44.34s | Loss: 0.7691 Grad: 88584.0000 LR: 3.9848e-05\n",
                        "Epoch: [1][350/599]Elapsed 51.72s | Loss: 0.7533 Grad: 84640.8047 LR: 5.0233e-05\n",
                        "Epoch: [1][400/599]Elapsed 59.08s | Loss: 0.7345 Grad: 102233.5078 LR: 6.0703e-05\n",
                        "Epoch: [1][450/599]Elapsed 66.44s | Loss: 0.7145 Grad: 79600.0234 LR: 7.0757e-05\n",
                        "Epoch: [1][500/599]Elapsed 73.80s | Loss: 0.6955 Grad: 49560.7461 LR: 7.9913e-05\n",
                        "Epoch: [1][550/599]Elapsed 81.15s | Loss: 0.6765 Grad: 57476.7422 LR: 8.7735e-05\n",
                        "Epoch: [1][598/599]Elapsed 88.19s | Loss: 0.6594 Grad: 64001.1719 LR: 9.3639e-05\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "9d30944a1c34477d9bc4f642d11233e8",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Valid:   0%|          | 0/150 [00:00<?, ?batch/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: [1][0/150]Elapsed 0.10s | Loss: 0.3597\n",
                        "Epoch: [1][50/150]Elapsed 4.86s | Loss: 0.4746\n",
                        "Epoch: [1][100/150]Elapsed 9.62s | Loss: 0.4953\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "----------------------------------------------------------------------------------------------------\n",
                        "Epoch 1 - Average Train Loss: 0.6594 | Average Valid Loss: 0.5030 | Time: 102.71s\n",
                        "Best model found in epoch 1 | valid loss: 0.5030\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "62f3ad7fb9c64e96b2998092cefa5fb8",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Train:   0%|          | 0/599 [00:00<?, ?batch/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: [2][0/599]Elapsed 0.10s | Loss: 0.5007 Grad: 150057.3750 LR: 9.3639e-05\n",
                        "Epoch: [2][50/599]Elapsed 7.41s | Loss: 0.4185 Grad: 75971.0703 LR: 9.7834e-05\n",
                        "Epoch: [2][100/599]Elapsed 14.79s | Loss: 0.4069 Grad: 71578.7891 LR: 9.9837e-05\n",
                        "Epoch: [2][150/599]Elapsed 22.16s | Loss: 0.4100 Grad: 59593.5156 LR: 9.9994e-05\n",
                        "Epoch: [2][200/599]Elapsed 29.52s | Loss: 0.4034 Grad: 28914.7852 LR: 9.9961e-05\n",
                        "Epoch: [2][250/599]Elapsed 36.87s | Loss: 0.3993 Grad: 39601.1992 LR: 9.9899e-05\n",
                        "Epoch: [2][300/599]Elapsed 44.21s | Loss: 0.3955 Grad: 39854.2031 LR: 9.9807e-05\n",
                        "Epoch: [2][350/599]Elapsed 51.55s | Loss: 0.3918 Grad: 46848.2617 LR: 9.9685e-05\n",
                        "Epoch: [2][400/599]Elapsed 58.92s | Loss: 0.3854 Grad: 28335.2754 LR: 9.9535e-05\n",
                        "Epoch: [2][450/599]Elapsed 66.27s | Loss: 0.3800 Grad: 52756.7930 LR: 9.9355e-05\n",
                        "Epoch: [2][500/599]Elapsed 73.61s | Loss: 0.3772 Grad: 37780.6367 LR: 9.9146e-05\n",
                        "Epoch: [2][550/599]Elapsed 80.96s | Loss: 0.3733 Grad: 28562.9863 LR: 9.8908e-05\n",
                        "Epoch: [2][598/599]Elapsed 88.01s | Loss: 0.3705 Grad: 60358.4570 LR: 9.8653e-05\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "98ffbc9e9cad4935ae1caab44de4386b",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Valid:   0%|          | 0/150 [00:00<?, ?batch/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: [2][0/150]Elapsed 0.10s | Loss: 0.3118\n",
                        "Epoch: [2][50/150]Elapsed 4.85s | Loss: 0.3850\n",
                        "Epoch: [2][100/150]Elapsed 9.62s | Loss: 0.3962\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "----------------------------------------------------------------------------------------------------\n",
                        "Epoch 2 - Average Train Loss: 0.3705 | Average Valid Loss: 0.3977 | Time: 102.53s\n",
                        "Best model found in epoch 2 | valid loss: 0.3977\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "099007b3f8424b8c989858ab509ee31f",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Train:   0%|          | 0/599 [00:00<?, ?batch/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: [3][0/599]Elapsed 0.10s | Loss: 0.3298 Grad: nan LR: 9.8653e-05\n",
                        "Epoch: [3][50/599]Elapsed 7.43s | Loss: 0.3010 Grad: 21338.7129 LR: 9.8359e-05\n",
                        "Epoch: [3][100/599]Elapsed 14.83s | Loss: 0.3003 Grad: 39418.8438 LR: 9.8036e-05\n",
                        "Epoch: [3][150/599]Elapsed 22.22s | Loss: 0.3095 Grad: 40957.5391 LR: 9.7685e-05\n",
                        "Epoch: [3][200/599]Elapsed 29.61s | Loss: 0.3049 Grad: 21981.3145 LR: 9.7306e-05\n",
                        "Epoch: [3][250/599]Elapsed 36.99s | Loss: 0.3028 Grad: 26094.0352 LR: 9.6899e-05\n",
                        "Epoch: [3][300/599]Elapsed 44.37s | Loss: 0.3040 Grad: 45831.8789 LR: 9.6464e-05\n",
                        "Epoch: [3][350/599]Elapsed 51.74s | Loss: 0.3011 Grad: 42579.3984 LR: 9.6002e-05\n",
                        "Epoch: [3][400/599]Elapsed 59.11s | Loss: 0.2969 Grad: 27818.4473 LR: 9.5513e-05\n",
                        "Epoch: [3][450/599]Elapsed 66.46s | Loss: 0.2935 Grad: 55390.7617 LR: 9.4997e-05\n",
                        "Epoch: [3][500/599]Elapsed 73.82s | Loss: 0.2934 Grad: 36681.0156 LR: 9.4455e-05\n",
                        "Epoch: [3][550/599]Elapsed 81.15s | Loss: 0.2925 Grad: 29872.9043 LR: 9.3886e-05\n",
                        "Epoch: [3][598/599]Elapsed 88.22s | Loss: 0.2922 Grad: 49741.2656 LR: 9.3316e-05\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "c10cf63d33e3494cadbef17ae96d2ebc",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Valid:   0%|          | 0/150 [00:00<?, ?batch/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: [3][0/150]Elapsed 0.11s | Loss: 0.2976\n",
                        "Epoch: [3][50/150]Elapsed 4.88s | Loss: 0.3757\n",
                        "Epoch: [3][100/150]Elapsed 9.65s | Loss: 0.3833\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "----------------------------------------------------------------------------------------------------\n",
                        "Epoch 3 - Average Train Loss: 0.2922 | Average Valid Loss: 0.3843 | Time: 102.77s\n",
                        "Best model found in epoch 3 | valid loss: 0.3843\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "c1160d9f3e514f4fa002ae4bd461c406",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Train:   0%|          | 0/599 [00:00<?, ?batch/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: [4][0/599]Elapsed 0.10s | Loss: 0.3630 Grad: inf LR: 9.3316e-05\n",
                        "Epoch: [4][50/599]Elapsed 7.41s | Loss: 0.2468 Grad: 29989.4531 LR: 9.2697e-05\n",
                        "Epoch: [4][100/599]Elapsed 14.77s | Loss: 0.2463 Grad: 47235.0469 LR: 9.2053e-05\n",
                        "Epoch: [4][150/599]Elapsed 22.13s | Loss: 0.2568 Grad: 39901.6680 LR: 9.1384e-05\n",
                        "Epoch: [4][200/599]Elapsed 29.49s | Loss: 0.2511 Grad: 22997.1211 LR: 9.0691e-05\n",
                        "Epoch: [4][250/599]Elapsed 36.86s | Loss: 0.2494 Grad: 22708.4727 LR: 8.9973e-05\n",
                        "Epoch: [4][300/599]Elapsed 44.21s | Loss: 0.2499 Grad: 59539.6602 LR: 8.9233e-05\n",
                        "Epoch: [4][350/599]Elapsed 51.57s | Loss: 0.2494 Grad: 40909.0781 LR: 8.8469e-05\n",
                        "Epoch: [4][400/599]Elapsed 58.92s | Loss: 0.2449 Grad: 37714.2500 LR: 8.7682e-05\n",
                        "Epoch: [4][450/599]Elapsed 66.26s | Loss: 0.2419 Grad: 78410.5000 LR: 8.6873e-05\n",
                        "Epoch: [4][500/599]Elapsed 73.62s | Loss: 0.2416 Grad: 40052.4180 LR: 8.6043e-05\n",
                        "Epoch: [4][550/599]Elapsed 80.95s | Loss: 0.2405 Grad: 32881.4570 LR: 8.5191e-05\n",
                        "Epoch: [4][598/599]Elapsed 88.00s | Loss: 0.2397 Grad: 65585.7422 LR: 8.4354e-05\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "475ecfb079264a9fb9f9a6a0b38ea54e",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Valid:   0%|          | 0/150 [00:00<?, ?batch/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: [4][0/150]Elapsed 0.10s | Loss: 0.2862\n",
                        "Epoch: [4][50/150]Elapsed 4.85s | Loss: 0.3762\n",
                        "Epoch: [4][100/150]Elapsed 9.60s | Loss: 0.3900\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "----------------------------------------------------------------------------------------------------\n",
                        "Epoch 4 - Average Train Loss: 0.2397 | Average Valid Loss: 0.3935 | Time: 102.50s\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "b6f5bacaedc945b6b02cb2d3a5398f91",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Train:   0%|          | 0/599 [00:00<?, ?batch/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: [5][0/599]Elapsed 0.10s | Loss: 0.2920 Grad: 204411.2812 LR: 8.4354e-05\n",
                        "Epoch: [5][50/599]Elapsed 7.41s | Loss: 0.2099 Grad: 36181.5898 LR: 8.3462e-05\n",
                        "Epoch: [5][100/599]Elapsed 14.81s | Loss: 0.2079 Grad: 45585.6836 LR: 8.2550e-05\n",
                        "Epoch: [5][150/599]Elapsed 22.21s | Loss: 0.2181 Grad: 37846.0625 LR: 8.1619e-05\n"
                    ]
                },
                {
                    "ename": "KeyboardInterrupt",
                    "evalue": "",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
                        "Cell \u001b[0;32mIn[4], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Use only half data for fast debugging\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# train_easy = train_easy[:len(train_easy)//2]\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# train_hard = train_hard[:len(train_hard)//2]\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[43mhms_predictor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_folds\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_easy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_hard\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mall_specs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mall_eegs\u001b[49m\u001b[43m)\u001b[49m\n",
                        "File \u001b[0;32m~/kaggle_hms/engine_hms_trainer.py:397\u001b[0m, in \u001b[0;36mHMSPredictor.train_folds\u001b[0;34m(self, train_easy, train_hard, all_specs, all_eegs)\u001b[0m\n\u001b[1;32m    394\u001b[0m train_folds \u001b[38;5;241m=\u001b[39m train_easy[train_easy[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfold\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m!=\u001b[39m fold]\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    395\u001b[0m valid_folds \u001b[38;5;241m=\u001b[39m train_easy[train_easy[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfold\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m fold]\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 397\u001b[0m valid_preds, loss_records \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train_fold\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_folds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalid_folds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mall_specs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mall_eegs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    399\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_per_fold\u001b[38;5;241m.\u001b[39mappend(loss_records)\n\u001b[1;32m    400\u001b[0m valid_folds[TARGETS_PRED] \u001b[38;5;241m=\u001b[39m valid_preds\n",
                        "File \u001b[0;32m~/kaggle_hms/engine_hms_trainer.py:463\u001b[0m, in \u001b[0;36mHMSPredictor._train_fold\u001b[0;34m(self, fold_id, train_folds, valid_folds, all_specs, all_eegs, stage, check_point)\u001b[0m\n\u001b[1;32m    459\u001b[0m valid_loader \u001b[38;5;241m=\u001b[39m DataLoader(valid_dataset, drop_last\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mloader_kwargs)\n\u001b[1;32m    461\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(model, train_loader, valid_loader, \u001b[38;5;28;01mNone\u001b[39;00m, DEVICE, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_config, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger, check_point)\n\u001b[0;32m--> 463\u001b[0m best_model_weights, valid_preds, loss_records \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    465\u001b[0m save_model_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_config\u001b[38;5;241m.\u001b[39mMODEL_NAME\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_fold_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfold_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_stage_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstage\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    466\u001b[0m torch\u001b[38;5;241m.\u001b[39msave(best_model_weights, os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjob_config\u001b[38;5;241m.\u001b[39mOUTPUT_DIR, save_model_name))\n",
                        "File \u001b[0;32m~/kaggle_hms/engine_hms_trainer.py:196\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    193\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time()\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m--> 196\u001b[0m train_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    197\u001b[0m valid_loss, valid_preds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_valid_epoch(epoch)\n\u001b[1;32m    199\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m time() \u001b[38;5;241m-\u001b[39m start_time\n",
                        "File \u001b[0;32m~/kaggle_hms/engine_hms_trainer.py:231\u001b[0m, in \u001b[0;36mTrainer._train_epoch\u001b[0;34m(self, epoch)\u001b[0m\n\u001b[1;32m    228\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    230\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m autocast(enabled\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mAMP):\n\u001b[0;32m--> 231\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    232\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss(y_pred, y)\n\u001b[1;32m    234\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mGRADIENT_ACCUMULATION_STEPS \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
                        "File \u001b[0;32m~/miniconda3/envs/kaggle/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
                        "File \u001b[0;32m~/miniconda3/envs/kaggle/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
                        "File \u001b[0;32m~/kaggle_hms/engine_hms_model.py:330\u001b[0m, in \u001b[0;36mCustomModel.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    328\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m    329\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__reshape_input(x)\n\u001b[0;32m--> 330\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeatures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    331\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcustom_layers(x)\n\u001b[1;32m    332\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
                        "File \u001b[0;32m~/miniconda3/envs/kaggle/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
                        "File \u001b[0;32m~/miniconda3/envs/kaggle/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
                        "File \u001b[0;32m~/miniconda3/envs/kaggle/lib/python3.11/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
                        "File \u001b[0;32m~/miniconda3/envs/kaggle/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
                        "File \u001b[0;32m~/miniconda3/envs/kaggle/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
                        "File \u001b[0;32m~/miniconda3/envs/kaggle/lib/python3.11/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
                        "File \u001b[0;32m~/miniconda3/envs/kaggle/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
                        "File \u001b[0;32m~/miniconda3/envs/kaggle/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
                        "File \u001b[0;32m~/miniconda3/envs/kaggle/lib/python3.11/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
                        "File \u001b[0;32m~/miniconda3/envs/kaggle/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
                        "File \u001b[0;32m~/miniconda3/envs/kaggle/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
                        "File \u001b[0;32m~/miniconda3/envs/kaggle/lib/python3.11/site-packages/timm/models/_efficientnet_blocks.py:186\u001b[0m, in \u001b[0;36mInvertedResidual.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    184\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mse(x)\n\u001b[1;32m    185\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv_pwl(x)\n\u001b[0;32m--> 186\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbn3\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhas_skip:\n\u001b[1;32m    188\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdrop_path(x) \u001b[38;5;241m+\u001b[39m shortcut\n",
                        "File \u001b[0;32m~/miniconda3/envs/kaggle/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
                        "File \u001b[0;32m~/miniconda3/envs/kaggle/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
                        "File \u001b[0;32m~/miniconda3/envs/kaggle/lib/python3.11/site-packages/timm/layers/norm_act.py:98\u001b[0m, in \u001b[0;36mBatchNormAct2d.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrack_running_stats:\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;66;03m# TODO: if statement only here to tell the jit to skip emitting this when it is None\u001b[39;00m\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_batches_tracked \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:  \u001b[38;5;66;03m# type: ignore[has-type]\u001b[39;00m\n\u001b[0;32m---> 98\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_batches_tracked\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[has-type]\u001b[39;00m\n\u001b[1;32m     99\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmomentum \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:  \u001b[38;5;66;03m# use cumulative moving average\u001b[39;00m\n\u001b[1;32m    100\u001b[0m             exponential_average_factor \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_batches_tracked)\n",
                        "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
                    ]
                }
            ],
            "source": [
                "# Use only half data for fast debugging\n",
                "# train_easy = train_easy[:len(train_easy)//2]\n",
                "# train_hard = train_hard[:len(train_hard)//2]\n",
                "\n",
                "hms_predictor.train_folds(train_easy, train_hard, all_specs, all_eegs)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "dataset = CustomDataset(train_easy, TARGETS, ModelConfig, all_specs, all_eegs, mode='test')\n",
                "\n",
                "X, y = dataset[0]\n",
                "print(X.shape, y.shape)\n",
                "\n",
                "model = CustomModel(ModelConfig, num_classes=6, pretrained=True)\n",
                "y_pred = model(X.unsqueeze(0))\n",
                "\n",
                "print(y_pred.shape)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from kl_divergence import score as kl_score\n",
                "\n",
                "\n",
                "def calc_kl_div(p, q, criterion):\n",
                "    \n",
                "    p = torch.tensor(p.astype(np.float32)).unsqueeze(0)\n",
                "    q = torch.tensor(q.astype(np.float32)).unsqueeze(0)\n",
                "    return criterion(F.log_softmax(p, dim=1), q).item()\n",
                "\n",
                "def calc_kaggle_score(solution, submission):\n",
                "    solution = solution.to_frame().T\n",
                "    solution[TARGETS] = solution[TARGETS].astype(np.float32)\n",
                "    submission = submission.to_frame().T\n",
                "    submission.columns = ['eeg_id'] + TARGETS\n",
                "    submission[TARGETS] = submission[TARGETS].astype(np.float32)\n",
                "    \n",
                "    return kl_score(solution, submission, 'eeg_id')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def evaluate_oof(oof_csv_path):\n",
                "    oof_df = pd.read_csv(oof_csv_path)\n",
                "    softmax = nn.Softmax(dim=1)\n",
                "    criterion = nn.KLDivLoss(reduction=\"batchmean\")\n",
                "\n",
                "    oof_df[\"kl_loss\"] = oof_df.apply(lambda row: \n",
                "        calc_kl_div(row[TARGETS_PRED].values, row[TARGETS].values, criterion), axis=1\n",
                "        )\n",
                "\n",
                "    kl_loss_all = criterion(\n",
                "        F.log_softmax(torch.tensor(oof_df[TARGETS_PRED].values.astype(np.float32)), dim=1),\n",
                "        torch.tensor(oof_df[TARGETS].values.astype(np.float32)),\n",
                "        )\n",
                "\n",
                "    print(f\"KL Loss All: {kl_loss_all}\")\n",
                "    print(f\"KL Loss Mean: {oof_df['kl_loss'].mean()}\")\n",
                "\n",
                "    y_pred = oof_df[TARGETS].values.astype(np.float32)\n",
                "    oof_df[TARGETS_PRED] = softmax(torch.tensor(y_pred)).numpy()\n",
                "\n",
                "    solution = oof_df[['eeg_id'] + TARGETS].copy()\n",
                "    submission = oof_df[['eeg_id'] + TARGETS_PRED].copy()\n",
                "    submission.columns = ['eeg_id'] + TARGETS\n",
                "\n",
                "    kaggle_score_all = kl_score(solution, submission, 'eeg_id')\n",
                "    \n",
                "    oof_df['kaggle_score'] = oof_df.apply(lambda row:\n",
                "        calc_kaggle_score(row[['eeg_id'] + TARGETS], row[['eeg_id'] + TARGETS_PRED]), axis=1\n",
                "        )\n",
                "\n",
                "    print(f\"Kaggle Score All: {kaggle_score_all}\")\n",
                "    print(f\"Kaggle Score Mean: {oof_df['kaggle_score'].mean()}\")\n",
                "\n",
                "    return oof_df, kl_loss_all, kaggle_score_all\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "oof_1, kl_loss_all, kaggle_score_all = evaluate_oof(f\"{JobConfig.OUTPUT_DIR}/oof_1.csv\")\n",
                "oof_2, kl_loss_all, kaggle_score_all = evaluate_oof(f\"{JobConfig.OUTPUT_DIR}/oof_2.csv\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "fig, axes = plt.subplots(4, 4, figsize=(10, 10), sharex=True, sharey=True)\n",
                "\n",
                "# rows = oof_df.iloc[-len(axes.ravel()):, :]\n",
                "rows = oof_1.sample(len(axes.ravel()))\n",
                "\n",
                "for i, (idx, row) in enumerate(rows.iterrows()):\n",
                "\n",
                "    ax = axes.ravel()[i]\n",
                "    ax.plot(row[TARGETS].values, label='True')\n",
                "    ax.plot(row[TARGETS_PRED].values, label='Pred')\n",
                "    ax.set_title(f\"{idx} | {row['target']} | KL: {row['kl_loss']:.4f}\")\n",
                "    ax.set_xticks(range(6))\n",
                "    ax.set_xticklabels(BRAIN_ACTIVITY)\n",
                "    ax.grid(True)\n",
                "    ax.legend()\n",
                "\n",
                "fig.tight_layout()\n",
                "fig.savefig(f\"{JobConfig.OUTPUT_DIR}/oof_examples_1.png\")\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "fig, axes = plt.subplots(4, 4, figsize=(10, 10), sharex=True, sharey=True)\n",
                "\n",
                "# rows = oof_2.iloc[5:5+len(axes.ravel()), :]\n",
                "rows = oof_2.sample(len(axes.ravel()))\n",
                "\n",
                "for i, (idx, row) in enumerate(rows.iterrows()):\n",
                "\n",
                "    ax = axes.ravel()[i]\n",
                "    y_true = row[TARGETS].values\n",
                "    y_pred = row[TARGETS_PRED].values\n",
                "    y_norm = (y_true - y_true.min()) / (y_true.max() - y_true.min())\n",
                "\n",
                "    ax.plot(row[TARGETS].values, label='True')\n",
                "    ax.plot(row[TARGETS_PRED].values, label='Pred')\n",
                "    ax.plot(y_norm, \"b:\", label='True Norm')\n",
                "\n",
                "    ax.set_title(f\"{idx} | {row['target']} | KL: {row['kl_loss']:.4f}\")\n",
                "    ax.set_xticks(range(6))\n",
                "    ax.set_xticklabels(BRAIN_ACTIVITY)\n",
                "    ax.grid(True)\n",
                "    ax.legend()\n",
                "\n",
                "fig.tight_layout()\n",
                "fig.savefig(f\"{JobConfig.OUTPUT_DIR}/oof_examples_2.png\")\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "row = oof_2.loc[6]\n",
                "\n",
                "min_pred = row[TARGETS_PRED].min()\n",
                "max_pred = row[TARGETS_PRED].max()\n",
                "print(min_pred, max_pred)\n",
                "\n",
                "print(row[TARGETS_PRED])\n",
                "\n",
                "targets_norm = (row[TARGETS] - row[TARGETS].min()) / (row[TARGETS].max() - row[TARGETS].min())\n",
                "\n",
                "targets_norm = targets_norm / targets_norm.sum()\n",
                "\n",
                "print(targets_norm)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "kaggle",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.6"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
