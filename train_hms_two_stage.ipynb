{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd \n",
                "import numpy as np \n",
                "import matplotlib.pyplot as plt\n",
                "\n",
                "from engine_hms_trainer import *\n",
                "from engine_hms_model import KagglePaths, LocalPaths, ModelConfig\n",
                "\n",
                "import torch\n",
                "from torch import nn\n",
                "import torch.nn.functional as F\n",
                "\n",
                "import warnings\n",
                "warnings.filterwarnings('ignore')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "paths = KagglePaths if os.path.exists(KagglePaths.OUTPUT_DIR) else LocalPaths\n",
                "print(\"Output Dir: \", paths.OUTPUT_DIR)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "train_easy, train_hard, all_specs, all_eegs = load_kaggle_data(\n",
                "    paths.TRAIN_CSV, paths.PRE_LOADED_SPECTOGRAMS, paths.PRE_LOADED_EEGS, split_entropy=ModelConfig.SPLIT_ENTROPY)\n",
                "\n",
                "print(train_easy.shape)\n",
                "print(train_hard.shape)\n",
                "\n",
                "# check if contain NaN\n",
                "print(train_easy.isnull().sum().sum())\n",
                "print(train_hard.isnull().sum().sum())\n",
                "\n",
                "display(train_easy.head())\n",
                "print(\" \")\n",
                "display(train_hard.head())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# check distribution of targets\n",
                "fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
                "train_easy[\"target\"].value_counts().plot(kind=\"bar\", ax=axes[0])\n",
                "train_hard[\"target\"].value_counts().plot(kind=\"bar\", ax=axes[1])\n",
                "axes[0].set_title(\"Easy\")\n",
                "axes[1].set_title(\"Hard\")\n",
                "fig.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# randomly sample from easy and add to hard.\n",
                "tgt_to_sample = ['Seizure', 'LRDA', 'GRDA']\n",
                "sample_ratio = 0.5 # 50% of easy to add to hard for each target label\n",
                "\n",
                "for tgt in tgt_to_sample:\n",
                "    easy_sample = train_easy[train_easy[\"target\"] == tgt].sample(frac=sample_ratio)\n",
                "    train_hard = pd.concat([train_hard, easy_sample], axis=0)\n",
                "\n",
                "print(\"Hard after adding easy: \", train_hard.shape)\n",
                "\n",
                "# check distribution of targets\n",
                "fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
                "train_easy[\"target\"].value_counts().plot(kind=\"bar\", ax=axes[0])\n",
                "train_hard[\"target\"].value_counts().plot(kind=\"bar\", ax=axes[1])\n",
                "axes[0].set_title(\"Easy\")\n",
                "axes[1].set_title(\"Hard\")\n",
                "fig.tight_layout()\n",
                "plt.show()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Config EfficientNet \n",
                "ModelConfig.EPOCHS = 6\n",
                "ModelConfig.BATCH_SIZE = 16\n",
                "ModelConfig.GRADIENT_ACCUMULATION_STEPS = 2\n",
                "ModelConfig.MODEL_BACKBONE = 'tf_efficientnet_b2'\n",
                "ModelConfig.MODEL_NAME = \"ENet_b2_xymask_add_hard_samples\"\n",
                "ModelConfig.USE_KAGGLE_SPECTROGRAMS = True\n",
                "ModelConfig.USE_EEG_SPECTROGRAMS = True\n",
                "ModelConfig.REGULARIZATION = None\n",
                "ModelConfig.AUGMENT = True\n",
                "ModelConfig.AUGMENTATIONS = ['xy_masking']\n",
                "\n",
                "hms_predictor = HMSPredictor(paths.OUTPUT_DIR, ModelConfig, k_fold=5)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# # Config ViTMAE\n",
                "# ModelConfig.EPOCHS = 6\n",
                "# ModelConfig.MODEL_BACKBONE = 'vit_mae_base'\n",
                "# ModelConfig.MODEL_NAME = \"ViTMAE_base_mlp_dropout_020\"\n",
                "# ModelConfig.AUGMENT = True\n",
                "# ModelConfig.USE_KAGGLE_SPECTROGRAMS = True\n",
                "# ModelConfig.USE_EEG_SPECTROGRAMS = True\n",
                "# ModelConfig.REGULARIZATION = None\n",
                "# ModelConfig.AUGMENTATIONS = ['xy_masking']\n",
                "# ModelConfig.MAE_PRETRAINED_WEIGHTS = \"./outputs/vit_mae_pretraining/ViTMAE_PreTrained_Best.pth\"\n",
                "# ModelConfig.MAE_HIDDEN_DROPOUT_PROB = 0.1\n",
                "# ModelConfig.MAE_ATTENTION_DROPOUT_PROB = 0.1\n",
                "# ModelConfig.DROP_RATE = 0.2\n",
                "\n",
                "# hms_predictor = HMSPredictor(paths.OUTPUT_DIR, ModelConfig, k_fold=5)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "hms_predictor.train_model(train_easy, train_hard, all_specs, all_eegs)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "pd.set_option('display.max_columns', None)\n",
                "KL_CRITERION = nn.KLDivLoss(reduction='batchmean')\n",
                "SOFTMAX = nn.Softmax(dim=1)\n",
                "\n",
                "TARGET2ID = {\n",
                "    'Seizure': 0,\n",
                "    'LPD': 1,\n",
                "    'GPD': 2,\n",
                "    'LRDA': 3,\n",
                "    'GRDA': 4,\n",
                "    'Other': 5\n",
                "}\n",
                "\n",
                "from kl_divergence import score as kaggle_score \n",
                "\n",
                "def calc_kaggle_score(oof_df):\n",
                "    submission_df = oof_df[['eeg_id']+TARGETS_PRED].copy()\n",
                "    submission_df.columns = ['eeg_id'] + TARGETS\n",
                "    solution_df = oof_df[['eeg_id']+TARGETS].copy()\n",
                "    return kaggle_score(solution_df, submission_df, 'eeg_id')\n",
                "\n",
                "def analyze_oof(oof_csv):\n",
                "\n",
                "    oof_df = pd.read_csv(oof_csv)\n",
                "    oof_df['target_pred'] = oof_df[TARGETS_PRED].apply(lambda x: np.argmax(x), axis=1)\n",
                "    oof_df['target_id'] = oof_df[TARGETS].apply(lambda x: np.argmax(x), axis=1)\n",
                "    \n",
                "    oof_df[\"kl_loss\"] = oof_df.apply(\n",
                "    lambda row: \n",
                "        KL_CRITERION(\n",
                "            F.log_softmax(\n",
                "                    torch.tensor(row[TARGETS_PRED].astype(np.float32)).unsqueeze(0)\n",
                "                , dim=1\n",
                "                ), \n",
                "            torch.tensor(row[TARGETS].astype(np.float32))\n",
                "            ).numpy(),\n",
                "    axis=1)\n",
                "\n",
                "    oof_df[\"kl_loss\"] = oof_df['kl_loss'].astype(np.float32)\n",
                "\n",
                "    oof_df[TARGETS_PRED] = SOFTMAX( torch.tensor(oof_df[TARGETS_PRED].values.astype(np.float32)))\n",
                "\n",
                "    oof_df.head()\n",
                "\n",
                "    return oof_df"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "csv_path = f'./outputs/{ModelConfig.MODEL_NAME}/{ModelConfig.MODEL_NAME}_oof_1.csv'\n",
                "oof_df = analyze_oof(csv_path)\n",
                "\n",
                "print(\"Kaggle Score: \", calc_kaggle_score(oof_df))\n",
                "print(\"Average KL Loss: \", oof_df[\"kl_loss\"].mean())\n",
                "\n",
                "oof_df.head()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "plot_oof = oof_df.copy()\n",
                "\n",
                "# plot confusion matrix\n",
                "from sklearn.metrics import confusion_matrix\n",
                "import seaborn as sns\n",
                "\n",
                "cm = confusion_matrix(plot_oof['target_id'], plot_oof['target_pred']) # (y_true, y_pred)\n",
                "cm = cm / cm.sum(axis=1)[:, np.newaxis]\n",
                "\n",
                "fig = plt.figure(figsize=(6, 6))\n",
                "sns.heatmap(cm, annot=True, cmap='Blues', xticklabels=TARGET2ID.keys(), yticklabels=TARGET2ID.keys())\n",
                "plt.xlabel('Predicted', fontsize=12)\n",
                "plt.ylabel('True', fontsize=12)\n",
                "plt.title(csv_path.split('/')[-1].split('.')[0], fontsize=12)\n",
                "fig.tight_layout()\n",
                "fig.savefig(f\"./outputs/{ModelConfig.MODEL_NAME}/{csv_path.split('/')[-1].split('.')[0]}_CM.png\")\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "oof_df[\"kl_loss\"].plot(kind='hist', bins=100, title='KL Loss Distribution', figsize=(8, 5))\n",
                "print(oof_df[\"kl_loss\"].mean())\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# new figure\n",
                "fig, axes = plt.subplots(6, 5, figsize=(18, 16), sharex=True, sharey=True)\n",
                "\n",
                "plot_oof = oof_df[oof_df['kl_loss'] > 2]\n",
                "\n",
                "for row in range(axes.shape[0]):\n",
                "    row_selects = plot_oof[plot_oof['target_id']==row]\n",
                "    target_label = BRAIN_ACTIVITY[row]\n",
                "    for col in range(axes.shape[1]):\n",
                "        ax = axes[row, col]\n",
                "        idx = np.random.choice(row_selects.index)\n",
                "        df_rows = plot_oof.loc[idx]\n",
                "        ax.plot(df_rows[TARGETS].values , label='True')\n",
                "        ax.plot(df_rows[TARGETS_PRED].values, label='Pred')\n",
                "        ax.set_title(f\"{idx} | KL: {df_rows['kl_loss']:.4f} \") #\n",
                "        ax.set_xticks(range(6))\n",
                "        ax.set_xticklabels(BRAIN_ACTIVITY)\n",
                "        ax.grid(True)\n",
                "        ax.legend()\n",
                "        if col == 0:\n",
                "            ax.set_ylabel(target_label, fontsize=12)\n",
                "       \n",
                "fig.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "csv_path = './outputs/ENet_b2_xymasking_remove_less/ENet_b2_xymasking_remove_less_oof_2.csv'\n",
                "\n",
                "oof_df = pd.read_csv(csv_path)\n",
                "\n",
                "oof_df[\"kl_loss\"] = oof_df.apply(\n",
                "    lambda row: \n",
                "        KL_CRITERION(\n",
                "            F.log_softmax(\n",
                "                SOFTMAX(\n",
                "                    torch.tensor(row[TARGETS_PRED].astype(np.float32)).unsqueeze(0)\n",
                "                    )\n",
                "                ), \n",
                "            torch.tensor(row[TARGETS].astype(np.float32))\n",
                "            ).numpy(),\n",
                "    axis=1)\n",
                "\n",
                "oof_df[\"kl_loss\"] = oof_df['kl_loss'].astype(np.float32)\n",
                "\n",
                "# y_pred = oof_df[TARGETS_PRED].values.astype(np.float32)\n",
                "# y_pred_smax = SOFTMAX(torch.tensor(y_pred)).numpy()\n",
                "# oof_df[TARGETS_PRED] = y_pred_smax\n",
                "\n",
                "oof_df['target_pred'] = oof_df[TARGETS_PRED].apply(lambda x: np.argmax(x), axis=1)\n",
                "oof_df['target_id'] = oof_df['target'].map(TARGET2ID)\n",
                "\n",
                "oof_df.head()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "oof_df[\"kl_loss\"].plot(kind='hist', bins=100, title='KL Loss Distribution', figsize=(8, 5))\n",
                "print(oof_df[\"kl_loss\"].mean())\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "KL_CRITERION(\n",
                "    torch.log(\n",
                "        SOFTMAX(\n",
                "            torch.tensor(oof_df[TARGETS_PRED].values.astype(np.float32))\n",
                "            )\n",
                "        ), \n",
                "    torch.tensor(oof_df[TARGETS].values.astype(np.float32))\n",
                "    ).numpy(),"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "plot_oof = oof_df.copy()\n",
                "\n",
                "# plot confusion matrix\n",
                "from sklearn.metrics import confusion_matrix\n",
                "import seaborn as sns\n",
                "\n",
                "cm = confusion_matrix(plot_oof['target_id'], plot_oof['target_pred']) # (y_true, y_pred)\n",
                "cm = cm / cm.sum(axis=1)[:, np.newaxis]\n",
                "\n",
                "fig = plt.figure(figsize=(6, 6))\n",
                "sns.heatmap(cm, annot=True, cmap='Blues', xticklabels=TARGET2ID.keys(), yticklabels=TARGET2ID.keys())\n",
                "plt.xlabel('Predicted', fontsize=12)\n",
                "plt.ylabel('True', fontsize=12)\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# new figure\n",
                "fig, axes = plt.subplots(6, 5, figsize=(18, 16), sharex=True, sharey=True)\n",
                "\n",
                "plot_oof = oof_df[oof_df['kl_loss'] > 0.2]\n",
                "\n",
                "for row in range(axes.shape[0]):\n",
                "    row_selects = plot_oof[plot_oof['target_id']==row]\n",
                "    target_label = BRAIN_ACTIVITY[row]\n",
                "    for col in range(axes.shape[1]):\n",
                "        ax = axes[row, col]\n",
                "        idx = np.random.choice(row_selects.index)\n",
                "        df_rows = plot_oof.loc[idx]\n",
                "        ax.plot(df_rows[TARGETS].values , label='True')\n",
                "        ax.plot(df_rows[TARGETS_PRED].values, label='Pred')\n",
                "        ax.set_title(f\"{idx} | KL: {df_rows['kl_loss']:.4f} \") #\n",
                "        ax.set_xticks(range(6))\n",
                "        ax.set_xticklabels(BRAIN_ACTIVITY)\n",
                "        ax.grid(True)\n",
                "        ax.legend()\n",
                "        if col == 0:\n",
                "            ax.set_ylabel(target_label, fontsize=12)\n",
                "       \n",
                "fig.tight_layout()\n",
                "plt.show()\n",
                "\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "oof_df[oof_df['eeg_id'] == 11127485]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "oof_df[oof_df['eeg_id'].duplicated()] #oof_df.shape #.groupby('eeg_id')['patient_id'].agg(['nunique', 'count']).sort_values(by='count', ascending=False).head(10)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "score_kaggle = oof_df2.loc[:10].apply(lambda row: calc_kaggle_score(row[['eeg_id']+TARGETS], row[['eeg_id']+TARGETS_PRED]), axis=1)\n",
                "score_kaggle"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "submission_df = oof_df2[['eeg_id']+TARGETS_PRED].copy()\n",
                "submission_df.columns = ['eeg_id'] + TARGETS\n",
                "\n",
                "solution_df = oof_df2[['eeg_id']+TARGETS].copy()\n",
                "\n",
                "score_value = kaggle_score(solution_df, submission_df, 'eeg_id')\n",
                "\n",
                "score_value"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# oof_df1, cv_1 = analyze_oof(\"./outputs/ENet_b2_xymasking_remove_less/ENet_b2_xymasking_remove_less_oof_1.csv\")\n",
                "# print(cv_1)\n",
                "# oof_df1.head()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "kaggle",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.6"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
