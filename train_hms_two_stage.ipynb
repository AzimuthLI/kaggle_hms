{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import pandas as pd \n",
                "import numpy as np \n",
                "import matplotlib.pyplot as plt\n",
                "from sklearn.metrics import confusion_matrix\n",
                "import seaborn as sns\n",
                "import gc\n",
                "\n",
                "from kl_divergence import score as kaggle_score \n",
                "from engine_hms_trainer import (\n",
                "    seed_everything, gen_non_overlap_samples, calc_entropy, evaluate_oof, get_logger, \n",
                "    Trainer, TARGETS, TARGETS_PRED, BRAIN_ACTIVITY\n",
                "    )\n",
                "from engine_hms_model import (\n",
                "    KagglePaths, LocalPaths, ModelConfig, CustomDataset, CustomEfficientNET, CustomVITMAE, DualEncoderModel, \n",
                ")\n",
                "\n",
                "import torch\n",
                "from torch import nn\n",
                "import torch.nn.functional as F\n",
                "from torch.utils.data import DataLoader, Dataset\n",
                "\n",
                "from time import ctime, time\n",
                "from sklearn.model_selection import KFold\n",
                "\n",
                "import warnings\n",
                "# warnings.filterwarnings('ignore')\n",
                "\n",
                "pd.set_option('display.max_columns', None)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Output Dir:  ./outputs/\n"
                    ]
                }
            ],
            "source": [
                "PATHS = KagglePaths if os.path.exists(KagglePaths.OUTPUT_DIR) else LocalPaths\n",
                "print(\"Output Dir: \", PATHS.OUTPUT_DIR)\n",
                "\n",
                "ALL_SPECS = np.load(PATHS.PRE_LOADED_SPECTROGRAMS, allow_pickle=True).item()\n",
                "ALL_EEGS = np.load(PATHS.PRE_LOADED_EEGS, allow_pickle=True).item()\n",
                "\n",
                "seed_everything(ModelConfig.SEED)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [],
            "source": [
                "def prepare_k_fold(df, k_folds=5):\n",
                "\n",
                "    kf = KFold(n_splits=k_folds, shuffle=True, random_state=ModelConfig.SEED)\n",
                "    unique_spec_id = df['spectrogram_id'].unique()\n",
                "    df['fold'] = k_folds\n",
                "\n",
                "    for fold, (train_index, valid_index) in enumerate(kf.split(unique_spec_id)):\n",
                "        df.loc[df['spectrogram_id'].isin(unique_spec_id[valid_index]), 'fold'] = fold\n",
                "\n",
                "    return df\n",
                "\n",
                "\n",
                "def train_fold(model, fold_id, train_folds, valid_folds, logger, stage=1, checkpoint=None):\n",
                "\n",
                "    train_dataset = CustomDataset(\n",
                "        train_folds, TARGETS, ModelConfig, ALL_SPECS, ALL_EEGS, mode=\"train\")\n",
                "\n",
                "    valid_dataset = CustomDataset(\n",
                "        valid_folds, TARGETS, ModelConfig, ALL_SPECS, ALL_EEGS, mode=\"valid\")\n",
                "\n",
                "    # ======== DATALOADERS ==========\n",
                "    loader_kwargs = {\n",
                "        \"batch_size\": ModelConfig.BATCH_SIZE,\n",
                "        \"num_workers\": ModelConfig.NUM_WORKERS,\n",
                "        \"pin_memory\": True,\n",
                "        \"shuffle\": False,\n",
                "    }\n",
                "    train_loader = DataLoader(train_dataset, drop_last=True, **loader_kwargs)\n",
                "    valid_loader = DataLoader(valid_dataset, drop_last=False, **loader_kwargs)\n",
                "\n",
                "    trainer = Trainer(model, ModelConfig, logger)\n",
                "    best_weights, best_preds, loss_records = trainer.train(\n",
                "        train_loader, valid_loader, from_checkpoint=checkpoint)\n",
                "\n",
                "    save_model_name = f\"{ModelConfig.MODEL_NAME}_fold_{fold_id}_stage_{stage}.pth\"\n",
                "    torch.save(best_weights, os.path.join(PATHS.OUTPUT_DIR, save_model_name))\n",
                "\n",
                "    del train_dataset, valid_dataset, train_loader, valid_loader\n",
                "    torch.cuda.empty_cache()\n",
                "    gc.collect()\n",
                "\n",
                "    return best_preds, loss_records\n",
                "\n",
                "def get_model(pretrained=True):\n",
                "    \n",
                "    backbone = ModelConfig.MODEL_BACKBONE\n",
                "\n",
                "    if \"efficientnet\" in backbone:\n",
                "        return CustomEfficientNET(ModelConfig, num_classes=6, pretrained=pretrained)\n",
                "    elif \"vit\" in backbone:\n",
                "        return CustomVITMAE(ModelConfig, num_classes=6, pretrained=pretrained)\n",
                "    elif \"dual\" in backbone:\n",
                "        return DualEncoderModel(ModelConfig, num_classes=6, pretrained=pretrained)\n",
                "    else:\n",
                "        return None"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [],
            "source": [
                "TARGET2ID = {'Seizure': 0, 'LPD': 1, 'GPD': 2, 'LRDA': 3, 'GRDA': 4, 'Other': 5}\n",
                "\n",
                "def calc_kaggle_score(oof_df):\n",
                "    submission_df = oof_df[['eeg_id']+TARGETS_PRED].copy()\n",
                "    submission_df.columns = ['eeg_id'] + TARGETS\n",
                "    solution_df = oof_df[['eeg_id']+TARGETS].copy()\n",
                "    return kaggle_score(solution_df, submission_df, 'eeg_id')\n",
                "\n",
                "def analyze_oof(oof_csv):\n",
                "\n",
                "    kl_criteria = nn.KLDivLoss(reduction='batchmean')\n",
                "    softmax = nn.Softmax(dim=1)\n",
                "\n",
                "    oof_df = pd.read_csv(oof_csv)\n",
                "    oof_df['target_pred'] = oof_df[TARGETS_PRED].apply(lambda x: np.argmax(x), axis=1)\n",
                "    oof_df['target_id'] = oof_df[TARGETS].apply(lambda x: np.argmax(x), axis=1)\n",
                "    \n",
                "    oof_df[\"kl_loss\"] = oof_df.apply(\n",
                "    lambda row: \n",
                "        kl_criteria(\n",
                "            F.log_softmax(\n",
                "                    torch.tensor(row[TARGETS_PRED].values.astype(np.float32)).unsqueeze(0)\n",
                "                , dim=1\n",
                "                ), \n",
                "            torch.tensor(row[TARGETS].values.astype(np.float32))\n",
                "            ).numpy(),\n",
                "    axis=1)\n",
                "\n",
                "    oof_df[\"kl_loss\"] = oof_df['kl_loss'].astype(np.float32)\n",
                "\n",
                "    oof_df[TARGETS_PRED] = softmax( torch.tensor(oof_df[TARGETS_PRED].values.astype(np.float32)) )\n",
                "\n",
                "    oof_df.head()\n",
                "\n",
                "    return oof_df"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "targets:  ['seizure_vote', 'lpd_vote', 'gpd_vote', 'lrda_vote', 'grda_vote', 'other_vote']\n",
                        "train_all.shape =  (20183, 12)\n",
                        "train_all nan_count:  0\n"
                    ]
                },
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>eeg_id</th>\n",
                            "      <th>seizure_vote</th>\n",
                            "      <th>lpd_vote</th>\n",
                            "      <th>gpd_vote</th>\n",
                            "      <th>lrda_vote</th>\n",
                            "      <th>grda_vote</th>\n",
                            "      <th>other_vote</th>\n",
                            "      <th>spectrogram_id</th>\n",
                            "      <th>min</th>\n",
                            "      <th>max</th>\n",
                            "      <th>patient_id</th>\n",
                            "      <th>target</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>0</th>\n",
                            "      <td>568657</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.000000</td>\n",
                            "      <td>0.25</td>\n",
                            "      <td>0.000000</td>\n",
                            "      <td>0.166667</td>\n",
                            "      <td>0.583333</td>\n",
                            "      <td>789577333</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>16.0</td>\n",
                            "      <td>20654</td>\n",
                            "      <td>Other</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1</th>\n",
                            "      <td>582999</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.857143</td>\n",
                            "      <td>0.00</td>\n",
                            "      <td>0.071429</td>\n",
                            "      <td>0.000000</td>\n",
                            "      <td>0.071429</td>\n",
                            "      <td>1552638400</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>38.0</td>\n",
                            "      <td>20230</td>\n",
                            "      <td>LPD</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>2</th>\n",
                            "      <td>642382</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.000000</td>\n",
                            "      <td>0.00</td>\n",
                            "      <td>0.000000</td>\n",
                            "      <td>0.000000</td>\n",
                            "      <td>1.000000</td>\n",
                            "      <td>14960202</td>\n",
                            "      <td>1008.0</td>\n",
                            "      <td>1032.0</td>\n",
                            "      <td>5955</td>\n",
                            "      <td>Other</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>3</th>\n",
                            "      <td>751790</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.000000</td>\n",
                            "      <td>1.00</td>\n",
                            "      <td>0.000000</td>\n",
                            "      <td>0.000000</td>\n",
                            "      <td>0.000000</td>\n",
                            "      <td>618728447</td>\n",
                            "      <td>908.0</td>\n",
                            "      <td>908.0</td>\n",
                            "      <td>38549</td>\n",
                            "      <td>GPD</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>4</th>\n",
                            "      <td>778705</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.000000</td>\n",
                            "      <td>0.00</td>\n",
                            "      <td>0.000000</td>\n",
                            "      <td>0.000000</td>\n",
                            "      <td>1.000000</td>\n",
                            "      <td>52296320</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>40955</td>\n",
                            "      <td>Other</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "   eeg_id  seizure_vote  lpd_vote  gpd_vote  lrda_vote  grda_vote  other_vote  \\\n",
                            "0  568657           0.0  0.000000      0.25   0.000000   0.166667    0.583333   \n",
                            "1  582999           0.0  0.857143      0.00   0.071429   0.000000    0.071429   \n",
                            "2  642382           0.0  0.000000      0.00   0.000000   0.000000    1.000000   \n",
                            "3  751790           0.0  0.000000      1.00   0.000000   0.000000    0.000000   \n",
                            "4  778705           0.0  0.000000      0.00   0.000000   0.000000    1.000000   \n",
                            "\n",
                            "   spectrogram_id     min     max  patient_id target  \n",
                            "0       789577333     0.0    16.0       20654  Other  \n",
                            "1      1552638400     0.0    38.0       20230    LPD  \n",
                            "2        14960202  1008.0  1032.0        5955  Other  \n",
                            "3       618728447   908.0   908.0       38549    GPD  \n",
                            "4        52296320     0.0     0.0       40955  Other  "
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        " \n",
                        "train_hard.shape =  (6187, 12)\n",
                        "train_hard nan_count:  0\n"
                    ]
                },
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>eeg_id</th>\n",
                            "      <th>seizure_vote</th>\n",
                            "      <th>lpd_vote</th>\n",
                            "      <th>gpd_vote</th>\n",
                            "      <th>lrda_vote</th>\n",
                            "      <th>grda_vote</th>\n",
                            "      <th>other_vote</th>\n",
                            "      <th>spectrogram_id</th>\n",
                            "      <th>min</th>\n",
                            "      <th>max</th>\n",
                            "      <th>patient_id</th>\n",
                            "      <th>target</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>0</th>\n",
                            "      <td>568657</td>\n",
                            "      <td>0.000000</td>\n",
                            "      <td>0.000000</td>\n",
                            "      <td>0.250000</td>\n",
                            "      <td>0.000000</td>\n",
                            "      <td>0.166667</td>\n",
                            "      <td>0.583333</td>\n",
                            "      <td>789577333</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>16.0</td>\n",
                            "      <td>20654</td>\n",
                            "      <td>Other</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1</th>\n",
                            "      <td>582999</td>\n",
                            "      <td>0.000000</td>\n",
                            "      <td>0.857143</td>\n",
                            "      <td>0.000000</td>\n",
                            "      <td>0.071429</td>\n",
                            "      <td>0.000000</td>\n",
                            "      <td>0.071429</td>\n",
                            "      <td>1552638400</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>38.0</td>\n",
                            "      <td>20230</td>\n",
                            "      <td>LPD</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>2</th>\n",
                            "      <td>1895581</td>\n",
                            "      <td>0.076923</td>\n",
                            "      <td>0.000000</td>\n",
                            "      <td>0.000000</td>\n",
                            "      <td>0.000000</td>\n",
                            "      <td>0.076923</td>\n",
                            "      <td>0.846154</td>\n",
                            "      <td>128369999</td>\n",
                            "      <td>1138.0</td>\n",
                            "      <td>1138.0</td>\n",
                            "      <td>47999</td>\n",
                            "      <td>Other</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>3</th>\n",
                            "      <td>2482631</td>\n",
                            "      <td>0.000000</td>\n",
                            "      <td>0.000000</td>\n",
                            "      <td>0.133333</td>\n",
                            "      <td>0.066667</td>\n",
                            "      <td>0.133333</td>\n",
                            "      <td>0.666667</td>\n",
                            "      <td>978166025</td>\n",
                            "      <td>1902.0</td>\n",
                            "      <td>1944.0</td>\n",
                            "      <td>20606</td>\n",
                            "      <td>Other</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>4</th>\n",
                            "      <td>2521897</td>\n",
                            "      <td>0.000000</td>\n",
                            "      <td>0.000000</td>\n",
                            "      <td>0.083333</td>\n",
                            "      <td>0.083333</td>\n",
                            "      <td>0.333333</td>\n",
                            "      <td>0.500000</td>\n",
                            "      <td>673742515</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>4.0</td>\n",
                            "      <td>62117</td>\n",
                            "      <td>Other</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "    eeg_id  seizure_vote  lpd_vote  gpd_vote  lrda_vote  grda_vote  \\\n",
                            "0   568657      0.000000  0.000000  0.250000   0.000000   0.166667   \n",
                            "1   582999      0.000000  0.857143  0.000000   0.071429   0.000000   \n",
                            "2  1895581      0.076923  0.000000  0.000000   0.000000   0.076923   \n",
                            "3  2482631      0.000000  0.000000  0.133333   0.066667   0.133333   \n",
                            "4  2521897      0.000000  0.000000  0.083333   0.083333   0.333333   \n",
                            "\n",
                            "   other_vote  spectrogram_id     min     max  patient_id target  \n",
                            "0    0.583333       789577333     0.0    16.0       20654  Other  \n",
                            "1    0.071429      1552638400     0.0    38.0       20230    LPD  \n",
                            "2    0.846154       128369999  1138.0  1138.0       47999  Other  \n",
                            "3    0.666667       978166025  1902.0  1944.0       20606  Other  \n",
                            "4    0.500000       673742515     0.0     4.0       62117  Other  "
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                }
            ],
            "source": [
                "# train_easy, train_hard, all_specs, all_eegs = load_kaggle_data(\n",
                "#     paths.TRAIN_CSV, paths.PRE_LOADED_SPECTOGRAMS, paths.PRE_LOADED_EEGS, split_entropy=ModelConfig.SPLIT_ENTROPY)\n",
                "\n",
                "train_csv = pd.read_csv(PATHS.TRAIN_CSV)\n",
                "targets = train_csv.columns[-6:]\n",
                "\n",
                "print(\"targets: \", targets.to_list())\n",
                "\n",
                "train_csv['entropy'] = train_csv.apply(calc_entropy, axis=1, tgt_list=targets)\n",
                "train_csv['total_votes'] = train_csv[targets].sum(axis=1)\n",
                "\n",
                "hard_csv = train_csv[train_csv['entropy'] < ModelConfig.SPLIT_ENTROPY].copy().reset_index(drop=True)\n",
                "\n",
                "train_all = gen_non_overlap_samples(train_csv, targets)\n",
                "train_hard = gen_non_overlap_samples(hard_csv, targets)\n",
                "\n",
                "print(\"train_all.shape = \", train_all.shape)\n",
                "print(\"train_all nan_count: \", train_all.isnull().sum().sum())\n",
                "display(train_all.head())\n",
                "\n",
                "print(\" \")\n",
                "\n",
                "print(\"train_hard.shape = \", train_hard.shape)\n",
                "print(\"train_hard nan_count: \", train_hard.isnull().sum().sum())\n",
                "display(train_hard.head())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [],
            "source": [
                "# # EfficientNet_B2_resplit (CV=0.5330731377333943)\n",
                "# ModelConfig.EPOCHS = 6\n",
                "# ModelConfig.BATCH_SIZE = 16\n",
                "# ModelConfig.GRADIENT_ACCUMULATION_STEPS = 1\n",
                "# ModelConfig.MODEL_BACKBONE = 'tf_efficientnet_b2'\n",
                "# ModelConfig.MODEL_NAME = \"EfficientNet_B2_resplit\"\n",
                "# ModelConfig.USE_KAGGLE_SPECTROGRAMS = True\n",
                "# ModelConfig.USE_EEG_SPECTROGRAMS = True\n",
                "# ModelConfig.REGULARIZATION = None\n",
                "# ModelConfig.AUGMENT = True\n",
                "# ModelConfig.AUGMENTATIONS = ['xy_masking']\n",
                "\n",
                "# # config DualEncoder\n",
                "# ModelConfig.EPOCHS = 6\n",
                "# ModelConfig.BATCH_SIZE = 16\n",
                "# ModelConfig.GRADIENT_ACCUMULATION_STEPS = 1\n",
                "# ModelConfig.MODEL_BACKBONE = 'dual_encoder'\n",
                "# ModelConfig.MODEL_NAME = \"DualEncoder_B0\"\n",
                "# ModelConfig.USE_KAGGLE_SPECTROGRAMS = True\n",
                "# ModelConfig.USE_EEG_SPECTROGRAMS = True\n",
                "# ModelConfig.REGULARIZATION = None\n",
                "# ModelConfig.AUGMENT = False\n",
                "# ModelConfig.AUGMENTATIONS = []\n",
                "# ModelConfig.DUAL_ENCODER_BACKBONE = 'tf_efficientnet_b0'\n",
                "\n",
                "# Config ViTMAE\n",
                "ModelConfig.EPOCHS = 15\n",
                "ModelConfig.BATCH_SIZE = 16\n",
                "ModelConfig.GRADIENT_ACCUMULATION_STEPS = 1\n",
                "ModelConfig.MODEL_BACKBONE = 'vit_mae_base'\n",
                "ModelConfig.MODEL_NAME = \"MAE_RawBase_SeqPool_epoch_15\"\n",
                "ModelConfig.AUGMENT = True\n",
                "ModelConfig.USE_KAGGLE_SPECTROGRAMS = True\n",
                "ModelConfig.USE_EEG_SPECTROGRAMS = True\n",
                "ModelConfig.REGULARIZATION = None\n",
                "ModelConfig.AUGMENTATIONS = ['xy_masking']\n",
                "ModelConfig.MAE_PRETRAINED_WEIGHTS = \"facebook/vit-mae-base\" #\"./outputs/vit_mae_pretraining/ViTMAE_PreTrained_Best.pth\"\n",
                "ModelConfig.MAE_HIDDEN_DROPOUT_PROB = 0.1\n",
                "ModelConfig.MAE_ATTENTION_DROPOUT_PROB = 0.1\n",
                "ModelConfig.DROP_RATE = 0.2"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "****************************************************************************************************\n",
                        "Script Start: Mon Mar 25 16:33:33 2024\n",
                        "Model Configurations:\n",
                        "SEED: 20\n",
                        "SPLIT_ENTROPY: 5.5\n",
                        "MODEL_NAME: MAE_RawBase_SeqPool_epoch_15\n",
                        "MODEL_BACKBONE: vit_mae_base\n",
                        "BATCH_SIZE: 16\n",
                        "EPOCHS: 15\n",
                        "GRADIENT_ACCUMULATION_STEPS: 1\n",
                        "DROP_RATE: 0.2\n",
                        "DROP_PATH_RATE: 0.25\n",
                        "WEIGHT_DECAY: 0.01\n",
                        "REGULARIZATION: None\n",
                        "USE_KAGGLE_SPECTROGRAMS: True\n",
                        "USE_EEG_SPECTROGRAMS: True\n",
                        "AMP: True\n",
                        "AUGMENT: True\n",
                        "AUGMENTATIONS: ['xy_masking']\n",
                        "PRINT_FREQ: 50\n",
                        "FREEZE: False\n",
                        "NUM_FROZEN_LAYERS: 0\n",
                        "NUM_WORKERS: 0\n",
                        "MAX_GRAD_NORM: 10000000.0\n",
                        "DUAL_ENCODER_BACKBONE: tf_efficientnet_b2\n",
                        "MAE_PRETRAINED_WEIGHTS: facebook/vit-mae-base\n",
                        "MAE_HIDDEN_DROPOUT_PROB: 0.1\n",
                        "MAE_ATTENTION_DROPOUT_PROB: 0.1\n",
                        "****************************************************************************************************\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Loading pretrained weights from facebook/vit-mae-base\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "====================================================================================================\n",
                        "Fold: 0 || Valid size 3988 \n",
                        "====================================================================================================\n",
                        "- First Stage -\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "c3219d0e94f84252841c1e495cf95cd6",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Train [0]:   0%|          | 0/1012 [00:00<?, ?batch/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch 1 [0/1012] | Train Loss: 1.4969 Grad: 119964.2812 LR: 4.0001e-06 | Elapse: 0.91s\n",
                        "Epoch 1 [50/1012] | Train Loss: 1.3669 Grad: 40882.8789 LR: 4.2675e-06 | Elapse: 4.86s\n",
                        "Epoch 1 [100/1012] | Train Loss: 1.3231 Grad: 46299.6016 LR: 5.0462e-06 | Elapse: 8.82s\n",
                        "Epoch 1 [150/1012] | Train Loss: 1.2943 Grad: 42300.8984 LR: 6.3278e-06 | Elapse: 12.76s\n",
                        "Epoch 1 [200/1012] | Train Loss: 1.2733 Grad: 144970.4531 LR: 8.0988e-06 | Elapse: 16.73s\n",
                        "Epoch 1 [250/1012] | Train Loss: 1.2660 Grad: 83684.8203 LR: 1.0340e-05 | Elapse: 20.67s\n",
                        "Epoch 1 [300/1012] | Train Loss: 1.2547 Grad: 93656.4375 LR: 1.3027e-05 | Elapse: 24.62s\n",
                        "Epoch 1 [350/1012] | Train Loss: 1.2509 Grad: 153152.7031 LR: 1.6132e-05 | Elapse: 28.54s\n",
                        "Epoch 1 [400/1012] | Train Loss: 1.2397 Grad: 183264.5625 LR: 1.9622e-05 | Elapse: 32.46s\n",
                        "Epoch 1 [450/1012] | Train Loss: 1.2220 Grad: 103367.3438 LR: 2.3458e-05 | Elapse: 36.40s\n",
                        "Epoch 1 [500/1012] | Train Loss: 1.2089 Grad: 119292.9609 LR: 2.7599e-05 | Elapse: 40.35s\n",
                        "Epoch 1 [550/1012] | Train Loss: 1.1930 Grad: 109320.5469 LR: 3.2003e-05 | Elapse: 44.26s\n",
                        "Epoch 1 [600/1012] | Train Loss: 1.1823 Grad: 242352.1719 LR: 3.6620e-05 | Elapse: 48.17s\n",
                        "Epoch 1 [650/1012] | Train Loss: 1.1744 Grad: 115451.9453 LR: 4.1402e-05 | Elapse: 52.08s\n",
                        "Epoch 1 [700/1012] | Train Loss: 1.1614 Grad: 182869.6406 LR: 4.6298e-05 | Elapse: 56.01s\n",
                        "Epoch 1 [750/1012] | Train Loss: 1.1516 Grad: 71610.8359 LR: 5.1254e-05 | Elapse: 59.93s\n",
                        "Epoch 1 [800/1012] | Train Loss: 1.1433 Grad: 96990.7188 LR: 5.6219e-05 | Elapse: 63.83s\n",
                        "Epoch 1 [850/1012] | Train Loss: 1.1324 Grad: 98363.6250 LR: 6.1139e-05 | Elapse: 67.75s\n",
                        "Epoch 1 [900/1012] | Train Loss: 1.1211 Grad: 154777.2969 LR: 6.5960e-05 | Elapse: 71.66s\n",
                        "Epoch 1 [950/1012] | Train Loss: 1.1120 Grad: 113893.1641 LR: 7.0633e-05 | Elapse: 75.57s\n",
                        "Epoch 1 [1000/1012] | Train Loss: 1.1035 Grad: 119195.1797 LR: 7.5105e-05 | Elapse: 79.54s\n",
                        "Epoch 1 [1011/1012] | Train Loss: 1.1018 Grad: 76590.3125 LR: 7.6057e-05 | Elapse: 80.45s\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "4d98e0e0acee4c2ebb74acba2b638032",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Valid [0]:   0%|          | 0/250 [00:00<?, ?batch/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch 1 [0/250] | Valid Loss: 0.7515 | Elapse: 0.06s\n",
                        "Epoch 1 [50/250] | Valid Loss: 0.9421 | Elapse: 2.51s\n",
                        "Epoch 1 [100/250] | Valid Loss: 0.9596 | Elapse: 5.07s\n",
                        "Epoch 1 [150/250] | Valid Loss: 0.9713 | Elapse: 7.67s\n",
                        "Epoch 1 [200/250] | Valid Loss: 0.9784 | Elapse: 10.30s\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "----------------------------------------------------------------------------------------------------\n",
                        "Epoch 1 - Average Loss: (train) 1.1018; (valid) 0.9758 | Time: 93.30s\n",
                        "Best model found in epoch 1 | valid loss: 0.9758\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch 1 [249/250] | Valid Loss: 0.9758 | Elapse: 12.85s\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "dd5d353c95fc455a99ce55cd88171be7",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Train [1]:   0%|          | 0/1012 [00:00<?, ?batch/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch 2 [0/1012] | Train Loss: 1.1342 Grad: 222867.9844 LR: 7.6143e-05 | Elapse: 0.09s\n",
                        "Epoch 2 [50/1012] | Train Loss: 0.9043 Grad: 101021.7891 LR: 8.0302e-05 | Elapse: 3.97s\n",
                        "Epoch 2 [100/1012] | Train Loss: 0.9019 Grad: 99565.1719 LR: 8.4158e-05 | Elapse: 7.88s\n",
                        "Epoch 2 [150/1012] | Train Loss: 0.9092 Grad: 101741.6719 LR: 8.7669e-05 | Elapse: 11.80s\n",
                        "Epoch 2 [200/1012] | Train Loss: 0.9074 Grad: 135650.0312 LR: 9.0798e-05 | Elapse: 15.78s\n",
                        "Epoch 2 [250/1012] | Train Loss: 0.9121 Grad: 208963.3906 LR: 9.3511e-05 | Elapse: 19.67s\n",
                        "Epoch 2 [300/1012] | Train Loss: 0.9058 Grad: 83757.8047 LR: 9.5780e-05 | Elapse: 23.54s\n",
                        "Epoch 2 [350/1012] | Train Loss: 0.9103 Grad: 164514.6562 LR: 9.7580e-05 | Elapse: 27.58s\n",
                        "Epoch 2 [400/1012] | Train Loss: 0.9060 Grad: 156066.2812 LR: 9.8891e-05 | Elapse: 31.47s\n",
                        "Epoch 2 [450/1012] | Train Loss: 0.9062 Grad: 63541.8789 LR: 9.9700e-05 | Elapse: 35.39s\n",
                        "Epoch 2 [500/1012] | Train Loss: 0.9034 Grad: 130645.9922 LR: 9.9998e-05 | Elapse: 39.27s\n",
                        "Epoch 2 [550/1012] | Train Loss: 0.8990 Grad: 118366.7969 LR: 9.9997e-05 | Elapse: 43.18s\n",
                        "Epoch 2 [600/1012] | Train Loss: 0.8933 Grad: 130020.2266 LR: 9.9988e-05 | Elapse: 47.08s\n",
                        "Epoch 2 [650/1012] | Train Loss: 0.8899 Grad: 125659.7422 LR: 9.9972e-05 | Elapse: 50.97s\n",
                        "Epoch 2 [700/1012] | Train Loss: 0.8836 Grad: 102107.8047 LR: 9.9949e-05 | Elapse: 54.84s\n",
                        "Epoch 2 [750/1012] | Train Loss: 0.8824 Grad: 124232.5234 LR: 9.9920e-05 | Elapse: 58.74s\n",
                        "Epoch 2 [800/1012] | Train Loss: 0.8828 Grad: 71782.2266 LR: 9.9884e-05 | Elapse: 62.64s\n",
                        "Epoch 2 [850/1012] | Train Loss: 0.8791 Grad: 68500.4062 LR: 9.9842e-05 | Elapse: 66.52s\n",
                        "Epoch 2 [900/1012] | Train Loss: 0.8726 Grad: 100106.0391 LR: 9.9793e-05 | Elapse: 70.40s\n",
                        "Epoch 2 [950/1012] | Train Loss: 0.8697 Grad: 97943.7578 LR: 9.9737e-05 | Elapse: 74.30s\n",
                        "Epoch 2 [1000/1012] | Train Loss: 0.8666 Grad: 80386.5547 LR: 9.9675e-05 | Elapse: 78.22s\n",
                        "Epoch 2 [1011/1012] | Train Loss: 0.8663 Grad: 96742.0391 LR: 9.9661e-05 | Elapse: 79.08s\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "a1c2e607152f4c318d6643b0e1fa49ec",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Valid [1]:   0%|          | 0/250 [00:00<?, ?batch/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch 2 [0/250] | Valid Loss: 0.6560 | Elapse: 0.05s\n",
                        "Epoch 2 [50/250] | Valid Loss: 0.8125 | Elapse: 2.50s\n",
                        "Epoch 2 [100/250] | Valid Loss: 0.7851 | Elapse: 5.05s\n",
                        "Epoch 2 [150/250] | Valid Loss: 0.8023 | Elapse: 7.66s\n",
                        "Epoch 2 [200/250] | Valid Loss: 0.8018 | Elapse: 10.29s\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "----------------------------------------------------------------------------------------------------\n",
                        "Epoch 2 - Average Loss: (train) 0.8663; (valid) 0.8039 | Time: 91.91s\n",
                        "Best model found in epoch 2 | valid loss: 0.8039\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch 2 [249/250] | Valid Loss: 0.8039 | Elapse: 12.83s\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "335769be412c431ebe1947a841d287d4",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Train [2]:   0%|          | 0/1012 [00:00<?, ?batch/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch 3 [0/1012] | Train Loss: 0.7860 Grad: 172501.9844 LR: 9.9659e-05 | Elapse: 0.10s\n",
                        "Epoch 3 [50/1012] | Train Loss: 0.7720 Grad: 97949.8672 LR: 9.9589e-05 | Elapse: 4.04s\n",
                        "Epoch 3 [100/1012] | Train Loss: 0.7588 Grad: 88034.0312 LR: 9.9512e-05 | Elapse: 7.94s\n",
                        "Epoch 3 [150/1012] | Train Loss: 0.7666 Grad: 120735.2578 LR: 9.9429e-05 | Elapse: 11.96s\n",
                        "Epoch 3 [200/1012] | Train Loss: 0.7683 Grad: 101304.0859 LR: 9.9339e-05 | Elapse: 15.87s\n",
                        "Epoch 3 [250/1012] | Train Loss: 0.7723 Grad: 142041.2500 LR: 9.9243e-05 | Elapse: 19.75s\n",
                        "Epoch 3 [300/1012] | Train Loss: 0.7668 Grad: 72669.3438 LR: 9.9140e-05 | Elapse: 23.64s\n",
                        "Epoch 3 [350/1012] | Train Loss: 0.7755 Grad: 148030.7344 LR: 9.9030e-05 | Elapse: 27.55s\n",
                        "Epoch 3 [400/1012] | Train Loss: 0.7770 Grad: 134449.6250 LR: 9.8914e-05 | Elapse: 31.45s\n",
                        "Epoch 3 [450/1012] | Train Loss: 0.7771 Grad: 80175.9453 LR: 9.8792e-05 | Elapse: 35.33s\n",
                        "Epoch 3 [500/1012] | Train Loss: 0.7735 Grad: 174752.9219 LR: 9.8663e-05 | Elapse: 39.28s\n",
                        "Epoch 3 [550/1012] | Train Loss: 0.7725 Grad: 108445.9141 LR: 9.8528e-05 | Elapse: 43.24s\n",
                        "Epoch 3 [600/1012] | Train Loss: 0.7694 Grad: 137804.3594 LR: 9.8387e-05 | Elapse: 47.16s\n",
                        "Epoch 3 [650/1012] | Train Loss: 0.7684 Grad: 119930.5938 LR: 9.8238e-05 | Elapse: 51.08s\n",
                        "Epoch 3 [700/1012] | Train Loss: 0.7625 Grad: 70013.4531 LR: 9.8084e-05 | Elapse: 55.01s\n",
                        "Epoch 3 [750/1012] | Train Loss: 0.7644 Grad: 101665.5625 LR: 9.7923e-05 | Elapse: 58.92s\n",
                        "Epoch 3 [800/1012] | Train Loss: 0.7671 Grad: 75332.3984 LR: 9.7756e-05 | Elapse: 62.88s\n",
                        "Epoch 3 [850/1012] | Train Loss: 0.7651 Grad: 71070.7734 LR: 9.7583e-05 | Elapse: 66.78s\n",
                        "Epoch 3 [900/1012] | Train Loss: 0.7610 Grad: 87673.5625 LR: 9.7403e-05 | Elapse: 70.72s\n",
                        "Epoch 3 [950/1012] | Train Loss: 0.7581 Grad: 93964.3281 LR: 9.7217e-05 | Elapse: 74.65s\n",
                        "Epoch 3 [1000/1012] | Train Loss: 0.7572 Grad: 68030.6484 LR: 9.7025e-05 | Elapse: 78.56s\n",
                        "Epoch 3 [1011/1012] | Train Loss: 0.7571 Grad: 64891.4844 LR: 9.6982e-05 | Elapse: 79.41s\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "51543293314d4703b3a8eaf7c98d708d",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Valid [2]:   0%|          | 0/250 [00:00<?, ?batch/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch 3 [0/250] | Valid Loss: 0.4342 | Elapse: 0.06s\n",
                        "Epoch 3 [50/250] | Valid Loss: 0.6990 | Elapse: 2.48s\n",
                        "Epoch 3 [100/250] | Valid Loss: 0.6841 | Elapse: 5.01s\n",
                        "Epoch 3 [150/250] | Valid Loss: 0.7000 | Elapse: 7.56s\n",
                        "Epoch 3 [200/250] | Valid Loss: 0.7012 | Elapse: 10.21s\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "----------------------------------------------------------------------------------------------------\n",
                        "Epoch 3 - Average Loss: (train) 0.7571; (valid) 0.7087 | Time: 92.18s\n",
                        "Best model found in epoch 3 | valid loss: 0.7087\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch 3 [249/250] | Valid Loss: 0.7087 | Elapse: 12.77s\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "6d0c3ade7d1847c597e8dd7d490d8ff2",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Train [3]:   0%|          | 0/1012 [00:00<?, ?batch/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch 4 [0/1012] | Train Loss: 0.7487 Grad: 149668.0156 LR: 9.6978e-05 | Elapse: 0.09s\n",
                        "Epoch 4 [50/1012] | Train Loss: 0.7082 Grad: 70096.8359 LR: 9.6778e-05 | Elapse: 4.05s\n",
                        "Epoch 4 [100/1012] | Train Loss: 0.6876 Grad: 74807.9141 LR: 9.6572e-05 | Elapse: 7.97s\n",
                        "Epoch 4 [150/1012] | Train Loss: 0.6960 Grad: 122819.4688 LR: 9.6360e-05 | Elapse: 11.89s\n",
                        "Epoch 4 [200/1012] | Train Loss: 0.6954 Grad: 110480.6172 LR: 9.6141e-05 | Elapse: 15.80s\n",
                        "Epoch 4 [250/1012] | Train Loss: 0.6986 Grad: 124092.7109 LR: 9.5917e-05 | Elapse: 19.72s\n",
                        "Epoch 4 [300/1012] | Train Loss: 0.6957 Grad: 75263.4141 LR: 9.5686e-05 | Elapse: 23.63s\n",
                        "Epoch 4 [350/1012] | Train Loss: 0.7015 Grad: 158884.6562 LR: 9.5450e-05 | Elapse: 27.52s\n",
                        "Epoch 4 [400/1012] | Train Loss: 0.7035 Grad: 118381.5625 LR: 9.5207e-05 | Elapse: 31.44s\n",
                        "Epoch 4 [450/1012] | Train Loss: 0.7027 Grad: 87112.3203 LR: 9.4959e-05 | Elapse: 35.33s\n",
                        "Epoch 4 [500/1012] | Train Loss: 0.6993 Grad: 142761.5625 LR: 9.4704e-05 | Elapse: 39.24s\n",
                        "Epoch 4 [550/1012] | Train Loss: 0.7005 Grad: 81553.4453 LR: 9.4444e-05 | Elapse: 43.21s\n",
                        "Epoch 4 [600/1012] | Train Loss: 0.6979 Grad: 95456.0703 LR: 9.4178e-05 | Elapse: 47.14s\n",
                        "Epoch 4 [650/1012] | Train Loss: 0.6976 Grad: 120159.5703 LR: 9.3906e-05 | Elapse: 51.10s\n",
                        "Epoch 4 [700/1012] | Train Loss: 0.6948 Grad: 62447.0938 LR: 9.3628e-05 | Elapse: 55.06s\n",
                        "Epoch 4 [750/1012] | Train Loss: 0.6964 Grad: 116413.9922 LR: 9.3344e-05 | Elapse: 58.99s\n",
                        "Epoch 4 [800/1012] | Train Loss: 0.6987 Grad: 79798.7188 LR: 9.3055e-05 | Elapse: 62.89s\n",
                        "Epoch 4 [850/1012] | Train Loss: 0.6987 Grad: 71284.8359 LR: 9.2760e-05 | Elapse: 66.83s\n",
                        "Epoch 4 [900/1012] | Train Loss: 0.6981 Grad: 99004.9062 LR: 9.2459e-05 | Elapse: 70.76s\n",
                        "Epoch 4 [950/1012] | Train Loss: 0.6974 Grad: 68825.9531 LR: 9.2153e-05 | Elapse: 74.67s\n",
                        "Epoch 4 [1000/1012] | Train Loss: 0.6963 Grad: 81756.0312 LR: 9.1841e-05 | Elapse: 78.60s\n",
                        "Epoch 4 [1011/1012] | Train Loss: 0.6964 Grad: 67369.3281 LR: 9.1771e-05 | Elapse: 79.46s\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "41e28da329914ae5b5f86c29a1f6c2d7",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Valid [3]:   0%|          | 0/250 [00:00<?, ?batch/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch 4 [0/250] | Valid Loss: 0.4259 | Elapse: 0.05s\n",
                        "Epoch 4 [50/250] | Valid Loss: 0.6840 | Elapse: 2.49s\n",
                        "Epoch 4 [100/250] | Valid Loss: 0.6525 | Elapse: 5.04s\n",
                        "Epoch 4 [150/250] | Valid Loss: 0.6782 | Elapse: 7.67s\n",
                        "Epoch 4 [200/250] | Valid Loss: 0.6850 | Elapse: 10.32s\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "----------------------------------------------------------------------------------------------------\n",
                        "Epoch 4 - Average Loss: (train) 0.6964; (valid) 0.6945 | Time: 92.33s\n",
                        "Best model found in epoch 4 | valid loss: 0.6945\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch 4 [249/250] | Valid Loss: 0.6945 | Elapse: 12.86s\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "89f42ddb27c940f3b44daeb196e554a1",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Train [4]:   0%|          | 0/1012 [00:00<?, ?batch/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch 5 [0/1012] | Train Loss: 0.7112 Grad: 160418.1719 LR: 9.1765e-05 | Elapse: 0.10s\n",
                        "Epoch 5 [50/1012] | Train Loss: 0.6515 Grad: 90979.2734 LR: 9.1446e-05 | Elapse: 4.09s\n",
                        "Epoch 5 [100/1012] | Train Loss: 0.6373 Grad: 76329.0156 LR: 9.1122e-05 | Elapse: 8.09s\n",
                        "Epoch 5 [150/1012] | Train Loss: 0.6387 Grad: 100398.1953 LR: 9.0792e-05 | Elapse: 12.01s\n",
                        "Epoch 5 [200/1012] | Train Loss: 0.6449 Grad: 77309.0312 LR: 9.0457e-05 | Elapse: 15.94s\n",
                        "Epoch 5 [250/1012] | Train Loss: 0.6471 Grad: 86744.7656 LR: 9.0117e-05 | Elapse: 19.86s\n",
                        "Epoch 5 [300/1012] | Train Loss: 0.6428 Grad: 84923.4766 LR: 8.9771e-05 | Elapse: 23.81s\n",
                        "Epoch 5 [350/1012] | Train Loss: 0.6474 Grad: 153732.4688 LR: 8.9420e-05 | Elapse: 27.74s\n",
                        "Epoch 5 [400/1012] | Train Loss: 0.6489 Grad: 119066.8594 LR: 8.9064e-05 | Elapse: 31.67s\n",
                        "Epoch 5 [450/1012] | Train Loss: 0.6526 Grad: 83390.6172 LR: 8.8703e-05 | Elapse: 35.55s\n",
                        "Epoch 5 [500/1012] | Train Loss: 0.6503 Grad: 113584.0469 LR: 8.8336e-05 | Elapse: 39.43s\n",
                        "Epoch 5 [550/1012] | Train Loss: 0.6505 Grad: 98851.3516 LR: 8.7965e-05 | Elapse: 43.35s\n",
                        "Epoch 5 [600/1012] | Train Loss: 0.6496 Grad: 110652.6250 LR: 8.7588e-05 | Elapse: 47.28s\n",
                        "Epoch 5 [650/1012] | Train Loss: 0.6495 Grad: 78277.4844 LR: 8.7207e-05 | Elapse: 51.18s\n",
                        "Epoch 5 [700/1012] | Train Loss: 0.6454 Grad: 73909.1953 LR: 8.6821e-05 | Elapse: 55.11s\n",
                        "Epoch 5 [750/1012] | Train Loss: 0.6466 Grad: 100945.6953 LR: 8.6429e-05 | Elapse: 59.02s\n",
                        "Epoch 5 [800/1012] | Train Loss: 0.6503 Grad: 79154.3203 LR: 8.6033e-05 | Elapse: 62.98s\n",
                        "Epoch 5 [850/1012] | Train Loss: 0.6507 Grad: 82687.8281 LR: 8.5632e-05 | Elapse: 66.88s\n",
                        "Epoch 5 [900/1012] | Train Loss: 0.6480 Grad: 83894.9922 LR: 8.5227e-05 | Elapse: 70.83s\n",
                        "Epoch 5 [950/1012] | Train Loss: 0.6475 Grad: 76767.3828 LR: 8.4817e-05 | Elapse: 74.74s\n",
                        "Epoch 5 [1000/1012] | Train Loss: 0.6466 Grad: 105134.3359 LR: 8.4402e-05 | Elapse: 78.69s\n",
                        "Epoch 5 [1011/1012] | Train Loss: 0.6468 Grad: 71422.8359 LR: 8.4310e-05 | Elapse: 79.55s\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "9209eb351684451b8ff3deaaa82269be",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Valid [4]:   0%|          | 0/250 [00:00<?, ?batch/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch 5 [0/250] | Valid Loss: 0.5469 | Elapse: 0.05s\n",
                        "Epoch 5 [50/250] | Valid Loss: 0.6528 | Elapse: 2.53s\n",
                        "Epoch 5 [100/250] | Valid Loss: 0.6426 | Elapse: 5.10s\n",
                        "Epoch 5 [150/250] | Valid Loss: 0.6672 | Elapse: 7.72s\n",
                        "Epoch 5 [200/250] | Valid Loss: 0.6690 | Elapse: 10.37s\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "----------------------------------------------------------------------------------------------------\n",
                        "Epoch 5 - Average Loss: (train) 0.6468; (valid) 0.6736 | Time: 92.48s\n",
                        "Best model found in epoch 5 | valid loss: 0.6736\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch 5 [249/250] | Valid Loss: 0.6736 | Elapse: 12.93s\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "205a63b9f3fb4325824ffbb6890b3f90",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Train [5]:   0%|          | 0/1012 [00:00<?, ?batch/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch 6 [0/1012] | Train Loss: 0.5598 Grad: 158147.5469 LR: 8.4302e-05 | Elapse: 0.10s\n",
                        "Epoch 6 [50/1012] | Train Loss: 0.6468 Grad: 86923.8203 LR: 8.3881e-05 | Elapse: 4.02s\n",
                        "Epoch 6 [100/1012] | Train Loss: 0.6122 Grad: 91893.5312 LR: 8.3456e-05 | Elapse: 7.94s\n",
                        "Epoch 6 [150/1012] | Train Loss: 0.6163 Grad: 104865.3438 LR: 8.3027e-05 | Elapse: 11.83s\n",
                        "Epoch 6 [200/1012] | Train Loss: 0.6115 Grad: 75960.3516 LR: 8.2593e-05 | Elapse: 15.74s\n",
                        "Epoch 6 [250/1012] | Train Loss: 0.6100 Grad: 106711.6406 LR: 8.2155e-05 | Elapse: 19.66s\n",
                        "Epoch 6 [300/1012] | Train Loss: 0.6085 Grad: 89312.8984 LR: 8.1713e-05 | Elapse: 23.58s\n",
                        "Epoch 6 [350/1012] | Train Loss: 0.6103 Grad: 136169.1875 LR: 8.1267e-05 | Elapse: 27.51s\n",
                        "Epoch 6 [400/1012] | Train Loss: 0.6119 Grad: 136466.6406 LR: 8.0816e-05 | Elapse: 31.40s\n",
                        "Epoch 6 [450/1012] | Train Loss: 0.6126 Grad: 94497.2500 LR: 8.0361e-05 | Elapse: 35.31s\n",
                        "Epoch 6 [500/1012] | Train Loss: 0.6093 Grad: 95490.2578 LR: 7.9903e-05 | Elapse: 39.25s\n",
                        "Epoch 6 [550/1012] | Train Loss: 0.6114 Grad: 93350.6875 LR: 7.9440e-05 | Elapse: 43.54s\n",
                        "Epoch 6 [600/1012] | Train Loss: 0.6102 Grad: 87742.8828 LR: 7.8974e-05 | Elapse: 47.55s\n",
                        "Epoch 6 [650/1012] | Train Loss: 0.6085 Grad: 49981.1797 LR: 7.8503e-05 | Elapse: 51.43s\n",
                        "Epoch 6 [700/1012] | Train Loss: 0.6060 Grad: 70444.4141 LR: 7.8029e-05 | Elapse: 55.31s\n",
                        "Epoch 6 [750/1012] | Train Loss: 0.6075 Grad: 119152.5312 LR: 7.7552e-05 | Elapse: 59.22s\n",
                        "Epoch 6 [800/1012] | Train Loss: 0.6101 Grad: 86213.8594 LR: 7.7070e-05 | Elapse: 63.13s\n",
                        "Epoch 6 [850/1012] | Train Loss: 0.6116 Grad: 92348.7578 LR: 7.6585e-05 | Elapse: 67.05s\n",
                        "Epoch 6 [900/1012] | Train Loss: 0.6105 Grad: 71152.0859 LR: 7.6097e-05 | Elapse: 70.96s\n",
                        "Epoch 6 [950/1012] | Train Loss: 0.6091 Grad: 70107.8125 LR: 7.5605e-05 | Elapse: 74.87s\n",
                        "Epoch 6 [1000/1012] | Train Loss: 0.6093 Grad: 100736.3750 LR: 7.5109e-05 | Elapse: 78.79s\n",
                        "Epoch 6 [1011/1012] | Train Loss: 0.6099 Grad: 74139.9062 LR: 7.5000e-05 | Elapse: 79.65s\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "31be7ac250dc4969a7b196e319e9315a",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Valid [5]:   0%|          | 0/250 [00:00<?, ?batch/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch 6 [0/250] | Valid Loss: 0.4617 | Elapse: 0.05s\n",
                        "Epoch 6 [50/250] | Valid Loss: 0.6550 | Elapse: 2.53s\n",
                        "Epoch 6 [100/250] | Valid Loss: 0.6457 | Elapse: 5.11s\n",
                        "Epoch 6 [150/250] | Valid Loss: 0.6660 | Elapse: 7.77s\n",
                        "Epoch 6 [200/250] | Valid Loss: 0.6715 | Elapse: 10.41s\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "----------------------------------------------------------------------------------------------------\n",
                        "Epoch 6 - Average Loss: (train) 0.6099; (valid) 0.6744 | Time: 92.64s\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch 6 [249/250] | Valid Loss: 0.6744 | Elapse: 12.98s\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "a89687cd5a1a4ec4ae9d758223402718",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Train [6]:   0%|          | 0/1012 [00:00<?, ?batch/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch 7 [0/1012] | Train Loss: 0.5924 Grad: 149223.6562 LR: 7.4990e-05 | Elapse: 0.09s\n",
                        "Epoch 7 [50/1012] | Train Loss: 0.5989 Grad: 93245.5859 LR: 7.4491e-05 | Elapse: 4.03s\n",
                        "Epoch 7 [100/1012] | Train Loss: 0.5895 Grad: 80092.4844 LR: 7.3988e-05 | Elapse: 7.90s\n",
                        "Epoch 7 [150/1012] | Train Loss: 0.5853 Grad: 89566.9531 LR: 7.3482e-05 | Elapse: 11.79s\n",
                        "Epoch 7 [200/1012] | Train Loss: 0.5802 Grad: 83732.4297 LR: 7.2973e-05 | Elapse: 15.66s\n",
                        "Epoch 7 [250/1012] | Train Loss: 0.5823 Grad: 85803.3672 LR: 7.2461e-05 | Elapse: 19.53s\n",
                        "Epoch 7 [300/1012] | Train Loss: 0.5806 Grad: 98000.6797 LR: 7.1946e-05 | Elapse: 23.41s\n",
                        "Epoch 7 [350/1012] | Train Loss: 0.5800 Grad: 158732.1250 LR: 7.1428e-05 | Elapse: 27.30s\n",
                        "Epoch 7 [400/1012] | Train Loss: 0.5749 Grad: 101585.0703 LR: 7.0908e-05 | Elapse: 31.34s\n",
                        "Epoch 7 [450/1012] | Train Loss: 0.5752 Grad: 86790.9844 LR: 7.0384e-05 | Elapse: 35.28s\n",
                        "Epoch 7 [500/1012] | Train Loss: 0.5725 Grad: 89048.9219 LR: 6.9858e-05 | Elapse: 39.16s\n",
                        "Epoch 7 [550/1012] | Train Loss: 0.5731 Grad: 90301.2734 LR: 6.9330e-05 | Elapse: 43.04s\n",
                        "Epoch 7 [600/1012] | Train Loss: 0.5710 Grad: 97719.7734 LR: 6.8798e-05 | Elapse: 46.93s\n",
                        "Epoch 7 [650/1012] | Train Loss: 0.5695 Grad: 82089.9453 LR: 6.8264e-05 | Elapse: 50.83s\n",
                        "Epoch 7 [700/1012] | Train Loss: 0.5665 Grad: 102522.5703 LR: 6.7728e-05 | Elapse: 54.74s\n",
                        "Epoch 7 [750/1012] | Train Loss: 0.5698 Grad: 113186.5312 LR: 6.7190e-05 | Elapse: 58.63s\n",
                        "Epoch 7 [800/1012] | Train Loss: 0.5732 Grad: 94293.9141 LR: 6.6649e-05 | Elapse: 62.50s\n",
                        "Epoch 7 [850/1012] | Train Loss: 0.5749 Grad: 89371.7188 LR: 6.6106e-05 | Elapse: 66.38s\n",
                        "Epoch 7 [900/1012] | Train Loss: 0.5727 Grad: 88333.1406 LR: 6.5561e-05 | Elapse: 70.26s\n",
                        "Epoch 7 [950/1012] | Train Loss: 0.5710 Grad: 57742.1523 LR: 6.5014e-05 | Elapse: 74.13s\n",
                        "Epoch 7 [1000/1012] | Train Loss: 0.5681 Grad: 120181.0703 LR: 6.4464e-05 | Elapse: 78.01s\n",
                        "Epoch 7 [1011/1012] | Train Loss: 0.5682 Grad: 79426.3984 LR: 6.4343e-05 | Elapse: 78.87s\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "5ffd22b44a1f4e9c919b5e61eeb33476",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Valid [6]:   0%|          | 0/250 [00:00<?, ?batch/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch 7 [0/250] | Valid Loss: 0.3921 | Elapse: 0.05s\n",
                        "Epoch 7 [50/250] | Valid Loss: 0.6713 | Elapse: 2.49s\n",
                        "Epoch 7 [100/250] | Valid Loss: 0.6519 | Elapse: 5.05s\n",
                        "Epoch 7 [150/250] | Valid Loss: 0.6738 | Elapse: 7.62s\n",
                        "Epoch 7 [200/250] | Valid Loss: 0.6742 | Elapse: 10.25s\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "----------------------------------------------------------------------------------------------------\n",
                        "Epoch 7 - Average Loss: (train) 0.5682; (valid) 0.6773 | Time: 91.67s\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch 7 [249/250] | Valid Loss: 0.6773 | Elapse: 12.80s\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "8fdfd889444d4cd48cd31ffb4076f65c",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Train [7]:   0%|          | 0/1012 [00:00<?, ?batch/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch 8 [0/1012] | Train Loss: 0.3970 Grad: 145703.7969 LR: 6.4332e-05 | Elapse: 0.09s\n",
                        "Epoch 8 [50/1012] | Train Loss: 0.5390 Grad: 73951.5625 LR: 6.3781e-05 | Elapse: 4.01s\n",
                        "Epoch 8 [100/1012] | Train Loss: 0.5379 Grad: 59853.1484 LR: 6.3228e-05 | Elapse: 7.89s\n",
                        "Epoch 8 [150/1012] | Train Loss: 0.5381 Grad: 108148.7422 LR: 6.2672e-05 | Elapse: 11.77s\n",
                        "Epoch 8 [200/1012] | Train Loss: 0.5382 Grad: 79860.5391 LR: 6.2116e-05 | Elapse: 15.67s\n",
                        "Epoch 8 [250/1012] | Train Loss: 0.5397 Grad: 101969.1719 LR: 6.1557e-05 | Elapse: 19.57s\n",
                        "Epoch 8 [300/1012] | Train Loss: 0.5381 Grad: 95052.9375 LR: 6.0997e-05 | Elapse: 23.45s\n",
                        "Epoch 8 [350/1012] | Train Loss: 0.5374 Grad: 191226.6094 LR: 6.0436e-05 | Elapse: 27.43s\n",
                        "Epoch 8 [400/1012] | Train Loss: 0.5381 Grad: 95677.6484 LR: 5.9873e-05 | Elapse: 31.36s\n",
                        "Epoch 8 [450/1012] | Train Loss: 0.5405 Grad: 126936.6719 LR: 5.9309e-05 | Elapse: 35.28s\n",
                        "Epoch 8 [500/1012] | Train Loss: 0.5387 Grad: 82434.2891 LR: 5.8744e-05 | Elapse: 39.20s\n",
                        "Epoch 8 [550/1012] | Train Loss: 0.5404 Grad: 90553.8750 LR: 5.8178e-05 | Elapse: 43.14s\n",
                        "Epoch 8 [600/1012] | Train Loss: 0.5382 Grad: 110543.4531 LR: 5.7610e-05 | Elapse: 47.11s\n",
                        "Epoch 8 [650/1012] | Train Loss: 0.5377 Grad: 80869.9844 LR: 5.7042e-05 | Elapse: 51.09s\n",
                        "Epoch 8 [700/1012] | Train Loss: 0.5348 Grad: 87065.5234 LR: 5.6472e-05 | Elapse: 54.98s\n",
                        "Epoch 8 [750/1012] | Train Loss: 0.5350 Grad: 116569.2578 LR: 5.5902e-05 | Elapse: 58.88s\n",
                        "Epoch 8 [800/1012] | Train Loss: 0.5377 Grad: 82134.8203 LR: 5.5331e-05 | Elapse: 62.85s\n",
                        "Epoch 8 [850/1012] | Train Loss: 0.5388 Grad: 121497.3125 LR: 5.4759e-05 | Elapse: 66.72s\n",
                        "Epoch 8 [900/1012] | Train Loss: 0.5374 Grad: 78556.4922 LR: 5.4187e-05 | Elapse: 70.60s\n",
                        "Epoch 8 [950/1012] | Train Loss: 0.5364 Grad: 74060.2500 LR: 5.3614e-05 | Elapse: 74.64s\n",
                        "Epoch 8 [1000/1012] | Train Loss: 0.5334 Grad: 140121.0469 LR: 5.3041e-05 | Elapse: 78.66s\n",
                        "Epoch 8 [1011/1012] | Train Loss: 0.5340 Grad: 106897.3438 LR: 5.2915e-05 | Elapse: 79.51s\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "e11bcff2602c43f3b73d7fa7007833f2",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Valid [7]:   0%|          | 0/250 [00:00<?, ?batch/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch 8 [0/250] | Valid Loss: 0.4070 | Elapse: 0.05s\n",
                        "Epoch 8 [50/250] | Valid Loss: 0.7081 | Elapse: 2.51s\n",
                        "Epoch 8 [100/250] | Valid Loss: 0.6699 | Elapse: 5.07s\n",
                        "Epoch 8 [150/250] | Valid Loss: 0.6854 | Elapse: 7.66s\n",
                        "Epoch 8 [200/250] | Valid Loss: 0.6949 | Elapse: 10.32s\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "----------------------------------------------------------------------------------------------------\n",
                        "Epoch 8 - Average Loss: (train) 0.5340; (valid) 0.7034 | Time: 92.41s\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch 8 [249/250] | Valid Loss: 0.7034 | Elapse: 12.89s\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "f262e479c4d34d3e8f1fe053f00d7421",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Train [8]:   0%|          | 0/1012 [00:00<?, ?batch/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch 9 [0/1012] | Train Loss: 0.4009 Grad: 174624.1406 LR: 5.2903e-05 | Elapse: 0.10s\n",
                        "Epoch 9 [50/1012] | Train Loss: 0.5355 Grad: 111552.3516 LR: 5.2329e-05 | Elapse: 3.99s\n",
                        "Epoch 9 [100/1012] | Train Loss: 0.5089 Grad: 50621.9766 LR: 5.1755e-05 | Elapse: 8.01s\n",
                        "Epoch 9 [150/1012] | Train Loss: 0.5147 Grad: 100171.1641 LR: 5.1181e-05 | Elapse: 11.95s\n",
                        "Epoch 9 [200/1012] | Train Loss: 0.5111 Grad: 73752.4062 LR: 5.0606e-05 | Elapse: 15.93s\n",
                        "Epoch 9 [250/1012] | Train Loss: 0.5087 Grad: 86965.5312 LR: 5.0031e-05 | Elapse: 19.90s\n",
                        "Epoch 9 [300/1012] | Train Loss: 0.5059 Grad: 141423.3281 LR: 4.9457e-05 | Elapse: 23.79s\n",
                        "Epoch 9 [350/1012] | Train Loss: 0.5106 Grad: 79033.5156 LR: 4.8882e-05 | Elapse: 27.72s\n",
                        "Epoch 9 [400/1012] | Train Loss: 0.5052 Grad: 111368.2734 LR: 4.8308e-05 | Elapse: 31.62s\n",
                        "Epoch 9 [450/1012] | Train Loss: 0.5051 Grad: 141484.8125 LR: 4.7734e-05 | Elapse: 35.55s\n",
                        "Epoch 9 [500/1012] | Train Loss: 0.5020 Grad: 89760.7266 LR: 4.7160e-05 | Elapse: 39.47s\n",
                        "Epoch 9 [550/1012] | Train Loss: 0.5032 Grad: 61195.7539 LR: 4.6586e-05 | Elapse: 43.35s\n",
                        "Epoch 9 [600/1012] | Train Loss: 0.5017 Grad: 55048.8008 LR: 4.6013e-05 | Elapse: 47.25s\n",
                        "Epoch 9 [650/1012] | Train Loss: 0.4988 Grad: 28764.0547 LR: 4.5441e-05 | Elapse: 51.18s\n",
                        "Epoch 9 [700/1012] | Train Loss: 0.4975 Grad: 49820.7031 LR: 4.4869e-05 | Elapse: 55.10s\n",
                        "Epoch 9 [750/1012] | Train Loss: 0.4984 Grad: 53776.8438 LR: 4.4298e-05 | Elapse: 59.00s\n",
                        "Epoch 9 [800/1012] | Train Loss: 0.5012 Grad: 40188.9141 LR: 4.3727e-05 | Elapse: 62.89s\n",
                        "Epoch 9 [850/1012] | Train Loss: 0.5032 Grad: 49781.9180 LR: 4.3157e-05 | Elapse: 66.79s\n",
                        "Epoch 9 [900/1012] | Train Loss: 0.5020 Grad: 50321.7617 LR: 4.2589e-05 | Elapse: 70.69s\n",
                        "Epoch 9 [950/1012] | Train Loss: 0.5008 Grad: 33504.7188 LR: 4.2021e-05 | Elapse: 74.58s\n",
                        "Epoch 9 [1000/1012] | Train Loss: 0.4990 Grad: 56478.8125 LR: 4.1454e-05 | Elapse: 78.46s\n",
                        "Epoch 9 [1011/1012] | Train Loss: 0.4988 Grad: 47643.3242 LR: 4.1330e-05 | Elapse: 79.31s\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "53321f9b709441aa826d691e76b71551",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Valid [8]:   0%|          | 0/250 [00:00<?, ?batch/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch 9 [0/250] | Valid Loss: 0.3888 | Elapse: 0.06s\n",
                        "Epoch 9 [50/250] | Valid Loss: 0.6493 | Elapse: 2.51s\n",
                        "Epoch 9 [100/250] | Valid Loss: 0.6101 | Elapse: 5.07s\n"
                    ]
                }
            ],
            "source": [
                "logger = get_logger(PATHS.OUTPUT_DIR, f\"{ModelConfig.MODEL_NAME}_train.log\")\n",
                "\n",
                "logger.info(f\"{'*' * 100}\")\n",
                "logger.info(f\"Script Start: {ctime()}\")\n",
                "logger.info(f\"Model Configurations:\")\n",
                "for key, value in ModelConfig.__dict__.items():\n",
                "    if not key.startswith(\"__\"):\n",
                "        logger.info(f\"{key}: {value}\")\n",
                "logger.info(f\"{'*' * 100}\")\n",
                "\n",
                "k_folds = 5\n",
                "train_all = prepare_k_fold(train_all, k_folds=k_folds)\n",
                "\n",
                "oof_stage_1, oof_stage_2 = pd.DataFrame(), pd.DataFrame()\n",
                "loss_history_1, loss_history_2 = [], []\n",
                "\n",
                "for fold in range(k_folds):\n",
                "    tik = time()\n",
                "\n",
                "    model = get_model(pretrained=True)\n",
                "    # model = CustomVITMAE(ModelConfig, num_classes=6, pretrained=False)\n",
                "\n",
                "    valid_folds = train_all[train_all['fold'] == fold].reset_index(drop=True)\n",
                "    train_folds = train_all[train_all['fold'] != fold].reset_index(drop=True)\n",
                "\n",
                "    # ============== STAGE 1 ==============\n",
                "    logger.info(f\"{'=' * 100}\\nFold: {fold} || Valid size {valid_folds.shape[0]} \\n{'=' * 100}\")\n",
                "    logger.info(f\"- First Stage -\")\n",
                "    valid_predicts, loss_records = train_fold(\n",
                "        model, fold, train_folds, valid_folds, logger, stage=1, checkpoint=None)\n",
                "\n",
                "    loss_history_1.append(loss_records)\n",
                "    valid_folds[TARGETS_PRED] = valid_predicts\n",
                "    oof_stage_1 = pd.concat([oof_stage_1, valid_folds], axis=0).reset_index(drop=True)\n",
                "    kl_loss_torch = evaluate_oof(valid_folds)\n",
                "    info = f\"{'=' * 100}\\nFold {fold} Valid Loss: {kl_loss_torch}\\n\"\n",
                "    info += f\"Elapse: {(time() - tik) / 60:.2f} min \\n{'=' * 100}\"\n",
                "    logger.info(info)\n",
                "    oof_stage_1.to_csv(os.path.join(PATHS.OUTPUT_DIR, f\"{ModelConfig.MODEL_NAME}_oof_1.csv\"), index=False)\n",
                "\n",
                "    # ============== STAGE 2 ==============\n",
                "    tik = time()\n",
                "    logger.info(f\"- Second Stage -\")\n",
                "    check_point = os.path.join(\n",
                "        PATHS.OUTPUT_DIR,\n",
                "        f\"{ModelConfig.MODEL_NAME}_fold_{fold}_stage_1.pth\"\n",
                "    )\n",
                "    logger.info(f\"Use Checkpoint: {check_point.split('/')[-1]}\")\n",
                "\n",
                "    model = get_model(pretrained=True)\n",
                "    valid_predicts, loss_records = train_fold(\n",
                "        model, fold, train_hard, valid_folds, logger, stage=2, checkpoint=check_point)\n",
                "\n",
                "    loss_history_2.append(loss_records)\n",
                "    valid_folds[TARGETS_PRED] = valid_predicts\n",
                "    oof_stage_2 = pd.concat([oof_stage_2, valid_folds], axis=0).reset_index(drop=True)\n",
                "    kl_loss_torch = evaluate_oof(valid_folds)\n",
                "    info = f\"{'=' * 100}\\nFold {fold} Valid Loss: {kl_loss_torch}\\n\"\n",
                "    info += f\"Elapse: {(time() - tik) / 60:.2f} min \\n{'=' * 100}\"\n",
                "    logger.info(info)\n",
                "    oof_stage_2.to_csv(os.path.join(PATHS.OUTPUT_DIR, f\"{ModelConfig.MODEL_NAME}_oof_2.csv\"), index=False)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "csv_path = f'./outputs/{ModelConfig.MODEL_NAME}_oof_2.csv'\n",
                "print(\"CSV Path: \", csv_path)\n",
                "\n",
                "oof_df = analyze_oof(csv_path)\n",
                "\n",
                "print(\"Kaggle Score: \", calc_kaggle_score(oof_df))\n",
                "print(\"Average KL Loss: \", oof_df[\"kl_loss\"].mean())\n",
                "\n",
                "display(oof_df.head())\n",
                "\n",
                "# plot confusion matrix\n",
                "cm = confusion_matrix(oof_df['target_id'], oof_df['target_pred']) # (y_true, y_pred)\n",
                "cm = cm / cm.sum(axis=1)[:, np.newaxis]\n",
                "\n",
                "fig = plt.figure(figsize=(6, 6))\n",
                "sns.heatmap(cm, annot=True, cmap='Blues', xticklabels=TARGET2ID.keys(), yticklabels=TARGET2ID.keys())\n",
                "plt.xlabel('Predicted', fontsize=12)\n",
                "plt.ylabel('True', fontsize=12)\n",
                "plt.title(csv_path.split('/')[-1].split('.')[0], fontsize=12)\n",
                "fig.tight_layout()\n",
                "fig.savefig(f\"./outputs/{csv_path.split('/')[-1].split('.')[0]}_CM.png\")\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# check distribution of targets\n",
                "fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
                "train_all[\"target\"].value_counts().plot(kind=\"bar\", ax=axes[0])\n",
                "train_hard[\"target\"].value_counts().plot(kind=\"bar\", ax=axes[1])\n",
                "axes[0].set_title(\"Easy\")\n",
                "axes[1].set_title(\"Hard\")\n",
                "fig.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# hms_predictor = HMSPredictor(paths.OUTPUT_DIR, ModelConfig, k_fold=5)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# hms_predictor.train_model(train_easy, train_hard, all_specs, all_eegs)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "\n",
                "\n",
                "# hms_predictor = HMSPredictor(paths.OUTPUT_DIR, ModelConfig, k_fold=5)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# new figure\n",
                "fig, axes = plt.subplots(6, 5, figsize=(18, 16), sharex=True, sharey=True)\n",
                "\n",
                "plot_oof = oof_df[oof_df['kl_loss'] > 0.2]\n",
                "\n",
                "for row in range(axes.shape[0]):\n",
                "    row_selects = plot_oof[plot_oof['target_id']==row]\n",
                "    target_label = BRAIN_ACTIVITY[row]\n",
                "    for col in range(axes.shape[1]):\n",
                "        ax = axes[row, col]\n",
                "        idx = np.random.choice(row_selects.index)\n",
                "        df_rows = plot_oof.loc[idx]\n",
                "        ax.plot(df_rows[TARGETS].values , label='True')\n",
                "        ax.plot(df_rows[TARGETS_PRED].values, label='Pred')\n",
                "        ax.set_title(f\"{idx} | KL: {df_rows['kl_loss']:.4f} \") #\n",
                "        ax.set_xticks(range(6))\n",
                "        ax.set_xticklabels(BRAIN_ACTIVITY)\n",
                "        ax.grid(True)\n",
                "        ax.legend()\n",
                "        if col == 0:\n",
                "            ax.set_ylabel(target_label, fontsize=12)\n",
                "       \n",
                "fig.tight_layout()\n",
                "plt.show()\n",
                "\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "kaggle",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.6"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
