{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dilated ResNet 1D Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, dilation=1, dropout=0.0):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        \n",
    "        self.bn1 = nn.BatchNorm1d(in_channels)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.conv1 = nn.Conv1d(\n",
    "            in_channels, out_channels, kernel_size, \n",
    "            stride=stride, \n",
    "            padding=dilation*(kernel_size//2), \n",
    "            dilation=dilation, \n",
    "            bias=False)\n",
    "        self.drop1 = nn.Dropout(p=dropout)\n",
    "        self.bn2 = nn.BatchNorm1d(out_channels)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.drop2 = nn.Dropout(p=dropout)\n",
    "        self.conv2 = nn.Conv1d(\n",
    "            out_channels, out_channels, kernel_size, \n",
    "            stride=stride, \n",
    "            padding=dilation*(kernel_size//2), \n",
    "            dilation=dilation, \n",
    "            bias=False)\n",
    "        \n",
    "        self.bn3 = nn.BatchNorm1d(out_channels)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.downsample = nn.MaxPool1d(kernel_size=2, stride=2, padding=0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        identity = self.downsample(identity)\n",
    "\n",
    "        out = self.bn1(x)\n",
    "        out = self.relu1(out)\n",
    "        out = self.drop1(out)\n",
    "        out = self.conv1(out)\n",
    "\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu2(out)\n",
    "        out = self.drop2(out)\n",
    "        out = self.conv2(out)\n",
    "\n",
    "        out = self.downsample(out)\n",
    "\n",
    "        out += identity\n",
    "        out = self.bn3(out)\n",
    "        out = self.relu3(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "class DeilatedResidualNet(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, n_layers, expansion_factor=4):\n",
    "        super(DeilatedResidualNet, self).__init__()\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.kernel_size = kernel_size\n",
    "        self.h_dim = out_channels // n_layers\n",
    "\n",
    "        dilation_rates = [expansion_factor**i for i in range(n_layers)]\n",
    "\n",
    "        self.blocks = nn.ModuleList([\n",
    "            ResidualBlock(self.in_channels, self.h_dim, self.kernel_size, dilation=dilation)\n",
    "            for dilation in dilation_rates\n",
    "        ])\n",
    "\n",
    "    def forward(self, x):\n",
    "        outputs = [ block(x) for block in self.blocks ]\n",
    "        output = torch.cat(outputs, dim=1)\n",
    "        \n",
    "        return output\n",
    "\n",
    "class DilatedResidualEncoder(nn.Module):\n",
    "    def __init__(self, kernel_sizes=[3, 5, 7, 9], in_channels=8, planes=24, dilate_layers=[6,3,1], expansion_factor=4):\n",
    "        super(DilatedResidualEncoder, self).__init__()\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.planes = planes\n",
    "        self.kernel_sizes = kernel_sizes\n",
    "        self.dilate_layers = dilate_layers\n",
    "        self.expansion_factor = expansion_factor\n",
    "\n",
    "        out_channels = self.planes * self.in_channels\n",
    "        fix_kernel_size = 5\n",
    "        self.conv1 = nn.Conv1d(\n",
    "            self.in_channels, out_channels, kernel_size=fix_kernel_size, stride=1, padding=fix_kernel_size//2\n",
    "            )\n",
    "        \n",
    "        self.blocks = nn.ModuleList([\n",
    "            nn.Sequential(*[\n",
    "                ResidualBlock(\n",
    "                    out_channels, out_channels, kernel_size, dilation=dilation\n",
    "                ) for dilation in self.dilate_layers\n",
    "            ])\n",
    "            for kernel_size in self.kernel_sizes\n",
    "        ])\n",
    "\n",
    "        self.pooling = nn.AdaptiveAvgPool1d(1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        outputs = [ block(x) for block in self.blocks ]\n",
    "        output = torch.cat(outputs, dim=1)\n",
    "        output = self.pooling(output).squeeze(-1)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([8, 768])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Model instantiation example\n",
    "input_channels = 8  # For 8-channel sequence input\n",
    "model = DilatedResidualEncoder()\n",
    "\n",
    "# Example input tensor\n",
    "example_input = torch.rand(8, input_channels, 2000)  # [batch_size, channels, seq_len]\n",
    "example_output = model(example_input)\n",
    "\n",
    "print(\"Output shape:\", example_output.shape)  # Expected shape: [batch, 768]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
