{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, gc\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import List, Dict\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from sklearn.model_selection import KFold, GroupKFold\n",
    "\n",
    "import timm\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision.transforms import v2\n",
    "from torch.optim.lr_scheduler import OneCycleLR\n",
    "from time import time, ctime\n",
    "\n",
    "from engine_hms_trainer import (\n",
    "    seed_everything, calc_entropy, evaluate_oof, get_logger, TARGETS, TARGETS_PRED, Trainer\n",
    ")\n",
    "from engine_hms_model import (\n",
    "    KagglePaths, LocalPaths, ModelConfig\n",
    ")\n",
    "\n",
    "from scipy.signal import butter, lfilter, freqz\n",
    "from scipy.stats import entropy\n",
    "from scipy.special import rel_entr\n",
    "\n",
    "from pyts.approximation import PiecewiseAggregateApproximation\n",
    "from pyts.preprocessing import MinMaxScaler\n",
    "from pyts.image import GramianAngularField\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "PATHS = KagglePaths if os.path.exists(KagglePaths.OUTPUT_DIR) else LocalPaths\n",
    "print(\"Output Dir: \", PATHS.OUTPUT_DIR)\n",
    "\n",
    "EEG_FEAT_ALL = [\n",
    "    'Fp1', 'F3', 'C3', 'P3', \n",
    "    'F7', 'T3', 'T5', 'O1', \n",
    "    'Fz', 'Cz', 'Pz', 'Fp2', \n",
    "    'F4', 'C4', 'P4', 'F8', \n",
    "    'T4', 'T6', 'O2', 'EKG'\n",
    "    ]\n",
    "\n",
    "EEG_FEAT_USE =  ['Fp1','T3','C3','O1','Fp2','C4','T4','O2']\n",
    "EEF_FEAT_INDEX = {x:y for x,y in zip(EEG_FEAT_USE, range(len(EEG_FEAT_USE)))}\n",
    "\n",
    "seed_everything(ModelConfig.SEED)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eeg_from_parquet(parquet_path: str, use_feature=EEG_FEAT_USE, display: bool = False) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    This function reads a parquet file and extracts the middle 50 seconds of readings. Then it fills NaN values\n",
    "    with the mean value (ignoring NaNs).\n",
    "    :param parquet_path: path to parquet file.\n",
    "    :param display: whether to display EEG plots or not.\n",
    "    :return data: np.array of shape  (time_steps, eeg_features) -> (10_000, 8)\n",
    "    \"\"\"\n",
    "    # === Extract full length EEG Sequence ===\n",
    "    # fill missing values with mean\n",
    "    # first fill missing values with mean of each column\n",
    "    # then if all values are missing, fill with 0\n",
    "    eeg = pd.read_parquet(parquet_path, columns=use_feature)\n",
    "    eeg = eeg.fillna(eeg.mean(skipna=True)).fillna(0)\n",
    "    data = eeg.values.astype(np.float32)\n",
    "\n",
    "    if display:\n",
    "        fig, ax = plt.subplots(len(use_feature), 1, figsize=(15, 3*len(use_feature)), sharex=True)\n",
    "        \n",
    "        for i, feat in enumerate(use_feature):\n",
    "            ax[i].plot(data[:, i], label=feat)\n",
    "            ax[i].legend()\n",
    "            ax[i].grid()\n",
    "       \n",
    "        name = parquet_path.split('/')[-1].split('.')[0]\n",
    "        ax[0].set_title(f'EEG {name}',size=16)\n",
    "        plt.show()    \n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CREATE_EEGS = True\n",
    "ALL_EEG_SIGNALS = {}\n",
    "eeg_paths = list(Path(PATHS.TRAIN_EEGS).glob('*.parquet'))\n",
    "preload_eegs_path = Path('./inputs/eegs_full.npy')\n",
    "\n",
    "if CREATE_EEGS:\n",
    "    count = 0\n",
    "    for parquet_path in tqdm(eeg_paths, total=len(eeg_paths)):\n",
    "        eeg_id = int(parquet_path.stem)\n",
    "        eeg_path = str(parquet_path)\n",
    "        data = eeg_from_parquet(eeg_path, display=count<1)\n",
    "        ALL_EEG_SIGNALS[eeg_id] = data\n",
    "        count += 1\n",
    "    np.save(\"./inputs/eegs_full.npy\", ALL_EEG_SIGNALS)\n",
    "else:\n",
    "    ALL_EEG_SIGNALS = np.load(preload_eegs_path, allow_pickle=True).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_non_overlap(train_csv, targets):\n",
    "\n",
    "    df = train_csv.groupby(['eeg_id'] + targets).agg({\n",
    "            'spectrogram_id': 'first',\n",
    "            'spectrogram_label_offset_seconds': ['min', 'max'],\n",
    "            'eeg_label_offset_seconds': ['min', 'max'],\n",
    "            'patient_id': 'first',\n",
    "            'expert_consensus': 'first',\n",
    "            'total_votes': 'sum',\n",
    "            'entropy': 'mean',\n",
    "            'is_hard': 'mean'\n",
    "        }).reset_index()\n",
    "\n",
    "    df.columns = [\"eeg_id\"] + targets + \\\n",
    "        ['spectrogram_id', 'min', 'max', 'eeg_off_min', 'eeg_off_max', 'patient_id', 'target', 'total_votes', 'average_entropy', 'is_hard']\n",
    "\n",
    "    df[targets] = df[targets].apply(lambda x: x / x.sum(), axis=1)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_csv = pd.read_csv(PATHS.TRAIN_CSV)\n",
    "targets = train_csv.columns[-6:].tolist()\n",
    "\n",
    "print(\"targets: \", targets)\n",
    "\n",
    "train_csv['total_votes'] = train_csv[targets].sum(axis=1)\n",
    "\n",
    "targets_prob = [f\"{t.split('_')[0]}_prob\" for t in targets]\n",
    "train_csv[targets_prob] = train_csv[targets].div(train_csv['total_votes'], axis=0)\n",
    "\n",
    "train_csv['entropy'] = train_csv[targets_prob].apply(lambda row: sum(rel_entr([1/6]*6, row.values+1e-5)), axis=1)\n",
    "train_csv['is_hard'] = (train_csv['entropy'] < 5.5).astype(int)\n",
    "\n",
    "train_all = get_non_overlap(train_csv, targets)\n",
    "train_hard = get_non_overlap(train_csv[train_csv['is_hard'] == 1].copy().reset_index(), targets)\n",
    "\n",
    "print(\"train_all: \", train_all.shape)\n",
    "print(\"hard samples: \", train_hard.shape)\n",
    "\n",
    "train_all.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_eeg = train_all.groupby('eeg_id').size().to_frame().reset_index()\n",
    "unique_eeg.columns = ['eeg_id', 'count']\n",
    "\n",
    "df_focus = train_all[train_all['eeg_id'].isin(unique_eeg[unique_eeg['count'] > 1]['eeg_id'])].copy()\n",
    "df_focus = df_focus.reset_index(drop=True)\n",
    "df_focus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ModelConfig.MODEL_BACKBONE = 'tf_efficientnet_b2'\n",
    "ModelConfig.MODEL_NAME = \"GAF_ENet_B2_Small_Fix_EEG\"\n",
    "ModelConfig.BATCH_SIZE = 8\n",
    "ModelConfig.GRADIENT_ACCUMULATION_STEPS = 1\n",
    "ModelConfig.EPOCHS = 6\n",
    "ModelConfig.DROP_RATE = 0.1\n",
    "ModelConfig.EARLY_STOP_ROUNDS = 5\n",
    "\n",
    "logger = get_logger(PATHS.OUTPUT_DIR, f\"{ModelConfig.MODEL_NAME}_train.log\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def butter_bandpass_filter(data, lowcut, highcut, fs, order=5):\n",
    "    b, a = butter(order, [lowcut, highcut], fs=fs, btype='band')\n",
    "    y = lfilter(b, a, data)\n",
    "    return y\n",
    "\n",
    "def denoise_filter(x):\n",
    "    # Sample rate and desired cutoff frequencies (in Hz).\n",
    "    fs = 200.0\n",
    "    lowcut = 1.0\n",
    "    highcut = 25.0\n",
    "    \n",
    "    # Filter a noisy signal.\n",
    "    T = 50\n",
    "    nsamples = T * fs\n",
    "    t = np.arange(0, nsamples) / fs\n",
    "    y = butter_bandpass_filter(x, lowcut, highcut, fs, order=6)\n",
    "    y = (y + np.roll(y,-1)+ np.roll(y,-2)+ np.roll(y,-3))/4\n",
    "    y = y[0:-1:4]\n",
    "    \n",
    "    return y\n",
    "\n",
    "def mu_law_encoding(data, mu):\n",
    "    mu_x = np.sign(data) * np.log(1 + mu * np.abs(data)) / np.log(mu + 1)\n",
    "    return mu_x\n",
    "\n",
    "def mu_law_expansion(data, mu):\n",
    "    s = np.sign(data) * (np.exp(np.abs(data) * np.log(mu + 1)) - 1) / mu\n",
    "    return s\n",
    "\n",
    "def quantize_data(data, classes):\n",
    "    mu_x = mu_law_encoding(data, classes)\n",
    "    return mu_x #quantized\n",
    "\n",
    "def butter_lowpass_filter(data, cutoff_freq=20, sampling_rate=200, order=4):\n",
    "    nyquist = 0.5 * sampling_rate\n",
    "    normal_cutoff = cutoff_freq / nyquist\n",
    "    b, a = butter(order, normal_cutoff, btype='low', analog=False)\n",
    "    filtered_data = lfilter(b, a, data, axis=0)\n",
    "    return filtered_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EEGSeqDataset(Dataset):\n",
    "    def __init__(self, df, config, eegs, mode='train', verbose=False):\n",
    "        self.df = df\n",
    "        self.mode = mode\n",
    "        self.eegs = eegs\n",
    "        self.verbose = verbose\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        X, y_prob = self.__data_generation(idx)\n",
    "        \n",
    "        return torch.tensor(X, dtype=torch.float32), torch.tensor(y_prob, dtype=torch.float32)\n",
    "    \n",
    "    def __data_generation(self, index):\n",
    "        row = self.df.iloc[index]\n",
    "\n",
    "        if self.verbose:\n",
    "            print(f\"Row {index}\", row[['eeg_id', 'eeg_off_min', 'eeg_off_max', 'target']].tolist())\n",
    "\n",
    "        X = np.zeros((10_000, 8), dtype='float32')\n",
    "        \n",
    "        start_sec = int((row['eeg_off_min'] + row['eeg_off_max']) // 2)\n",
    "        data = self.eegs[row.eeg_id][start_sec*200 : (start_sec+50)*200]\n",
    "\n",
    "        # === Feature engineering ===\n",
    "        X[:,0] = data[:,EEF_FEAT_INDEX['Fp1']] - data[:,EEF_FEAT_INDEX['T3']]\n",
    "        X[:,1] = data[:,EEF_FEAT_INDEX['T3']] - data[:,EEF_FEAT_INDEX['O1']]\n",
    "\n",
    "        X[:,2] = data[:,EEF_FEAT_INDEX['Fp1']] - data[:,EEF_FEAT_INDEX['C3']]\n",
    "        X[:,3] = data[:,EEF_FEAT_INDEX['C3']] - data[:,EEF_FEAT_INDEX['O1']]\n",
    "\n",
    "        X[:,4] = data[:,EEF_FEAT_INDEX['Fp2']] - data[:,EEF_FEAT_INDEX['C4']]\n",
    "        X[:,5] = data[:,EEF_FEAT_INDEX['C4']] - data[:,EEF_FEAT_INDEX['O2']]\n",
    "\n",
    "        X[:,6] = data[:,EEF_FEAT_INDEX['Fp2']] - data[:,EEF_FEAT_INDEX['T4']]\n",
    "        X[:,7] = data[:,EEF_FEAT_INDEX['T4']] - data[:,EEF_FEAT_INDEX['O2']]\n",
    "\n",
    "        # === Standarize ===\n",
    "        X = np.clip(X,-1024, 1024)\n",
    "        X = np.nan_to_num(X, nan=0) / 32.0\n",
    "\n",
    "        # === Butter Low-pass Filter ===\n",
    "        # !!! change to bandpass filter (low=0.5, hight=20, order=2) !!!\n",
    "        # X = butter_lowpass_filter(X)\n",
    "        X = butter_bandpass_filter(X, .5, 20, 200, order=2)\n",
    "\n",
    "        if self.mode != 'test':\n",
    "            y_prob = row[TARGETS].values.astype(np.float32)\n",
    "        else:\n",
    "            y_prob = np.zeros(6, dtype='float32')\n",
    "\n",
    "        return X, y_prob\n",
    "\n",
    "def collate_gaf_image(batch):\n",
    "    # Assuming `batch` is a list of tuples (X, y) where X is the time series and y is the label\n",
    "    # Initialize GASF and GADF\n",
    "    gasf = GramianAngularField(image_size=50, method='summation')\n",
    "    gadf = GramianAngularField(image_size=50, method='difference')\n",
    "    chunk_starts = [0, 2000, 4000, 6000, 8000]\n",
    "    chunk_len = 2000\n",
    "    ts_len, n_channels = batch[0][0].shape\n",
    "    \n",
    "    transformed_x = []\n",
    "    for sample_id, (X, y) in enumerate(batch):\n",
    "        channel_images = []\n",
    "        for channel_id in range(n_channels):\n",
    "            chunk_images = []\n",
    "            for t_start in chunk_starts:\n",
    "                t_end = t_start + 2000\n",
    "                x_ts = X[t_start:t_end, channel_id].reshape(1, -1)\n",
    "                x_gasf = gasf.transform(x_ts)\n",
    "                x_gadf = gadf.transform(x_ts)\n",
    "                # Concatenate GASF, GADF, and a zero matrix along the vertical axis\n",
    "                gaf_combined = np.concatenate([x_gasf, x_gadf], axis=0)\n",
    "                chunk_images.append(gaf_combined)\n",
    "            # Concatenate all chunks for this channel along the horizontal axis\n",
    "            chunk_full = np.concatenate(chunk_images, axis=2)\n",
    "            channel_images.append(chunk_full)\n",
    "            \n",
    "        sample_image = np.concatenate(channel_images, axis=1)\n",
    "        c, h, w = sample_image.shape\n",
    "        sample_image = np.concatenate([sample_image, np.zeros((1, h, w))], axis=0)\n",
    "        sample_image = np.nan_to_num(sample_image, nan=0.0)\n",
    "        transformed_x.append(sample_image)\n",
    "    \n",
    "    # Convert to PyTorch tensors\n",
    "    x_tensor = torch.tensor(np.array(transformed_x), dtype=torch.float32)\n",
    "    y_tensor = torch.stack([item[1] for item in batch])\n",
    "    return x_tensor, y_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = EEGSeqDataset(df_focus, ModelConfig, ALL_EEG_SIGNALS, mode=\"train\", verbose=True)\n",
    "\n",
    "batches = [train_dataset[i] for i in range(7, 11)]\n",
    "x_gaf, y_gaf = collate_gaf_image(batches) # -> (batch_size, n_channels, h, w)\n",
    "print(x_gaf.shape, y_gaf.shape)\n",
    "\n",
    "fig, axes = plt.subplots(1, 4, figsize=(20, 10))\n",
    "x_gaf_array = x_gaf.detach().to('cpu').numpy()\n",
    "for item in range(4):\n",
    "    ax = axes.flatten()[item]\n",
    "    img = x_gaf_array[item]\n",
    "    ax.imshow(np.transpose(img, (1, 2, 0)))\n",
    "    ax.set_title(\", \".join([f\"{v:.2f}\" for t, v in zip(TARGETS, y_gaf[item].tolist())]))\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the dataset\n",
    "train_dataset = EEGSeqDataset(train_all, ModelConfig, ALL_EEG_SIGNALS, mode=\"train\", verbose=False)\n",
    "train_loader = DataLoader(train_dataset, drop_last=True, batch_size=16, num_workers=4, pin_memory=True, shuffle=False, collate_fn=collate_gaf_image)\n",
    "\n",
    "fig, axes = plt.subplots(1, 4, figsize=(20, 10))\n",
    "for batch in train_loader:\n",
    "    X, y = batch\n",
    "    print(f\"X shape: {X.shape}\")\n",
    "    print(f\"y shape: {y.shape}\")\n",
    "    for item in range(4):\n",
    "        ax = axes.flatten()[item]\n",
    "        img = X.detach().to('cpu').numpy()[item]\n",
    "        ax.imshow(np.transpose(img, (1, 2, 0)))\n",
    "        ax.set_title(\", \".join([f\"{v:.2f}\" for t, v in zip(TARGETS, y[item].tolist())]))\n",
    "    break\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAF_EfficientNet(nn.Module):\n",
    "\n",
    "    def __init__(self, config, num_classes: int = 6, pretrained: bool = True):\n",
    "        super(GAF_EfficientNet, self).__init__()\n",
    "        \n",
    "        self.config = config\n",
    "\n",
    "        self.model = timm.create_model(\n",
    "            config.MODEL_BACKBONE,\n",
    "            pretrained=pretrained,\n",
    "            drop_rate=config.DROP_RATE,\n",
    "            drop_path_rate=config.DROP_PATH_RATE,\n",
    "        )\n",
    "\n",
    "        self.features = nn.Sequential(*list(self.model.children())[:-2])\n",
    "        \n",
    "        self.custom_layers = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(self.model.num_features, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.custom_layers(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = EEGSeqDataset(train_all, ModelConfig, ALL_EEG_SIGNALS, mode=\"train\")\n",
    "train_loader = DataLoader(train_dataset, drop_last=True, batch_size=16, num_workers=4, pin_memory=True, shuffle=False, collate_fn=collate_gaf_image)\n",
    "\n",
    "model = GAF_EfficientNet( ModelConfig, num_classes=6 )\n",
    "\n",
    "for i, batch in enumerate(train_loader):\n",
    "    X, y = batch\n",
    "    print(f\"X shape: {X.shape}\")\n",
    "    print(f\"y shape: {y.shape}\")\n",
    "    \n",
    "    y_pred = model(X)\n",
    "    print(y_pred.shape)\n",
    "    break \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_id = 0\n",
    "# feat = rnn_out.detach().cpu().numpy()\n",
    "# print(feat[0].mean(axis=0).shape)\n",
    "\n",
    "# fig, ax = plt.subplots(2, 1, figsize=(20, 5))\n",
    "# # for i in range(0, feat.shape[1], 16):\n",
    "# #     ax[0].plot(feat[:, i].detach().cpu().numpy())\n",
    "# ax[0].plot(feat[0, -1, :])\n",
    "# ax[0].plot(feat[0].mean(axis=0))\n",
    "# ax[1].plot(resnet_out[0].detach().cpu().numpy())\n",
    "\n",
    "# plt.title(f\"Feature {feature_id}\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_k_fold(df, k_folds=5):\n",
    "\n",
    "    kf = KFold(n_splits=k_folds)\n",
    "    unique_spec_id = df['spectrogram_id'].unique()\n",
    "    df['fold'] = k_folds\n",
    "\n",
    "    for fold, (train_index, valid_index) in enumerate(kf.split(unique_spec_id)):\n",
    "        df.loc[df['spectrogram_id'].isin(unique_spec_id[valid_index]), 'fold'] = fold\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def train_fold(model, fold_id, train_folds, valid_folds, logger, stage=1, checkpoint=None):\n",
    "\n",
    "    train_dataset = EEGSeqDataset(train_folds, ModelConfig, ALL_EEG_SIGNALS, mode=\"train\")\n",
    "    valid_dataset = EEGSeqDataset(valid_folds, ModelConfig, ALL_EEG_SIGNALS, mode=\"valid\")\n",
    "\n",
    "    # ======== DATALOADERS ==========\n",
    "    loader_kwargs = {\n",
    "        \"batch_size\": ModelConfig.BATCH_SIZE,\n",
    "        \"num_workers\": ModelConfig.NUM_WORKERS,\n",
    "        \"pin_memory\": True,\n",
    "        \"shuffle\": False,\n",
    "    }\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, drop_last=True, collate_fn=collate_gaf_image, **loader_kwargs)\n",
    "    valid_loader = DataLoader(valid_dataset, drop_last=False, collate_fn=collate_gaf_image, **loader_kwargs)\n",
    "\n",
    "    trainer = Trainer(model, ModelConfig, logger)\n",
    "    best_weights, best_preds, loss_records = trainer.train(\n",
    "        train_loader, valid_loader, from_checkpoint=checkpoint)\n",
    "\n",
    "    save_model_name = f\"{ModelConfig.MODEL_NAME}_fold_{fold_id}_stage_{stage}.pth\"\n",
    "    torch.save(best_weights, os.path.join(PATHS.OUTPUT_DIR, save_model_name))\n",
    "\n",
    "    del train_dataset, valid_dataset, train_loader, valid_loader\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "    return best_preds, loss_records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_folds = 5\n",
    "train_all = prepare_k_fold(train_all, k_folds=k_folds)\n",
    "\n",
    "# gkf = GroupKFold(n_splits=k_folds)\n",
    "# for fold, (train_index, valid_index) in enumerate(gkf.split(train_all, train_all.target, train_all.patient_id)):\n",
    "#     train_all.loc[valid_index, \"fold\"] = int(fold)\n",
    "\n",
    "\n",
    "# for fold in range(k_folds):\n",
    "#     print(f\"Fold {fold} = {len(train_all[train_all['fold'] == fold])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Major Train Loop\n",
    "\n",
    "# ================== Logger ==================\n",
    "\n",
    "logger.info(f\"{'*' * 100}\")\n",
    "logger.info(f\"Script Start: {ctime()}\")\n",
    "logger.info(f\"Model Configurations:\")\n",
    "for key, value in ModelConfig.__dict__.items():\n",
    "    if not key.startswith(\"__\"):\n",
    "        logger.info(f\"{key}: {value}\")\n",
    "logger.info(f\"{'*' * 100}\")\n",
    "\n",
    "# ================== Run Training ==================\n",
    "\n",
    "oof_stage_1 = pd.DataFrame()\n",
    "loss_history_1 = []\n",
    "\n",
    "logger.info(f\"{'=' * 100}\\nStage 1: Train ResNetGRU\\n{'=' * 100}\")\n",
    "for fold in range(k_folds):\n",
    "    tik = time()\n",
    "\n",
    "    ModelConfig.RESNET_GRU_DROPOUT = 0.0\n",
    "\n",
    "    model = GAF_EfficientNet( ModelConfig, num_classes=6 )\n",
    "    \n",
    "    valid_folds = train_all[train_all['fold'] == fold].reset_index(drop=True)\n",
    "    train_folds = train_all[train_all['fold'] != fold].reset_index(drop=True)\n",
    "\n",
    "    logger.info(f\"{'=' * 100}\\nFold: {fold} || Valid: {valid_folds.shape[0]}; \\n{'=' * 100}\")\n",
    "    logger.info(f\"- Train: {train_folds.shape[0]}; Epoch = {ModelConfig.EPOCHS}; Dropout = {ModelConfig.RESNET_GRU_DROPOUT} -\")\n",
    "    valid_predicts, loss_records = train_fold(\n",
    "        model, fold, train_folds, valid_folds, logger, stage=1, checkpoint=None)\n",
    "\n",
    "    loss_history_1.append(loss_records)\n",
    "    valid_folds[TARGETS_PRED] = valid_predicts\n",
    "    oof_stage_1 = pd.concat([oof_stage_1, valid_folds], axis=0).reset_index(drop=True)\n",
    "    kl_loss_torch = evaluate_oof(valid_folds)\n",
    "    info = f\"{'=' * 100}\\nFold {fold} Valid Loss: {kl_loss_torch}\\n\"\n",
    "    info += f\"Elapse: {(time() - tik) / 60:.2f} min \\n{'=' * 100}\"\n",
    "    logger.info(info)\n",
    "    oof_stage_1.to_csv(os.path.join(PATHS.OUTPUT_DIR, f\"{ModelConfig.MODEL_NAME}_oof_1.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot loss history\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8, 5))\n",
    "for i, loss in enumerate(loss_history_1):\n",
    "    ax.plot(loss['train'], marker=\"*\", ls=\"-\", label=f\"Fold {i} Train\")\n",
    "    ax.plot(loss['valid'], marker=\"o\", ls=\":\", label=f\"Fold {i} Valid\")\n",
    "\n",
    "ax.grid()\n",
    "fig.tight_layout()\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## STAGE 2\n",
    "oof_stage_2 = pd.DataFrame()\n",
    "loss_history_2 = []\n",
    "\n",
    "logger.info(f\"{'=' * 100}\\nStage 2: Train ResNetGRU\\n{'=' * 100}\")\n",
    "for fold in range(k_folds):\n",
    "    tik = time()\n",
    "    \n",
    "    valid_folds = train_all[train_all['fold'] == fold].reset_index(drop=True)\n",
    "\n",
    "    logger.info(f\"- Hard: {train_folds.shape[0]}; Epoch: {ModelConfig.EPOCHS}; Dropout: {ModelConfig.RESNET_GRU_DROPOUT} -\")\n",
    "    check_point = os.path.join(\n",
    "        PATHS.OUTPUT_DIR,\n",
    "        f\"{ModelConfig.MODEL_NAME}_fold_{fold}_stage_1.pth\"\n",
    "    )\n",
    "    logger.info(f\"Use Checkpoint: {check_point.split('/')[-1]}\")\n",
    "\n",
    "    model = GAF_EfficientNet( ModelConfig, num_classes=6 )\n",
    "\n",
    "    valid_predicts, loss_records = train_fold(\n",
    "        model, fold, train_hard, valid_folds, logger, stage=2, checkpoint=check_point)\n",
    "\n",
    "    loss_history_2.append(loss_records)\n",
    "    valid_folds[TARGETS_PRED] = valid_predicts\n",
    "    oof_stage_2 = pd.concat([oof_stage_2, valid_folds], axis=0).reset_index(drop=True)\n",
    "    kl_loss_torch = evaluate_oof(valid_folds)\n",
    "    info = f\"{'=' * 100}\\nFold {fold} Valid Loss: {kl_loss_torch}\\n\"\n",
    "    info += f\"Elapse: {(time() - tik) / 60:.2f} min \\n{'=' * 100}\"\n",
    "    logger.info(info)\n",
    "    oof_stage_2.to_csv(os.path.join(PATHS.OUTPUT_DIR, f\"{ModelConfig.MODEL_NAME}_oof_2.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot loss history\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8, 5))\n",
    "for i, loss in enumerate(loss_history_2):\n",
    "    ax.plot(loss['train'], marker=\"*\", ls=\"-\", label=f\"Fold {i} Train\")\n",
    "    ax.plot(loss['valid'], marker=\"o\", ls=\":\", label=f\"Fold {i} Valid\")\n",
    "\n",
    "ax.grid()\n",
    "fig.tight_layout()\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kl_divergence import score as kaggle_score \n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "TARGET2ID = {'Seizure': 0, 'LPD': 1, 'GPD': 2, 'LRDA': 3, 'GRDA': 4, 'Other': 5}\n",
    "\n",
    "def calc_kaggle_score(oof_df):\n",
    "    submission_df = oof_df[['eeg_id']+TARGETS_PRED].copy()\n",
    "    submission_df.columns = ['eeg_id'] + TARGETS\n",
    "    solution_df = oof_df[['eeg_id']+TARGETS].copy()\n",
    "    return kaggle_score(solution_df, submission_df, 'eeg_id')\n",
    "\n",
    "def analyze_oof(oof_csv):\n",
    "\n",
    "    kl_criteria = nn.KLDivLoss(reduction='batchmean')\n",
    "    softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    oof_df = pd.read_csv(oof_csv)\n",
    "    oof_df['target_pred'] = oof_df[TARGETS_PRED].apply(lambda x: np.argmax(x), axis=1)\n",
    "    oof_df['target_id'] = oof_df[TARGETS].apply(lambda x: np.argmax(x), axis=1)\n",
    "    \n",
    "    oof_df[\"kl_loss\"] = oof_df.apply(\n",
    "    lambda row: \n",
    "        kl_criteria(\n",
    "            F.log_softmax(\n",
    "                    torch.tensor(row[TARGETS_PRED].values.astype(np.float32)).unsqueeze(0)\n",
    "                , dim=1\n",
    "                ), \n",
    "            torch.tensor(row[TARGETS].values.astype(np.float32))\n",
    "            ).numpy(),\n",
    "    axis=1)\n",
    "\n",
    "    oof_df[\"kl_loss\"] = oof_df['kl_loss'].astype(np.float32)\n",
    "\n",
    "    oof_df[TARGETS_PRED] = softmax( torch.tensor(oof_df[TARGETS_PRED].values.astype(np.float32)) )\n",
    "\n",
    "    oof_df.head()\n",
    "\n",
    "    return oof_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = f'./outputs/{ModelConfig.MODEL_NAME}_oof_1.csv'\n",
    "print(\"CSV Path: \", csv_path)\n",
    "\n",
    "oof_df = analyze_oof(csv_path)\n",
    "\n",
    "print(\"Kaggle Score: \", calc_kaggle_score(oof_df))\n",
    "print(\"Average KL Loss: \", oof_df[\"kl_loss\"].mean())\n",
    "\n",
    "display(oof_df.head())\n",
    "\n",
    "# plot confusion matrix\n",
    "cm = confusion_matrix(oof_df['target_id'], oof_df['target_pred']) # (y_true, y_pred)\n",
    "cm = cm / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "fig = plt.figure(figsize=(6, 6))\n",
    "sns.heatmap(cm, annot=True, cmap='Blues', xticklabels=TARGET2ID.keys(), yticklabels=TARGET2ID.keys())\n",
    "plt.xlabel('Predicted', fontsize=12)\n",
    "plt.ylabel('True', fontsize=12)\n",
    "plt.title(csv_path.split('/')[-1].split('.')[0], fontsize=12)\n",
    "fig.tight_layout()\n",
    "fig.savefig(f\"./outputs/{csv_path.split('/')[-1].split('.')[0]}_CM.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = f'./outputs/ResNetGRU/ResNetGRU_oof_2.csv'\n",
    "print(\"CSV Path: \", csv_path)\n",
    "\n",
    "oof_df = analyze_oof(csv_path)\n",
    "\n",
    "print(\"Kaggle Score: \", calc_kaggle_score(oof_df))\n",
    "print(\"Average KL Loss: \", oof_df[\"kl_loss\"].mean())\n",
    "\n",
    "display(oof_df.head())\n",
    "\n",
    "# plot confusion matrix\n",
    "cm = confusion_matrix(oof_df['target_id'], oof_df['target_pred']) # (y_true, y_pred)\n",
    "cm = cm / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "fig = plt.figure(figsize=(6, 6))\n",
    "sns.heatmap(cm, annot=True, cmap='Blues', xticklabels=TARGET2ID.keys(), yticklabels=TARGET2ID.keys())\n",
    "plt.xlabel('Predicted', fontsize=12)\n",
    "plt.ylabel('True', fontsize=12)\n",
    "plt.title(csv_path.split('/')[-1].split('.')[0], fontsize=12)\n",
    "fig.tight_layout()\n",
    "fig.savefig(f\"./outputs/{csv_path.split('/')[-1].split('.')[0]}_CM.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
