{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shiyi/miniconda3/envs/kaggle/lib/python3.11/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/home/shiyi/miniconda3/envs/kaggle/lib/python3.11/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from transformers import ViTMAEForPreTraining\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision.transforms import v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PreTrainDataset(Dataset):\n",
    "\n",
    "    def __init__(\n",
    "        self, \n",
    "        df: pd.DataFrame,\n",
    "        all_specs: Dict[str, np.ndarray],\n",
    "        all_eegs: Dict[str, np.ndarray],\n",
    "    ): \n",
    "        self.df = df\n",
    "        self.spectrograms = all_specs\n",
    "        self.eeg_spectrograms = all_eegs\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        X, y = self.__data_generation(index)\n",
    "        X, y = self.__transform(X, y)\n",
    "        return X, y\n",
    "    \n",
    "    def __data_generation(self, index): # --> [(C=8) x (H=128) x (W=256)]\n",
    "        \n",
    "        row = self.df.iloc[index]\n",
    "        r = int((row['min'] + row['max']) // 4)\n",
    "        \n",
    "        img_list = []\n",
    "        for region in range(4):\n",
    "            img = np.zeros((128, 256), dtype='float32')\n",
    "\n",
    "            spectrogram = self.spectrograms[row['spectrogram_id']][r:r+300, region*100:(region+1)*100].T\n",
    "            spectrogram = transform_spectrogram(spectrogram)\n",
    "            \n",
    "            img[14:-14, :] = spectrogram[:, 22:-22] / 2.0\n",
    "            img_list.append(img)\n",
    "\n",
    "        img = self.eeg_spectrograms[row['eeg_id']]\n",
    "        img_list += [img[:, :, i] for i in range(4)]\n",
    "      \n",
    "        X = np.array(img_list, dtype='float32')\n",
    "        X = torch.tensor(X, dtype=torch.float32)\n",
    "                \n",
    "        if (self.mode == 'train') or (self.mode == 'valid'):\n",
    "            y = row[self.label_cols].values.astype(np.float32)\n",
    "        elif self.mode == 'test':\n",
    "            y = np.zeros(len(self.label_cols), dtype=np.float32)\n",
    "        else:\n",
    "            raise ValueError(f\"Invalid mode {self.mode}!\")\n",
    "        \n",
    "        y = torch.tensor(y, dtype=torch.float32)\n",
    "        \n",
    "        return X, y\n",
    "\n",
    "    def __transform(self, x, y):\n",
    "\n",
    "        return x, y"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
