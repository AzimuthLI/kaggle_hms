{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, gc\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import List, Dict\n",
    "from tqdm.notebook import tqdm\n",
    "from time import time, ctime\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from sklearn.model_selection import KFold, GroupKFold\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "from engine_hms_trainer import (\n",
    "    seed_everything, evaluate_oof, get_logger, TARGETS, TARGETS_PRED, Trainer\n",
    ")\n",
    "\n",
    "from engine_hms_model import (\n",
    "    KagglePaths, LocalPaths, ModelConfig\n",
    ")\n",
    "\n",
    "from scipy.signal import butter, lfilter, freqz\n",
    "from scipy.stats import entropy\n",
    "from scipy.special import rel_entr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output Dir:  ./outputs/\n"
     ]
    }
   ],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "PATHS = KagglePaths if os.path.exists(KagglePaths.OUTPUT_DIR) else LocalPaths\n",
    "print(\"Output Dir: \", PATHS.OUTPUT_DIR)\n",
    "\n",
    "EEG_FEAT_ALL = [\n",
    "    'Fp1', 'F3', 'C3', 'P3', \n",
    "    'F7', 'T3', 'T5', 'O1', \n",
    "    'Fz', 'Cz', 'Pz', 'Fp2', \n",
    "    'F4', 'C4', 'P4', 'F8', \n",
    "    'T4', 'T6', 'O2', 'EKG'\n",
    "    ]\n",
    "\n",
    "EEG_FEAT_USE =  ['Fp1','T3','C3','O1','Fp2','C4','T4','O2']\n",
    "EEF_FEAT_INDEX = {x:y for x,y in zip(EEG_FEAT_USE, range(len(EEG_FEAT_USE)))}\n",
    "\n",
    "seed_everything(ModelConfig.SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eeg_from_parquet(parquet_path: str, display: bool = False) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    This function reads a parquet file and extracts the middle 50 seconds of readings. Then it fills NaN values\n",
    "    with the mean value (ignoring NaNs).\n",
    "    :param parquet_path: path to parquet file.\n",
    "    :param display: whether to display EEG plots or not.\n",
    "    :return data: np.array of shape  (time_steps, eeg_features) -> (10_000, 8)\n",
    "    \"\"\"\n",
    "    # === Extract middle 50 seconds ===\n",
    "    eeg = pd.read_parquet(parquet_path, columns=EEG_FEAT_USE)\n",
    "    rows = len(eeg)\n",
    "    offset = (rows - 10_000) // 2 # 50 * 200 = 10_000\n",
    "    eeg = eeg.iloc[offset:offset+10_000] # middle 50 seconds, has the same amount of readings to left and right\n",
    "    if display: \n",
    "        plt.figure(figsize=(10,5))\n",
    "        offset = 0\n",
    "    # === Convert to numpy ===\n",
    "    data = np.zeros((10_000, len(EEG_FEAT_USE))) # create placeholder of same shape with zeros\n",
    "    for index, feature in enumerate(EEG_FEAT_USE):\n",
    "        x = eeg[feature].values.astype('float32') # convert to float32\n",
    "        mean = np.nanmean(x) # arithmetic mean along the specified axis, ignoring NaNs\n",
    "        nan_percentage = np.isnan(x).mean() # percentage of NaN values in feature\n",
    "        # === Fill nan values ===\n",
    "        if nan_percentage < 1: # if some values are nan, but not all\n",
    "            x = np.nan_to_num(x, nan=mean)\n",
    "        else: # if all values are nan\n",
    "            x[:] = 0\n",
    "        data[:, index] = x\n",
    "        if display: \n",
    "            if index != 0:\n",
    "                offset += x.max()\n",
    "            plt.plot(range(10_000), x-offset, label=feature)\n",
    "            offset -= x.min()\n",
    "    if display:\n",
    "        plt.legend()\n",
    "        name = parquet_path.split('/')[-1].split('.')[0]\n",
    "        plt.yticks([])\n",
    "        plt.title(f'EEG {name}',size=16)\n",
    "        plt.show()    \n",
    "    return data\n",
    "\n",
    "def get_non_overlap(df_csv, targets):\n",
    "    # Reference Discussion:\n",
    "    # https://www.kaggle.com/competitions/hms-harmful-brain-activity-classification/discussion/467021\n",
    "\n",
    "    tgt_list = targets.tolist()\n",
    "    brain_activity = ['seizure', 'lpd', 'gpd', 'lrda', 'grda', 'other']\n",
    "\n",
    "    agg_dict = {\n",
    "        'spectrogram_id': 'first',\n",
    "        'spectrogram_label_offset_seconds': ['min', 'max'],\n",
    "        'patient_id': 'first',\n",
    "        'expert_consensus': 'first'\n",
    "    }\n",
    "\n",
    "    for tgt in tgt_list:\n",
    "        agg_dict[tgt] = 'sum'\n",
    "\n",
    "    groupby = df_csv.groupby(['eeg_id'])\n",
    "    train = groupby.agg(agg_dict)\n",
    "    train = train.reset_index()\n",
    "  \n",
    "    train.columns = ['eeg_id', 'spectrogram_id', 'min', 'max', 'patient_id', 'target'] + tgt_list\n",
    "    train['total_votes'] = train[tgt_list].sum(axis=1)\n",
    "    train[tgt_list] = train[tgt_list].apply(lambda x: x / x.sum(), axis=1)\n",
    "    \n",
    "    return train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "CREATE_EEGS = False\n",
    "ALL_EEG_SIGNALS = {}\n",
    "eeg_paths = list(Path(PATHS.TRAIN_EEGS).glob('*.parquet'))\n",
    "preload_eegs_path = Path('./inputs/eegs.npy')\n",
    "\n",
    "if CREATE_EEGS:\n",
    "    for parquet_path in tqdm(eeg_paths, total=len(eeg_paths)):\n",
    "        # Save EEG to Python dictionary of numpy arrays\n",
    "        eeg_id = int(parquet_path.stem)\n",
    "        eeg_path = str(parquet_path)\n",
    "        data = eeg_from_parquet(eeg_path, display=eeg_id<1)\n",
    "        ALL_EEG_SIGNALS[eeg_id] = data\n",
    "\n",
    "    np.save(\"./inputs/eegs.npy\", ALL_EEG_SIGNALS)\n",
    "else:\n",
    "    ALL_EEG_SIGNALS = np.load(preload_eegs_path, allow_pickle=True).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "targets:  ['seizure_vote', 'lpd_vote', 'gpd_vote', 'lrda_vote', 'grda_vote', 'other_vote']\n",
      "train_all:  (17834, 15)\n",
      "hard samples:  (3578, 15)\n",
      "easy samples:  (14256, 15)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eeg_id</th>\n",
       "      <th>is_hard</th>\n",
       "      <th>spectrogram_id</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>target</th>\n",
       "      <th>total_votes</th>\n",
       "      <th>averge_entropy</th>\n",
       "      <th>seizure_vote</th>\n",
       "      <th>lpd_vote</th>\n",
       "      <th>gpd_vote</th>\n",
       "      <th>lrda_vote</th>\n",
       "      <th>grda_vote</th>\n",
       "      <th>other_vote</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>568657</td>\n",
       "      <td>1</td>\n",
       "      <td>789577333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>20654</td>\n",
       "      <td>Other</td>\n",
       "      <td>48</td>\n",
       "      <td>4.584192</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.583333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>582999</td>\n",
       "      <td>1</td>\n",
       "      <td>1552638400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>20230</td>\n",
       "      <td>LPD</td>\n",
       "      <td>154</td>\n",
       "      <td>4.870032</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.071429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>642382</td>\n",
       "      <td>0</td>\n",
       "      <td>14960202</td>\n",
       "      <td>1008.0</td>\n",
       "      <td>1032.0</td>\n",
       "      <td>5955</td>\n",
       "      <td>Other</td>\n",
       "      <td>2</td>\n",
       "      <td>7.802343</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>751790</td>\n",
       "      <td>0</td>\n",
       "      <td>618728447</td>\n",
       "      <td>908.0</td>\n",
       "      <td>908.0</td>\n",
       "      <td>38549</td>\n",
       "      <td>GPD</td>\n",
       "      <td>1</td>\n",
       "      <td>7.802343</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>778705</td>\n",
       "      <td>0</td>\n",
       "      <td>52296320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40955</td>\n",
       "      <td>Other</td>\n",
       "      <td>2</td>\n",
       "      <td>7.802343</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1629671</td>\n",
       "      <td>0</td>\n",
       "      <td>2036345030</td>\n",
       "      <td>0.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>37481</td>\n",
       "      <td>Seizure</td>\n",
       "      <td>51</td>\n",
       "      <td>7.802343</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1895581</td>\n",
       "      <td>1</td>\n",
       "      <td>128369999</td>\n",
       "      <td>1138.0</td>\n",
       "      <td>1138.0</td>\n",
       "      <td>47999</td>\n",
       "      <td>Other</td>\n",
       "      <td>13</td>\n",
       "      <td>4.847483</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.846154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2061593</td>\n",
       "      <td>0</td>\n",
       "      <td>320962633</td>\n",
       "      <td>1450.0</td>\n",
       "      <td>1450.0</td>\n",
       "      <td>23828</td>\n",
       "      <td>Other</td>\n",
       "      <td>1</td>\n",
       "      <td>7.802343</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2078097</td>\n",
       "      <td>0</td>\n",
       "      <td>2074135650</td>\n",
       "      <td>3342.0</td>\n",
       "      <td>3342.0</td>\n",
       "      <td>61174</td>\n",
       "      <td>Other</td>\n",
       "      <td>2</td>\n",
       "      <td>7.802343</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2366870</td>\n",
       "      <td>0</td>\n",
       "      <td>1232582129</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>23633</td>\n",
       "      <td>Other</td>\n",
       "      <td>18</td>\n",
       "      <td>6.134196</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2482631</td>\n",
       "      <td>1</td>\n",
       "      <td>978166025</td>\n",
       "      <td>1902.0</td>\n",
       "      <td>1944.0</td>\n",
       "      <td>20606</td>\n",
       "      <td>Other</td>\n",
       "      <td>105</td>\n",
       "      <td>3.236383</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2521897</td>\n",
       "      <td>1</td>\n",
       "      <td>673742515</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>62117</td>\n",
       "      <td>Other</td>\n",
       "      <td>24</td>\n",
       "      <td>3.172763</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2918824</td>\n",
       "      <td>0</td>\n",
       "      <td>1211648246</td>\n",
       "      <td>3462.0</td>\n",
       "      <td>3462.0</td>\n",
       "      <td>14965</td>\n",
       "      <td>Seizure</td>\n",
       "      <td>2</td>\n",
       "      <td>7.802343</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3108700</td>\n",
       "      <td>0</td>\n",
       "      <td>223960986</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>55677</td>\n",
       "      <td>Other</td>\n",
       "      <td>3</td>\n",
       "      <td>7.802343</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3625731</td>\n",
       "      <td>0</td>\n",
       "      <td>2091405434</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6935</td>\n",
       "      <td>GRDA</td>\n",
       "      <td>1</td>\n",
       "      <td>7.802343</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     eeg_id  is_hard  spectrogram_id     min     max  patient_id   target  \\\n",
       "0    568657        1       789577333     0.0    16.0       20654    Other   \n",
       "1    582999        1      1552638400     0.0    38.0       20230      LPD   \n",
       "2    642382        0        14960202  1008.0  1032.0        5955    Other   \n",
       "3    751790        0       618728447   908.0   908.0       38549      GPD   \n",
       "4    778705        0        52296320     0.0     0.0       40955    Other   \n",
       "5   1629671        0      2036345030     0.0   160.0       37481  Seizure   \n",
       "6   1895581        1       128369999  1138.0  1138.0       47999    Other   \n",
       "7   2061593        0       320962633  1450.0  1450.0       23828    Other   \n",
       "8   2078097        0      2074135650  3342.0  3342.0       61174    Other   \n",
       "9   2366870        0      1232582129     0.0    30.0       23633    Other   \n",
       "10  2482631        1       978166025  1902.0  1944.0       20606    Other   \n",
       "11  2521897        1       673742515     0.0     4.0       62117    Other   \n",
       "12  2918824        0      1211648246  3462.0  3462.0       14965  Seizure   \n",
       "13  3108700        0       223960986     0.0     0.0       55677    Other   \n",
       "14  3625731        0      2091405434     0.0     0.0        6935     GRDA   \n",
       "\n",
       "    total_votes  averge_entropy  seizure_vote  lpd_vote  gpd_vote  lrda_vote  \\\n",
       "0            48        4.584192      0.000000  0.000000  0.250000   0.000000   \n",
       "1           154        4.870032      0.000000  0.857143  0.000000   0.071429   \n",
       "2             2        7.802343      0.000000  0.000000  0.000000   0.000000   \n",
       "3             1        7.802343      0.000000  0.000000  1.000000   0.000000   \n",
       "4             2        7.802343      0.000000  0.000000  0.000000   0.000000   \n",
       "5            51        7.802343      1.000000  0.000000  0.000000   0.000000   \n",
       "6            13        4.847483      0.076923  0.000000  0.000000   0.000000   \n",
       "7             1        7.802343      0.000000  0.000000  0.000000   0.000000   \n",
       "8             2        7.802343      0.000000  0.000000  0.000000   0.000000   \n",
       "9            18        6.134196      0.000000  0.333333  0.000000   0.000000   \n",
       "10          105        3.236383      0.000000  0.000000  0.133333   0.066667   \n",
       "11           24        3.172763      0.000000  0.000000  0.083333   0.083333   \n",
       "12            2        7.802343      1.000000  0.000000  0.000000   0.000000   \n",
       "13            3        7.802343      0.000000  0.000000  0.000000   0.000000   \n",
       "14            1        7.802343      0.000000  0.000000  0.000000   0.000000   \n",
       "\n",
       "    grda_vote  other_vote  \n",
       "0    0.166667    0.583333  \n",
       "1    0.000000    0.071429  \n",
       "2    0.000000    1.000000  \n",
       "3    0.000000    0.000000  \n",
       "4    0.000000    1.000000  \n",
       "5    0.000000    0.000000  \n",
       "6    0.076923    0.846154  \n",
       "7    0.000000    1.000000  \n",
       "8    0.000000    1.000000  \n",
       "9    0.000000    0.666667  \n",
       "10   0.133333    0.666667  \n",
       "11   0.333333    0.500000  \n",
       "12   0.000000    0.000000  \n",
       "13   0.000000    1.000000  \n",
       "14   1.000000    0.000000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_csv = pd.read_csv(PATHS.TRAIN_CSV)\n",
    "targets = train_csv.columns[-6:].tolist()\n",
    "\n",
    "print(\"targets: \", targets)\n",
    "\n",
    "train_csv['total_votes'] = train_csv[targets].sum(axis=1)\n",
    "\n",
    "targets_prob = [f\"{t.split('_')[0]}_prob\" for t in targets]\n",
    "train_csv[targets_prob] = train_csv[targets].div(train_csv['total_votes'], axis=0)\n",
    "\n",
    "train_csv['entropy'] = train_csv[targets_prob].apply(lambda row: sum(rel_entr([1/6]*6, row.values+1e-5)), axis=1)\n",
    "train_csv['is_hard'] = (train_csv['entropy'] < 5.5).astype(int)\n",
    "\n",
    "agg_dict = {\n",
    "    'spectrogram_id': 'first',\n",
    "    'spectrogram_label_offset_seconds': ['min', 'max'],\n",
    "    'patient_id': 'first',\n",
    "    'expert_consensus': 'first',\n",
    "    'total_votes': 'sum',\n",
    "    'entropy': 'mean'\n",
    "}\n",
    "\n",
    "for tgt in targets:\n",
    "    agg_dict[tgt] = 'sum'\n",
    "    \n",
    "train_all = train_csv.groupby(['eeg_id', 'is_hard']).agg(agg_dict).reset_index()\n",
    "train_all.columns = ['eeg_id', 'is_hard', 'spectrogram_id', 'min', 'max', 'patient_id', 'target', 'total_votes', 'averge_entropy'] + targets\n",
    "train_all[targets] = train_all[targets].apply(lambda x: x / x.sum(), axis=1)\n",
    "\n",
    "print(\"train_all: \", train_all.shape)\n",
    "print(\"hard samples: \", train_all[train_all['is_hard'] == 1].shape)\n",
    "print(\"easy samples: \", train_all[train_all['is_hard'] == 0].shape)\n",
    "\n",
    "train_all.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ModelConfig.MODEL_BACKBONE = 'transformer'\n",
    "# ModelConfig.MODEL_NAME = \"transformer_1D\"\n",
    "# ModelConfig.BATCH_SIZE = 32\n",
    "# ModelConfig.GRADIENT_ACCUMULATION_STEPS = 1\n",
    "# ModelConfig.EPOCHS = 30\n",
    "# ModelConfig.DROP_RATE = 0.1\n",
    "# ModelConfig.EARLY_STOP_ROUNDS = 5\n",
    "# ModelConfig.EEG_SEQ_DOWNSAMPLE = None\n",
    "\n",
    "# logger = get_logger(PATHS.OUTPUT_DIR, f\"{ModelConfig.MODEL_NAME}_train.log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def butter_bandpass_filter(data, lowcut, highcut, fs, order=5):\n",
    "    b, a = butter(order, [lowcut, highcut], fs=fs, btype='band')\n",
    "    y = lfilter(b, a, data)\n",
    "    return y\n",
    "\n",
    "def denoise_filter(x):\n",
    "    # Sample rate and desired cutoff frequencies (in Hz).\n",
    "    fs = 200.0\n",
    "    lowcut = 1.0\n",
    "    highcut = 25.0\n",
    "    \n",
    "    # Filter a noisy signal.\n",
    "    T = 50\n",
    "    nsamples = T * fs\n",
    "    t = np.arange(0, nsamples) / fs\n",
    "    y = butter_bandpass_filter(x, lowcut, highcut, fs, order=6)\n",
    "    y = (y + np.roll(y,-1)+ np.roll(y,-2)+ np.roll(y,-3))/4\n",
    "    y = y[0:-1:4]\n",
    "    \n",
    "    return y\n",
    "\n",
    "def mu_law_encoding(data, mu):\n",
    "    mu_x = np.sign(data) * np.log(1 + mu * np.abs(data)) / np.log(mu + 1)\n",
    "    return mu_x\n",
    "\n",
    "def mu_law_expansion(data, mu):\n",
    "    s = np.sign(data) * (np.exp(np.abs(data) * np.log(mu + 1)) - 1) / mu\n",
    "    return s\n",
    "\n",
    "def quantize_data(data, classes):\n",
    "    mu_x = mu_law_encoding(data, classes)\n",
    "    return mu_x #quantized\n",
    "\n",
    "def butter_lowpass_filter(data, cutoff_freq=20, sampling_rate=200, order=4):\n",
    "    nyquist = 0.5 * sampling_rate\n",
    "    normal_cutoff = cutoff_freq / nyquist\n",
    "    b, a = butter(order, normal_cutoff, btype='low', analog=False)\n",
    "    filtered_data = lfilter(b, a, data, axis=0)\n",
    "    return filtered_data\n",
    "\n",
    "class EEGSeqDataset(Dataset):\n",
    "    def __init__(self, df, config, eegs, mode='train'):\n",
    "        self.df = df\n",
    "        self.config = config\n",
    "        self.mode = mode\n",
    "        self.eegs = eegs\n",
    "        self.downsample = config.EEG_SEQ_DOWNSAMPLE\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        X, y_prob = self.__data_generation(idx)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            X = X[::self.downsample,:]\n",
    "\n",
    "        return torch.tensor(X, dtype=torch.float32), torch.tensor(y_prob, dtype=torch.float32)\n",
    "    \n",
    "    def __data_generation(self, index):\n",
    "        row = self.df.iloc[index]\n",
    "        X = np.zeros((10_000, 8), dtype='float32')\n",
    "        \n",
    "        data = self.eegs[row.eeg_id]\n",
    "        # === Feature engineering ===\n",
    "        X[:,0] = data[:,EEF_FEAT_INDEX['Fp1']] - data[:,EEF_FEAT_INDEX['T3']]\n",
    "        X[:,1] = data[:,EEF_FEAT_INDEX['T3']] - data[:,EEF_FEAT_INDEX['O1']]\n",
    "\n",
    "        X[:,2] = data[:,EEF_FEAT_INDEX['Fp1']] - data[:,EEF_FEAT_INDEX['C3']]\n",
    "        X[:,3] = data[:,EEF_FEAT_INDEX['C3']] - data[:,EEF_FEAT_INDEX['O1']]\n",
    "\n",
    "        X[:,4] = data[:,EEF_FEAT_INDEX['Fp2']] - data[:,EEF_FEAT_INDEX['C4']]\n",
    "        X[:,5] = data[:,EEF_FEAT_INDEX['C4']] - data[:,EEF_FEAT_INDEX['O2']]\n",
    "\n",
    "        X[:,6] = data[:,EEF_FEAT_INDEX['Fp2']] - data[:,EEF_FEAT_INDEX['T4']]\n",
    "        X[:,7] = data[:,EEF_FEAT_INDEX['T4']] - data[:,EEF_FEAT_INDEX['O2']]\n",
    "\n",
    "        # === Standarize ===\n",
    "        X = np.clip(X,-1024, 1024)\n",
    "        X = np.nan_to_num(X, nan=0) / 32.0\n",
    "\n",
    "        # === Butter Low-pass Filter ===\n",
    "        # !!! change to bandpass filter (low=0.5, hight=20, order=2) !!!\n",
    "        X = butter_lowpass_filter(X)\n",
    "        # X = butter_bandpass_filter(X, .5, 20, 200, order=2)\n",
    "\n",
    "        if self.mode != 'test':\n",
    "            y_prob = row[TARGETS].values.astype(np.float32)\n",
    "        else:\n",
    "            y_prob = np.zeros(6, dtype='float32')\n",
    "\n",
    "        return X, y_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class MultiHeadAttention(nn.Module):\n",
    "#     def __init__(self, embed_size, heads):\n",
    "#         super(MultiHeadAttention, self).__init__()\n",
    "#         self.embed_size = embed_size\n",
    "#         self.heads = heads\n",
    "#         self.head_dim = embed_size // heads\n",
    "        \n",
    "#         assert (\n",
    "#             self.head_dim * heads == embed_size\n",
    "#         ), \"Embedding size needs to be divisible by heads\"\n",
    "        \n",
    "#         self.values = nn.Linear(self.head_dim, self.head_dim, bias=False)\n",
    "#         self.keys = nn.Linear(self.head_dim, self.head_dim, bias=False)\n",
    "#         self.queries = nn.Linear(self.head_dim, self.head_dim, bias=False)\n",
    "#         self.fc_out = nn.Linear(heads * self.head_dim, embed_size)\n",
    "        \n",
    "#     def forward(self, values, keys, query):\n",
    "#         N = query.shape[0]\n",
    "#         value_len, key_len, query_len = values.shape[1], keys.shape[1], query.shape[1]\n",
    "        \n",
    "#         # Split the embedding into self.heads pieces\n",
    "#         values = values.reshape(N, value_len, self.heads, self.head_dim)\n",
    "#         keys = keys.reshape(N, key_len, self.heads, self.head_dim)\n",
    "#         queries = query.reshape(N, query_len, self.heads, self.head_dim)\n",
    "        \n",
    "#         values = self.values(values)\n",
    "#         keys = self.keys(keys)\n",
    "#         queries = self.queries(queries)\n",
    "        \n",
    "#         # Attention mechanism\n",
    "#         energy = torch.einsum(\"nqhd,nkhd->nhqk\", [queries, keys])\n",
    "#         attention = torch.softmax(energy / (self.embed_size ** (1/2)), dim=3)\n",
    "        \n",
    "#         out = torch.einsum(\"nhql,nlhd->nqhd\", [attention, values]).reshape(\n",
    "#             N, query_len, self.heads * self.head_dim\n",
    "#         )\n",
    "        \n",
    "#         out = self.fc_out(out)\n",
    "#         return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, embed_size, heads, dropout, forward_expansion):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        self.attention = nn.MultiheadAttention(embed_dim=embed_size, num_heads=heads, dropout=dropout)\n",
    "        self.norm1 = nn.LayerNorm(embed_size)\n",
    "        self.norm2 = nn.LayerNorm(embed_size)\n",
    "        \n",
    "        self.feed_forward = nn.Sequential(\n",
    "            nn.Linear(embed_size, forward_expansion * embed_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(forward_expansion * embed_size, embed_size),\n",
    "        )\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Ensure input is in the correct shape (seq_len, batch_size, embed_dim) for nn.MultiheadAttention\n",
    "        x = x.permute(1, 0, 2)\n",
    "        \n",
    "        # Apply multi-head attention\n",
    "        attention_output, _ = self.attention(x, x, x)\n",
    "        x = x + self.dropout(attention_output)\n",
    "        x = self.norm1(x.permute(1, 0, 2))  # Revert to (batch_size, seq_len, embed_dim) for layer normalization\n",
    "        \n",
    "        # Apply feed-forward network\n",
    "        forward = self.feed_forward(x)\n",
    "        out = self.dropout(self.norm2(forward + x))\n",
    "        \n",
    "        return out\n",
    "    \n",
    "class PositionalEmbedding(nn.Module):\n",
    "    def __init__(self, max_length, embed_size):\n",
    "        super(PositionalEmbedding, self).__init__()\n",
    "        self.embed_size = embed_size\n",
    "\n",
    "        # Create a matrix of shape [max_length, embed_size] representing the positional encoding for max_length positions\n",
    "        pe = torch.zeros(max_length, embed_size)\n",
    "        for pos in range(max_length):\n",
    "            for i in range(0, embed_size, 2):\n",
    "                pe[pos, i] = np.sin(pos / (10000 ** ((2 * i)/embed_size)))\n",
    "                pe[pos, i + 1] = np.cos(pos / (10000 ** ((2 * (i + 1))/embed_size)))\n",
    "                \n",
    "        pe = pe.unsqueeze(0)  # Add batch dimension [1, max_length, embed_size]\n",
    "        self.register_buffer('pe', pe, persistent=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: Tensor of shape [batch_size, seq_len, embed_size]\n",
    "        # Adds positional encoding to each sequence element in the batch\n",
    "        x = x + self.pe[:, :x.size(1)]\n",
    "        return x\n",
    "    \n",
    "class DownsampleBlock(nn.Module):\n",
    "    def __init__(self, input_channels, output_channels, kernel_size, dilation, stride, padding):\n",
    "        super(DownsampleBlock, self).__init__()\n",
    "        self.conv = nn.Conv1d(input_channels, output_channels, kernel_size, \n",
    "                              stride=stride, padding=padding, dilation=dilation)\n",
    "        self.activation = nn.ReLU()\n",
    "        self.norm = nn.BatchNorm1d(output_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: Tensor of shape [batch_size, channels, seq_len]\n",
    "        x = self.conv(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.norm(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EEGSeqTransformer(nn.Module):\n",
    "    def __init__(self, input_channels, seq_length, embed_size, num_transformer_blocks, heads, forward_expansion, dropout, num_classes):\n",
    "        super(EEGSeqTransformer, self).__init__()\n",
    "        \n",
    "        # Initial downsampling and embedding\n",
    "        self.downsample_block = DownsampleBlock(\n",
    "            input_channels=input_channels, \n",
    "            output_channels=embed_size, \n",
    "            kernel_size=3, \n",
    "            dilation=4, \n",
    "            stride=2, \n",
    "            padding=2)\n",
    "        \n",
    "        # self.positional_embedding = PositionalEmbedding(seq_length // 2, embed_size)\n",
    "        \n",
    "        # # Transformer blocks\n",
    "        # self.transformer_blocks = nn.Sequential(\n",
    "        #     *[TransformerBlock(embed_size, heads, dropout, forward_expansion) for _ in range(num_transformer_blocks)]\n",
    "        # )\n",
    "        \n",
    "        # # Classifier head\n",
    "        # self.output_linear = nn.Linear(embed_size, num_classes)\n",
    "        # self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        print(\"Input shape: \", x.shape)\n",
    "        # x: [batch_size, seq_length, input_channels]\n",
    "        x = x.permute(0, 2, 1)  # Conv1D expects [batch_size, channels, length]\n",
    "        x = self.downsample_block(x)\n",
    "        print(\"Downsample output: \", x.shape)\n",
    "\n",
    "        # x = x.permute(0, 2, 1)  # Back to [batch_size, length, channels] for the rest of the network\n",
    "        # x = self.positional_embedding(x)\n",
    "        # print(\"Positional embedding output: \", x.shape)\n",
    "        \n",
    "        # x = self.transformer_blocks(x)\n",
    "        \n",
    "        # # Apply the specified pooling type\n",
    "        # if self.pooling_type == 'average':\n",
    "        #     x = torch.mean(x, dim=1)\n",
    "        # elif self.pooling_type == 'sequence':\n",
    "        #     x = x[:, -1, :]\n",
    "        # elif self.pooling_type == 'learnable_sequence':\n",
    "        #     x = self.seq_pool(x)  # Apply learnable sequence pooling\n",
    "        \n",
    "        # x = self.dropout(x)\n",
    "        # x = self.output_linear(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: torch.Size([2, 10000, 8])\n",
      "y shape: torch.Size([2, 6])\n",
      "Input shape:  torch.Size([2, 10000, 8])\n",
      "Downsample output:  torch.Size([2, 512, 4998])\n",
      "Positional embedding output:  torch.Size([2, 4998, 512])\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 60.00 MiB. GPU 0 has a total capacity of 10.76 GiB of which 9.81 MiB is free. Including non-PyTorch memory, this process has 10.73 GiB memory in use. Of the allocated memory 9.65 GiB is allocated by PyTorch, and 34.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 23\u001b[0m\n\u001b[1;32m     21\u001b[0m X, y \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mto(DEVICE), y\u001b[38;5;241m.\u001b[39mto(DEVICE)\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# y_pred, resnet_out, rnn_out = model(X)\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28mprint\u001b[39m(y_pred\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/kaggle/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/kaggle/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[31], line 36\u001b[0m, in \u001b[0;36mEEGSeqTransformer.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     33\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpositional_embedding(x)\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPositional embedding output: \u001b[39m\u001b[38;5;124m\"\u001b[39m, x\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m---> 36\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransformer_blocks\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# Apply the specified pooling type\u001b[39;00m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooling_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124maverage\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/kaggle/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/kaggle/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/kaggle/lib/python3.11/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/kaggle/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/kaggle/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[23], line 20\u001b[0m, in \u001b[0;36mTransformerBlock.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     17\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Apply multi-head attention\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m attention_output, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattention\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(attention_output)\n\u001b[1;32m     22\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm1(x\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m))  \u001b[38;5;66;03m# Revert to (batch_size, seq_len, embed_dim) for layer normalization\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/kaggle/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/kaggle/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/kaggle/lib/python3.11/site-packages/torch/nn/modules/activation.py:1241\u001b[0m, in \u001b[0;36mMultiheadAttention.forward\u001b[0;34m(self, query, key, value, key_padding_mask, need_weights, attn_mask, average_attn_weights, is_causal)\u001b[0m\n\u001b[1;32m   1227\u001b[0m     attn_output, attn_output_weights \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mmulti_head_attention_forward(\n\u001b[1;32m   1228\u001b[0m         query, key, value, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed_dim, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_heads,\n\u001b[1;32m   1229\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39min_proj_weight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39min_proj_bias,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1238\u001b[0m         average_attn_weights\u001b[38;5;241m=\u001b[39maverage_attn_weights,\n\u001b[1;32m   1239\u001b[0m         is_causal\u001b[38;5;241m=\u001b[39mis_causal)\n\u001b[1;32m   1240\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1241\u001b[0m     attn_output, attn_output_weights \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmulti_head_attention_forward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1242\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_heads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1243\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43min_proj_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43min_proj_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1244\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias_k\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias_v\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_zero_attn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1245\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mout_proj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mout_proj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1246\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1247\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkey_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey_padding_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1248\u001b[0m \u001b[43m        \u001b[49m\u001b[43mneed_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mneed_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1249\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattn_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1250\u001b[0m \u001b[43m        \u001b[49m\u001b[43maverage_attn_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maverage_attn_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1251\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_causal\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1252\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_first \u001b[38;5;129;01mand\u001b[39;00m is_batched:\n\u001b[1;32m   1253\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m attn_output\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m), attn_output_weights\n",
      "File \u001b[0;32m~/miniconda3/envs/kaggle/lib/python3.11/site-packages/torch/nn/functional.py:5336\u001b[0m, in \u001b[0;36mmulti_head_attention_forward\u001b[0;34m(query, key, value, embed_dim_to_check, num_heads, in_proj_weight, in_proj_bias, bias_k, bias_v, add_zero_attn, dropout_p, out_proj_weight, out_proj_bias, training, key_padding_mask, need_weights, attn_mask, use_separate_proj_weight, q_proj_weight, k_proj_weight, v_proj_weight, static_k, static_v, average_attn_weights, is_causal)\u001b[0m\n\u001b[1;32m   5334\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m use_separate_proj_weight:\n\u001b[1;32m   5335\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m in_proj_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse_separate_proj_weight is False but in_proj_weight is None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 5336\u001b[0m     q, k, v \u001b[38;5;241m=\u001b[39m \u001b[43m_in_projection_packed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_proj_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_proj_bias\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5337\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   5338\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m q_proj_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse_separate_proj_weight is True but q_proj_weight is None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/kaggle/lib/python3.11/site-packages/torch/nn/functional.py:4859\u001b[0m, in \u001b[0;36m_in_projection_packed\u001b[0;34m(q, k, v, w, b)\u001b[0m\n\u001b[1;32m   4857\u001b[0m     proj \u001b[38;5;241m=\u001b[39m linear(q, w, b)\n\u001b[1;32m   4858\u001b[0m     \u001b[38;5;66;03m# reshape to 3, E and not E, 3 is deliberate for better memory coalescing and keeping same order as chunk()\u001b[39;00m\n\u001b[0;32m-> 4859\u001b[0m     proj \u001b[38;5;241m=\u001b[39m \u001b[43mproj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munflatten\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mE\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranspose\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontiguous\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4860\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m proj[\u001b[38;5;241m0\u001b[39m], proj[\u001b[38;5;241m1\u001b[39m], proj[\u001b[38;5;241m2\u001b[39m]\n\u001b[1;32m   4861\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   4862\u001b[0m     \u001b[38;5;66;03m# encoder-decoder attention\u001b[39;00m\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 60.00 MiB. GPU 0 has a total capacity of 10.76 GiB of which 9.81 MiB is free. Including non-PyTorch memory, this process has 10.73 GiB memory in use. Of the allocated memory 9.65 GiB is allocated by PyTorch, and 34.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "train_dataset = EEGSeqDataset(train_all, ModelConfig, ALL_EEG_SIGNALS, mode=\"train\")\n",
    "train_loader = DataLoader(train_dataset, drop_last=True, batch_size=2, num_workers=4, pin_memory=True, shuffle=False)\n",
    "\n",
    "model = EEGSeqTransformer(\n",
    "    input_channels=8, \n",
    "    seq_length=10_000, \n",
    "    embed_size=512, \n",
    "    num_transformer_blocks=1, \n",
    "    heads=4, \n",
    "    forward_expansion=4, \n",
    "    dropout=0.1, \n",
    "    num_classes=6\n",
    ")\n",
    "\n",
    "model.to(DEVICE)\n",
    "\n",
    "for batch in train_loader:\n",
    "    X, y = batch\n",
    "    print(f\"X shape: {X.shape}\")\n",
    "    print(f\"y shape: {y.shape}\")\n",
    "    X, y = X.to(DEVICE), y.to(DEVICE)\n",
    "    # y_pred, resnet_out, rnn_out = model(X)\n",
    "    y_pred = model(X)\n",
    "    print(y_pred.shape)\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
